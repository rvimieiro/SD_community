208

Probability Update: Conditioning vs. Cross-Entropy

Adam J. Grove

Joseph Y. Halpern

4 Independence Way
Princeton, N J 08540

Dept. of Computer Science

grove@research.nj.nec.com

halpern@cs.cornell.edu

NEC Research Institute

Cornell University
Ithaca, NY 14853

http:/ /www.cs.cornell.edu/home/halpern

Abstract

Conditioning is the generally agreed-upon
method for updating probability distribu­
tions when one learns that an event is cer­
tainly true. But it has been argued that
we need other rules, in particular the rule
of cross-entropy minimization, to handle up­
dates that involve uncertain information. In
this paper we re-examine such a case: van
Fraassen's Judy Benjamin problem [1987],
which in essence asks how one might update
given the value of a conditional probability.
We argue that-contrary to the suggestions
in the literature-it is possible to use simple
conditionalization in this case, and thereby
obtain answers that agree fully with intu­
ition. This contrasts with proposals such as
cross-entropy, which are easier to apply but
can give unsatisfactory answers. Based on
the lessons from this example, we speculate
on some general philosophical issues concern­
ing probability update.
1

INTRODUCTION

How should one update one's beliefs, represented as a
probability distribution Pr over some space S, when
new evidence is received? The standard Bayesian an­
swer is applicable whenever the new evidence asserts
that some event T � S is true (and furthermore, this
is all that the evidence tells us). In this case we simply
condition on T, leading to the distribution Pr{·IT).
For successful "real-world" applications of probability
theory so far, conditioning has been a mostly sufficient
answer to the problem of update. But many people
have argued that conditioning is not a philosophically
adequate answer (in particular, [Jeffrey 1983]). Once
we try to build a truly intelligent agent interacting in
complex ways with a rich world, conditioning may end
up being practically inadequate. as well.
The problem is that some of the information that we
receive is not of the form "Tis (definitely) true" for

any T. What would one do with a constraint such as
" Pr ( T ) = 2/3" or "the expected value of some ran­
dom variable on S is 2/3". We cannot condition on
this information, since it is not an event in S. Yet
it is clearly useful information. So how should we in­
corporate it? There is in fact a rich literature on the
subject (e.g., see [Bacchus, Grove, Halpern, and Koller
1994; Diaconis and Zabell 1982; Jeffrey 1983; Jaynes
1983; Paris and Vencovska 1992; Uffink 1995]). Most
proposals attempt to find the probability distribution
that satisfies the new information and is in some sense
the "closest" to the original distribution Pr. Certainly
the best known and most studied of these proposals is
to use the rule of minimizing cross-entropy [Kullback
and Leibler 1951] as a way of updating with general
probabilistic information. This rule can also be shown
to generalize Jeffrey's rule [Jeffrey 1983], which in turn
generalizes conditioning.
But is cross-entropy ( CE) really such a good rule? The
traditional justifications of CE are that it satisfies vari­
ous sets of criteria (such as those of [Shore and Johnson
1980]) which, while plausible, are certainly not com­
pelling [Uffink 1995]. Van Fraassen, in a paper entitled
"A problem for relative information [CE] minimizers
in probability kinematics" [1981] instead approached
the question in a different way: he looked at how CE
behaves on a simple specific example. He calls his ex­
ample the Judy Benjamin (JB) problem; in essence
it is just the question of how one should update by a
conditional probability assertion, i.e., "Pr(AIB) = c"
for some events A, B and c E [0, 1].
As we now explain, van Fraassen uncovers what seems
(to us) to be an unintuitive feature of cross-entropy,
although in later papers on the same issue he endorses
CE and a family of other similar rules. Furthermore,
none of his rules agree with most people's strong in­
tuition about the solution to his problem. The pur­
pose of this paper is to give a new analysis, which is
based on simple conditionalization, and is (we argue)
in good agreement with people's expectations. Our
hope is that the example and our analysis will be an
instructive study of the subtleties involved in proba­
bility update, and in particular the dangers involved
in indiscriminately applying supposedly "simple" and

Probability Update: Conditioning vs. Cross-Entropy

"general" rules like CE.
Van Fraassen explains the JB problem as follows
[1987]:
[The story] derives from the movie Private
in which Goldie Hawn, playing
the title character, joins the Army. She and
her platoon, participating in war games on
the side of the "Blue Army", are dropped in
the wilderness, to scout the opposition ("Red
Army"). They are soon lost. Leaving the
movie script now, suppose the area is di­
vided into two halves, Blue and Red territory,
which each territory is divided into Head­
quarters Company area and Second Com­
pany area. They were dropped more or less
at the center, and therefore feel it is equally
likely that they are now located in one area
as in another. This gives us the following
muddy Venn diagram, drawn as a map of the
area:
Benjamin,

1/4

Red2nd

1/4

RedHQ

12
B !Ue
They have some difficulty contacting their
own HQ by radio, but finally succeed and de­
scribe what they can see around them. After
a while, the office at HQ radios: "I can't be
sure where you are. If you are in Red ter­
ritory, the odds are 3:1 that you are in HQ
Company area ..." At this point the radio
gives out.
We must now consider how Judy Benjamin
should adjust her opinions, if she accepts this
radio message as the sole and correct con­
straint to impose. The question on which we
should focus is: what does it do to the proba­
bility that they are in friendly Blue territory?
Does it increase, or decrease, or stay at its
present level of l /2?
The intuitive response is that the message should not
change the a priori probability of 1/2 of being in Blue
territory. More precisely, according to this response,
Judy's posterior probability distribution should place
probability 1/4 on being at each of the two quad­
rants in the Blue territory, probability 3/8 on being
in the Headquarters Company area of Red territory,
and probability 1/8 on being in the Second Company
area of Red territory. Van Fraassen [1987] notes that
his many informal surveys of seminars and conference
audiences find that people overwhelmingly give this
answer.

209

However, this intuitive answer is inconsistent with
cross-entropy. In fact, it can be shown that cross­
entropy has the rather peculiar property that if HQ
had said "If you are in Red territory, the odds are
o: : 1 that you are in HQ company area ... ", then for
all o: f: 1, the posterior probability of being in Blue
territory (according to the distribution that minimizes
cross-entropy and satisfies this constraint) would be
greater than 1/2; it would stay at 1/2 only if o: = 1.
This seems (to us, at least) highly counterintuitive.
Why should Judy come to believe she is more likely to
be in Blue territory, almost no matter what the mes­
sage says about o:? For example, what if Judy knew
in advance that she would receive such a message for
some a f: 1, and simply did not know the value of
o:. Should she then increase the probability of being
in Blue territory even before hearing the message? As
van Fraassen [1981] says, as part of an extended dis­
cussion of this phenomenon:
It is hard not to speculate that the dangerous
implications of being in the enemy's head­
quarters area are causing Judy Benjamin to
indulge in wishful thinking... 1
However, as van Fraassen points out (crediting Peter
Williams for the observation), there also seems to be a
problem with the intuitive response. Presumably there
is nothing special about hearing the odds of being in
Red territory are 3:1. The posterior probability of be­
ing in Blue territory should be 1/2 no matter what
the odds are, if we really believe that this information
is irrelevant to the probability of being in Blue terri­
tory. But if o: = 0 then, to quote van Fraassen [1987],
"he would have told her, in effect, 'You are not in Red
Second Company area'". Assuming that this is indeed
equivalent, it seems that Judy could have used simple
conditionalization, with the result that her posterior
probability of being in Blue territory would be 2/3,
not 1/2.

In [van Fraassen 1987; van Fraassen, Hughes, and
Harman 1986], van Fraassen and his colleagues for­
mulate various principles that they argue an update
rule should satisfy. Their first principle is motivated
by the observation above and simply says that, when
conditioning seems applicable, the answer should be
that obtained by conditioning. To state this more pre­
cisely, let q = o:/(l+o:) be the probability (rather than
the odds) of being in red HQ company area given that
Judy is in Red territory. In the case of the JB problem,
the first principle becomes:
If q = 1 the prior is transformed by simple
conditionalization on the event "Red HQ area
or Blue territory"; if q = 0 by simple condi­
tionalization on "Red 2nd company area or
Blue territory".

1We remark that this behavior of CE has also been
cussed and criticized
1987].

in

a

dis­

more general setting [Seidenfeld

210

Grove and Halpern

This first principle already eliminates the intuitive
rule, i.e., the rule that the posterior probability should
stay at 1/2 no matter what q is. (Note also that we
cannot make the rule consistent with this principle by
trea.ting q = 0 and q = 1 as special cases, unless we are
prepared to accept a rule that is discontinuous in q.)
For van Fraassen, this is apparently a decisive refuta­
tion of the intuitive rule, which he thus says is flawed
[van Fraassen 1987].

This does not deny the usefulness of rules like CE.
There will be some (perhaps large) family of situations
in which CE is indeed appropriate, and we would like
to better understand what this family is and how to
recognize it. But if CE (or any other rule) is blindly
applied whenever the information is of the appropriate
syntactic form, we should not be surprised if the results
are often unexpected and unhelpful.

However, in this paper we give a new2 and simple anal­
ysis of the JB problem. We believe that our solution is
well-motivated, and it agrees completely with the in­
tuitive answer. It thus also does not exhibit the coun­
terintuitive behavior of CE.

2

Our basic idea is simply to use conditioning, but to do
so in a larger space where it makes sense (i.e., where
the information we receive is an event). Of course,
people have always realized that this option is avail­
able. It is perhaps not popular because it appears to
pose certain serious philosophical and practical prob­
lems as a general approach. In particular, which lar ger
space do we use? There may be many equally natural
possibilities, leading to different answers, so the rule
will be indeterminate. Also possible is that all ex­
tended spaces we can think of seem equally unnatural
and contrived; again, we will be stuck. In addition,
there is the practical concern that a rich enough space
might be vastly larger and more complicated to work
in than the original.
Against this, a rule like cross-entropy seems extremely
attractive. It provides a single general recipe which
can be mechanically applied to a huge space of up­
dates. Even families of rules, such as van Fraassen
proposes, are not so bad: aft er one has chosen a rule
(usually by selecting a single real-valued parameter
[Uffink 1995]), the rest is again mechanical, general,
and determinate. Furthermore, all these rules work in
the original spaceS, without requiring expansion, and
so may be more practical in a computational sense.
all we do in this paper is analyze one particular
problem, we must be careful in making general state­
ments on the basis of our results. Nevertheless, they
do seem to support the claim that sometimes, the only
"right" way to update, especially in an incompletely
specified situation, is to think very carefully about the
real nature and origin of the information we receive,
and then (try to) do whatever is necessary to find a
suitable larger space in which we can condition. If
this doesn't lead to conclusive results, perhaps this is
because we do not understand the information well
enough to update with it. However much we might
wish for one, a genemlly satisfactory mechanical rule
such as cross-entropy, which saves us all this question­
ing and work, probably does not exist.
Since

2 Although

we are aware of no published analysis simi­

lar to our own, we have learned that Seidenfeld has earlier
presented a closely related analysis in several lectures [Sei­
denfeld 1997].

CONDITIONING

In this section, we present our alternative analysis of
the JB problem. In the following, let B1, B2, R�, R2
denote the events that Judy is in, respectively, Blue
HQ, Blue Second Company, Red HQ, and Red Second
Company areas. Let B = B1 V B2 and R = R1 V R2.
The message HQ sent, "If you are in Red territory,
the odds are 3:1 that you are in HQ Company area",
is equivalent to asserting that the conditional proba­
bility of R1 given R is true is 3/4. In general, let M(q)
be the similar message asserting that this probability
is q E [0, lj for some q not necessarily = 3/4 (i.e., the
announced odds are q/(1 - q) : 1 instead of 3 : 1).
We use Prjrior to denote Judy's prior beliefs (i.e., be­
fore the message is received) and Prj to denote her
posterior distribution after receiving M(q).
The key step is to re-examine the problem from the be­
ginning, and ask ourselves how Judy should treat HQ's
message. Note t hat Van Ftaassen explicitly assumes,
in his statement of the problem, that HQ's statement
should be treated as a constraint on Judy's beliefs.
Thus, he interprets it as an imperative: "Make your
beliefs be such that this is true!" This interpretation
of probabilistic informat ion as constraints is a common
one (especially in the context of CE), but is difficult
to justify [Uffi.nk 1996]. Van Fraassen is, of course,
quite aware of the philosophical issues raised by his
interpretation; see [van Fraassen 1980].

But is the interpretation that HQ's stat ement should
be regarded as a constraint on Judy's beliefs the only
possible one? Note that, as the story is presented, it
certainly sounds as though HQ was trying to give Judy
some true and useful information. But, at the time
M is sent, the statement that Prjriar(RtJR) 3/4 is
clearly not true of Judy's beliefs. Thus, if we wish to
interpret M as referring directly to Judy's beliefs, we
will be unable to regard it as a factual assertion in any
straightforward sense.
=

But suppose we instead view M(q) as being a cor­
rect statement regarding HQ 's beliefs; i.e., as asserting
PrnQ(RtJR) = q where PrnQ denotes HQ's distribu­
tion over where Judy might be. This certainly seems
to be a reasonable interpretation in light of the story.
How should Judy react to it? Unfortunately, the story
does not give us enough information to be able to pro­
vide a definite answer to this question. Judy's correct
reaction to the message depends on aspects of the situ­
ation that were not included in the problem statem ent.

Probability Update: Conditioning vs. Cross-Entropy

The followi n g is a partial list of things that could be
relevant: W hat does Judy know about HQ's beliefs
and knowledge? How did HQ expect Judy to react to
the message, and what did Judy know about these ex­
pectations? What messages could HQ have sent? For
instance , might HQ have sent M(q) for some other
value of q if it were appropriate, or would it have said
something else entirely if q # 3/4? Does Judy believe
that HQ even has th e option of sen ding messages that
are not of the form M(q); if so, what mess ag es?3 And
so o n .
We now give one particular analysis,
filling in such missing details in what

which follows by
we feel is a plau­
sible way. As we said, we assume that M(3/4) is a fac­
tual statement about HQ's beliefs. We further assume
that, no matter what HQ actually knows, its message

would always have been simply M(q) for the appropri­
a te value of q. Thus, Judy can read nothing more into
M(q) other than to regard it as a true statement about
HQ's beliefs. As noted in the previous paragraph , even
to get this far relies on several strong assumptions .
Once Judy he ars M(q), it seems n at ural to want to
The problem is t hat , as yet, we
condition on it.
have not introduced a space in which M(q) is an
ev ent. Of course, there are many possible such spaces.
To construct an appropriate one, we must consider
how Jud y models HQ ' s beli efs , and what she believes
about these beliefs. Again, here we make perhaps
the simplest possible choice. We suppose that Judy
models HQ's beliefs as a distribution ove r the four

R1, R2, B1, B2.

Pr��c be the distribution on {R11 R2, B11 B2} such that Pr��c (R1) = a,
p a, ,c
P rHQa ,b , c (R2 ) = b, pr a,b,c
HQ (B1 ) = c, r HbQ (B2 ) =
1 - a - b - c. Thus the set of all possible distri­

quadrants

butions

HQ

Let

might have, given our assumptions, is

PHQ = {Pr��cla,b,c2:0, a+b+c�l}. In the
following , we view Pr nQ (R 1 I R), Pr HQ( RI) , Pr HQ(B ) ,
and so on, as random variables on the space PHQ·
Thus, for example, "Pr nQ(R1IR) < q" denotes the
event {Pr��c I Pr';;� c (R1IR) < q}.
Again, we stress that we are not forced to use P HQ·
Judy might actually have a richer model of HQ's be­
liefs (e.g., she might think that HQ makes finer geo­
graphical distinctions than simply the four quadrants)
or a coarser model (e.g., J udy might take as the space
of possibilities the possible values of PrnQ(RliR), and

ab out HQ' s

211

bel iefs .

Since Judy d oes not know what HQ actually believes,
her beliefs will be a distribution over distributions,
i.e., a dis tribu tion over PnQ·
Which distribution?
Again, we have many choices, but a na tural one is
to suppose that before Judy hears the message, she
considers a uniform distribution over ( a, b, c) t uples .
Formally, we consider the distribution function defined

by Prj7�q{Pr�8c I a::; A,b::; B,c::; C}) =ABC,
so that the density function is j ust 1. We also use the
notation Prj HQ to denote Judy's beliefs about HQ's
/
beliefs after receiving M(q).
It might be thought that, having decided to take PH Q
as the set of possible beliefs that HQ could have and
given the (implicit) assumption that Ju d y is initially
completely ignorant of HQ's beliefs, the prior density
on P HQ is determined complet ely. Unfortunately, this
is not the case. Ther e is no unique "uniform distribu­
tion" on PnQ· Uniformity depends on how we choose
to parameterize the space. We have chosen to param­
eterize the elements of this space by a triple (a, b, c)
denoting the probabilities of R1, R2, and Bt, respec­

tively. However, we could have chosen to characterize
an element of the space by a triple (a', b', c') denot­
ing the square of the probabilities of R1, R2, and B1,
re spec tivel y. Or perhaps more reasonably, we could
have chosen to characterize an element by a triple
( a11, b11, c") denoting the probability of R, the probabil­
ity of R1 given R, and the probability of B1 given B.
A uniform distribution with respect to either of these
parameterizations would be far from uniform with re­
spect to the parameterization we have chosen, and vice
versa.4 This is, of course, just an instan ce of the well­
known impossibility of defining a unique notion of 'l.mi­
form in a continuous sp ace [H ow son and U rbach 1989].
Since M(q) is an event in the new space 'PHQ, Judy
should be able to condition on it. One might object
that, since M(q) is an event of measure 0, condition­
ing is not well defined. This is t rue, but there are
t w o (closely related) ways of dealing with this prob­
lem. The more elementary and intuitive approach is
based on the observation that, in practice, HQ w ill
n ot (in general) be able to announce its value for
Pr nQ(RI IR) exactly, since this could require HQ to
announce an infinite-precision real number. It seems
more reasonable to regard the announced value of q
as being rounded or approximated in some fashion. In

not reason about the rest of HQ's distribution). How­
ever, given the description of the story, PHQ seems to
be the most natural space for Judy to model her beliefs

particular, we might suppose that M(q) really means
PtHQ(RIIR) E [q - E, q + e) for some small val ue
E > 0. This event has non-zero probability according

first

4We note, however, that the uniform densities with
respect to all 4 possible parameterizations that involv­

3To see the possible relevance of this, note that if there
are other possible messages, then the very fact that HQ's
message was not one of these others could be impor­

tant information in and of itself: Judy might reason that

M(3/4)

must have been the most important fact HQ pos­

sessed. On the other hand, since the radio died before the
message was completed, such inferences depend heavily on
the protocol Judy expects HQ to follow .

to Prj7�'Q,

and

so

conditioning is unproblematic.

ing choosing 3 out of the 4 probabilities from PrnQ(Rt),
Pr nQ(R2 ) , PrnQ(Bt), PrnQ(Bz ) do lead to the same dis­
tribution over PnQ. and so o ur decision to use the first
three of these probabilities does not affect

our

analysis.

Grove and Halpern

212

The second approach directly invokes the standard def­
inition of conditioning on (the value of) a random
variable. We briefly review the details here. Sup­
pose we have two random variables X and Y.
If

Pr(X

=

a)

>

Pr(Y

0, then

defined as Pr(Y = b (l X =
would expect. If Pr(X = a )

bJX

) is just
a) as we
0, then we take the

=

a)/ Pr(X

=

=

a

=

straightforward analogue of this definition using den­

sity functions. If fxy(x, y) is the joint density function
for X and Y, and fx ( x ) is the density for X alone,
then the conditional density of Y given X is given
by Jy,x(yJx) = fxy(x,y)ffx(x). Using the density
function we can then compute the probability by inte­
grating as usual. Further details can be found in any
standard text on probability (for instance [Papoulis

1984]).

To use this approach, we need to identify a random
variable X and value b such that M(q) corresponds
to the event X = b. The choice of random variable

is crucial; we can easily have two random variables X
and X' such that X == b and X' = b are the same
event, yet conditioning on X =band X'= b leads to
different results, since X and X' have different density
functions. In our case there is an obvious choice of
random variable, given our description of the situation:

PrHq(B) < p and Prn q ( R1 J R ) < q are independent!
This is of course extremely intuitive: It seems reason"
able that HQ's beliefs about the probability of Judy
being in Blue Territory should be independent of HQ's

beliefs of her being in Red HQ area, given that she is
in Red territory.

Using this, it is trivial to prove the following proposi"
tion, which holds whether we choose to use any par"
ticular t: > 0, or if we use the standard definition of
conditioning on the value of a random variable (which,
as we have said, essentially corresponds to considering
the limit as t-> 0). In this proposition, pr8(p) denotes
the density function for the random variable P r m�(B);
i.e., pr B(P) = dPrJ/HQ(PraQ{B) < p)jdp. Similarly,
pr B (P I M(q))

pr8(p)

=

6p- 6p2,

(1),

for the next result.)

Proposition 2.1

PrnQ(B) = p

< PI M( q))/dp .
it immediately follows that
although we do not need this fact

= dPrJ/HQ(PrnQ( B)

(Note that from

and

:

In (P

M(q)

prB(P)

HQ, Prjj�rQ),

the events

are independent. Formally,

=

pr8(pJM(q)).

is easy to see that the two approaches give us the same

With this result, we are very close to showing that
Judy's beliefs regarding the probability of her be­
ing in Blue territory don't change as a result of the

and then considering the limit as the interval width

regarding where Judy is . The posterior distribution

PrnQ(RtiR).

With this choice of random variable, it

answer; the use of the density function corresponds to
considering a small interval around PrnQ(RtiR} = q,
tends to 0.

message.

PnQ,

Pr';;�c(RtiR) = af( a +b,)
Prjj�'Q(PrnQ(RtiR)

<

we have

q)

1-a.-b 1 dcdbda
r t-a.
1c=O
1qa=O h=a(l-q)
11 rl a 1-a-b1dcdhda
a.=O J b=O 1c=O
1-a-b dcdhd
6 r
a
1
Ja=O b=� c=O
q

=

11-a 1
q

=

==

=

1:0 1:�;1_•1 (1- a- b)dbda
6 lq (q- a)2 da

6

q

q

a=O

< p)

=

(3- 2p)p2,

Prjj�Q(Prnq(R1IR) < qAPr nQ(B)

< p)

and

is a distribution on

j/HQ(·) Prj/;Q(·I M(q)) is still a distribution on
=

Pnq.

As a result of conditioning, Judy revises her
beliefs about HQ's beliefs. But to determine Judy's
beliefs about where she is we need a distribution on
{Rt, R2, Bt, B2 }. The question is how Judy's beliefs
about HQ's beliefs about where she is are related to
her beliefs about where she is. Notice that there is
no necessary relation. After all, for all we know, Judy
might think that HQ has no reliable information, and
thus decide to ignore HQ's statement when forming her
opinion regarding where she is. But, in keeping with
the spirit of the story, we assume that Judy trusts HQ,
and thus forms her beliefs by taking expectations over
her beliefs about HQ's beliefs. For example, if Judy
was certain that HQ was certain that she was in Blue
territory, then she would ascribe probability 1 to being
in Blue territory. More generally, Judy weights HQ's
beliefs according to her beliefs about how likely it is
that HQ holds those beliefs. We formalize this trust
assumption as follows:

22
q

Two other results, which are derived in a similar fash­
ion, also tmn out to be useful:

Prj/;Q(PrnQ(B)

Prj�Q

that is, on Judy's beliefs about HQ's beliefs

Pr

Before computing the result of conditioning on M(q)
(under either approach), it t urns out to be use­
ful to do some more general computations.
Since

Notice that

(1)

== q( 3-2p)p2 .

The point here is not just the values themselves, but,
more importantly, that the final distribution function
is the product of the first two. That is, the events

(Trust)

At any point in time, Judy's beliefs about
event in the space {R1, R2, B1. B2} are
formed by taking expectations of HQ's probability
of the same event, according to Judy's distribu­
any

tion over HQ's possible beliefs. Formally, we have:

Pr �(E)
=

f
Pr�; HQ(Pr';J8c) Pr';J8c(E) dabc
lPr�·�cEPHQ

213

Pr obability Update: Conditioning vs. Cross-Entropy

=
(

:0 prk(e) e de)
1{prior}
probability

U [0, 1].(In the second line, which
for t E
theory, pr}.;(e)
follows from standard
is the density function of the random variable

Pr�8c(E);
e)jde.)

1;

i.e., pr (e)

= dPr�/HQ(Pr�8c(E)

<

Note that when we apply this rule before Judy receives
the message, so that t

prior, we have

=

Pr�;'-ior(B1) =

Pr�rior(B2) = Prrio r(Rl) = Prrior(R2) =

1/4, which

is consistent with our earlier assumption that Judy
started with a uniform prior on { Bt, B2, Rt, R2}.

M(q).
q

The desired result now follows quite readily using the
The re­
trust principle after Judy has received
sult is that, no matter what the value of is, her beliefs
regarding being in Blue territory remain unchanged,
exactly in accord with most people's strong intuitions.

Theorem 2.2:

Proof:

Pr'j(B)

=

1/2

for all

q

E

[0, 1].

{
Prj HQ(Pr';[8c) Pr';j�c(B) dabc
}p,�·Q•EPHQ /

Prj(B)
=

i:/rB(PIM(q))pdp
1:0 pr8(p) pdp
1:0 (6p- 6p2)pdp

=

1/2.

(1))

I

Note that this theorem applies even if q = 1. Van
Fraassen would interpret the message M(l) as mean­
ing that Judy is definitely not in R2. We interpret
this it as PrnQ(R1IR) E [1 - t:, 1] for some (arbitrar­
ily) small and unspecified € > 0. Although the two
interpretations seem close (after all, they differ by at
most t: in the probability that they assign to R1 and
R2), they are not equivalent. As Theorem 2.2 shows,
this is a significant difference. It is the claimed equiv­
alence of the two interpretations that was behind van
Fraassen's first principle, and hence his rejection of the
intuitive answer that P r (B ) = 1/2. This equivalence
may be correct under van Fraassen's constraint based
interpretation of M, but it is not inevitable under our
is indeed a factual
alternative reading, in which
announcement (but about HQ's beliefs, not Judy's).

j

M

3

DIS CUSSION

belief as
characterized by

{Rt, R2,B1, B2}.

to
a

M(q),

4.

q

M(q) is interpreted as meaning that Pr nQ( ) E
[q �, + €], so that we can condition on this

- q

event. (However, our result holds no matter what
t: is. Thu s we can regard t: as an arbitrarily small
and unknown nonzero quantity.)
5. Judy's distribution on {Bt, B2, Rt, R2} was de­
rived by taking the expectation of her beliefs re­
garding HQ's beliefs.
Although these assumptions seem to us quite reason­
able, they are clearly not the only assumptions that
could have been made. It is certainly worth trying to
understand to what extent our results depend on these
assumptions, and in particular whether they can be ex­
tended to provide more general statements of how to
update by probabilistic information.
considered by van Fraassen and his colleagues? As we
said in the introduction, such rules may be useful in
certain cases, but we believe it is an important research
question to understand and explain precisely when.
We do not, in particular, find CE to give particularly
plausible results in the JB problem. But how could
this have been predicted in advance?
The JB problem shows that we need more than just an
axiomatic justification for the use of CE (or any other
method of update). An alternative to the use of a rule
is to do what we have done for the JB problem in this
paper: that is, to try to "complete the picture" in as
much detail as possible, so that ultimately all we need
to do is condition. In practice, this may be unneces­
sarily complex and shortcuts (such as CE) might exist.
However, it would be useful to understand better the
assumptions that are necessary for their use to cor­
respond to conditioning. In any case we believe that
some of the issues we addressed cannot be avoided: it
will never be sensible to blindly apply a rule, like CE,
to all information that merely "seems" probabilistic or
can be reformulated as such. Rather, one must always
think carefully about precisely what the information
means.

Acknowledgments

It is worth reviewing the assumptions that were nec­
essary for us to prove Theorem 2.2. We assumed:
1. HQ's

3. The only messages that HQ could send were those
and the one that HQ did send
of the form
was the one that correctly reflected HQ's beliefs.

W here does this leave CE and all the other methods

(by Theorem 2 .2)

(from

2. Judy's beliefs regarding HQ's beliefs were
characterized by the uniform distribution on
HQ's beliefs, when parameterized by the tuple
(PrsQ(RI), PrsQ(R2), PrnQ(Bt ) ) .

where Judy is can be
distribution on the space

We thank Teddy Seidenfeld and Bas van Fraa.ssen for
useful comments. The second author's work was sup­
ported in part by the NSF, under grant IRl-96-25901,
and the Air Force Office of Scientific Research ( AFSC),
under grant F94620-96-1-0323.

214

Grove and Halpern

References

Bacchus, F., A. J. Grove, J. Y. Halpern,
and D. Koller (1994). Generating new be­
liefs from old. In Proc. Tenth Annual Confer­
ence on Uncertainty Artificial Intelligence,

pp.

37-45. Available by anonymous ftp from lo­
gos.uwaterloo.cajpub/bacchus or via WWW at
http: / /logos.uwaterloo.ca.
Diaconis, P. and S. L. Zabell (1982). Updating sub­
jective probability. Journal of the American Sta­
tistical Society 77 ( 38 0), 822-830.
Howson, C. and P. Urbach (1989). Scientific Rea­
soning: The Bayesian Approach. La Salle, Illi­
nois: Open Court.
Jaynes, E . T. (1983). Papers on Probability, Statis­
tics, and Statistical Physics. Dordrecht, Nether­
lands: Riedel. Edited by R. Rosenkrantz.
Jeffrey, R. C. (198 3). The Logic of Decision.
Chicago: University of Chicago Press. First Edi­
tion Published 1965.
Kullback, S. and R. A. Leibler (1951). On infor­
mation and sufficiency. Annals of Mathematical
Statistics 22, 76-86.
A. (1984). Probability, Random Variables,
and Stochastic Processes. Chicago: McGraw­

Papoulis,

Hill.
Paris, J. B. and A. Vencovska (1992). A method
for updating justifying minimum cross entropy.
International Journal of Approximate Reason­
ing 7, 1-18.

Seidenfeld, T. (1987). Entropy and uncertainty. In
I. B. MacNeill and G. J. Umphrey (Eds.), Foun­
dations of Statistical Inference, pp. 259-287. Rei­
del. An earlier version appeared in Philosophy of
Science, vol. 53, pp. 467-491.
Seidenfeld, T. (1997). Personal communication.
Shore, J. E. and R. W. Johnson (198 0). Axiomatic
derivation of the principle of maximum entropy

and the principle of minimimum cross-entropy.
IEEE Transactions on Information Theory IT-

26(1), 26-37.
Uffink, J. (1995). Can the maximum entropy prin­
ciple be explained as a consistency requirement?
Stud. Hist. Phil. Mod. Phys. 26(3), 223-261.
Uffink, J. (1996). The constraint rule of the max­
imum entropy principle. Stud. Hist. Phil. Mod.
Phys. 27(1), 47-79.
van Fraassen, B. C. (1980). Rational belief and prob­
ability kinematics.

Philosophy of Science 41,

165-187.

van Fraassen, B. C. (1981). A problem for relative
information mini mizers . British Journal for the
Philosophy of Science 32, 375-379.
van Fraassen, B. C. (1987). Symmetries of personal
probability kinematics. In N. Rescher (Ed.), Sci­
entific Enquiry in Philsophical Perspective, pp.
183-223. Lanham, Maryland: University Press
of America.

van Fraassen, B. C., R. I. G. Hughes, and G. Har­
man (1986). A problem for relative information
minimizers in probability kinematics, continued.

British Journal for the Philosophy of Science 37,

453-475.

