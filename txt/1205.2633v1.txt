UAI 2009

KUMAR & KOLLER

313

MAP Estimation of Semi-Metric MRFs via Hierarchical Graph Cuts

M. Pawan Kumar
Computer Science Department
Stanford University

Daphne Koller
Computer Science Department
Stanford University

pawan@cs.stanford.edu

koller@cs.stanford.edu

Abstract
We consider the task of obtaining the maximum
a posteriori estimate of discrete pairwise random
fields with arbitrary unary potentials and semimetric pairwise potentials. For this problem,
we propose an accurate hierarchical move making strategy where each move is computed efficiently by solving an st-MINCUT problem. Unlike previous move making approaches, e.g. the
widely used α-expansion algorithm, our method
obtains the guarantees of the standard linear programming ( LP) relaxation for the important special case of metric labeling. Unlike the existing LP relaxation solvers, e.g. interior-point algorithms or tree-reweighted message passing, our
method is significantly faster as it uses only the
efficient st-MINCUT algorithm in its design. Using both synthetic and real data experiments,
we show that our technique outperforms several
commonly used algorithms.

1 Introduction
Markov random fields ( MRFs) offer an expressive and intuitive framework for several important problems in artificial
intelligence and machine learning. Given a set of random
variables along with a neighborhood relationship defined
over them, an MRF offers a concise representation of the
probability of each labeling (i.e. a particular assignment of
labels to the variables) in terms of potentials defined over
the cliques of random variables. Due to the central role of
MRFs in various applications, algorithms that perform efficient and accurate inference on them are highly desirable.
One important and well-studied class of inference, called
maximum a posteriori (MAP) estimation, seeks the labeling
with the maximum probability.
We consider a special case of MAP estimation, known as
semi-metric labeling [4], where (i) the size of the maximal
clique is 2 (a pairwise MRF); and (ii) the pairwise potentials
are defined by a semi-metric distance function over labels.
Although these may seem like very restrictive assumptions,
several problems in computer vision and related areas can

be expressed using semi-metric labeling, from low level
tasks like image denoising and stereo reconstruction [30]
to high level tasks like pose estimation [9] and scene segmentation [27]. Hence, the semi-metric labeling problem
merits special attention.
We describe a novel algorithm for semi-metric labeling
which approximates a given semi-metric distance function
using a mixture of r-hierarchically well-separated tree (rHST) metrics [1]. The r- HST metrics form an amenable
class of distance functions which admit elegant divide-andconquer approaches for several problems [1, 8]. In our
case, they not only result in easier-to-solve instances of
MAP estimation, they also provide an accurate approximation of the original problem. Given a mixture of r-HSTs,
we reformulate semi-metric labeling using a set of r-HST
metric labeling problems (i.e. MAP estimation for r-HST
metric pairwise potentials), where each problem is specified by one component of the mixture. We show how each
resulting r-HST metric labeling problem can be solved accurately using an iterative procedure that only employs the
efficient st-MINCUT algorithm [3] in its design. Unlike previous st-MINCUT based approaches, our method provides
the best known approximation bound for the important special case of metric labeling (i.e. when the pairwise potentials are defined by a metric distance function). In practice, our technique outperforms several state of the art algorithms on both synthetic and real data experiments.

2 Related Work
The most commonly used algorithms for semi-metric labeling can be broadly divided into two categories: message
passing and move making. Message passing algorithms attempt to minimize approximations of the free energy associated with the MRF [10, 14, 15, 29, 34, 36]. Amongst
them, the algorithms of [14, 15, 34] are closely related
to the linear programming ( LP) relaxation of semi-metric
labeling [7, 17, 25, 33]. Although message passing algorithms provide accurate MAP estimates, they can be computationally expensive in certain cases [30].
Move making approaches refer to a large class of iterative algorithms which move from one labeling to the other

314

KUMAR & KOLLER

while ensuring that the probability of the labeling never
decreases. The move space, i.e. the search space for the
new labeling, is restricted to a subspace of the original
search space that can be explored efficiently. Typically, the
move space is explored using the st-MINCUT algorithm,
e.g. in αβ-swap [4] and α-expansion [5]. However, recently researchers have also used more sophisticated algorithms such as quadratic pseudo-boolean optimization [2]
(e.g. see [13, 21, 35]). Move making algorithms are generally preferred in applications which involve a large number
of random variables, e.g. on image-sized MRFs in computer
vision, due to their efficiency.

3 Preliminaries
Consider an MRF defined over a set of random variables
V = {v1 , v2 , · · · , vN }, each of which can take a value from
a discrete label set L = {l1 , l2 , · · · , lH }. Furthermore, let
E define the neighborhood such that va and vb are neighbors if and only if (va , vb ) ∈ E. A labeling of the MRF is
a function f : {1, 2, · · · , N } → {1, 2, · · · , H} such that
variable va takes label lf (a) . Associated with each labeling
is its probability Pr(f |θ) = exp(−Q(f ; θ))/Z, where Z
is the partition function and Q(·; θ) is the Gibbs energy:
Q(f ; θ) =

X

va ∈V

θa (f (a))+

X

θab (f (a), f (b)). (1)

(va ,vb )∈E

Here θa (f (a)) and θab (f (a), f (b)) denote unary and pairwise potentials respectively. For semi-metric labeling,
the pairwise potentials are of the form θab (f (a), f (b)) =
wab d(f (a), f (b)), where wab ≥ 0 and d(·, ·) is a semimetric distance function. Recall that d(·, ·) is semi-metric
if and only if: (i) d(i, i) = 0, ∀i; and (ii) d(i, j) =
d(j, i) > 0, ∀i 6= j. Examples of commonly used semimetric distance measures include the truncated linear function, d(i, j) = min{|i − j|, M } where the truncation factor M ≥ 0, the truncated quadratic function, d(i, j) =
min{(i − j)2 , M }, and the uniform metric (a special case
of truncated linear/quadratic function with M = 1). Within
this setting, the problem of MAP estimation is formally
specified as: f ∗ = arg minf Q(f ; θ).

4 The r-HST Metric Labeling Problem
As mentioned earlier, there are two key ingredients to our
MAP estimation algorithm: (i) approximating a given semimetric by a mixture of r-HST metrics; and (ii) solving
each resulting r-HST metric labeling problem. We begin
by defining r-HST metrics and designing an efficient move
making algorithm for the corresponding labeling problem.
The next section describes a simple yet accurate procedure
for approximating semi-metrics.
4.1 The r-HST Metric
An r-HST metric [1] dt (·, ·) is specified by a rooted tree
whose edge lengths are non-negative and satisfy the following properties: (i) the edge lengths from any node to
all of its children are the same; and (ii) the edge lengths

UAI 2009

along any path from the root to a leaf decrease by a factor of at least r > 1. Given such a tree, known as r-HST,
the distance dt (i, j) is the sum of the edge lengths on the
unique path between them. Note that, as the name suggests,
an r-HST specifies a metric distance. In other words, it is
a semi-metric distance function that satisfies the triangular inequality: d(i, j) − d(j, k) ≤ d(i, k), ∀i, j, k. In this
paper, we consider only those r-HSTs where all the labels
in the set L are at the leaves of the r-HST. As observed
in several earlier works [1, 6, 8], r-HSTs satisfying this assumption are sufficient to provide an accurate approximation of a given semi-metric distance function. Fig. 1 shows
an example r-HST over H = 6 labels with r = 2.

Figure 1: An example r-HST metric. The distances between

nodes are specified by path lengths, e.g. dt (1, 2) = 4, dt (4, 5) =
2 and dt (1, 4) = 11.

4.2 The Move Making Algorithm
For a given r-HST metric dt (·, ·), we define an MRF parameterized by θt with arbitrary unary potentials θat (i) and
t
pairwise potentials of the form θab
(i, j) = wab dt (i, j). We
show how to obtain an accurate MAP estimate for the parameter θt , known as the r-HST metric labeling problem,
using a novel approach based on the st-MINCUT algorithm.
Our approach is a divide-and-conquer method consisting
of two steps: (i) replace the original problem by a series of
subproblems that are easier to solve; and (ii) combine the
solutions of the subproblems to obtain an accurate solution
of the original problem. Each of the subproblems is specified by a node in the given r-HST, and their solutions are
combined using the standard α-expansion algorithm [5].
In more detail, consider a node p of the given r-HST. We
say that a label li belongs to the node p (denoted by i ∈ p) if
and only if it is a leaf node in the subtree rooted at p. Let Lp
denote the set of labels that belong to p, i.e. Lp = {i|i ∈ p}.
The subproblem defined at node p is to find the labeling f p
of the random variables V that minimizes the energy under
the constraint that each variable va ∈ V takes a label from
the set Lp . Note that if p is the root node of the given r-HST,
then the subproblem is the same as the original problem.
On the other hand, if p is the leaf node, then the solution to
the subproblem is trivial, i.e. f p (a) = p for all va ∈ V. In
fact, as one moves from the root towards the leaves of the
r-HST, the label set of the subproblem keeps reducing in
size thereby making the subproblems easier to solve. This
observation suggests the following hierarchical approach:
solve the easier subproblems at level m + 1 of the r-HST
and use their labelings to solve the subproblem defined by
their parent nodes at level m.

UAI 2009

KUMAR & KOLLER

It remains to be seen how exactly a subproblem at node p
can benefit from the labelings of its child nodes. To answer this we consider the stage of the above hierarchical
approach where we have to solve the subproblem defined
at node p, having already obtained the labelings of the subproblems associated with the children of p. We denote
these labelings by f1 , · · · , fC where C is the number of
child nodes of p. To find the labeling f p for the subproblem at p efficiently, we restrict the label of each variable
va to be one of the C labels specified by the child nodes.
In other words, f p (a) = fi (a) where i ∈ {1, · · · , C} is
the index of the child node from which va takes its label.
Note that different variables can take labels from different
child nodes. In order to find the indices of the child nodes
for all variables, we define a parameter θp such that the
corresponding unary and pairwise potentials are given by
p
θap (i) = θat (fi (a)), θab
(i, j) = wab dt (fi (a), fj (b)),
∀(va , vb ) ∈ E, i, j ∈ {1, · · · , C}.
(2)

We obtain an approximate MAP estimate f ′ for the parameter θp using α-expansion (see [18] for details). Using the
properties of r-HST metrics, it follows that each move of
α-expansion results in a submodular problem that can be
solved exactly. The labeling f ′ provides the required indices of the child nodes to obtain the labeling f p as
f p (a) = fi (a) where i = f ′ (a), ∀va ∈ V.
(3)
The hierarchical approach for solving the r-HST metric
labeling problem terminates when the subproblem corresponding to the root node is solved. Our method is not only
easy to implement and effective in practice, it also provides
the approximation bounds of the LP relaxation [7, 11].
Specifically, the following property holds true:
Theorem 4.1 [18]: For r-HST metric labeling we obtain an
approximation bound of O(1).

5 The Semi-Metric Labeling Problem
Similar to MAP estimation, several problems specified on
r-HST metrics are well-known to be amenable to efficient
divide-and-conquer approaches [1, 8]. However, their use
in the AI community has been very limited thus far. The
main reason for this would appear to be their restrictive
form which may not offer an accurate model for real-world
applications. A natural way to address this deficiency is to
use a mixture of r-HST metrics instead of a single r-HST.
5.1 Learning a Mixture of r-HSTs.
Given a distance function d(·, ·), we would like to learn a
set of r-HST metrics D = {dt (·, ·), t = 1, · · · , T } along
with a probability distribution ρ on them such that the distortion is minimized, that is
P t t


ρ d (i, j)
.
(4)
(D∗ , ρ∗ ) = arg min max t
i6=j
D,ρ
d(i, j)
When the distance function is a metric, Fakcharoenphol
et al. [8] provide a simple yet accurate randomized algorithm for sampling r-HST metrics. Below, we describe their

315

method for r = 2 while noting that it can be easily extended
for any value of r.
It is helpful to think of each level of an r-HST as a clustering
of labels such that a node p defines a cluster of labels Lp =
{i|i ∈ p} (i.e. i is a leaf node of the subtree rooted at p). In
other words, an r-HST defines a hierarchical clustering of
labels. Let the clustering at level m be denoted by C m . The
root node denotes the trivial clustering which consists of all
the labels C 1 = {1, · · · , H}. Given the clusters C m−1 , C m
is obtained by further clustering the labels {j|j ∈ p} for
each node p ∈ C m−1 .
Without loss of generality, we assume that the diameter
∆ = maxi6=j d(i, j) = 2δ for an integer δ ≥ 1 and
mini6=j d(i, j) > 1. Due to the above assumptions, the rHST would consist of at most δ levels. The algorithm is initialized by: (i) picking a random permutation π of the label
indices {1, 2, · · · , H}, which defines a priority ordering on
the cluster centers; and (ii) choosing a value of β ∈ [1, 2]
from the distribution Pr(x) = 1/(x log 2). Note that both
the permutation π and value of β are fixed throughout the
process, i.e. they are selected once before running the clustering algorithm for all levels. Given C m−1 , the clustering
at level m is obtained as follows:
• Consider a node p ∈ C m−1 . Define βm = 2δ−m β.
• For a label i ∈ p, find the first label j according to the
permutation π such that d(i, j) ≤ βm .
• Assign the label i to the cluster centered at j.
• Repeat for all labels i ∈ p and nodes p ∈ C m−1 .
The edge length ep from a node p to each of its children
is given by ∆p /2 where ∆p denotes the diameter of the
cluster of labels Lp specified by p. Fakcharoenphol et al.
[8] showed that ∆p reduces by at least a factor of r = 2 for
metric distances, thereby providing us with an r-HST.
Importantly, the method of [8] can also be applied for approximating semi-metric distance functions. However, as
the triangular inequality is not satisfied, the resulting tree
will not be an r-HST. Nonetheless, the tree obtained using this method would provide a metric distance function
which can then be approximated to r-HST metrics by applying the above procedure again. The only question that
remains is the number of r-HSTs T to be employed. In order to answer this question, we note that [8] also provided
a deterministic version of the above algorithm for solving a
related problem that we call the dual procedure ( DP):
X
yij dt (i, j), s.t. dt (i, j) ≥ d(i, j), (5)
DP (y): min
t
d (·,·)

i,j

for some values of yij ≥ 0. In other words, DP provides
one r-HST that minimizes the non-negatively weighted sum
of distances that dominate the original distance d(·, ·) (i.e.
dt (i, j) ≥ d(i, j), for all i, j). Note that each r-HST
sampled from the randomized procedure described above
dominates d(·, ·). Briefly, DP works by derandomizing the

316

KUMAR & KOLLER

above procedure using conditional expectation. In other
words, the elements of the permutation π are obtained sequentially by computing the expectation of equation (5)
given the previously selected elements of the permutation.
Using DP, Charikar et al. [6] provided an iterative algorithm to obtain a small mixture of r-HST metrics (with
O(H log H) r-HSTs). The algorithm initializes the mixture
to one r-HST. In our implementation, we found the r-HST
obtained by solving the DP (5) for the values yij = 1 for
all i, j to be a good initialization. Let (D, ρ) denote the
mixture after n iterations which consists of n r-HSTs. The
(n + 1)st r-HST is obtained by defining

P t t
(
1
t ρ d (i,j)
if i 6= j,
exp
d(i,j)
λd(i,j)
(6)
yij =
0
otherwise,
and solving DP(y). Here λ > 0 is the user defined learning
rate. Note that in the above values of yij , the pairs of labels
li and lj which result in a bigger distortion are given more
weight while solving the DP. The probability distribution
over the n + 1 r-HSTs is updated to ((1 − λ)ρ; λ) where (; )
denotes vector concatenation. Although more sophisticated
clustering algorithms may be used, the above method is appealing due to its ease of implementation. Furthermore, it
also provides an accurate approximation as evidenced by
the following result from [8] and its simple extension.
Theorem 5.1 [8]: When d(·, ·) is a metric distance function, the above approach provides a mixture of r-HST metrics with distortion of O(log H).
Theorem 5.2: Let d(·, ·) be a semi-metric which satisfies
the following relaxed version of triangular inequality:
d(i, j) − d(j, k) ≤ γd(i, k), ∀i, j, k,

(7)

for some value of γ ≥ 1. The above approach provides a mixture of r-HST metrics with a distortion of
O((γ log H)2 ) with respect to d(·, ·). Note that any distance function defined over a finite number of labels will
admit a finite γ.
5.2 Approximating Semi-Metric Labeling
Once the mixture of r-HSTs is learnt, the original semimetric labeling problem parameterized by θ can be approximated by a set of r-HST metric labeling problems specified
by parameters θt , t = 1, · · · , T , where
t
θat (i) = θa (i), θab
(i, j) = wab dt (i, j).

(8)

As shown in the previous section, r-HST metric labeling can be solved efficiently and accurately using an stMINCUT based approach. Hence, in order to solve semimetric labeling, we solve the set of r-HST metric labeling
problems to obtain the labelings f t . We then combine these
labelings to obtain the final labeling f , using the same approach as the one used to combine the labelings of the children of node p of the r-HST (see § 4.2). Note that, unlike the

UAI 2009

problem of combining labelings of child nodes, in this case
the moves of α-expansion are no longer necessarily submodular. In other words, we are not guaranteed to obtain
the optimal move at each iteration. In order to overcome
this problem, we solve the α-expansion procedure by using
the primal dual scheme of [16]. This has two advantages:
(i) it reduces the run-time of α-expansion; and (ii) it handles non-submodular moves by truncating the edges with
negative capacities in the st-MINCUT graph to 0. At each iteration of α-expansion, we move to a new labeling only if it
decreases the energy. Otherwise we retain the old labeling
and repeat the procedure until we can no longer decrease
the energy for any iteration of α-expansion. We initialize
the labeling by the lowest energy labeling amongst the set
{f t , t = 1, · · · , T }. The α-expansion procedure described
above guarantees that the energy is not increased at any iteration. In other words, the energy of the labeling obtained
by our approach is bounded from above by the energy of
the best labeling provided by solving the set of r-HST metric labeling problems. Using this observation along with
Theorems 5.1 and 5.2 allows us to prove the following approximation bounds for our overall approach.
Theorem 5.3 [18]: For the metric and semi-metric labeling
problems, we obtain an approximation bound of O(log H)
and O((γ log H)2 ) respectively.
In practice, when solving a subproblem at node p of an
r-HST, we use the given distance function d(·, ·) to specify the pairwise potentials of θp instead of r-HST metric
dt (·, ·). This tends to improve the quality of the labelings
whilst retaining the approximation bound. Specifically,
Observation 5.4 [18]: Theorem 5.3 also holds true if the rHST metric dt (·, ·) is replaced by the given distance d(·, ·)
in equation (2) for all subproblems defined by the r-HSTs.
Note that our algorithm provides the guarantees of the LP
relaxation for the metric labeling problem. Together with
the results for truncated convex models [5, 20], this implies
that there exist moving making algorithms which match all
known LP relaxation guarantees when the number of labels is smaller than the number of variables (i.e. H < N ).
Although the above theorem shows that our approach provides a tight approximation, we can further improve its accuracy by using a hard EM strategy described below.
5.3 Refining the Labeling
For a given semi-metric labeling problem, consider the labeling f obtained using the method described above. The
energy defined by f is given by
X
X
wab d(f (a), f (b))
Q(f ; θ) =
θa (f (a)) +
va ∈V

(va ,vb )∈E

(9)

We define a set of non-negative weights y as
X
wab ,
yij =
(va ,vb )∈E,f (a)=i,f (b)=j

(10)

UAI 2009

KUMAR & KOLLER

317

(ii)
(iii)
(iv)
(v)
(i)
(ii)
(iii)
(iv)
(v)
52094 50221 48112 47613
α-exp
0.44
0.36
0.29
0.30
0.36
51938 51055 48487 47579
αβ-swap
0.65
0.86
0.52
0.51
0.47
51318 48132 47355 46612
TRW- S
104.29 178.97 713.70 703.82 709.36
60269 52841 48136 47402
BP - S
15.78
45.63
150.36 129.68 141.79
51842
R-swap
1.97
10.73
51641
R-exp
5.78
30.73
51587 48146 47538 46651
Our
10.22
12.84
1.86
10.58
12.25
51413 48146 47382 46638
Our+ EM
25.66
64.08
5.02
32.75
57.50
(a) Energy
(b) Time
Table 1: Average energy and time (in seconds) of MAP estimation algorithms computed using 100 randomly generated MRFs. The
columns denote the five cases considered (see text). The three smallest average energy values and average timings are shown in bold.
Note that range swap and range expansion are only applicable to truncated convex models. Hence, their timing and energy is not
reported for other cases. As the results indicate, our approach provides an accurate MAP estimate efficiently.
α-exp
αβ-swap
TRW- S
BP - S
R-swap
R-exp
Our
Our+ EM

(i)
48645
48721
47506
50942
48045
47998
47850
47823

i.e. yij is the contribution of labels li and lj to the energy (9). Specifically, using y, the energy of the labeling
f can be rewritten as
X
X
yij d(i, j).
(11)
Q(f ; θ) =
θa (f (a)) +

Synthetic Data. We consider the following cases of the
MAP estimation problem: (i) truncated linear metrics; (ii)
truncated quadratic semi-metrics; (iii) r-HST metrics; (iv)
general metrics; and (v) general semi-metrics. Note that
for uniform metric labeling, our approach reduces to αi,j
va ∈V
expansion and hence, we do not consider such problems in
our evaluation. In each of the five cases above, we generWe obtain an r-HST metric dt (·, ·) by solving DP (5) for the
ated 100 random 4-connected grid structured MRFs of size
values of y defined above. The metric dt (·, ·) provides an
100
× 100 with H = 20. The unary potentials were rant
MRF parameterized by θ as defined in equation (8). Since
domly sampled from the uniform distribution defined over
the metric dt (·, ·) dominates the given distance d(·, ·) it folthe interval [0, 10] (denoted by u(0, 10)). The pairwise polows that
tentials for the five cases were generated as follows. For
X
X
the truncated convex models (cases (i) and (ii)) the truncayij dt (i, j) ⇒ Q(f ; θ) ≤ Q(f ; θt ). (12) tion factor was sampled from u(0, 10). For r-HST metrics
yij d(i, j) ≤
i,j
i,j
we defined a random hierarchical clustering of labels with
the edge lengths at the root sampled from u(0, 10). The
Now consider the case when the above inequality holds
edge
lengths at other levels were sampled while ensuring
with an equality. In other words, DP provides an r-HST
that
the
properties of the r-HST metric hold true. In order
metric which exactly models the weighted sum of distances
to
generate
a general metric distance function, we defined
where the weights are specified by y. We can now solve the
t
a
complete
graph
over the labels with random edge lengths
r-HST metric labeling problem corresponding to θ in orfrom
u(0,
10).
The
distance function d(i, j) between labels
′
′
der to obtain a new labeling f . If the labeling f is such
t
t
i
and
j
is
given
by
the shortest path from i to j. A gen′
that Q(f ; θ ) ≤ Q(f ; θ ) then we are guaranteed not to ineral
semi-metric
distance
was defined by randomly samcrease the energy of the solution by moving from labeling
pling
the
values
of
d(i,
j)
where i 6= j from u(0, 10) and
′
f to labeling f since
setting d(i, i) = 0 for all i.
Q(f ′ ; θt ) ≤ Q(f ; θt ) = Q(f ; θ) ⇒ Q(f ′ ; θ) ≤ Q(f ; θ).
The MRFs were used to test several state of the art MAP
(13)
estimation algorithms: α-expansion [5], αβ-swap [4], seThe process of obtaining a new r-HST metric followed by
quential tree-reweighted message passing ( TRW- S) [14], sea new labeling f ′ can be repeated till we reach a local minquential belief propagation ( BP - S) [24], range swap [32],
ima. Note that the above inequality is obtained by assumand range expansion [20]. We used publicly available code
ing that the DP can be solved exactly. However, this cannot
for these approaches to compare them with the two variants
be guaranteed for general semi-metric distance functions.
of our method: with and without using the hard EM strategy
Nonetheless, in practice we use the above procedure to redescribed in § 5.3.
fine the labeling obtained by solving each r-HST metric laThe α-expansion algorithm was solved using the primalbeling problem. As the results in the next section show, it
dual scheme of [16] (for both the original problem as well
helps further decrease the energy of the labelings obtained
as the various subproblems used in our approach). Recall
by our method at the cost of more computation time.
that [16] also handles non-submodular moves and hence, is
6 Experiments
capable of solving semi-metric labeling problems like cases
We compare our approach to several state of the art MAP
(ii) and (v). All the move making algorithms were initialestimation algorithms using both synthetic and real data
ized to the constant labeling f (a) = 1 for all va . For the
experiments. In all our experiments we set r = 2. Empiritruncated convex models (cases (i) and (ii)) the messages of
cally, we found that the accuracy of our approach saturates
TRW- S and BP - S were computed efficiently using the disafter using T = 50 r-HSTs to define the mixture.

318

KUMAR & KOLLER

tance transform technique [9]. We report the results of the
methods described in [20, 32] (denoted by R-exp and Rswap respectively) only for truncated convex models since
these approaches are not applicable to the other cases.
Table 1 lists the average time required and the average
value of the energy obtained for various methods. Our approach is slower than previous move making algorithms (αexpansion and αβ-swap) as it solves a set of r-HST metric
labeling problems. However, in terms of the energy values, it significantly outperforms them in all cases. It even
provides similar results to the methods of [20, 32] which
were specifically designed for the truncated convex models. The energy values obtained by our approach also compare favorably with TRW- S. In terms of speed, our method
is significantly faster than TRW- S, especially in cases where
the distance transform trick cannot be employed. As mentioned earlier, the computational efficiency of our method
is due to the fact that it only uses the efficient st-MINCUT
algorithm in its design. Finally, we also note that the hard
EM strategy decreases the energy of the labeling. However,
it is slower since it has to solve at least one instance of the
DP (5) for each r- HST in the mixture.
Scene Registration. Given two images of different
scenes with some common elements (e.g. both scenes contain buildings, see Fig. 2), scene registration requires us to
find a point to point correspondence from one image to the
other. In this work, we follow the framework of [22] and
define an MRF whose variables correspond to the pixels of
the first image. The labels of the variables denote the displacement that the pixel undergoes from the first image to
its corresponding pixel in the second image. The neighborhood is defined such that the MRF forms a 4-connected
grid graph. The unary potentials are given by the ℓ1 difference between the SIFT features [23] of corresponding
points. The pairwise potentials, which enforce smoothness
of the displacement map, are defined as

UAI 2009

can be speeded up by using the decomposable model [26].
However, this makes the approximations to the free energy
weaker thereby providing less accurate results.
A related problem to scene registration, known as stereo reconstruction, is concerned with obtaining correspondences
between two images of the same scene. The image pairs
are epipolar rectified, i.e. the vertical displacement of each
pixel is known to be 0. The unary potentials are computed
using the difference in the RGB values of the corresponding pixels (instead of the SIFT feature), and the pairwise
potentials are given by equation (14) with M = 5 and
κ = 20. We compared our approach with other algorithms on two standard stereo pairs used in computer vision, namely ‘teddy’ and ‘tsukuba’. Our method provides a
labeling with lower energy than α-expansion and αβ-swap
using H = 40 labels, as shown in Fig. 3.
Image Denoising Image denoising is a classic problem
in low-level computer vision. Given an image with noise
and/or missing pixels, the task is to obtain a ‘clean’ version
of the image, i.e. remove the noise and fill up the missing
pixels. The problem is modeled as an MRF whose variables
correspond to the image pixels and whose edges define a
4-connected grid graph. The labels are the 256 possible
intensity values that lie in the interval [0, 255]. The unary
potentials are given by the squared difference between the
intensity corresponding to the label and the observed intensity in the image. Since natural images are smooth, i.e.
neighboring pixels tend to have similar intensity values, it
is common practice to employ truncated convex pairwise
potentials. In this work, we use
θab (i, j) = 30 min{|i − j|, 50}.

(15)

We compared our method with the state of the art MAP estimation algorithms on two standard images, namely ‘house’
and ‘penguin’. Fig. 4 shows the results obtained. Similar
to other synthetic and real data experiments, our approach
θab (i, j) = κ (min{|u(i) − u(j)|, M } + min{|v(i) − v(j)|, M }) , obtains labelings with lower energy values than the other
(14)
move making algorithms (although it takes a longer time
where (u(i), v(i)) and (u(j), v(j)) are the horizontal and
since it solves a series of r-HST metric labeling problems).
vertical displacements specified by labels li and lj respecIn terms of the energy values, our method is outperformed
tively, M is the truncation factor and κ is the scaling factor.
by TRW- S but is computationally more efficient.
Since the above pairwise potential forms a metric distance,
The results for scene segmentation are provided in [18].
our approach can be applied to obtain the solution.
In our experiments, we use the values of u(i) ∈ [−5, 5]
and v(i) ∈ [−5, 5], i.e. the total number of labels for each
random variable is H = 121. The truncation factor M was
set to 5 and the scaling factor κ = 1. Fig. 2 shows the results obtained for three pairs of images using six different
MAP estimation algorithms along with the corresponding
energy values and timings. Similar to the synthetic data
experiments, our approach outperforms other move making approaches in terms of accuracy, and it outperforms
TRW- S in terms of speed. In fact, the accuracy of our
method is very similar to TRW- S. Note that TRW- S and BP - S

7 Discussion
We presented a move making approach for the semi-metric
labeling problem which approximates the given semimetric into a mixture of r-HST metrics and solves each of
the resulting problems using an efficient st-MINCUT based
algorithm. Our approach provides the guarantees of the
LP relaxation for the metric labeling problem. Together
with the work of [5, 20], this provides further evidence of
a link between randomized rounding techniques used with
convex relaxations and move making algorithms. We believe that further investigations in this direction would help

UAI 2009
Image-1

KUMAR & KOLLER
Image-2

α-exp

αβ-swap

319

TRW- S

BP - S

Our

Our+ EM

(Energy, Timing)

82036, 1.66

83023, 8.15

81118, 1371.11 84396, 218.04 81315, 104.89 81258, 373.60

(Energy, Timing)

68572, 1.27

69767, 2.78

67616, 1058.25 70239, 159.98 67682, 73.61

(Energy, Timing)

78222, 2.06

79808, 3.77

77457, 1400.82 80002, 228.92 77466, 111.88 77463, 383.34

67676, 240.49

Figure 2: Scene registration results. The image pairs are obtained from [22]. In each row, the first image is warped into the second
image using the displacements found by various MAP estimation algorithms. The energy values and timings in seconds for the algorithms
are shown below the corresponding warped image. The three smallest values of the energy and time required are highlighted in bold.
Image-1

Image-2

α-exp

αβ-swap

TRW- S

BP - S

Our

Our+ EM

(Energy, Timing)

78776, 12.07

97999, 34.59

62777, 263.28 126824, 50.38 65116, 152.74 65008, 361.81

(Energy, Timing)

15322, 4.49

18425, 13.43

13257, 169.12

56280, 29.60

14135, 72.09

14135, 203.12

Figure 3: Stereo reconstruction results. Each row shows the displacement map obtained by various MAP estimation algorithms along
with their corresponding energy values and timings in seconds.
α-exp

αβ-swap

TRW- S

BP - S

Energy
Timing

32186163
26.13

32189264
90.74

32173383
529.60

Energy
Timing

11075641
5.09

11074426
25.22

11068226
174.33

Image

Our

Our+ EM

32626969
115.84

32181820
294.72

32181820
465.57

11105845
32.94

11072828
70.55

11072332
204.55

Figure 4: Image denoising results. Each row shows the ‘clean’ image obtained by different MAP estimation algorithms along with
their corresponding energy values and timings in seconds. The black regions in the original image indicate missing pixels. The unary
potentials for missing pixels is set to be a constant for all labels. The three lowest energy values and timings are highlighted in bold.

320

KUMAR & KOLLER

design move making algorithms for more complex relaxations such as [19, 28]. In practice, the results on both
synthetic and real data experiments show that our method
reduces the gap in performance between move making algorithms and message passing approaches. This is particularly true for applications where the unary potentials do
not dominate the pairwise potentials, i.e. the prior specified by the MRF plays a vital role in obtaining good results
(e.g. in scene registration). Such scenarios occur not only
during testing, but during parameter learning of MRFs as
well (for example, structured SVMs [31] solve a series of
MAP estimation problems to learn log-linear models). An
interesting direction for future research would be to generalize our move making approach to other hierarchical distance functions that approximate semi-metric distances accurately and can be learnt efficiently. Similar to the existing
move making algorithms [12], the possibility of extending
our approach to solve special cases of higher order potentials should also be explored.
Acknowledgments. We thank Stephen Gould for helpful discussions and careful proofreading of the manuscript.
The first author is funded by the DARPA grant SA499610929-5.

References
[1] Y. Bartal. On approximating arbitrary metrics by tree metrics. In STOC, 1998.
[2] E. Boros and P. Hammer. Pseudo-boolean optimization.
Discrete Applied Mathematics, 123:155–225, 2002.
[3] Y. Boykov and V. Kolmogorov. An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision. PAMI, 26(9):1124–1137, 2004.
[4] Y. Boykov, O. Veksler, and R. Zabih. Markov random fields
with efficient approximations. In CVPR, 1998.
[5] Y. Boykov, O. Veksler, and R. Zabih. Fast approximate energy minimization via graph cuts. In ICCV, pages 377–384,
1999.
[6] M. Charikar, C. Chekuri, A. Goel, S. Guha, and S. Plotkin.
Approximating a finite metric by a small number of tree
metrics. In FOCS, 1998.
[7] C. Chekuri, S. Khanna, J. Naor, and L. Zosin. A linear
programming formulation and approximation algorithms for
the metric labelling problem. SIAM Journal on Disc. Math.,
18(3):606–635, 2005.
[8] J. Fakcharoenphol, S. Rao, and K. Talwar. A tight bound on
approximating arbitrary metrics by tree metrics. In STOC,
2003.
[9] P. Felzenszwalb and D. Huttenlocher. Efficient matching of
pictorial structures. In CVPR, pages II: 66–73, 2000.
[10] T. Hazan and A. Shashua. Convergent message-passing algorithms for inference over general graphs with convex free
energy. In UAI, 2008.
[11] J. Kleinberg and E. Tardos. Approximation algorithms for
classification problems with pairwise relationships: Metric
labeling and Markov random fields. In STOC, 1999.
[12] P. Kohli, L. Ladicky, and P. Torr. Robust higher order potentials for enforcing label consistency. In CVPR, 2008.
[13] P. Kohli, A. Shekhovtsov, C. Rother, V. Kolmogorov, and
P. Torr. On partial optimality in multi-label MRFs. In ICML,
2008.

UAI 2009

[14] V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. PAMI, 2006.
[15] N. Komodakis, N. Paragios, and G. Tziritas. MRF optimization via dual decomposition: Message-passing revisited. In
ICCV, 2007.
[16] N. Komodakis, G. Tziritas, and N. Paragios. Fast, approximately optimal solutions for single and dynamic MRFs. In
CVPR, 2007.
[17] A. Koster, C. van Hoesel, and A. Kolen. The partial constraint satisfaction problem: Facets and lifting theorems.
Operations Research Letters, 23(3-5):89–97, 1998.
[18] M. P. Kumar and D. Koller. MAP estimation of semi-metric
MRFs via hierarchical graph cuts. Technical report, Stanford University, 2009.
[19] M. P. Kumar, V. Kolmogorov, and P. Torr. An analysis of
convex relaxations for MAP estimation. In NIPS, 2007.
[20] M. P. Kumar and P. Torr. Improved moves for truncated
convex models. In NIPS, 2008.
[21] V. Lempitsky, S. Roth, and C. Rother. FusionFlow:
Discrete-continuous optimization for optical flow estimation. In CVPR, 2008.
[22] C. Liu, J. Yuen, A. Torralba, J. Sivic, and W. Freeman.
SIFT flow: Dense correspondence across different scenes.
In ECCV, 2008.
[23] D. Lowe. Object recognition from local scale-invariant features. In ICCV, 1999.
[24] J. Pearl. Probabilistic Reasoning in Intelligent Systems:
Networks of Plausible Inference. Morgan Kauffman, 1998.
[25] M. Schlesinger. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika, 1976.
[26] A. Shekhovstov, I. Kovtun, and V. Hlavac. Efficient MRF
deformation model for non-rigid image matching. In CVPR,
2007.
[27] J. Shotton, J. Winn, C. Rother, and A. Criminisi. TextonBoost: Joint appearance, shape and context modeling for
multi-class object recognition and segmentation. In ECCV,
pages I: 1–15, 2006.
[28] D. Sontag and T. Jaakkola. New outer bounds for the
marginal polytope. In NIPS, 2007.
[29] D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. Tightening LP relaxations for MAP using message passing. In UAI, 2008.
[30] R. Szeliski, R. Zabih, D. Scharstein, O. Veksler, V. Kolmogorov, A. Agarwala, M. Tappen, and C. Rother. A comparative study of energy minimization methods for Markov
random fields with smoothness-based priors. PAMI, 2008.
[31] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.
Support vector learning for interdependent and structured
output spaces. In ICML, 2004.
[32] O. Veksler. Graph cut based optimization for MRFs with
truncated convex priors. In CVPR, 2007.
[33] M. Wainwright, T. Jaakkola, and A. Willsky. MAP estimation via agreement on trees: Message passing and linear
programming. Info. Th., 2005.
[34] Y. Weiss, C. Yanover, and T. Meltzer. MAP estimation, linear programming and belief propagation with convex free
energies. In UAI, 2007.
[35] O. Woodford, P. Torr, I. Reid, and A. Fitzgibbon. Global
stereo reconstruction under second order smoothness priors.
In CVPR, 2008.
[36] J. Yedidia, W. Freeman, and Y. Weiss. Generalized belief
propagation. In NIPS, pages 689–695, 2001.

