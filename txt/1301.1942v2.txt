Bayesian Optimization in a Billion Dimensions

Bayesian Optimization in a Billion Dimensions
via Random Embeddings
Ziyu Wang

ziyu.wang@cs.ox.ac.uk

Department of Computer Science, University of Oxford

Frank Hutter

fh@cs.uni-freiburg.de

arXiv:1301.1942v2 [stat.ML] 10 Jan 2016

Department of Computer Science, University of Freiburg

Masrour Zoghi

m.zoghi@uva.nl

Department of Computer Science, University of Amsterdam

David Matheson

davidm@cs.ubc.ca

Department of Computer Science, University of British Columbia

Nando de Freitas

nando@cs.ox.ac.uk

Department of Computer Science, University of Oxford
Canadian Institute for Advanced Research

Abstract
Bayesian optimization techniques have been successfully applied to robotics, planning,
sensor placement, recommendation, advertising, intelligent user interfaces and automatic
algorithm configuration. Despite these successes, the approach is restricted to problems of
moderate dimension, and several workshops on Bayesian optimization have identified its
scaling to high-dimensions as one of the holy grails of the field. In this paper, we introduce
a novel random embedding idea to attack this problem. The resulting Random EMbedding
Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present
a thorough theoretical analysis of REMBO. Empirical results confirm that REMBO can
effectively solve problems with billions of dimensions, provided the intrinsic dimensionality
is low. They also show that REMBO achieves state-of-the-art performance in optimizing
the 47 discrete parameters of a popular mixed integer linear programming solver.

1. Introduction
Let f : X â†’ R be a function on a compact subset X âŠ† RD . We address the following global
optimization problem
x? = arg max f (x).
xâˆˆX

We are particularly interested in objective functions f that may satisfy one or more of the
following criteria: they do not have a closed-form expression, are expensive to evaluate, do
not have easily available derivatives, or are non-convex. We treat f as a blackbox function
that only allows us to query its function value at arbitrary x âˆˆ X . To address objectives of
this challenging nature, we adopt the Bayesian optimization framework.
In a nutshell, in order to optimize a blackbox function f , Bayesian optimization uses a
prior distribution that captures our beliefs about the behavior of f , and updates this prior
with sequentially acquired data. Specifically, it iterates the following phases: (1) use the
1

Wang, Hutter, Zoghi, Matheson, & de Freitas

t=2
objective fn (f( Â·))

observation (x)

acquisition max
acquisition function (u( Â·))

t=3

new observation (xt )

t=4

posterior mean (Âµ( Â·))

posterior uncertainty
(Âµ( Â·) Â± Ïƒ( Â·))

Figure 1: Three consecutive iterations of Bayesian optimization for a toy one-dimensional
problem. The unknown objective function is approximated with at Gaussian process (GP) at each iteration. The figure shows the mean and confidence intervals
for this process. It also shows the acquisition function in the lower green shaded
plots. The acquisition is high where the GP predicts a high objective (exploitation) and where the prediction uncertainty is high (exploration). Note that the
area on the far left remains under-sampled, as (despite having high uncertainty)
it is correctly predicted to be unlikely to improve over the highest observation.

prior to decide at which input x âˆˆ X to query f next; (2) evaluate f (x); and (3) update
the prior based on the new data hx, f (x)i. Step 1 uses a so-called acquisition function that
quantifies the expected value of learning the value of f (x) for each x âˆˆ X . This procedure
is illustrated in Figure 1.
2

Bayesian Optimization in a Billion Dimensions

The role of the acquisition function is to trade off exploration and exploitation; popular
choices include Thompson sampling (Thompson, 1933; Hoffman, Shahriari, & de Freitas,
2014), probability of improvement (Jones, 2001), expected improvement (MocÌŒkus, 1994),
upper-confidence-bounds (Srinivas, Krause, Kakade, & Seeger, 2010), and online portfolios
of these (Hoffman, Brochu, & de Freitas, 2011). These are typically optimized by choosing
points where the predictive mean is high (exploitation) and where the variance is large
(exploration). Since they typically have an analytical expression that is easy to evaluate,
they are much easier to optimize than the original objective function, using off-the-shelf
numerical optimization algorithms.1
The term Bayesian optimization was coined several decades ago by Jonas MocÌŒkus (1982).
A popular version of the method is known as efficient global optimization in the experimental
design literature since the 1990s (Jones, Schonlau, & Welch, 1998). Often, the approximation of the objective function is obtained using Gaussian process (GP) priors. For this
reason, the technique is also referred to as GP bandits (Srinivas et al., 2010). However,
many other approximations of the objective have been proposed, including Parzen estimators (Bergstra, Bardenet, Bengio, & KeÌgl, 2011), Bayesian parametric models (Wang
& de Freitas, 2011), treed GPs (Gramacy, Lee, & Macready, 2004) and random forests
(Brochu, Cora, & de Freitas, 2009; Hutter, 2009; Hutter, Hoos, & Leyton-Brown, 2011).
These may be more suitable than GPs when the number of iterations grows without bound,
or when the objective function is believed to have discontinuities. We also note that often
assumptions on the smoothness of the objective function are encoded without use of the
Bayesian paradigm, while leading to similar algorithms and theoretical guarantees (see, for
example, Bubeck, Munos, Stoltz, & Szepesvari, 2011, and the references therein). There is
a rich literature on Bayesian optimization, and for further details we refer readers to more
tutorial treatments (Brochu et al., 2009; Jones et al., 1998; Jones, 2001; Lizotte, Greiner,
& Schuurmans, 2011; MocÌŒkus, 1994; Osborne, Garnett, & Roberts, 2009) and recent theoretical results (Srinivas et al., 2010; Bull, 2011; de Freitas, Smola, & Zoghi, 2012).
Bayesian optimization has been demonstrated to outperform other state-of-the-art blackbox optimization techniques when function evaluations are expensive and the number of
allowed function evaluations is therefore low (Hutter, Hoos, & Leyton-Brown, 2013). In
recent years, it has found increasing use in the machine learning community (Rasmussen,
2003; Brochu, de Freitas, & Ghosh, 2007; Martinez-Cantin, de Freitas, Doucet, & Castellanos, 2007; Lizotte, Wang, Bowling, & Schuurmans, 2007; Frazier, Powell, & Dayanik,
2009; Azimi, Fern, & Fern, 2010; Hamze, Wang, & de Freitas, 2013; Azimi, Fern, & Fern,
2011; Hutter et al., 2011; Bergstra et al., 2011; Gramacy & Polson, 2011; Denil, Bazzani,
Larochelle, & de Freitas, 2012; Mahendran, Wang, Hamze, & de Freitas, 2012; Azimi, Jalali,
& Fern, 2012; Hennig & Schuler, 2012; Marchant & Ramos, 2012; Snoek, Larochelle, &
Adams, 2012; Swersky, Snoek, & Adams, 2013; Thornton, Hutter, Hoos, & Leyton-Brown,
1. This optimization step can in fact be circumvented when using treed multi-scale optimistic optimization
as recently demonstrated by Wang and de Freitas (2014). There also exist several more involved Bayesian
non-linear experimental design approaches for constructing the acquisition function, where the utility to
be optimized involves an entropy of an aspect of the posterior. This includes the work of Hennig and
Schuler (2012) for finding maxima of functions, the works of Kueck, de Freitas, and Doucet (2006) and
Kueck, Hoffman, Doucet, and de Freitas (2009) for learning functions, and the work of Hoffman, Kueck,
de Freitas, and Doucet (2009) for estimating Markov decision processes. These works rely on expensive
approximate inference methods for computing intractable integrals.

3

Wang, Hutter, Zoghi, Matheson, & de Freitas

2013). Despite many success stories, the approach is restricted to problems of moderate
dimension, typically up to about 10. Of course, for a great many problems this is all that
is needed. However, to advance the state of the art, we need to scale the methodology to
high-dimensional parameter spaces. This is the goal of this paper.
It is difficult to scale Bayesian optimization to high dimensions. To ensure that a global
optimum is found, we require good coverage of X , but as the dimensionality increases, the
number of evaluations needed to cover X increases exponentially. As a result, there has been
little progress on this challenging problem, with a few exceptions. Bergstra et al. (2011) introduced a non-standard Bayesian optimization method based on a tree of one-dimensional
density estimators and applied it successfully to optimize the 238 parameters of a complex vision architecture (Bergstra, Yamins, & Cox, 2013). Hutter et al. (2011) used random forests
models in Bayesian optimization to achieve state-of-the-art performance in optimizing up
to 76 mixed discrete/continuous parameters of algorithms for solving hard combinatorial
problems, and to successfully carry out combined model selection and hyperparameter optimization for the 768 parameters of the Auto-WEKA framework (Thornton et al., 2013).
Eggensperger, Feurer, Hutter, Bergstra, Snoek, Hoos, and Leyton-Brown (2013) showed
that these two methods indeed yielded the best performance for high-dimensional hyperparameter optimization (e.g., in deep belief networks). However, both are based on weak
uncertainty estimates that can fail even for the optimization of very simple functions and
lack theoretical guarantees.
In the linear bandits case, Carpentier and Munos (2012) recently proposed a compressed
sensing strategy to attack problems with a high degree of sparsity. Also recently, Chen,
Castro, and Krause (2012) made significant progress by introducing a two stage strategy
for optimization and variable selection of high-dimensional GPs. In the first stage, sequential
likelihood ratio tests, with a couple of tuning parameters, are used to select the relevant
dimensions. This, however, requires the relevant dimensions to be axis-aligned with an
ARD kernel. Chen and colleagues provide empirical results only for synthetic examples (of
up to 400 dimensions), but they provide key theoretical guarantees.
Many researchers have noted that for certain classes of problems most dimensions do not
change the objective function significantly; examples include hyper-parameter optimization
for neural networks and deep belief networks (Bergstra & Bengio, 2012), as well as other
machine learning algorithms and various state-of-the-art algorithms for solving N P-hard
problems (Hutter, Hoos, & Leyton-Brown, 2014). That is to say these problems have â€œlow
effective dimensionalityâ€. To take advantage of this property, Bergstra and Bengio (2012)
proposed to simply use random search for optimization â€“ the rationale being that points
sampled uniformly at random in each dimension can densely cover each low-dimensional
subspace. As such, random search can exploit low effective dimensionality without knowing
which dimensions are important. In this paper, we exploit the same property in a new
Bayesian optimization variant based on random embeddings.
Figure 2 illustrates the idea behind random embeddings in a nutshell. Assume we know
that a given D = 2 dimensional black-box function f (x1 , x2 ) only has d = 1 important
dimensions, but we do not know which of the two dimensions is the important one. We
can then perform optimization in the embedded 1-dimensional subspace defined by x1 = x2
since this is guaranteed to include the optimum.
4

Bayesian Optimization in a Billion Dimensions

x1

x1

g
in
dd
be
Em

x2

x*

Important

x*

Unimportant

x2

Figure 2: This function in D=2 dimesions only has d=1 effective dimension: the vertical
axis indicated with the word important on the right hand side figure. Hence,
the 1-dimensional embedding includes the 2-dimensional functionâ€™s optimizer.
It is more efficient to search for the optimum along the 1-dimensional random
embedding than in the original 2-dimensional space.

As we first demonstrated in a recent IJCAI conference paper (Wang, Zoghi, Hutter,
Matheson, & de Freitas, 2013), random embeddings enable us to scale Bayesian optimization
to arbitrary D provided the objective function has low intrinsic dimensionality. Importantly,
the algorithm associated with this idea, which we called REMBO, is not restricted to cases
with axis-aligned intrinsic dimensions but applies to any d-dimensional linear subspace.
Djolonga, Krause, and Cevher (2013) recently proposed an adaptive, but more expensive,
variant of REMBO with theoretical guarantees.
In this journal version of our work, we expand the presentation to provide more details throughout. In particular, we expand our description of the strategy for selecting the
boundaries of the low-dimensional space and for setting the kernel length scale parameter;
we show by means of an additional application (automatic configuration of random forest
body-part classifiers) that the performance of our technique does not collapse when the
problem does not have an obvious low effective dimensionality. Our experiments (Section
4) also show that REMBO can solve problems of previously untenable high extrinsic dimensions, and that REMBO can achieve state-of-the-art performance for optimizing the 47
discrete parameters of a popular mixed integer linear programming solver.

2. Bayesian Optimization
As mentioned in the introduction, Bayesian optimization has two ingredients that need to
be specified: The prior and the acquisition function. In this work, we adopt GP priors.
We review GPs very briefly and refer the interested reader to the book by Rasmussen and
Williams (2006). A GP is a distribution over functions specified by its mean function m(Â·)
5

Wang, Hutter, Zoghi, Matheson, & de Freitas

and covariance k(Â·, Â·). More specifically, given a set of points x1:t , with xi âˆˆ RD , we have
f (x1:t ) âˆ¼ N (m(x1:t ), K(x1:t , x1:t )),
where K(x1:t , x1:t )i,j = k(xi , xj ) serves as the covariance matrix. A common choice of k is
the squared exponential function (see Definition 7 on page 11), but many other choices are
possible depending on our degree of belief about the smoothness of the objective function.
An advantage of using GPs lies in their analytical tractability. In particular, given
observations x1:t with corresponding values f1:t , where fi = f (xi ), and a new point xâˆ— , the
joint distribution is given by:
 

 

f1:t
m(x1:t )
K(x1:t , x1:t ) k(x1:t , xâˆ— )
âˆ¼N
,
.
fâˆ—
mâˆ—
k(xâˆ— , x1:t )
k(xâˆ— , xâˆ— )
For simplicity, we assume that m(x1:t ) = 0 and mâˆ— = 0. Using the Sherman-MorrisonWoodbury formula, one can easily arrive at the posterior predictive distribution:
f âˆ— |Dt , xâˆ— âˆ¼ N (Âµ(xâˆ— |Dt ), Ïƒ(xâˆ— |Dt )),
with data Dt = {x1:t , f1:t }, and mean and variance
Âµ(xâˆ— |Dt ) = k(xâˆ— , x1:t )K(x1:t , x1:t )âˆ’1 f1:t
Ïƒ(xâˆ— |Dt ) = k(xâˆ— , xâˆ— ) âˆ’ k(xâˆ— , x1:t )K(x1:t , x1:t )âˆ’1 k(x1:t , xâˆ— ).
That is, we can compute the posterior predictive mean Âµ(Â·) and variance Ïƒ(Â·) exactly for
any point xâˆ— .
At each iteration of Bayesian optimization, one has to re-compute the predictive mean
and variance. These two quantities are used to construct the second ingredient of Bayesian
optimization: The acquisition function. In this work, we report results for the expected
improvement acquisition function (MocÌŒkus, 1982; Vazquez & Bect, 2010; Bull, 2011):
u(x|Dt ) = E(max{0, ft+1 (x) âˆ’ f (x+ )}|Dt ).
In this definition, x+ = arg maxxâˆˆ{x1:t } f (x) is the element with the best objective value in
the first t steps of the optimization process. The next query is:
xt+1 = arg max u(x|Dt ).
xâˆˆX

Note that this utility favors the selection of points with high variance (points in regions
not well explored) and points with high mean value (points worth exploiting). We also
experimented with the UCB acquisition function (Srinivas et al., 2010; de Freitas et al.,
2012) and found it to yield similar results. The optimization of the closed-form acquisition
function can be carried out by off-the-shelf numerical optimization procedures, such as DIRECT (Jones, Perttunen, & Stuckman, 1993) and CMA-ES (Hansen & Ostermeier, 2001);
it is only based on the GP model of the blackbox function f and does not require additional
evaluations of f .
The Bayesian optimization procedure is shown in Algorithm 1.
6

Bayesian Optimization in a Billion Dimensions

Algorithm 1 Bayesian Optimization
1: Initialize D0 as âˆ….
2: for t = 1, 2, . . . do
3:
Find xt+1 âˆˆ RD by optimizing the acquisition function u: xt+1 = arg maxxâˆˆX u(x|Dt ).
4:
Augment the data Dt+1 = Dt âˆª {(xt+1 , f (xt+1 ))}.
5:
Update the kernel hyper-parameters.
6: end for

3. Random Embedding for Bayesian Optimization
Before introducing our new algorithm and its theoretical properties, we need to define what
we mean by effective dimensionality formally.
Definition 1. A function f : RD â†’ R is said to have effective dimensionality de , with
de â‰¤ D, if
â€¢ there exists a linear subspace T of dimension de such that for all x> âˆˆ T âŠ‚ RD and
xâŠ¥ âˆˆ T âŠ¥ âŠ‚ RD , we have f (x> + xâŠ¥ ) = f (x> ), where T âŠ¥ denotes the orthogonal
complement of T ; and
â€¢ de is the smallest integer with this property.
We call T the effective subspace of f and T âŠ¥ the constant subspace.
This definition simply states that the function does not change along the coordinates
xâŠ¥ , and this is why we refer to T âŠ¥ as the constant subspace. Given this definition, the
following theorem shows that problems of low effective dimensionality can be solved via
random embedding.
Theorem 2. Assume we are given a function f : RD â†’ R with effective dimensionality
de and a random matrix A âˆˆ RDÃ—d with independent entries sampled according to N (0, 1)
and d â‰¥ de . Then, with probability 1, for any x âˆˆ RD , there exists a y âˆˆ Rd such that
f (x) = f (Ay).
Proof. Please refer to the appendix.
Theorem 2 says that given any x âˆˆ RD and a random matrix A âˆˆ RDÃ—d , with probability
1, there is a point y âˆˆ Rd such that f (x) = f (Ay). This implies that for any optimizer x? âˆˆ
RD , there is a point y? âˆˆ Rd with f (x? ) = f (Ay? ). Therefore, instead of optimizing in the
high dimensional space, we can optimize the function g(y) = f (Ay) in the lower dimensional
space. This observation gives rise to our new Random EMbedding Bayesian Optimization
(REMBO) algorithm (see Algorithm 2). REMBO first draws a random embedding (given
by A) and then performs Bayesian optimization in this embedded space.
In many practical optimization tasks, the goal is to optimize f over a compact subset
X âŠ‚ RD (typically a box), and f can often not be evaluated outside of X . Therefore, when
REMBO selects a point y such that Ay is outside the box X , it projects Ay onto X before
evaluating f . That is, g(y) = f (pX (Ay)), where pX : RD â†’ RD is the standard projection
operator for our box-constraint: pX (y) = arg minzâˆˆX kz âˆ’ yk2 ; see Figure 3. We still need
to describe how REMBO chooses the bounded region Y âŠ‚ Rd , inside which it performs
7

Wang, Hutter, Zoghi, Matheson, & de Freitas

y

d=1

Algorithm 2 REMBO: Bayesian Optimization with Random Embedding. Blue text denotes parts that are changed compared to standard Bayesian Optimization.
1: Generate a random matrix A âˆˆ RDÃ—d
2: Choose the bounded region set Y âŠ‚ Rd
3: Initialize D0 as âˆ….
4: for t = 1, 2, . . . do
5:
Find yt+1 âˆˆ Rd by optimizing the acquisition function u: yt+1 = arg maxyâˆˆY u(y|Dt ).
6:
Augment the data Dt+1 = Dt âˆª {(yt+1 , f (Ayt+1 ))}.
7:
Update the kernel hyper-parameters.
8: end for

D=2

Convex projection

d
be

din

g

Em

of

to

Figure 3: Embedding from d = 1 into D = 2. The box illustrates the 2D constrained space
X , while the thicker red line illustrates the 1D constrained space Y. Note that if
Ay is outside X , it is projected onto X . The set Y must be chosen large enough
so that the projection of its image, AY, onto the effective subspace (vertical axis
in this diagram) covers the vertical side of the box.

Bayesian optimization. This is important because REMBOâ€™s effectiveness depends on the
size of Y. Locating the optimum within Y is easier if Y is small, but if we set Y too small it
may not actually contain the global optimizer. In the following theorem, we show that we
can choose Y in a way that only depends on the effective dimensionality de such that the
optimizer of the original problem is contained in the low dimensional space with constant
probability.
Theorem 3. Suppose we want to optimize a function f : RD â†’ R with effective dimension
de â‰¤ d subject to the box constraint X âŠ‚ RD , where X is centered around 0. Suppose
further that the effective subspace T of f is such that T is the span of de basis vectors,
and let x?> âˆˆ T âˆ© X be an optimizer of f inside T . If A is a D Ã— d random matrix
with independent standard Gaussian
entries, there exists an optimizer y? âˆˆ Rd such that
âˆš
de
?
?
?
?
f (Ay ) = f (x> ) and ky k2 â‰¤  kx> k2 with probability at least 1 âˆ’ .
Proof. Please refer to the appendix.
8

Bayesian Optimization in a Billion Dimensions

Theorem 3 says that if the set X in the original space is a box constraint, then there
exists anâˆšoptimizer x?> âˆˆ X that is de -sparse such that with probability at least 1 âˆ’ ,
ky? k2 â‰¤ de kx?> k2 where f (Ay? ) = f (x?> ). If the box constraint is X = [âˆ’1, 1]D (which is
always achievable through rescaling), we have with probability at least 1 âˆ’  that
âˆš
âˆš
de ?
de p
?
de .
ky k2 â‰¤
kx> k2 â‰¤


Hence, to choose Y, we must ensure that the ball of radius de /, centred at the origin, lies
inside Y.
In practice, we have found that it is very
âˆš unlikely that the optimizer falls on the corner of
?
the box constraint, implying that kx> k < de . Thus setting Y too big may be unnecessarily
wasteful. To improve our understanding of this effect, we developed a simulation study, in
which we drew random Gaussian matrices, used them to map various potential optimizers
? âˆˆ Y, and studied the norms of y? .
x?> to their corresponding points y>
>
Assume for simplicity of presentation that Y is axis-aligned and de -dimensional (the
argument applies when d > de ). The section of the random matrix A that maps points
in Y to T is a random Gaussian matrix of dimension de Ã— de . Let us call this section of
the matrix B. Since random Gaussian matrices are rotationally invariant in distribution,
d
we have for any orthonormal matrix O and a random Gaussian matrix B, OB = B. That

âˆ’1 d
is, OB and B are equal in distribution. Similarly, for Bâˆ’1 , OBâˆ’1 = BOT
= Bâˆ’1 .
d

Therefore, Bâˆ’1 is also rotationally invariant. Hence, kBâˆ’1 x> kâˆž = kBâˆ’1 x0> kâˆž as long as
kx> k2 = kx0> k2 . Following this equivalence for the supremum norm of projected vectors, it
suffices to choose a point with the largest norm in [âˆ’1, 1]de in our simulations. We chose
x> = [1, 1, Â· Â· Â· , 1].
We conducted simulations for several embedding dimensions, de âˆˆ {1, 2, Â· Â· Â· , 50}, by
drawing 10000 random Gaussian matrices and computing kBâˆ’1 xkâˆž . We found that with
empirical probability above 1 âˆ’  (for decreasing values of ), it was the case that
1
max{log(de ), 1}.


d
These simulations indicate that we could set Y = âˆ’ 1 max{log(de ), 1}, 1 max{log(de ), 1} e .
âˆš
Weâˆšdidâˆš this in our experiments and in particular chose  = log(d)/ d, so that Y was
[âˆ’ d, d]d . Note that Theorem 3 is not useful for this choice, which suggests that there is
room to improve this aspect of our theory.
Some careful readers may wonder about the effect of the extrinsic dimensionality D.
In the following theorem, we show that given the same intrinsic dimensions, the extrinsic
dimensionality does not have an effect at all; in other words, REMBO is invariant to the
addition of unimportant dimensions.
kBâˆ’1 xkâˆž <

Theorem 4 (Invariance to addition of unimportant dimensions). Let f : Rde â†’ R and for
any D âˆˆ N, D â‰¥ de , define fD : RD â†’ R such that fD adds D âˆ’ de truly unimportant
(D2 âˆ’D1 )Ã—d be random
dimensions to f : fD (z) = f (z1:de ). Let A1 âˆˆ RD1 Ã—d
 and
 A0 âˆˆ R
A1
Gaussian matrices with D2 â‰¥ D1 â‰¥ d and let A2 =
. Then, REMBO run using the
A0
9

Wang, Hutter, Zoghi, Matheson, & de Freitas

same dimension d â‰¥ de and bounded region Y yields exactly the same function values when
run with A1 on fD1 as when run with A2 on fD2 .
Proof. We only need to show that for each y âˆˆ Rd , we have fD1 (A1 y) = fD2 (A2 y) since
this step of REMBO (line 6 of Algorithm 2) is the only one that differs between the two
algorithm runs. When this function evaluation step yields the same results for every y âˆˆ Rd ,
then the two REMBO runs behave identically since the algorithm
 is otherwise identical
 and

A1
A1 y
deterministic after the selection of A in Step 1. Since A2 =
, we have A2 y =
.
A0
A0 y
Since D2 â‰¥ D1 â‰¥ de , the first de entries of this D2 Ã— 1 vector A2 y are the first de entries of
A1 y. We thus have fD1 (A1 y) = f ([A1 y]1:de ) = f ([A2 y]1:de ) = fD2 (A2 y).
Finally, we show that REMBO is also invariant to rotations in the sense that given different rotation matrices, running REMBO would result in the same distributions of observed
function values. The argument is made concise in the following results.
Lemma 5. Consider function f : RD â†’ R. Let fR : RD â†’ R be such that fR (x) = f (Rx)
for some orthonormal matrix R âˆˆ RDÃ—D . Then, REMBO run in bounded region Y yields
exactly the same sequence of function values when run with A on f as when run with Râˆ’1 A
on fR for a matrix A âˆˆ RDÃ—d .
Proof. REMBO uses f and A (resp. fR and Râˆ’1 A) only in one spot (in line 6). Thus, the
proof is trivial by showing that f (Ayt+1 ) = fR (Râˆ’1 Ayt+1 ) through simple algebra:
fR (Râˆ’1 Ayt+1 ) = f (RRâˆ’1 Ayt+1 ) = f (Ayt+1 ).

Theorem 6 (Invariance to rotations). Consider function f : RD â†’ R. Let fR : RD â†’ R
be such that fR (x) = f (Rx) for some orthonormal matrix R âˆˆ RDÃ—D . Then, given random
Gaussian matrices A1 âˆˆ RDÃ—d and A2 âˆˆ RDÃ—d , REMBO run in bounded region Y yields
in distribution the same sequence of function values when run with A1 on f as when run
with A2 on fR .
d

Proof. Since R is orthonormal, we have Râˆ’1 A1 = A2 . Therefore, REMBO run in bounded
region Y yields in distribution the same sequence of function values when run with Râˆ’1 A1
on fR as when run with A2 on fR . We have also by Lemma 5 that REMBO run in bounded
region Y yields exactly the same sequence of function values when run with A1 on f as when
run with Râˆ’1 A1 on fR . The conclusion follows from combining the previous arguments.
3.1 Increasing the Success Rate of REMBO
Theorem 3 only guarantees that Y contains the optimum with probability at least 1âˆ’; with
probability Î´ â‰¤  the optimizer lies outside of Y. There are several ways to guard against
this problem. One is to simply run REMBO multiple times with different independently
drawn random embeddings. Since the probability of failure with each embedding is Î´, the
probability of the optimizer not being included in the considered space of k independently
drawn embeddings is Î´ k . Thus, the failure probability vanishes exponentially quickly in
10

Bayesian Optimization in a Billion Dimensions

the number of REMBO runs, k. Note also that these independent runs can be trivially
parallelized to harness the power of modern multi-core machines and large compute clusters.
Another way of increasing REMBOâ€™s success rate is to increase
the dimensionality d

it uses internally. When d > de , with probability 1 we have dde different embeddings of
dimensionality de . That is, we only need to select de columns of A âˆˆ RDÃ—d to represent
the de relevant dimensions of x. The algorithm can achieve this by setting the remaining
d âˆ’ de sub-components of the d-dimensional vector y to zero. Informally, since we have
more embeddings, it is more likely that one of these will include the optimizer. In our
experiments, we will assess the merits and shortcomings of these two strategies.
3.2 Choice of Kernel
Since REMBO uses GP-based Bayesian optimization to search in the region Y âŠ‚ Rd , we
need to define a kernel between two points y(1) , y(2) âˆˆ Y. We begin with the standard
definition of the squared exponential kernel:
Definition 7. Let KSE (y) = exp(âˆ’kyk2 /2). Given a length scale ` > 0, we define the
corresponding squared exponential kernel as
!
y(1) âˆ’ y(2)
(2)
d (1)
k` (y , y ) = KSE
`
It is possible to work with two variants of this kernel. First, we can use k`d (y1 , y2 ) as in
Definition 7. We refer to this kernel as the low-dimensional kernel. We can also adopt an
implicitly defined high-dimensional kernel on X :
!
(1) ) âˆ’ p (Ay(2) )
p
(Ay
X
X
k`D (y(1) , y(2) ) = KSE
,
`
where pX : RD â†’ RD is the projection operator for our box-constraint as above (see
Figure 3).
Note that when using this high-dimensional kernel, we are fitting the GP in D dimensions. However, the search space is no longer the box X , but it is instead given by the much
smaller subspace {pX (Ay) : y âˆˆ Y}. Importantly, in practice it is easier to maximize the
acquisition function in this subspace.
Both kernel choices have strengths and weaknesses. The low-dimensional kernel has the
benefit of only requiring the construction of a GP in the space of intrinsic dimensionality
d, whereas the high-dimensional kernel requires the GP to be constructed in a space of
extrinsic dimensionality D. However, the low-dimensional kernel may waste time exploring
in the region of the embedding outside of X (see Figure 2) because two points far apart
in this region may be projected via pX to nearby points on the boundary of X . The highdimensional kernel is not affected by this problem because the search is conducted directly
on {pX (Ay) : y âˆˆ Y} with distances calculated in X and not in Y.
The choice of kernel also depends on whether our variables are continuous, integer or
categorical. The categorical case is important because we often encounter optimization
11

Wang, Hutter, Zoghi, Matheson, & de Freitas

Algorithm 3 Bayesian Optimization with Hyper-parameter Optimization.
input Threshold tÏƒ .
input Upper and lower bounds U > L > 0 for hyper-parameter.
input Initial length scale hyper-parameter ` âˆˆ [L, U ].
1: Initialize C = 0
2: for t = 1, 2, . . . do
3:
Find
p xt+1 by optimizing the acquisition function u: xt+1 = arg maxxâˆˆX u(x|Dt ).
4:
if Ïƒ 2 (xt+1 ) < tÏƒ then
5:
C =C +1
6:
else
7:
C=0
8:
end if
9:
Augment the data Dt+1 = {Dt , (xt+1 , f (xt+1 ))}
10:
if t mod 20 = 0 or C = 5 then
11:
if C = 5 then
12:
U = max{0.9`, L}
13:
C=0
14:
end if
15:
Learn the hyper-parameter by optimizing the log marginal likelihood by using
DIRECT and CMA-ES: ` = arg maxlâˆˆ[L,U ] log p(f1:t+1 |x1:t+1 , l)
16:
end if
17: end for
problems that contain discrete choices. We define our kernel for categorical variables as:


Î»
D (1)
(2)
(1)
(2) 2
kÎ» (y , y ) = exp âˆ’ h(s(Ay ), s(Ay )) ,
2
where y(1) , y(2) âˆˆ Y âŠ‚ Rd , the function s maps continuous d-dimensional vectors to discrete
D-dimensional vectors, and h defines the distance between two discrete vectors. In more
detail, s(x) first uses pX to project x to xÌ„ âˆˆ [âˆ’1, 1]D . For each dimension xÌ„i of xÌ„, s then
maps xÌ„i to a discrete value by scaling and rounding. In our experiments, following Hutter
(1)
(2)
(2009), we defined h(x(1) , x(2) ) = |{i : xi 6= xi }| so as not to impose an artificial ordering
between the values of categorical parameters. In essence, we measure the distance between
two points in the low-dimensional space as the Hamming distance between their mappings
in the high-dimensional space.
3.3 Hyper-parameter Optimization
For Bayesian optimization (and therefore REMBO), it is difficult to manually estimate
the true length scale hyper-parameter of a problem at hand. To avoid any manual steps and
to achieve robust performance across diverse sets of objective functions, in this paper we
adopted an adaptive hyper-parameter optimization scheme. The length scale of GPs is often
set by maximizing marginal likelihood (Rasmussen & Williams, 2006; Jones et al., 1998).
However, as demonstrated by Bull (2011), this approach, when implemented naively, may
not guarantee convergence. This is not only true of approaches that maximize the marginal
12

Bayesian Optimization in a Billion Dimensions

likelihood, but also of approaches that rely on Monte Carlo sampling from the posterior
distribution (Brochu, Brochu, & de Freitas, 2010; Snoek et al., 2012) when the number of
data is very small, unless the prior is very informative.
Here, we propose to optimize the length scale parameter ` by maximizing the marginal
likelihood subject to an upper bound U which is decreased when the algorithm starts
exploiting too much. Full details are given in Algorithm 3. We say that the algorithm
is
p exploiting when the standard deviation at the maximizer of the acquisition function
Ïƒ(xt+1 ) is less than some threshold tÏƒ for 5 consecutive iterations. Intuitively, this means
that the algorithm did not emphasize exploration (searching in new parts of the space,
where the predictive uncertainty is high) for 5 consecutive iterations. When this criterion
is met, the algorithm decreases its upper bound U multiplicatively and re-optimizes the
hyper-parameter subject to the new bound. Even when the criterion is not met the hyperparameter is re-optimized every 20 iterations. For each optimization of the acquisition
function, the algorithm runs both DIRECT (Jones et al., 1993) and CMA-ES (Hansen &
Ostermeier, 2001) and uses the result of the best of the two options. The astute reader may
wonder about the difficulty of optimizing the acquisition functions. For REMBO, however,
we have not found the optimization of the acquisition function to be a problem since we only
need to optimize it in the low-dimensional space and our acquisition function evaluations
are cheap, allowing us tens of thousands of evaluations in seconds that (empirically) suffice
to cover the low-dimensional space well.
The motivation of this algorithm is to rather err on the side of having too small a length
scale: given a squared exponential kernel k` , with a smaller length scale than another kernel
k, one can show that any function f in the RKHS characterized by k is also an element of the
RKHS characterized by k` . Thus, when running expected improvement, one can safely use
k` instead of k as the kernel of the GP and still preserve convergence (Bull, 2011). We argue
that (with a small enough lower bound L) the algorithm would eventually reduce the upper
bound enough to allow convergence. Also, the algorithm would not explore indefinitely as
L is required to be positive. In our experiments, we set the initial constraint [L, U ] to be
[0.01, 50] and set tÏƒ = 0.002.
We want to stress the fact that the above argument is only known to hold for a class
of kernels over continuous domains (e.g. squared exponential and MateÌrn class kernels).
Although we believe that a similar argument could be made for integer and categorical
kernels, rigorous arguments concerning convergence under these kernels remain a challenge
in Bayesian optimization.

4. Experiments
We now study REMBO empirically. We first use synthetic functions of small intrinsic dimensionality de = 2 but extrinsic dimension D up to 1 billion to demonstrate REMBOâ€™s
independence of D. Then, we apply REMBO to automatically optimize the 47 parameters of a widely-used mixed integer linear programming solver and demonstrate that it
achieves state-of-the-art performance. However, we also warn against the blind application
of REMBO. To illustrate this, we study REMBOâ€™s performance for tuning the 14 parameters of a random forest body part classifier used by Kinect. In this application, all the
D = 14 parameters appear to be important, and while REMBO (based on d = 3) finds
13

Wang, Hutter, Zoghi, Matheson, & de Freitas

reasonable solutions (better than random search and comparable to what domain experts
achieve), standard Bayesian optimization can outperform REMBO (and the domain experts) in such moderate-dimensional spaces. More optimistically, this random forest tuning
application shows that REMBO does not fail catastrophically when it is not clear that the
optimization problem has low effective dimensionality.
4.1 Experimental Setup
For all our experiments, we used a single robust version of REMBO that automatically sets
its GPâ€™s length scale parameter as described in Section 3.3. The code for REMBO, as well as
all data used in our experiments is publicly available at https://github.com/ziyuw/rembo.
Some of our experiments required substantial computational resources, with the computational expense of each experiment depending mostly on the cost of evaluating the
respective black-box function. While the synthetic experiments in Section 4.2 only required
minutes for each run of each method, optimizing the mixed integer programming solver
in Section 4.4 required 4-5 hours per run, and optimizing the random forest classifier in
Section 4.5 required 4-5 days per run. In total, we used over half a year of CPU time for
the experiments in this paper. In the first two experiments, we study the effect of our
two methods for increasing REMBOâ€™s success rate (see Section 3.1) by running different
numbers of independent REMBO runs with different settings of its internal dimensionality
d.
4.2 Bayesian Optimization in a Billion Dimensions
The experiments in this section employ a standard de = 2-dimensional benchmark function
for Bayesian optimization, embedded in a D-dimensional space. That is, we add D âˆ’ 2
additional dimensions which do not affect the function at all. More precisely, the function
whose optimum we seek is f (x1:D ) = g(xi , xj ), where g is the Branin function
g(x1 , x2 ) = (x2 âˆ’

5.1 2 5
1
x1 + x1 âˆ’ 6)2 + 10(1 âˆ’
) cos(x1 ) + 10
2
4Ï€
Ï€
8Ï€

and where i and j are selected once using a random permutation. To measure the performance of each optimization method, we used the optimality gap: the difference of the best
function value it found and the optimal function value.
We evaluate REMBO using a fixed budget of 500 function evaluations that is spread
across multiple interleaved runs â€” for example, when using k = 4 interleaved REMBO runs,
each of them was only allowed 125 function evaluations. We study the choices of k and d by
considering several combinations of these values. The results in Table 1 demonstrate that
interleaved runs helped improve REMBOâ€™s performance. We note that in 13/50 REMBO
runs, the global optimum was indeed not contained in the box Y REMBO searched with
d = 2; this is the reason for the poor mean performance of REMBO with d = 2 and k = 1.
However, the remaining 37 runs performed very well, and REMBO thus performed well
when using multiple interleaved runs: with a failure rate of 13/50=0.26 per independent
run, the failure rate using k = 4 interleaved runs is only 0.264 â‰ˆ 0.005. One could easily
achieve an arbitrarily small failure rate by using many independent parallel runs. Using a
larger d is also effective in increasing the probability of the optimizer falling into REMBOâ€™s
14

Bayesian Optimization in a Billion Dimensions

Figure 4: Comparison of random search (RANDOM), Bayesian optimization (BO), method
by Chen et al. (2012) (HD BO), and REMBO. Left: D = 25 extrinsic dimensions;
Right: D = 25, with a rotated objective function; Bottom: D = 109 extrinsic
dimensions. We plot means and 1/4 standard deviation confidence intervals of
the optimality gap across 50 trials.

box Y but at the same time slows down REMBOâ€™s convergence (such that interleaving
several short runs loses its effectiveness).
Next, we compared REMBO to standard Bayesian optimization (BO) and to random
search, for an extrinsic dimensionality of D = 25. Standard BO is well known to perform
well in low dimensions, but to degrade above a tipping point of about 15-20 dimensions.
Our results for D = 25 (see Figure 4, left) confirm that BO performed rather poorly just
above this critical dimensionality (merely tying with random search). REMBO, on the
other hand, still performed very well in 25 dimensions.
One important advantage of REMBO is that â€” in contrast to the approach of Chen
et al. (2012) â€” it does not require the effective dimension to be coordinate aligned. To
demonstrate this fact empirically, we rotated the embedded Branin function by an orthogonal rotation matrix R âˆˆ RDÃ—D . That is, we replaced f (x) by f (Rx). Figure 4 (middle)
shows that REMBOâ€™s performance is not affected by this rotation.
Finally, since REMBO is independent of the extrinsic dimensionality D as long as the
intrinsic dimensionality de is small, it performed just as well in D = 1 000 000 000 dimensions
15

Wang, Hutter, Zoghi, Matheson, & de Freitas

k
10
5
4
2
1

d=2
0.0022 Â± 0.0035
0.0004 Â± 0.0011
0.0001 Â± 0.0003
0.1514 Â± 0.9154
0.7406 Â± 1.8996

d=4
0.1553 Â± 0.1601
0.0908 Â± 0.1252
0.0654 Â± 0.0877
0.0309 Â± 0.0687
0.0143 Â± 0.0406

d=6
0.4865 Â± 0.4769
0.2586 Â± 0.3702
0.3379 Â± 0.3170
0.1643 Â± 0.1877
0.1137 Â± 0.1202

Table 1: Optimality gap for de = 2-dimensional Branin function embedded in D = 25
dimensions, for REMBO variants using a total of 500 function evaluations. The
variants differed in the internal dimensionality d and in the number of interleaved
runs k (each such run was only allowed 500/k function evaluations). We show
mean and standard deviations of the optimality gap achieved after 500 function
evaluations.

(see Figure 4, right). To the best of our knowledge, the only other existing method that
can be run in such high dimensionality is random search.
For reference, we also evaluated the method of Chen et al. (2012) for these functions,
confirming that it does not handle rotation gracefully: while it performed best in the nonrotated case for D = 25, it performed worst in the rotated case. It could not be used
efficiently for more than D = 1, 000. Based on a Mann-Whitney U test with Bonferroni
multiple-test correction, all performance differences were statistically significant, except
Random vs. standard BO. Finally, comparing REMBO to the method of Chen et al. (2012),
we also note that REMBO is much simpler to implement and that its results are very reliable
(with interleaved runs).
4.3 Synthetic Discrete Experiment
In this section, we test the high-dimensional kernel with a synthetic experiment. Specifically,
we again optimize the Branin function, but restrict its domain to 225 discrete points on a
regular grid. As above, we added 23 additional irrelevant dimensions to make the problem
25-dimensional in total.
We used a small fixed budget of 100 function evaluations for all algorithms involved
as the problem would require no more than 225 evaluations to be solved completely. We
used k = 4 interleaved runs for REMBO. We again compare REMBO to random search
and standard BO. For REMBO, we use the high-dimensional kernel to handle the discrete
nature of the problem. The result of the comparison is summarized in Figure 5. Standard
BO again suffered from the high extrinsic dimensionality and performed slightly worse than
random search. REMBO, on the other hand, performed well in this setting.
4.4 Automatic Configuration of a Mixed Integer Linear Programming Solver
State-of-the-art algorithms for solving hard computational problems tend to parameterize
several design choices in order to allow a customization of the algorithm to new problem domains. Automated methods for algorithm configuration have recently demonstrated
that substantial performance gains of state-of-the-art algorithms can be achieved in a fully
16

Bayesian Optimization in a Billion Dimensions

Figure 5: Comparison of random search (RANDOM), Bayesian optimization (BO), and
REMBO. D = 25 extrinsic dimensions. We plot means and 1/4 standard deviation confidence intervals of the optimality gap across 50 trials.

automated fashion (MocÌŒkus, MocÌŒkus, & MocÌŒkus, 1999; Hutter, Hoos, Leyton-Brown, &
StuÌˆtzle, 2009; Hutter, Hoos, & Leyton-Brown, 2010; Vallati, Fawcett, Gerevini, Hoos, &
Saetti, 2011; Bergstra et al., 2011; Wang & de Freitas, 2011). These successes have led
to a paradigm shift in algorithm development towards the active design of highly parameterized frameworks that can be automatically customized to particular problem domains
using optimization (Hoos, 2012; Bergstra et al., 2013; Thornton et al., 2013). The resulting algorithm configuration problems have been shown to have low dimensionality (Hutter
et al., 2014), and here, we demonstrate that REMBO can exploit this low dimensionality
even in the discrete spaces typically encountered in algorithm configuration. We use a configuration problem obtained from Hutter et al. (2010), aiming to configure the 40 binary
and 7 categorical parameters of lpsolve (Berkelaar, Eikland, & Notebaert, 2016) , a popular
mixed integer programming (MIP) solver that has been downloaded over 40 000 times in
the last year. The objective is to minimize the optimality gap lpsolve can obtain in a time
limit of five seconds for a MIP encoding of a wildlife corridor problem from computational
sustainability (Gomes, van Hoeve, & Sabharwal, 2008). Algorithm configuration usually
aims to improve performance for a representative set of problem instances, and effective
methods need to solve two orthogonal problems: searching the parameter space effectively
and deciding how many instances to use in each evaluation (to trade off computational overhead and over-fitting). Our contribution is for the first of these problems; to focus on how
effectively the different methods search the parameter space, we only consider configuration
on a single problem instance.
Due to the discrete nature of this optimization problem, we could only apply REMBO
using the high-dimensional kernel for categorical variables kÎ»D (y(1) , y(2) ) described in Section 3.2. While we have not proven any theoretical guarantees for discrete optimization
17

Wang, Hutter, Zoghi, Matheson, & de Freitas

Figure 6: Performance of various methods for configuration of lpsolve; we show the optimality gap lpsolve achieved with the configurations found by the various methods (lower is better). Left: a single run of each method; Right: performance with
k = 4 interleaved runs.

problems, REMBO appears to effectively exploit the low effective dimensionality of at least
this particular optimization problem.
Figure 6 (left) compares BO, REMBO, and the baseline random search against ParamILS
(Hutter et al., 2009) and SMAC (Hutter et al., 2011). ParamILS and SMAC were specifically
designed for the configuration of algorithms with many discrete parameters and define the
current state of the art for this problem. Nevertheless, here SMAC and our vanilla REMBO
method performed best. Based on a Mann-Whitney U test with Bonferroni multiple-test
correction, they both yielded statistically significantly better results than both Random
and standard BO; no other performance differences were significant. The figure only shows
REMBO with d = 5 to avoid clutter, but we did not optimize this parameter; the only
other value we tried (d = 3) resulted in indistinguishable .
As in the synthetic experiment, REMBOâ€™s performance could be further improved by
using multiple interleaved runs. However, as shown by Hutter, Hoos, and Leyton-Brown
(2012), multiple independent runs can also improve the performance of SMAC and especially
ParamILS. Thus, to be fair, we re-evaluated all approaches using interleaved runs. Figure
6 (right) shows that ParamILS and REMBO benefitted most from interleaving k = 4 runs.
However, the statistical test results did not change, still showing that SMAC and REMBO
outperformed Random and BO, with no other significant performance differences.
4.5 Automatic Configuration of Random Forest Kinect Body Part Classifier
We now evaluate REMBOâ€™s performance for optimizing the 14 parameters of a random
forest body part classifier. This classifier closely follows the proprietary system used in the
Microsoft Kinect (Shotton, Fitzgibbon, Cook, Sharp, Finocchio, Moore, Kipman, & Blake,
2011) and is available at https://github.com/david-matheson/rftk.
18

Bayesian Optimization in a Billion Dimensions

Figure 7: Left: ground truth depth, ground truth body parts and predicted body parts;
Right: features specified by offsets u and v.

We begin by describing some details of the dataset and classifier in order to build
intuition for the objective function and the parameters being optimized. The data we
used consists of pairs of depth images and ground truth body part labels. Specifically,
we used 1 500 pairs of 320x240 resolution depth and body part images, each of which was
synthesized from a random pose of the CMU mocap dataset. Depth, ground truth body
parts and predicted body parts (as predicted by the classifier described below) are visualized
for one pose in Figure 7 (left). There are 19 body parts plus one background class. For each
of these 20 possible labels, the training data contained 25 000 pixels, randomly selected from
500 training images. Both validation and test data contained all pixels in the 500 validation
and test images, respectively.
The random forest classifier is applied to one pixel P at a time. At each node of each of
its decision trees, it computes the depth difference between two pixels described by offsets
from P and compares this to a threshold. At training time, many possible pairs of offsets
are generated at random, and the pair yielding highest information gain for the training
data points is selected. Figure 7 (right) visualizes a potential feature for the pixel in the
green box: it computes the depth difference between the pixels in the red box and the white
box, specified by respective offsets u and v. At training time, u and v are drawn from two
independent 2-dimensional Gaussian distributions, each of which is parameterized by its
two mean parameters Âµ1 and Âµ2 and three covariance terms Î£11 , Î£12 , and Î£22 (Î£21 = Î£12
because of symmetry). These constitute 10 of the parameters that need to be optimized,
with range [-50,50] for the mean components and [1, 200] for the covariance terms. Low
covariance terms yield local features, while high terms yield global features. Next to these
ten parameters, the random forest classifier has four other standard parameters, outlined
in Table 2. It is well known in computer vision that many of the parameters described here
are important. Much research has been devoted to identifying their best values, but results
are dataset specific, without definitive general answers.
The objective in optimizing these RF classifier parameters is to find a parameter setting
that learns the best classifier in a given time budget of five minutes. To enable competitive
performance in this short amount of time, at each node of the tree only a random subset of
19

Wang, Hutter, Zoghi, Matheson, & de Freitas

Table 2: Parameter ranges for random forest classifier. For the purpose of optimization,
the maximum tree depth and the number of potential offsets were transformed to
log space.
Parameter

Range

Max. tree depth
Min. No. samples for non leaf nodes
No. potential offsets to evaluate
Bootstrap for per tree sampling

[1 60]
[1 100]
[1 5000]
[T F]

data points is considered. Also note that the above parameters do not include the number
of trees T in the random forest; since performance improves monotonically in T , we created
as many trees as possible in the time budget. Trees are constructed depth first and returned
in their current state when the time budget is exceeded. Using a fixed budget results in
a subtle optimization problem because of the complex interactions between the various
parameters (maximum depth, number of potential offsets, number of trees and accuracy).
It is unclear a priori whether a low-dimensional subspace of these 14 interacting parameters exists that captures the classification accuracy of the resulting random forests.
We performed large-scale computational experiments with REMBO, random search, and
standard Bayesian optimization (BO) to study this question. In this experiment, we used
the high-dimensional kernel for REMBO to avoid the potential over-exploration problems
of the low-dimensional kernel described in Section 3.2. We believed that D = 14 dimensions
would be small enough to avoid inefficiencies in fitting the GP in D dimensions. This belief
was confirmed by the observation that standard BO (which operates in D = 14 dimensions)
performed well for this problem.
Figure 8 (left) shows the results that can be obtained by a single run of random search,
BO, and REMBO. Remarkably, REMBO clearly outperformed random search, even based
on as few as d = 3 dimensions.2 However, since the extrinsic dimensionality was â€œonlyâ€
a moderate D = 14, standard Bayesian optimization performed well, and since it was
not limited to a low-dimensional subspace it outperformed REMBO. Nevertheless, several
REMBO runs actually performed very well, comparably with the best runs of BO. Consequently, when running k = 4 interleaved runs of each method, REMBO performed almost
as well as BO, matching its performance up to about 450 function evaluations (see Figure
8, right).
We conclude that the parameter space of this RF classifier does not appear to have a
clear low effective dimensionality; since the extrinsic dimensionality is only moderate, this
leads REMBO to perform somewhat worse than standard Bayesian optimization, but it is
still possible to achieve reasonable performance based on as little as d = 3 dimensions.
2. Due to the large computational expense of this experiment (in total over half a year of CPU time), we
only performed conclusive experiments with d = 3; preliminary runs of REMBO with d = 4 performed
somewhat worse than those with d = 3 for a budget of 200 function evaluations, but were still improving
at that point.

20

Bayesian Optimization in a Billion Dimensions

Figure 8: Performance of various methods for optimizing RF parameters for body part
classification. For all methods, we show RF accuracy (mean Â± 1/4 standard
deviation across 10 runs) for all 2.2 million non background pixels in the 500pose validation set, using the RF parameters identified by the method. The
results on the test set were within 1% of the results on the validation set. Left:
performance with a single run of each method; Right: performance with k = 4
interleaved runs.

5. Conclusion
We have demonstrated that it is possible to use random embeddings in Bayesian optimization to optimize functions of extremely high extrinsic dimensionality D provided that
they have low intrinsic dimensionality de . Moreover, our resulting REMBO algorithm is
coordinate independent and it only requires a simple modification of the original Bayesian
optimization algorithm; namely multiplication by a random matrix. We proved REMBOâ€™s
independence of D theoretically and empirically validated it by optimizing low-dimensional
functions embedded in previously untenable extrinsic dimensionalities of up to 1 billion.
We also theoretically and empirically showed REMBOâ€™s rotational invariance. Finally, we
demonstrated that REMBO achieves state-of-the-art performance for optimizing the 47 discrete parameters of a popular mixed integer programming solver, thereby providing further
evidence for the observation (already put forward by Bergstra, Hutter and colleagues) that,
for many problems of great practical interest, the number of important dimensions indeed
appears to be much lower than their extrinsic dimensionality.
We note that the central idea of our work â€“ using an otherwise unmodified optimization procedure in a randomly embedded space â€“ in principle could be applied to arbitrary
optimization procedures. Evaluating the effciency of this technique for other procedures is
an interesting topic for future work.

Acknowledgements
We thank Christof SchoÌˆtz for proofreading a draft of this article.
21

Wang, Hutter, Zoghi, Matheson, & de Freitas

References
Azimi, J., Fern, A., & Fern, X. (2010). Batch Bayesian optimization via simulation matching.
In Advances in Neural Information Processing Systems, pp. 109â€“117.
Azimi, J., Fern, A., & Fern, X. (2011). Budgeted optimization with concurrent stochasticduration experiments. In Advances in Neural Information Processing Systems, pp.
1098â€“1106.
Azimi, J., Jalali, A., & Fern, X. (2012). Hybrid batch Bayesian optimization. In International Conference on Machine Learning.
Bergstra, J., Bardenet, R., Bengio, Y., & KeÌgl, B. (2011). Algorithms for hyper-parameter
optimization. In Advances in Neural Information Processing Systems, pp. 2546â€“2554.
Bergstra, J., & Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13, 281â€“305.
Bergstra, J., Yamins, D., & Cox, D. D. (2013). Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In
International Conference on Machine Learning, pp. 115â€“123.
Berkelaar, M., Eikland, K., & Notebaert, P. (2016). lpsolve : Open source (Mixed-Integer)
Linear Programming system. http://lpsolve.sourceforge.net/.
Brochu, E., Brochu, T., & de Freitas, N. (2010). A Bayesian interactive optimization
approach to procedural animation design. In Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, pp. 103â€“112.
Brochu, E., Cora, V. M., & de Freitas, N. (2009). A tutorial on Bayesian optimization of
expensive cost functions, with application to active user modeling and hierarchical
reinforcement learning. Tech. rep. UBC TR-2009-23 and arXiv:1012.2599v1, Dept. of
Computer Science, University of British Columbia.
Brochu, E., de Freitas, N., & Ghosh, A. (2007). Active preference learning with discrete
choice data. In Advances in Neural Information Processing Systems, pp. 409â€“416.
Bubeck, S., Munos, R., Stoltz, G., & Szepesvari, C. (2011). X-armed bandits. Journal of
Machine Learning Research, 12, 1655â€“1695.
Bull, A. D. (2011). Convergence rates of efficient global optimization algorithms. Journal
of Machine Learning Research, 12, 2879â€“2904.
Carpentier, A., & Munos, R. (2012). Bandit theory meets compressed sensing for high
dimensional stochastic linear bandit. In Artificial Intelligence and Statistics, pp. 190â€“
198.
Chen, B., Castro, R., & Krause, A. (2012). Joint optimization and variable selection of highdimensional Gaussian processes. In International Conference on Machine Learning.
de Freitas, N., Smola, A., & Zoghi, M. (2012). Exponential regret bounds for Gaussian process bandits with deterministic observations. In International Conference on Machine
Learning.
Denil, M., Bazzani, L., Larochelle, H., & de Freitas, N. (2012). Learning where to attend
with deep architectures for image tracking. Neural Computation, 24 (8), 2151â€“2184.
22

Bayesian Optimization in a Billion Dimensions

Djolonga, J., Krause, A., & Cevher, V. (2013). High dimensional Gaussian process bandits.
In Advances in Neural Information Processing Systems, pp. 1025â€“1033.
Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., & Leyton-Brown,
K. (2013). Towards an empirical foundation for assessing Bayesian optimization of
hyperparameters. In NIPS Workshop on Bayesian Optimization in Theory and Practice.
Frazier, P., Powell, W., & Dayanik, S. (2009). The knowledge-gradient policy for correlated
normal beliefs. INFORMS journal on Computing, 21 (4), 599â€“613.
Gomes, C. P., van Hoeve, W., & Sabharwal, A. (2008). Connections in networks: A hybrid
approach. In International Conference on Integration of Artificial Intelligence and
Operations Research, Vol. 5015, pp. 303â€“307.
Gramacy, R. B., Lee, H. K. H., & Macready, W. G. (2004). Parameter space exploration
with Gaussian process trees. In International Conference on Machine Learning, pp.
45â€“52.
Gramacy, R., & Polson, N. (2011). Particle learning of gaussian process models for sequential
design and optimization. Journal of Computational and Graphical Statistics, 20 (1),
102â€“118.
Hamze, F., Wang, Z., & de Freitas, N. (2013). Self-avoiding random dynamics on integer
complex systems. ACM Transactions on Modelling and Computer Simulation, 23 (1),
9:1â€“9:25.
Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution
strategies. Evolutionary Computation, 9 (2), 159â€“195.
Hennig, P., & Schuler, C. (2012). Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 98888, 1809â€“1837.
Hoffman, M., Brochu, E., & de Freitas, N. (2011). Portfolio allocation for Bayesian optimization. In Uncertainty in Artificial Intelligence, pp. 327â€“336.
Hoffman, M., Kueck, H., de Freitas, N., & Doucet, A. (2009). New inference strategies for
solving Markov decision processes using reversible jump MCMC. In Uncertainty in
Artificial Intelligence, pp. 223â€“231.
Hoffman, M., Shahriari, B., & de Freitas, N. (2014). On correlation and budget constraints
in model-based bandit optimization with application to automatic machine learning.
In Artificial Intelligence and Statistics.
Hoos, H. H. (2012). Programming by optimization. Communications of the ACM, 55 (2),
70â€“80.
Hutter, F. (2009). Automated Configuration of Algorithms for Solving Hard Computational
Problems. Ph.D. thesis, University of British Columbia, Vancouver, Canada.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2014). An efficient approach for assessing
hyperparameter importance. In International Conference on Machine Learning.
Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2010). Automated configuration of mixed
integer programming solvers. In Conference on Integration of Artificial Intelligence
and Operations Research, pp. 186â€“202.
23

Wang, Hutter, Zoghi, Matheson, & de Freitas

Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2011). Sequential model-based optimization
for general algorithm configuration. In Learning and Intelligent Optimization, pp.
507â€“523.
Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2012). Parallel algorithm configuration. In
Learning and Intelligent Optimization, pp. 55â€“70.
Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2013). An evaluation of sequential modelbased optimization for expensive blackbox functions. In Proceedings of GECCO-13
Workshop on Blackbox Optimization Benchmarking (BBOBâ€™13).
Hutter, F., Hoos, H. H., Leyton-Brown, K., & StuÌˆtzle, T. (2009). ParamILS: an automatic
algorithm configuration framework. Journal of Artificial Intelligence Research, 36,
267â€“306.
Jones, D. R., Perttunen, C. D., & Stuckman, B. E. (1993). Lipschitzian optimization without
the Lipschitz constant. J. of Optimization Theory and Applications, 79 (1), 157â€“181.
Jones, D. (2001). A taxonomy of global optimization methods based on response surfaces.
Journal of Global Optimization, 21 (4), 345â€“383.
Jones, D., Schonlau, M., & Welch, W. (1998). Efficient global optimization of expensive
black-box functions. Journal of Global optimization, 13 (4), 455â€“492.
Kueck, H., de Freitas, N., & Doucet, A. (2006). SMC samplers for Bayesian optimal nonlinear design. In IEEE Nonlinear Statistical Signal Processing Workshop, pp. 99â€“102.
Kueck, H., Hoffman, M., Doucet, A., & de Freitas, N. (2009). Inference and learning for
active sensing, experimental design and control. In Pattern Recognition and Image
Analysis, Vol. 5524, pp. 1â€“10.
Lizotte, D., Greiner, R., & Schuurmans, D. (2011). An experimental methodology for
response surface optimization methods. Journal of Global Optimization, 53 (4), 1â€“38.
Lizotte, D., Wang, T., Bowling, M., & Schuurmans, D. (2007). Automatic gait optimization
with Gaussian process regression. In International Joint Conference on Artificial
Intelligence, pp. 944â€“949.
Mahendran, N., Wang, Z., Hamze, F., & de Freitas, N. (2012). Adaptive MCMC with
Bayesian optimization. Journal of Machine Learning Research - Proceedings Track,
22, 751â€“760.
Marchant, R., & Ramos, F. (2012). Bayesian optimisation for intelligent environmental
monitoring. In NIPS workshop on Bayesian Optimization and Decision Making.
Martinez-Cantin, R., de Freitas, N., Doucet, A., & Castellanos, J. A. (2007). Active policy
learning for robot planning and exploration under uncertainty. In Robotics, Science
and Systems.
MocÌŒkus, J. (1982). The Bayesian approach to global optimization. In Systems Modeling
and Optimization, Vol. 38, pp. 473â€“481. Springer.
MocÌŒkus, J. (1994). Application of Bayesian approach to numerical methods of global and
stochastic optimization. J. of Global Optimization, 4 (4), 347â€“365.
24

Bayesian Optimization in a Billion Dimensions

MocÌŒkus, J., MocÌŒkus, A., & MocÌŒkus, L. (1999). Bayesian approach for randomization of
heuristic algorithms of discrete programming. American Math. Society.
Osborne, M. A., Garnett, R., & Roberts, S. J. (2009). Gaussian processes for global optimisation. In Learning and Intelligent Optimization, pp. 1â€“15.
Rasmussen, C. E. (2003). Gaussian processes to speed up hybrid Monte Carlo for expensive
Bayesian integrals. In Bayesian Statistics 7.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes for Machine Learning.
The MIT Press.
Rudelson, M., & Vershynin, R. (2010). Non-asymptotic theory of random matrices: Extreme
singular values. In International Congress of Mathematicians, pp. 1576â€“1599.
Sankar, A., Spielman, D., & Teng, S. (2003). Smoothed analysis of the condition numbers
and growth factors of matrices. Tech. rep. Arxiv preprint cs/0310022, MIT.
Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., Kipman, A.,
& Blake, A. (2011). Real-time human pose recognition in parts from single depth
images. In IEEE Computer Vision and Pattern Recognition, pp. 1297â€“1304.
Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems,
pp. 2960â€“2968.
Srinivas, N., Krause, A., Kakade, S. M., & Seeger, M. (2010). Gaussian process optimization
in the bandit setting: No regret and experimental design. In International Conference
on Machine Learning, pp. 1015â€“1022.
Steinwart, I., & Christmann, A. (2008). Support Vector Machines. Springer.
Swersky, K., Snoek, J., & Adams, R. P. (2013). Multi-task Bayesian optimization. In
Advances in Neural Information Processing Systems, pp. 2004â€“2012.
Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another
in view of the evidence of two samples. Biometrika, 25 (3/4), 285â€“294.
Thornton, C., Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2013). Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In ACM
SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 847â€“855.
Vallati, M., Fawcett, C., Gerevini, A. E., Hoos, H. H., & Saetti, A. (2011). Generating
fast domain-optimized planners by automatically configuring a generic parameterised
planner. In ICAPS Planning and Learning Workshop.
Vazquez, E., & Bect, J. (2010). Convergence properties of the expected improvement algorithm with fixed mean and covariance functions. Journal of Statistical Planning and
Inference, 140, 3088â€“3095.
Wang, Z., & de Freitas, N. (2011). Predictive adaptation of hybrid Monte Carlo with
Bayesian parametric bandits. In NIPS Deep Learning and Unsupervised Feature Learning Workshop.
Wang, Z., & de Freitas, N. (2014). Bayesian multiscale optimistic optimization. In Artificial
Intelligence and Statistics.
25

Wang, Hutter, Zoghi, Matheson, & de Freitas

Wang, Z., Zoghi, M., Hutter, F., Matheson, D., & de Freitas, N. (2013). Bayesian optimization in high dimensions via random embeddings. In International Joint Conference
on Artificial Intelligence, pp. 1778â€“1784.

Appendix A. Proof of Theorem 2
Proof. Since f has effective dimensionality de , there exists an effective subspace T âŠ‚ RD ,
such that rank(T ) = de . Furthermore, any x âˆˆ RD decomposes as x = x> + xâŠ¥ , where
x> âˆˆ T and xâŠ¥ âˆˆ T âŠ¥ . Hence, f (x) = f (x> + xâŠ¥ ) = f (x> ). Therefore, without loss of
generality, it will suffice to show that for all x> âˆˆ T , there exists a y âˆˆ Rd such that
f (x> ) = f (Ay).
Let Î¦ âˆˆ RDÃ—de be a matrix, whose columns form an orthonormal basis for T . Hence,
for each x> âˆˆ T , there exists a c âˆˆ Rde such that x> = Î¦c. Let us for now assume that
Î¦T A has rank de . If Î¦T A has rank de , there exists a y such that (Î¦T A)y = c. The
orthogonal projection of Ay onto T is given by
Î¦Î¦T Ay = Î¦c = x> .
Thus Ay = x> + x0 for some x0 âˆˆ T âŠ¥ since x> is the projection Ay onto T . Consequently,
f (Ay) = f (x> + x0 ) = f (x> ).
It remains to show that, with probability one, the matrix Î¦T A has rank de . Let
Ae âˆˆ RDÃ—de be a submatrix of A consisting of any de columns of A, which are i.i.d. samples distributed according to N (0, I). Then, Î¦T ai are i.i.d. samples from N (0, Î¦T Î¦) =
2
N (0de , Ide Ã—de ), and so we have Î¦T Ae , when considered as an element of Rde , is a sample
2
from N (0d2e , Id2e Ã—d2e ). On the other hand, the set of singular matrices in Rde has Lebesgue
measure zero, since it is the zero set of a polynomial (i.e. the determinant function) and
polynomial functions are Lebesgue measurable. Moreover, the Normal distribution is absolutely continuous with respect to the Lebesgue measure, so our matrix Î¦T Ae is almost
surely non-singular, which means that it has rank de and so the same is true of Î¦T A, whose
columns contain the columns of Î¦T Ae .

Appendix B. Proof of Theorem 3
Proof. Since X is a box constraint, by projecting x? to T we get x?> âˆˆ T âˆ© X . Also, since
x? = x?> + xâŠ¥ for some xâŠ¥ âˆˆ T âŠ¥ , we have f (x? ) = f (x?> ). Hence, x?> is an optimizer. By
using the same argument as appeared in Proposition 1, it is easy to see that with probability
1 âˆ€x âˆˆ T âˆƒy âˆˆ Rd such that Ay = x + xâŠ¥ where xâŠ¥ âˆˆ T âŠ¥ . Let Î¦ be the matrix whose
columns form a standard basis for T . Without loss of generality, we can assume that
 
I
Î¦ = de
0
Then, as shown in Proposition 2, there exists a y? âˆˆ Rd such that Î¦Î¦T Ay? = x?> . Note
that for each column of A, we have
 

Ide 0
T
Î¦Î¦ ai âˆ¼ N 0,
.
0 0
26

Bayesian Optimization in a Billion Dimensions

Therefore Î¦Î¦T Ay? = x?> is equivalent to By? = xÌ„?> where B âˆˆ Rde Ã—de is a random matrix
with independent standard Gaussian entries and xÌ„?> is the vector that contains the first de
entries of x?> (the rest are 0â€™s). By Theorem 3.4 of (Sankar, Spielman, & Teng, 2003), we
have
âˆš 

de
âˆ’1
P kB k2 â‰¥
â‰¤ .

Thus, with probability at least 1âˆ’, ky? k â‰¤ kBâˆ’1 k2 kxÌ„?> k2 = kBâˆ’1 k2 kx?> k2 â‰¤

âˆš

de
?
 kx> k2 .

Appendix C. Regret Bounds
In this section, we provide regret results for REMBO in the special case that (1) the embedded subspace has the same dimension as the effective dimension and (2) the embedded
subspace contains a maximum of the function f inside the box X . More specifically, here
we will analyze a simplified version of the algorithm that performs Bayesian optimization
only inside the box X rather than considering its extension beyond X and projecting onto
the boundary of X as done in our actual implementation.
We acknowledge that this mismatch between the theoretical results and our actual
algorithm is rather unsatisfactory. However, some of the obstacles that stand in the way of
a complete analysis of the algorithm are currently insurmountable, since they would require
the development of new tools that are far beyond the scope of this paper. We point these
out at the end of this section and hope that our partial result will motivate the development
of such tools, which might not otherwise receive any attention from the community.
We begin our mathematical treatment with the definitions of simple regret and the skew
squared exponential (SSE) kernel.
Definition 8. Given a function f : X â†’ R and a sequence of points {xt }âˆž
t=1 âŠ† X , the
simple regret with respect to the set X at time T is defined to be rf (T ) = supX f âˆ’
T

max f (xt ).
t=1

Definition 9. Given a symmetric, positive-definite matrix âˆ† and KSE , we define the corresponding skew squared exponential kernel as


kâˆ† (y(1) , y(2) ) = KSE âˆ†âˆ’1/2 (y(1) âˆ’ y(2) ) .
Given âˆ†, and X âŠ† Rd , we denote the Reproducing Kernel Hilbert Spaces (RKHSs)
corresponding to kâˆ† by Hkâˆ† (Steinwart & Christmann, 2008, Definition 4.18). Note that
for the setting âˆ† = `2 I we recover the squared exponential kernel k`d introduced earlier. To
simplify notation, we introduce yet another definition.
Definition 10. Consider the function f : S â†’ R, where S âŠ‚ RD is a d-dimensional
subspace of RD . Let Î¦ âˆˆ RDÃ—d be a matrix whose columns form an orthonormal basis for
S. We define the canonical representation f : Rd â†’ R of f as f (x) = f (Î¦x).
Our main result below shows that the simple regret of a variation of REMBO vanishes
1
with rate O(tâˆ’ d ) with high probability. This REMBO variant uses a fixed kernel parameter
length scale ` and, more importantly, restricts its search to its embedding inside the box X .
27

Wang, Hutter, Zoghi, Matheson, & de Freitas

We only make the assumption that the cost function restricted to T is governed by a
skew squared exponential kernel, a much weaker assumption than the standard assumption
that the cost function is governed by an axis aligned kernel in D dimensions (see, e.g., Bull,
2011). Despite the fact that the cost function restricted to T is governed by a skew squared
exponential kernel, the result shows that we can control the regret using the low-dimensional
squared exponential kernel.
Theorem 11. Let X âŠ‚ RD be a compact subset with non-empty interior that is convex
and contains the origin and f : RD â†’ R, a function with effective dimension d. Suppose
that the canonical representation of the restriction of f to its effective subspace T , denoted
f |T , is an element of the RKHS Hkâˆ† (Rd ) with âˆ† symmetric and positive definite and also
satisfying 0 < r2 < Î»min (âˆ†) â‰¤ Î»max (âˆ†) < R2 for constants r and R, where Î»min (âˆ†) and
Î»max (âˆ†) are the extreme eigenvalues of âˆ†.
Let A be a DÃ—d matrix, whose elements are drawn from the normal distribution N (0, 1).
Then, given any  > 0, we can choose a length-scale ` = `() such that running REMBO
with kernel k`d on the restriction of f to the image of A inside X has simple regret with
1
respect to the set Im A âˆ© X in O(tâˆ’ d ) with probability 1 âˆ’ .
This theorem does not follow directly from the results of Bull (2011), since the kernel
is not aligned with the axes, both in the high-dimensional space and the lower dimensional
embedding.
Please refer to Appendix D for the proof of this theorem. The general idea of the proof
is as follows. If we have a squared exponential kernel k` , with a smaller length scale than a
given kernel kâˆ† , then an element f of the RKHS of kâˆ† is also an element of the RKHS of k`
(see Lemma 15 in the Appendix for more details). So, when running expected improvement,
one can safely use k` instead of kâˆ† as the kernel and still obtain a regret bound. Most of
the proof is dedicated to finding a length scale ` that fits â€œunderneathâ€ our kernel, so we
can replace our kernel with k` , to which we can apply the results of Bull (2011).
Note that in the above theorem we make the assumption that the embedded dimension
and the effective dimension are equal to each other. Given bounds such as Proposition 1 of
de Freitas et al. (2012), we strongly believe that a similar result holds when the embedded
dimension is higher than the effective dimension; however, the analysis of that setting
remains elusive due to the fact that none of the methods available in the literature on regret
bounds for Bayesian optimization algorithms can handle kernels that have flat dimensions
(i.e. when âˆ† is not positive-definite), and adapting them to such a case requires tools from
statistics that have yet to be developed. Given that, theoretical bounds for the case with
de < d are outside the scope of this work.
Moreover, note that this theorem provides a sublinear regret result for REMBO with
respect to the whole set X only in the situation that Im A intersects the maximum locus
of the function f inside the set X . Note that Theorem 3 provides a lower bound on the
probability of this happening in the special case that the effective subspace is axis-aligned.
Proving regret bounds for situations in which the image of A only contains a maximum
outside of X would require dealing with the RKHS of non-stationary kernels, since the projection operator pX can have non-constant Jacobian. This is related to the situation with
treed GPs (Gramacy et al., 2004), with the additional, immensely complicating ingredient
that is the continuity assumption imposed along the boundaries of the various partitions of
28

Bayesian Optimization in a Billion Dimensions

the space (since pX is continuous). Similar to the theory of Partial Differential Equations,
where boundary conditions are the hardest part of the problem, we anticipate this modification to be a non-trivial, albeit very interesting, undertaking, and pose it as an open
problem to the community.
Remark 12. The above theorem would also hold for a class of stationary kernels which
includes the popular MateÌrn kernel. For conciseness of presentation, we do not include this
result, but refer the curious reader to Bull (2011) for more details.

Appendix D. Proof of Theorem 11
Before embarking on the proof of Theorem 11, we introduce some definitions and state a
few preliminary results, which we quote from Bull (2011) to facilitate the reading of this
exposition.
R
T
b
We denote the Fourier transform of any function Ï†(x) as Ï†(Î¾)
= Rd eâˆ’2Ï€ix Î¾ Ï†(x)dx. In
this section we consider kernels of the form
1

kâˆ† (x(1) , x(2) ) = Kâˆ† (x(1) âˆ’ x(2) ) = K(âˆ†âˆ’ 2 (x(1) âˆ’ x(2) ))
b such that K
b is isotropic
where âˆ† is a positive definite matrix and K has Fourier transform K
and radially non-increasing. Notice that both the squared exponential kernel and the skew
squared exponential kernel introduced in Definition 9 of the main text are represented in
the form above. The popular kernels from the MateÌrn class can also be represented in this
form. In general, the results in this section would follow for any kernel that satisfies the
four assumptions detailed by Bull (2011).
Lemma 13 (Lemma 1 of Bull (2011)). H(Rd ) is the space of real continuous functions
f âˆˆ L2 (Rd ) whose norm
Z b 2
|f (Î¾)|
2
kf kH(Rd ) :=
dÎ¾
b
K(Î¾)
is finite, taking 0/0 = 0.
Lemma 14 (Lemma 2 of Bull (2011)). Given a set S âŠ† Rd , H(S) is the space of functions
f = g|S (f is g restricted to S) for some g âˆˆ H(Rd ), with norm
kf kH(S) := inf kgkH(Rd ) ,
g|S=f

and there is a unique g minimizing this expression.
Lemma 15 (Lemma 4 of Bull (2011), extended to our setting). Let S âŠ† Rd and âˆ† and
âˆ†0 be two symmetric positive definite matrices. Let Î»max (âˆ†0 ), Î»min (âˆ†) be the largest and
the smallest eigenvalues of âˆ†0 , âˆ† respectively such that Î»max (âˆ†0 ) â‰¤ Î»min (âˆ†). Then f âˆˆ
Hkâˆ† (S) implies f âˆˆ Hkâˆ†0 (S) and also

kf kHk

(S)
âˆ†0

â‰¤

|âˆ†|
|âˆ†0 |

where |âˆ†| is the determinant of âˆ†.
29

1
2

kf kHk

âˆ†

(S)

Wang, Hutter, Zoghi, Matheson, & de Freitas

Proof. Since âˆ† and âˆ†0 are positive definite we can write âˆ† = QT Î£Q and âˆ†0 = Q0T Î£0 Q0
 0 1
| 2
. Since Î»max (âˆ†0 ) â‰¤ Î»min (âˆ†), we know
where Q and Q0 are orthonormal. Let C = |âˆ†
|âˆ†|
that
1
1
kÎ£0 2 Q0 Î¾k2 = Î¾ T âˆ†0 Î¾ â‰¤ Î¾ T âˆ†Î¾ = kÎ£ 2 QÎ¾k2 .
b is isotropic and radially non-increasing, we have that
As K
1
01 0
0 1 b
0 1
âˆ’1 d
0 1 b
d
d
K
âˆ†0 (Î¾) = |âˆ† | 2 K(Î£ 2 Q Î¾) â‰¥ |âˆ† | 2 K(Î£ 2 QÎ¾) = |âˆ† | 2 |âˆ†| 2 Kâˆ† (Î¾) = C Kâˆ† (Î¾)

where the first and the second last equality follows from the following property of Fourier
1 b
âˆ’T Î¾) if h(x) = f (M x) given a non-singular matrix M . Given
transforms: b
h(Î¾) = |M
| f (M
f âˆˆ Hkâˆ† (S), let g âˆˆ Hkâˆ† (Rd ) be its minimum norm extension, as in Lemma 14. By the
definition of RKHS norm in Lemma 13,
Z
Z
|b
g |2
|b
g |2
â‰¤
= C âˆ’1 kf k2Hk (S) .
kf k2Hk (S) = kgk2Hk (Rd ) =
âˆ†
d
d
âˆ†0
âˆ†0
Kâˆ†0
C Kâˆ†
Since C is finite, by Lemma 13 we have that f âˆˆ Hkâˆ† (S) implies f âˆˆ Hkâˆ†0 (S).
Definition 16. Given a map Ï€ : S â†’ T between any two sets S and T , and any map
f :T
Â· Â· Ã— T} â†’ R, with n â‰¥ 1, we define the pull-back of f under Ï€ as follows:
| Ã— Â·{z
n-times

Ï€ âˆ— f (s1 , . . . , sn ) := f (Ï€(s1 ), . . . , Ï€(sn )) .
That is, one evaluates the pull-back Ï€ âˆ— f on points in S by first â€œpushing them forwardâ€
onto T and then using f to get a number.
If the map Ï€ is given by a matrix A, we will use the notation Aâˆ— f for the pull-back of f
under the linear map induced by A. Moreover, given a matrix A and a set S in its target
space, we will denote by Aâˆ’1 (S) the set of all points that are mapped into S by A.
Proposition 17 (Theorem 2 by Bull (2011), paraphrased for our particular setting). Given
a squared exponential kernel k` on a compact subset Y âŠ‚ Rd and a function f âˆˆ H` (Y),
then applying
Expected Improvement to f results in simple regret that diminishes according

âˆ’ d1
to O t
, with the constants worsening as the norm kf kH` (Y) increases.
Proof of Theorem 11. The proof of this result is structured into two parts. In the first part
of the proof, we give an analytic expression for the true kernel kâˆ†d in the low dimensional
space over which we optimize. In the second part of the proof, we show that this kernel is
well-behaved with high probability (specifically the maximum and minimum eigenvalues of
âˆ†d are bounded above and below by constants depending on the probability of failure) and
apply Proposition 17 to acquire the convergence rate.
Let Î¦ âˆˆ RDÃ—d be a matrix, whose columns form an orthonormal basis for T . Let
Î  = Î¦T Î¦Î¦T : X â†’ Rd . Note that Î  is composed of an orthogonal projection from X to
T and a bijective map from T to Rd . We will also denote the corresponding matrix by Î .
Recall from the theorem statement that f |T is assumed to be an element of the RKHS
Hkâˆ† , and that we have f = Î âˆ— f |T , i.e. f is obtained from â€œstretching f |T openâ€ along the
orthogonal subspace of T . We can also define the kernel over RD by k D := Î âˆ— kâˆ† .
30

d=1

Bayesian Optimization in a Billion Dimensions

y

D=2
ing

dd
be

Em

d=1
Figure 9: A illustration of the different kernels defined in this proof. In this figure, the
red line represents the one-dimensional space Y over which we optimize. The
blue region is the original high-dimensional space. The green line represents the
effective subspace T projected to a one-dimensional space through Î . The true
kernel Kâˆ† is defined on the green region. The true kernel on the high-dimensional
space is then naturally k D = Î âˆ— kâˆ† and the true kernel on Y is Kâˆ†d = Aâˆ— k D .
To optimize without the knowledge of Kâˆ†d , we use a kernel k` which with high
probability is thinner than Kâˆ†d in all directions thus preserving convergence
properties.

Now, given the embedding Rd ,â†’ RD defined by the matrix A, the pull-back function
is an element of the RKHS HAâˆ— kD : Henceforth, we will use the notation

Aâˆ— f

kâˆ†d := Aâˆ— k D = Aâˆ— Î âˆ— kâˆ† = (Î A)âˆ— kâˆ† .
In more detail, for y(1) , y(2) âˆˆ Rd


kâˆ†d (y(1) , y(2) ) = K (y(1) âˆ’ y(2) )> A> Î > âˆ†âˆ’1 Î A(y(1) âˆ’ y(2) ) .
For a pictorial illustration of the different kernels defined in this proof, please refer to
Figure 9.
Since Î  is an orthogonal projection matrix, it has an SVD decomposition Î  = USV
consisting of an orthogonal d Ã— d matrix U, an orthogonal D Ã— D matrix V and a d Ã— D
matrix S that has the following form:
ï£®
ï£¹
1 0 Â·Â·Â· 0 0 Â·Â·Â· 0
ï£¯0 1 Â· Â· Â· 0 0 Â· Â· Â· 0ï£º
ï£¯
ï£º
S = ï£¯. . .
.. .. . .
.. ï£º .
.
.
.
ï£°. .
. . .
. .ï£»
0 0 Â·Â·Â· 1 0 Â·Â·Â· 0
31

Wang, Hutter, Zoghi, Matheson, & de Freitas

Now, given a fixed orthogonal matrix O âˆˆ RDÃ—D and a random Gaussian vector v âˆ¼
N (0, IDÃ—D ), due to the rotational symmetry of the normal distribution, the vector Ov is
also a sample from N (0, IDÃ—D ). Therefore, given a random Gaussian matrix Î“, OÎ“ is also
a random Gaussian matrix with the same distribution of entries. Moreover, given S as
above, SÎ“ is a d Ã— D random Gaussian matrix, since multiplying any matrix by S on the
left simply extracts the first d rows of the matrix.
Given this, if we fix an orthogonal decomposition âˆ†âˆ’1 = P> Dâˆ’1 P, where P is orthogonal and D is a diagonal matrix with the eigenvalues of âˆ† along the diagonal, we can
conclude that
G := PÎ A = PUSVA
is a random Gaussian matrix, and so the matrix âˆ†d = A> Î > âˆ†âˆ’1 Î A can be decomposed
into random Gaussian and diagonal matrices as follows:
> âˆ’1
âˆ†âˆ’1
d = G D G.

Since random Gaussian matrices, as argued in the proof of Theorem 2, have full rank almost
surely, âˆ†âˆ’1
d is of full rank and is positive definite.
In the remainder of this proof, we replace kâˆ†d with a kernel k` that is â€œthinnerâ€ than
kâˆ†d and so Aâˆ— f is also an element of the RKHS of k` . By showing that this is true,
REMBO (which uses k` ) has enough approximation power. Moreover, the statement of
Proposition 17 applies.
Let smin (M) and smax (M) denote the smallest and the largest singular values of a matrix
M. With this notation in hand, we point out the following two facts about concentration
of singular values:
I. Since for any pair of matrices A and B, we have smax (AB) â‰¤ smax (A)smax (B), we
get
1
smax (G)2
2
âˆ’1
= Î»max (âˆ†âˆ’1
)
â‰¤
s
(G)
s
(D
)
â‰¤
max
max
d
Î»min (âˆ†d )
r2
and since G is a random matrix with Gaussian entries, we have (cf. Equation 2.3 by
Rudelson and Vershynin (2010))


âˆš
2
P smax (G) < 2 d + t â‰¤ 1 âˆ’ 2eâˆ’t /2 ,
and so with probability 1 âˆ’ 2 , we have
âˆš
smax (G) < 2 d +

r

4
2 ln .


Therefore, with probability 1 âˆ’ 2 , we have
ï£«

ï£¶2

r
ï£¸ .
q
Î»min (âˆ†d ) > ï£­ âˆš
4
2 d + 2 ln 
Henceforth, we will use the notation
r
q
` = `() := âˆš
2 d + 2 ln 4
32

(1)

Bayesian Optimization in a Billion Dimensions

II. On the other hand, we have
1
smin (G)2
= Î»min (âˆ†âˆ’1
) â‰¥ smin (G)2 smin (Dâˆ’1 ) â‰¥
d
Î»max (âˆ†d )
R2
together with the following probabilistic bound on smin (G) (cf. Equation 3.2 by
Rudelson and Vershynin (2010)):


Î´
> 1 âˆ’ Î´.
P smin (G) > âˆš
d
So, with probability 1 âˆ’ 2 , we have

smin (G) > âˆš ,
2 d
and so
Î»max (âˆ†d ) <

4dR2
2

(2)

holds with probability 1 âˆ’ 2 .
In what follows, we will use the notation:
âˆš
2R d
U = U () :=

Now, with these estimates in hand, we have that by Lemma 14 and Lemma 15 the
following bound holds with probability 1 âˆ’ :
âˆ—



âˆ—

kA f kH` (Aâˆ’1 (X )) â‰¤ kA f kH` (Rd ) â‰¤

U ()
`()

d
2

kAâˆ— f kHâˆ†

d

(Rd )

(3)

Since the transformation Î A is invertible, we have that the map (Î A)âˆ— : Hâˆ† (Rd ) â†’
Hâˆ†d (Rd ) (recall that kâˆ†d = k(Î A)âˆ— âˆ† ) that sends g âˆˆ Hâˆ† to (Î A)âˆ— g is an isomorphism of
Hilbert spaces and so
f |T
= kAâˆ— f kHâˆ† (Rd )
(4)
d
Hâˆ† (R )



d



since we have Aâˆ— f = Aâˆ— Î âˆ— f |T = (Î A)âˆ— f |T .
By combining 3 and 4, we have that
âˆ—

kA f kH` (Aâˆ’1 (X )) â‰¤



U ()
`()

d
2

f |T

Hâˆ† (Rd )

.

Now that we know that the H` (Rd ) norm of Aâˆ— f is finite, we can apply the Expected
Improvement algorithm to it on the set Aâˆ’1 (X ) with kernel k` , instead of the unknown
1
kernel kâˆ†d , and then Proposition 17 tells us that the simple regret would be in O tâˆ’ d .

33

