UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

230

Building a Stochastic Dynamic Model of Application Use

Peter J. Gorniak

David Poole

Department of Computer Science

Department of Computer Science

University of British Columbia

University of British Columbia

Vancouver, B.C., Canada, V6T 1Z4

Vancouver, B.C., Canada, V6T 1Z4

pgorniak@cs.ubc.ca

poole@cs.ubc.ca

Abstract

is usually non-trivial, time-consuming to repeat and
increases application complexity.

Many intelligent user interfaces employ applica­
tion and user models to determine the user's pref­
erences, goals and likely future actions.

3.

Researchers work from various, often hand-crafted
application models.

Such

building work in

models require application analysis, adaptation

2,

In addition to the application

an application designer needs

to specify such a model.

and expansion. Building and maintaining such

This process is often not

straightforward and may rely on empirical data from

models adds a substantial amount of time and

user trials.

labour to the application development cycle. We

An application designer's primary task

does not include designing such a model, and thus the

present a system that observes the interface of an

task seems an added difficulty to him or her. Also, the

unmodified application and records users' inter­

model needs to be updated and will tend to lag behind

actions with the application. From a history of

the application during maintenance.

such observations we build a coarse state space
of observed interface states and actions between
them. To refine the space, we hypothesize sub­

We are currently addressing these problems by investigat­

states based upon the histories that led users to

ing how much knowledge can be extracted from a user's

a given state. We evaluate the information gain

interaction with an application without any prior informa­

of possible state splits, varying the length of the

tion about the application's purpose or structure and with­

histories considered in such splits. In this way,

out any modifications to the application (somewhat in the

we automatically produce a stochastic dynamic

spirit of (Lieberman 1998).) We hypothesize that enough

model of the application and of how it is used.

knowledge can be extracted to yield a detailed model of the

To evaluate our approach, we present models de­

application and its user. This model can then serve both as

rived from real-world application usage data.

a knowledge source for other algorithms as well as provide
a context under which to unite methods. Specifically, we
endeavour to construct a detailed state space together with

1

Introduction

a stochastic policy for the user's behaviour and in this way
describe the application structure and the user traversing it.

Artificial Intelligence supplies a vast set of tools to be ap­

An intelligent user interface, for example a help system,

plied to the design of intelligent user interfaces.

W hile

can access information about the user's context and goals

our previous research (Gorniak 1998) as well as countless

from our model, and thus tailor its presentation to the user's

other projects sample indulgently from this set and often

needs. Most importantly, we set out to construct this model

produce quite impressive results in their own environments

without modifying the application and without running ex­

(for example, see (Horvitz, Breese, Heckerman, Hovel and

plicit user trials. In fact, the system we present works as

Rommelse 1998) and (Albrecht, Zukerman, Nicholson and

a wrapper to the Java runtime environment and is able to

Bud 1997),) there emerge some new challenges when one

model the use of any Java application

attempts to apply these results to a new application.

without customization of either the application or our sys­

run

on the system

tem.
1. The research results often do not transfer easily to a
new application.

2.

Some other application independent user models build
no application model at all, and thus do not provide

The actual implementation used in the research re­

any automatic analysis of the application.

lies upon a modified application.

worse in cases where such application knowledge boosts

This modification

They perform

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

performance, such as future action prediction (Davison
and Hirsh 1998). Others stop early on in their analysis
and subsequently rely on application specific knowledge
(Encarnacao 1997). We are not aware of other work that
attempts to identify the current state of application and user
without any knowledge or modification of the application.
Related in the model building area is the next action predic­
tion work for web precaching by Zukerman, Albrecht and
Nicholson (1999). They work with combinations of sim­
ple Markov models and based on request counts and do not
identify the system's state in more detail. Our goal is also
akin to some work in the areas of data mining and specif­
ically clustering. For example, Cadez, Heckerman, Meek,
Smyth and White (2000) cluster users based on their web
page request patterns for visualization purposes, but they
do not build a detailed stochastic dynamic model like ours.
Let us view the user as an agent. Our assumption is that we
can and have observed this agent acting in an environment,
namely using an application. Artificial Intelligence con­
cerns itself with agents acting in environments and worries
about what decisions such agents should make. A common
approach to such a problem consists of phrasing it in terms
of states and actions between states and coming up with a
policy that, perhaps stochastically, dictates which actions to
take in which states (Boutilier, Dean and Hanks 1999). We
are faced with the opposite problem: we see an agent acting
in an environment and want to model the agent's decision
process. We assume that the agent acts according to a pol­
icy. Each action is the result of some (possibly stochastic)
function of what the agent observes and the agent's belief
state. Our goal is to determine this policy and the state
space to which it applies.
Previously, we have shown this approach to perform ex­
ceedingly well in predicting future user actions (Gorniak
and Poole 2000). In that research we identified the user's
state implicitly by finding the longest sequences in ob­
served history that match the actions the user just per­
formed, similar to (McCallum 1996). We ranked possible
future actions according to the lengths of these matches.
Our goal in the research presented here is to explicitly iden­
tify the states of user and application. This results in a
detailed model of how one or many people are using the
application. Such a model can help application designers
analyse their applications and augment them with intelli­
gent extensions. For example, it is easy to learn about user
behaviour and find unexpected consequences of a design
decision. Or, in building an intelligent help system, the de­
signer can query our system for the user's current state and
context, as well as our prediction for the user's future ac­
tions and then tailor the help to that scenario. Note that
while we lean on some techniques from classification algo­
rithms, we are not dealing with a standard machine learning
problem here. Our emphasis lies on a humanly readable
and usable model. Therefore, we cannot offer a numeri-

231

cal performance measure of how well our system performs
its task. Instead, we illustrate that the model we infer for
real application usage data provides a useful foundation for
application analysis and extension.
In Section 2 we describe the motivation behind our state
identification algorithm and compare it to its implicit sib­
ling, ONISI (On-Line Implicit State Identification (Gorniak
and Poole 2000)). Section 3 describes the Java implemen­
tation of the work presented here. This implementation
works as a wrapper to existing Java applications and is able
to record their interfaces states as well as user actions with­
out modifications to the original application. Section 4 dis­
cusses the performance of this algorithm on real user data
from an example application and analyses the resulting ap­
plication model. Finally, Section 5 concludes and points to
future work.
2

Explicit State Identification Algorithm

Our implementation (see Section 3) supplies us with a
record of observations of the application's interface states
and the user's actions that lead from one observed interface
state to another. That is, our recorded history consists of
sequences of state observation/user action pairs. The ob­
served states are often very coarse in that they are nowhere
close to fulfilling the Markov assumption. Users tend to
take very different courses of actions from them according
to different goals. Overall, our approach to automatically
deriving a refined state space (as with ONISI in (Gorniak
and Poole 2000)) consists of identifying behavioural pat­
terns that the user engages in and that predict future user
actions well. However, to predict the next user action ON­
lSI was given the history sequence that just occurred and it
proceeded to find long matches to it in recorded history, un­
der the (correct) assumption that users normally continue
such patterns in identical ways. OFESI (Off-line Explicit
State Identification), the algorithm discussed here, has a
different goal. Rather than striving to predict the next ac­
tion accurately, its purpose is to identify meaningful states
that explain overall user behaviour. As a consequence, ON­
lSI considers a single long match of a behavioural pattern
an important predictor, but OFESI needs to group identified
patterns into sets that delimit distinct user states.
This state refinement problem can be viewed as a classi­
fication task: given the occurrences of a state in recorded
history, the action sequences that precede them, and the ac­
tions that follow them, how should we group the sequences
such that the groups give us as much information as pos­
sible about what action will occur after the state? This
problem sounds much akin to the problem of picking an
attribute to split on in building a decision tree using ID3
(Quinlan 1986). However, the natural attributes to use in
splitting a state are the action sequences preceding it. These
attributes are many-valued, producing a split into a large

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

232

number of substates. Instead, we would like to split the
state into as many states 'as make sense', that is, as are use­
ful in capturing possible user intentions when reaching the
observed interface state. We need to dynamically construct
attributes with fewer values to predict substates.
We choose for OFESI to perform hierarchical binary splits
of a state according to how much information such a split
yields about the actions taken from it, and according to how
many instances of such actions the new substates explain.
Grouping the preceding action sequences in such a way
supplies us with a new attribute with values that identify
relevant substates well.
State to be split

Histories oflength 2

Future action counts

we sum the next action distributions of their constituent
members to arrive at two distributions for the newly cre­
ated substates. In tum, we may choose to split the new
substates again in a hierarchical fashion. There is likely to
be some redundancy amongst the resulting sets. For exam­
ple, if all preceding sequences that end in the same action
are grouped into one of the substates, that single action is
enough to identify all these sequences. Thus, OFESI's last
step examines the sequence sets for such redundancies and
replaces groups of sequences with a shorter sequence wher­
ever possible.
The main question now is: how can we split the set of pre­
ceding fixed length sequences into two, such that the result­
ing sets convey as much information as possible about the
next action? Just as in building a decision tree, we evalu­
ate possible sets according to their information gain. For a
set of history sequences defining a states the information
needed to fully predict the next action if there are n actions
possible overall is
n

Is
( )

=

-

LP8(a;) logPs(a;)
i=l

where P8(a;) is the probability with which action i occurs
in states, i.e. the number of times the action occurs in this
state in history divided by the number of times the state
occurs in history (Shannon and Weaver 1949).
A new subsets1 ofs leaves us with a remaining informa­
tion need of
n

R(sl)

Sequence Merging
Merged relevant Histories

Split state

Future action counts
a1(sl)

'---� a2(sl)

)-----•

a1(sl)
a•(sl)

=-

LPs,(aj)1ogP81(aj),
j= l

for that part of the original state, so the split of
ands2 yields an information gain of

s

intosl

'-----r- a!(s2)

}-----•

a2(s2)
aJ(s2)
a.(s2)

Figure 1: State Splitting
Figure 1 depicts the schema OFESI employs in splitting a
state. We initially consider all distinct fixed length history
sequences that have preceded an interface state in recorded
history. In the following discussion, a state is a set of such
sequences together with the observed interface state they
lead to. The length of these sequences is an input to the
algorithm. We discuss the choice of length in Section 4.
History also supplies us with a distribution over next ac­
tions that users chose in the state. In fact, each preceding
action sequence carries such a distribution, their sum being
the state's action distribution. We now split the set of pre­
ceding history sequences into two. For the resulting sets,

where P(si) is the probability with which the predictions
grouped into substate s 1 occur. We need to split the set
of action sequences into two subsets such that this value is
maximized.
We use a form of stochastic local search to optimize infor­
mation gain of the subset split (Hoos 1998). Specifically,
we initialize the search by splitting the history sequences
leading to the interface state into two random subsets. Each
search step moves exactly one sequence from one set to the
other. To perform a step we pick the move that increases in­
formation gain the most with probability p and pick a ran­
dom move with probability 1 - p. We only move attributes
that have not been moved for at least k steps, and reset
the search process if information gain has not improved for
m search steps. We discuss the parameter settings for this
search in Section 4.4.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

//States are represented by sets of

Given settings for searchSteps,

//action sequences leading to single

p,

//interface states.
Given settings for Amin,

233

k,

m;

OFESI-binary-split(actionSequences)
Gmin,

Randomly split actionSequences into

sequenceLength;
OFESI()

statel,

{

Let gain

For each interface state s
Let resultingStates

=

state2;

G(actionSequences,

=

{

statel,

state2);

{};

Let bestGain

Find all actionSequences of

gain;

=

Let stagnantCount

0;

=

length sequenceLength

Let bestSplit

that precede s;

For searchSteps number of times

Call OFESI-split-state(

=

{statel,

With probability p

actionSequences,

state2}
{

{

Move action a that maximises

resultingStates);

gain improvement

Replace s by substates found

when moved between

in resultingStates;

sets and hasn't been
moved for k steps;
else

OFESI-split-state(actionSequences,
resultingStates)
Let

{gain,

substatel,

{

Move random action a;
{

substate2}

Let gain

=

OFESI-binary-split(

statel,

actionSequences);
If gain

>

G(actionSequences,

>

If gain

Gmin

bestGain

Let bestGain

AND the number of actions
predicted by each of

gain;

=

Let bestSplit

state2);

{

=

{statel,

state2};

statel and state2

Let stagnantCount

is greater than Amin

else

Call OFESI-split-state(statel,

=

0;

{

stagnantCount++;

resultingStates);
Call OFESI-split-state(state2,

if(stagnantCount

resultingStates);
else

>

m)

Randomly split

{

actionSequences into

Append actionSequences to

statel,

state2;

resultingStates;
return

Figure 2: The OFESI Algorithm

OFESI accepts the best split if it yields an information gain
of at least Gmin and if for each set the sum of the action
instances that set predicts is at least A min. This restricts
splits to those that still yield a reasonable amount of infor­
mation about the actions taken from a state and avoids splits
that do yield information, but create substates that explain
an insignificant amount of actions. Both parameters can­
not be optimized in any objective sense, but rather depend
on one's goals in using OFESI. We discuss their impact in
Section 4.3.
Upon a successful split, OFESI now considers each sub­
state as the new state to be split and continues splitting
in this hierarchical fashion as long as each split fulfills
the Gmin and Amin restrictions. Figures 2 and 3 outline

{bestGain,

bestSplit};

Figure 3: Binary State Split Algorithm
the complete OFESI algorithm without the final sequence
merging step.
3

Implementation

Java's reflective capabilities and dynamic loading strategy
make the language a prime candidate for an application in­
dependent approach (JDK 1998). It allows not only inspec­
tion of a structure of known visual components, but it can
also inspect unknown components for state information.
Java and JavaBeans introduced standard naming conven­
tions for object methods. For example, isVisibleO returns
the visibility status of visual components, whereas getEn­
abledO returns whether they are currently useable. Com­
ponents derived from standard Abstract Window Toolkit

234

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

components inherit these methods automatically, and other
components should define them. Java's Reflection mech­
anism, on the other hand, allows one to check whether a
given object includes one of these state-revealing methods,
and lets one call this method without knowing the object's
class. Finally, Java's dynamic loading of classes rids the de­
veloper of needing to link with or even know about classes
that will be present at runtime. Using these tools, one can
establish the user interface state of an application built us­
ing Java at runtime by dynamically linking into its code,
examining the methods available in its objects and calling
the methods relevant to the interface state. This process
requires no modification of the targeted application at all.
The system used for the experiments presented below runs
as a wrapper to a Java application. Before it starts the appli­
cation, it hooks itself into the application's event queue and
thus sees all event activity within the Java Abstract Window
Toolkit and components derived from it. It intercepts each
such event that it considers an action (such as a button be­
ing pressed or a window closed) and records the observed
state of the application's interface before and after the event
occurs. In this way, this system establishes a state space of
interface observations as a person uses the application and
records a history consisting of actions and visited states at
the same time.
The applications 1 under consideration here are educational
AI applications. They were written to help undergraduate
university students learn concepts in Artificial Intelligence.
One application familiarizes the student with search prob­
lems and algorithms, the second deals with constraint sat­
isfaction problems and the third demonstrates backpropa­
gation neural network learning. In each, the student has the
option to either load an example problem or to create his
or her own problem by drawing a graph. He or she can
then switch to a problem solution mode and step through
the various algorithms at different levels of detail. The
students used these applications to solve homework prob­
lems for an introductory AI course they were taking. Most
of the assignment questions referred to a supplied exam­
ple problem, so the students tended to explore the problem
creation facilities of the applications less than their solving
functionality. The following discussion and results focus
mainly on the application for search algorithms.
4

4.1

Observed State Space

Figure 4 shows the state space of interface states our sys­
tem observes from users of the search algorithm applica­
tion. The figure represents the space exactly as recorded,
except for that we have given the states meaningful names.
Reflecting the division of the application into two modes,
problem creation and problem solution mode, the graph
exhibits two distinct components. The right hand compo­
nent corresponds to problem solution mode, whereas the
left hand one corresponds to problem creation mode. The
students were mainly using the application to solve prob­
lems that were given to them, so we recorded significantly
more data for problem solution mode. The following dis­
cussion therefore focusses on the right hand subcomponent
of Figure 4.
In this component, we see two distinct ways of examining
search algorithms using this application. Students can ei­
ther step through a problem using a search algorithm, or
they can show the result of the algorithm given the prob­
lem. At most times they can reset the search, which trans­
ports them back to the Problem Solution start state. Dur­
ing stepping, they can still ask to be shown the result at
any time. Show Result and Goal Node Reached are the
states in which dialog boxes are shown. We can distin­
guish two versions of these states, one in which the stu­
dent has stepped previously, and one in which the student
asked to see the result directly from the Problem Solution
state. W hile this graph is interesting, it tells us little about
whether a student will choose to step or examine the re­
sult in Problem Solution state. We now demonstrate how
OFESI splits states to give us exactly that information.
4.2

State Splitting Results

First, let us examine the state Stepping and how OFESI
splits it. Table 1 lists the original next action distribution of
this state.

Results and Discussion

There exists no obvious user-independent performance
measure for the system presented here. Its usefulness de­
pends on the goals of the person employing the system, be
it to debug an existing application, to design additional ap­
plication components or to simply perform a study of appli­
cation usage. We have evaluated the implicit version of our
can
applications
1The
http://www.cs.ubc.ca/labsllci/Clspace/.

state identification approach to predict future user actions
in (Gorniak and Poole 2000) and we are currently work­
ing to apply the explicit version presented here to another
problem that can benefit from explicit state identification,
namely that of deriving structure for Hidden Markov Mod­
els (Rabiner 1989). In the following sections, we present
the model OFESI derives for the search application and ar­
gue that it captures significant features of user behaviour.

be

found

at

We see that there are three main actions users choose from
this state: They either step, fine step, or reset the search.
Intuitively, we would like to split the state into three sub­
states, each predicted by an appropriate set of history se­
quences leading to it. Tables 2 and 3 show a substate
OFESI suggests when considering history sequences of
length one by giving the action sequences predicting the
state and the action distribution in the state, respectively.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

235

Figure 4: Original Interface States Observed in Search Application
Table 1: Original Action Distribution for Stepping
Count

Action

Table 3: Next Action Counts for
2)

Stepping

Action

Show Frontier
Reset Search
Step
Display Node Heuristics
Show Result
Display Edge Costs
Fine Step

5
54
738
1
6
1
393

Show Frontier
Reset Search
Step
Display Node Heuristics
Show Result
Fine Step

This substate is a result of the initial binary split of Step­
ping OFESI performs, which splits the state into one sub­
state predominantly predicting the Step action and another
predicting the Fine Step action.
Table 2: Sequences Defining Stepping Substate
Previous State

Previous Action

Problem Solution

Step
Display Edge Costs
Step

Stepping
Stepping

This substate makes sense, judging from the intuition be­
hind the action sequences that predict it (a user that stepped
before is likely to step again), and from the next action dis­
tribution that is dominated by the Step action. This sub­
state will not be split again, but OFESI does split its dual
substate in a hierarchical call into substates that predict the
Fine Step action and the Reset Search action (it is predicted
by the last state having been Goal Node Reached after
Stepping.) As run here, with Gmin
0.15, Amin
10
and an action sequence length of one, OFESI suggests ex­
actly three states. We do not include the details for the other
two substates for space reasons.
=

=

The choice of action sequence length constitutes a trade off
between computational and explanatory complexity on the
one hand and explanatory power on the other hand. That
is, short action sequences (say, of length one) are easy to

Substate (Table

Count

4
16

733
1

5
2

read and there are few of them, whereas there tend to be
exponentially more sequences with each additional action
considered. More longer sequences allow us to split the
state at least as well, and usually better, than few shorter
sequences, but due to their number the splitting process is
computational more expensive and the resulting substates
are hard to interpret based on the action sequences (they
are still often easily interpretable from the actions they pre­
dict.) At the same time, overfitting may occur with longer
action sequences in the sense that patterns peculiar to the
training history may be used to identify substates.
Table 4 shows the action distribution for the substate pre­
dicting the Step action as derived by OFESI run with se­
quence length four. It is clear that the split is cleaner Table 4: Refined Next Actions Counts
Action

Show Frontier
Reset Search
Step
Display Node Heuristics
Show Result

Count

2
13
736
1
4

there are no more Fine Step actions predicted by this state,
and more Step actions predicted. We refrain from including
the unwieldy set of action sequences that predicts this state.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

236

Figure

5:

Split State Subspace for Search Application

Upon examining this set we find that in essence OFESI was

users ask for the process to be reset both after just having

able to take into account features like that if the last action

reset it and after switching search strategies or search op­

was Step, but the three before that were Fine Step, the user

tions (as obvious from the action sequences OFESI attaches

is likely to choose Fine Step next.

to the new substate.) Clearly, it is due to a flaw in the in­
terface that users engage in this behaviour. In general, the

4.3

state space shown in Figure

Refined State Space

5 presents

much more detailed

model of application use, and its states yield far more pre­
Figure

5 shows the state space

after running OFESI on the

right hand component of state space shown in Figure

4.

dictive power than the originally observed coarse interface
states.

States are labelled by their original name followed by the
most frequently occurring action in their next action distri­

4.4

Information Gain Optimization

bution if they are substates of the originally observed inter­
run

with Grnin

=

0.15, Arnin

=

10

As mentioned before, we employ stochastic local search to

These parameters can

optimize information gain when splitting a state into two

be set differently according to one's goal in running OFESI.

substates. The complexity of this search largely depends

Generally, lower settings of G rnin will produce more states,

on the length of the action sequences considered.

but states at lower levels of the hierarchical split will tend

sequences of length one, there are only few items to be

not to contribute much to distinguishing between possible

grouped and most parameter settings find the optimal so­

face states. OFESI was

and an action sequence length of

5.

With

Lower settings of Arnin will also produce

lution quickly. With longer sequence the number of items

more states, but these states will tend to distinguish ac­

in the groups tends to grow exponentially, and the search

tions that occur less often. First, notice the three substates

quickly becomes more complex. However, we found that

next actions.

of the Stepping state as discussed in Section

4.2.

In the

with sequences of length five the search rarely find better

500

same fashion, OFESI splits Problem Solution into four

solutions after more than

substates, according to whether the user is likely to Step

provements in later steps tend to be much smaller than in

steps. In addition, the im­

or Fine Step through the problem, to ask to be shown the

earlier ones and we do not necessarily care to find the op­

result or to reset the search. The last of these Problem So­

timal split as long as we find a very good one, so running

lution/ActionEvent on Reset Search is an artifact of the

the search to

user interface design. The problem solution process is in

of 0.1 and restarting after the solution has not improved af­

its initial state if the user is in Problem Solution state, but

ter

80

500

steps, with a probability of random steps

steps proved sufficient for our purposes. We do not

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

claim that these are in any way the optimal parameters, but
they appear to work well enough in practise.
5

Conclusion and Future Work

We have presented a system that observes user actions and
application interface states from an unmodified applica­
tion. It deduces a coarse state space that the user is travers­
ing from this observed history and a stochastic policy that
describes the user's behaviour. Together, these form a
stochastic dynamic model of application use. Each inter­
face observed state has an associated next action distribu­
tion that potentially includes high frequencies for several
actions. To enhance the model, we use OFESI to split
states in a hierarchical fashion by optimizing the informa­
tion gain on the original next action distribution that such a
split yields. We have shown this algorithm to split states
recorded in user trials into substates of good predictive
power. These substates form a new, more informative state
space of the use of the application, and supply us with a
more decisive policy.
While the state spaces derived by OFESI are those one
would wish for, we intend to prove the usefulness of our
automatic application and user modeling strategy by aug­
menting one of our applications with a component that uses
the model's information. We also intend to build an appli­
cation design and analysis tool that uses OFESI to produce
a state space of an existing application and helps the appli­
cation designer in evaluating past design decisions based
upon real application usage. In addition, an application de­
signer could add information to the state space, for example
by giving states names or by grouping states into contexts,
and could then interface to an API we provide to access
information about the current state and context as well as
future contexts and goals of the user.
Finally, there is another area of research that could take
advantage of a general way to infer meaningful states
from a sequence of observations: Hidden Markov Mod­
els (Rabiner 1989). We are currently investigating whether
OFESI as presented here can help in finding the optimal
number of states for a Hidden Markov Model and give hints
as to which observations each state should account for and
where in the model it belongs.
References

Albrecht, D. W., Zukerman, 1., Nicholson, A. E. and Bud,
A.: 1997, Towards a bayesian model for keyhole
plan recognition in large domains, User Modeling:
Proceedings of the Sixth International Conference,
UM97.
Boutilier, C., Dean, T. and Hanks, S.: 1999, Decision­
theoretic planning: Structural assumptions and com-

237

putational leverage, Journal of AI Research 11, 1-94.
Cadez, 1., Heckerman, D., Meek, C., Smyth, P. and White,
S.: 2000, Visualization of navigation patterns on a
web site using model based clustering, Technical Re­
port MSR-T R-00-18, Unversity of California, Irvine.
Davison, B. D. and Hirsh, H.: 1998, Predicting sequences
of user actions, Technical report, Rutgers, The State
University of New York.
Encarnacao, L.: 1997, Concept and Realization of intel­
ligent user support in interactive graphics applica­
tions, PhD thesis, Eberhard-Karls-Universitat Tiibin­
gen, Fakultiit fiir Informatik.
Gorniak, P. J.: 1998, Sorting email messages by topic.
Project Report.
Gorniak, P. J. and Poole, D.: 2000, Predicting future us­
er actions by observing unmodified applications, Pro­
ceedings of the 17th National Conference on Artificial
Intelligence, AAAI-2000.
Hoos, H. H.: 1998, Stochastic Local Search - Method,
Models and Applications, PhD thesis, Technische
Universitat Darmstadt.
Horvitz, E., Breese, J., Heckerman, D., Hovel, D. and
Rommelse, K.: 1998, The lumiere project: Bayesian
user modeling for inferring the goals and needs of
software users, Uncertainty in Artifical Intelligence,
Proceedings of the Fourteenth Conference.
JDK: 1998, Java Development Kit Documentation.
URL: http:/ljava.sun.com/products/jdk/1.1/docs/
Lieberman, H.: 1998, Integrating user interface agents with
conventional applications, Proceedings of the Inter­
national Conference on Intelligent User Interfaces,
San Francisco.
McCallum, A. R.: 1996, Instance-based state identification
for reinforcement learning, Technical report, Univer­
sity of Rochester.
Quinlan, J.: 1986, Induction of decision trees, Machine
Learning 1, 81-106.
Rabiner, L.: 1989, A tutorial on hidden markov models and
selected applications in speech recognition, Proceed­
ings of the IEEE, Vol. 77(2).
Shannon, C. and Weaver, W.: 1949, The Mathematical The­
ory of Communication, University of Illionois Press,
Urbana.
Zukerman, 1., Albrecht, D. and Nicholson, A.: 1999, Pre­
dicting users' requests on the www, User Model­
ing: Proceedings of the 7th International Conference,
UM99.

