The Probability of a Possibility: Adding Uncertainty to Default Rules

461

The Probability of a Possibility:
Adding Uncertainty to Default Rules

Craig Boutilier
Department of Computer Science
University of British Columbia
Vancouver, British Columbia
CANADA, V6T 1Z2
email: cebly@cs.ubc.ca

Abstract
We present a semantics for adding uncertainty to
conditional logics for default reasoning and be­
lief revision. We are able to treat conditional sen­
tences as statements of conditional probability,
and express rules for revision such as "If A were
believed, then B would be believed to degree
p." This method of revision extends conditional­
ization by allowing meaningful revision by sen­
tences whose probability is zero. This is achieved
through the use of counterfactual probabilities.
Thus, our system accounts for the best properties
of qualitative methods of update (in particular, the
AGM theory of revision) and probabilistic meth­
ods. We also show how our system can be viewed
as a unification of probability theory and possi­
bility theory, highlighting their orthogonality and
providing a means for expressing the probability
of a possibility. We also demonstrate the connec­
tion to Lewis's method of imaging.

1

Introduction

Recently, a number of (more or less equivalent) conditional
theories for default reasoning and belief revision have been
proposed (Kraus, Lehmann and Magidor 1990; Goldszmidt
and Pearl 1991; Boutilier 1990, 1992a, 1993a, 1993b). The
cornerstone of such conditional logics is a conditional con­
nective=?. The sentence A => B can be interpreted as a
default rule of the form "If A then normally B." A =? B
may also be interpreted as a subjunctive conditional of the
form "If an agent were to believe A then it would believe
B." According to the Ramsey test such a conditional is true
iff the agent comes to accept B when it revises its beliefs to
incorporate a new sentence A (Stalnaker 1968). Thus, any
conditional logic can be thought of as determining a theory
of belief revision.

Thus, we will be able to capture statements of the form
"If an agent believed A, it would believe B to degree p."
The notion of revision determined by such statements will
extend the usual process of conditionalization through the
use of counterfactual probabilities.
1.1

Conditional Logic and Degrees of Belief

The logics cited above, should we take=? to be a subjunctive
interpreted according to the Ramsey test, all correspond to
the well-knownAGM theory of belief revision (Alchourron,
Gllrdenfors and Makinson 1985; Gllrdenfors 1988). In fact,
it has been shown that default rules of the above form can
be interpreted as subjunctive conditionals (Boutilier 1992c,
1993b; Makinson and Gl\rdenfors 1990). One need only
view default rules as subjunctive conditionals that express
constraints on bow an agent revises a theory of expecta­
tions. In what follows, we usually take A ::} B to be a
subjunctive conditional, assuming that such a conditional
may be interpreted as a default rule with no difficulty.
A feature of conditional logics that has lead to their success
in the representation of defeasible inference is the fact that
conditionals can be used to express default rules and sub­
junctives in a very natural way and can be used to derive
new rules. In particular, it is consistent to assert together
the conditionals A ::} C and A 11 B =? ..,c, demonstrat­
ing the defeasibility inherent in conditional reasoning. This
fact can be exploited in the representation of uncertain or
context-dependent inference: in context A, C is a reason­
able conclusion; but if B is known as well, C is no longer
acceptable. For example, in certain approaches to model­

g

based diagnosis, preference is given to dia noses requiring
as few faulty components as possible. So a conditional
default rule might suggest that, given observation Ot, com­
ponent Ct alone is faulty. Given an additional observation
02 however, C1 might fail to be a diagnosis.
As mentioned above, a difficulty with the conditional ap­

Unfortunately, such conditionals cannot be used to represent
uncertainty in the revision process. In this paper, we present
a system in which one can express conditionals of this form,
but attach to the consequent of the conditional a degree of

proach to defauJt inference and belief revision is its cate­
gorical nature. One can represent the fact that Cis (fully)
believed or that it is not; but no other distinctions can be
made, for example, with respect to degree of belief. If
neither C nor ..,c is fully believed, both are "serious pos­
sibilities," but neither can be preferred to the other; so, for

belief to capture the uncertainty inherent in the conclusion .

example, an agent cannot decide whether to act on the ba-

462

Boutilier

sis of C or -,c. Similar remarks apply to conditionals: if
an agent accepts both -,(A=> C) and -,(A => -,C) then,
should the agent adopt A, the relative likelihood of C and
-,c cannot be represented. In our informal example, we
might have a default that exactly one of components C1, C2
or C3 is faulty given 01 • Thus, in context 01. all multiple
faults (and single faults involving other components) are
rejected as serious possibilities. This reduces the space of
candidate diagnoses, but does not allow one to distinguish
the remaining candidates. Typically, we want to investigate
alternatives according to their likelihood (de Kleer 1991;
Poole 1993). If failure of C1 is more likely than that of C 2
or c3 'testing strategies (say) might be altered.
Probabilistic representations can be used to circumvent this
difficulty. One can assign probabilities to each possibility
admitted by a belief set or knowledge base KB. We think of
such probabilities as degrees ofbelief. A serious possibility
relative to any belief set is any sentence A such that P(A) >
0. A (full) belief is any sentence A such that P(A) = 1.
With respect to a given KB, the conditional A => C means
that revising KB to accommodate A results in a belief in C.
Assuming that we have a probability function P assigning
degrees of belief to the possibilities admitted by KB, it is
natural to assume that revising KB by A is identical to con­
ditionalization of P by A; thus, asserting A=> C amounts
to stating that P(CIA) = 1. Furthermore, it provides a
natural means of specifying "uncertain" conditionals: if
P(CIA) = p then we might say that a conditional A=> C
Jwlds to degree p (if an agent came to believe A it would
believe C to degree p). Unfortunately, there is a crucial dif­
ficulty with such an approach. If P(A) = 0, then P(CIA)
is undefined or given some trivial value for all C. In con­
trast, conditionals A => C are meaningful in the case where
-,A E KB. Theories of revision provide nontrivial results,
new beliefs, possibilities and impossibilities, even when
the new information A is inconsistent with KB (indeed, this
is the principle case for belief revision). For instance, in
model-based diagnosis, typically one only looks for a diag­
nosis when observation 0 is inconsistentwithKB (typically
a system description together with normality assumptions).
Conditioning on 0 is then meaningless.
In order to augment arbitrary conditionals with degrees of
belief we need some generalization of conditional proba­
bility, whereby it is meaningful to assert P( CIA) = p (for
some non-extreme value p) when P(A) = 0. In this paper
we present a semantics for just such a system. We use the
notion of counterfactual probability as described by Stal­
naker (1970) and Lewis (1976). Our system can be viewed
as a refinement and a semantic model for counterfactual
probabilities. We demonstrate the relationship to existing
conditional logics for default reasoning and belief revision.
In particular, we show that our logic (conservatively) ex­
tends and unifies two predominant views of belief updating:
probabilistic conditionalization and the AGM theory of re­
vision. We also describe our system in terms of possibilistic
logic (Dubois and Prade 1988). As pointed out in (Boutilier
1992b), possibilistic logic cannot be used to represent un­
certainty or degrees of belief. Rather it should be viewed as
a representation mechanism for the entrenchment of certain

beliefs (see Section 2); thus it provides a means for updat­
ing by counterfactual sentences. In this sense, our logic is a
unification of probability theory and possibility theory that
highlights their orthogonality and adds to possibility theory
the means to express the probability of a possibility.
1.2

Why Use Categorical Rules?

If

one is going to use probabilities as degrees of belief, it
seems natural to question the need for (categorical) default
rules, conditionals or counterfactual probabilities. If one is
going to allow a sentence A in KB to be retracted when ..,A
is learned, why not simply assign A some degree of belief
less than 1 in the first place and use standard techniques such
as conditionalization to incorporate new items of belief?
If one wishes to allow the possibility that any "belief' can
be overturned given the proper evidence, then full belief
can be granted only to tautologies, and every contingency
must have some probability. To take a slightly less extreme
view, one might accord observational reports (say) the sta­
tus of full belief, but still no conclusions drawn from these
would be certain. Presumably, there are certain computa­
tional advantages to be gained by ruling out possibilities that
are very unlikely (Cheeseman 1985; Harman 1986). Chief
among these is the ability to exploit logical rules of infer­
ence. Such rules allow conclusions to be reached in manner
that is independent of context, in contrast to probabilistic
inference. The locality of logical rules can be exploited
if parts of the knowledge base (are assumed to) have full
belief (Pearl 1988).
It may also be that the cost associated with reaching incor­
rect (unhedged) conclusions and being forced to revise the
belief set is outweighed by the probability of being correct.
We might therefore think of a default rule as an instantia­
tion of an acceptance rule (Kyburg 1961). If A => B is a
conditional held by the agent, we take it to mean that there
is a certain utility associated with complete acceptance of
B given A. 1 On this view, it is reasonable to allow a con­
ditional A => B to be held even when ..,A is accorded
full belief, P(-,A) = 1. Consequently, we do not take a
P(A) = 0 to indicate that A is (logically or physically)
impossible, but simply that is is not, to use Levi's (1980)
terminology, a serious possibility.
1.3

Overview

In Section 2 we review the possible worlds semantics for
epistemic states, conditional logics and belief revision,
showing its strong relation to possibility theory. In Sec­
tion 3 we add probabilities to this system in such a way
that the conditional probability P(B lA) is meaningful even
when P(A) = 0. We show that our method of belief re­
vision extends the AGM theory so that degrees of belief
can be represented in revised belief sets, and that revision
is identical to conditionalization if the update A is a serious
possibility (i.e., if P(A) > 0). We also demonstrate how
1 We do not address here the issue of how one determines
appropriate acceptance rules; but in general decision-theoretic
criteria should be brought to bear.

The Probability of a Possibility: Adding Uncertainty to Default Rules

463

one may "index" degrees of possibility so that correct infer­
ences can be simulated without resorting to explicit counter­
factual probabilities (thus, standard probabilistic reasoning
techniques can be applied to this reasoning process). In
Section 4 we illustrate the relationship of our system to the
method of imaging proposed by Lewis (1976). In particu­
lar, we show that our revision method fits the pattern of both
generalized imaging and conditionalization. This stands in
contrast to a widely-held view that conditionalization and
generalized imaging are irreconcilable (Gardenfors 1988).
We conclude with a discussion of updated counterfactual
probabilities and iterated revision.

revision functions. A CO-model consists of a set of worlds
W � V and an ordering relation� on W reflecting the de­
gree of plausibility attributed to various worlds by an agent.
We interpret w � v as "w is at least as plausible as v." We
insist that� be a total preorder on W (that is, a transitive,
connected binary relation- see below). Intuitively, the
most plausible worlds in W are those consistent with the
agent's beliefs. All other worlds are epistemically impossi­
ble, but some are more plausible than others. A CO-model
is a K-revision model just in case the set of most plausible
worlds, those minimal in�. is exactly IIKII· It is just these
models that can be reasonably used to represent and belief
set K and its revision.

2

Should an agent learn some information that contradicts its
beliefs, IIKII can no longer be held as a reasonable epis­
temic state. If -,A E K and A is learned, the agent must
adopt a new belief set KA. of which A is a member. Seman­
tically, we simply require that the agent's new epistemic
state be represented by the set of most plausible A-worlds,
those minimal in �. Should B be true at each such world
we say that B E KA.. According to the Ramsey test, this
captures the acceptance conditions for a subjunctive condi­
tional A => B: if the agent believed A, it would believe B.
In (Boutilier 1992a, 1993b) we provide a strong represen­
tation theorem relating this model to the AGM theory. We
provide further technical details below.

Belief Revision and Possibilistic Logic

To keep the presentation simple, we assume a propositional
language LcPL generated by a finite set of atomic variables
P. The set of classical valuations for this language is
denoted V, elements of V usually referred to as worlds.
We take an agent to possess a deductively closed set of
beliefs K (typically the closure of some finite knowledge
base KB). The usual semantics for belief models the agent's
belief state as a set of epistemically possible worlds, those
worlds that make each belief in K true. Using the modal
connective 8 for belief, an epistemic state (set of worlds)
W satisfies BA just when A is true at each world in W. 2
We introduce several definitions. The set of A-worlds is
denoted I lAII = { w E V : w F= A}. For a set of formulae
K, the set of K-worlds IIKII is simply the set of worlds
satisfying each element of K.
2.1

Belief Revision

This model of epistemic states is reasonable as long as an
agent's beliefs never strain the credibility of K. However,
should an agent learn some sentence A such that -,AE K,
some revision of the agent's belief set and epistemic state
is required. One of the best known theories of revision
of this type is the AGM theory (Alchourr6n, Gardenfors
and Makinson 1985; Gardenfors 1988). In its most widely
cited form, the theory is presented as a set of postulates
constraining logically acceptable revision functions. If K
is some belief set, KA. denotes the belief set resulting from
the revision of K to include A. One of the hallmarks of the
AGM theory is its commitment to the principle of minimal
change: one should give up as few beliefs as possible in
K when attempting to accommodate A. The postulates
impose certain logical constraints on this notion. A key
and characteristic property of AGM revision operators is
that K � KA. whenever -,A fl. K: if no beliefs have to
be given up in order to accept A, then none should be. We
call any revision function * that satisfies the postulates and
AGM revision operator.
In (Boutilier 1992a, 1993b) we present a possible worlds
semantics and modal logic for the representation of AGM
2A

somewhat more involved notion of satisfaction is required
to capture iterated belief sentences, but this will suffice for our
informal presentation.

2.2

Possibilistic Logic

In (Boutilier 1992b) we show how the modal logic CO can
be used to capture qualitative possibilistic logic. We review
this connection here, and formalize the model of revision
discussed above in possibilistic terms.
Possibilistic logic has been developed to a great extent by
Dubois and Prade (see their (1988) for a survey). A possi­
bility measure II maps the sentences of LcPL into the real
interval [0, 1]. The value II(a) is intended to represent the
degree of possibility of a. We take this to represent the
amount of surprise associated with adopting a as an epis­
temic possibility. If II(a) = 1 there is no surprise (i.e., a
is consistent with the agent's beliefs), while II(a) = 0 in­
dicates that surprise is maximal (i.e., an agent would never
adopt a). A possibility measure must satisfy the following
three properties:
(a) II(T) =1
(b) II(l.) =0
(c) II(A V B) =max(II(A), II(B))

necessity measure N is a similar mapping, associating
with a a degree of necessity. We take N (a) to represent
the amount of surprise associated with giving up belief in
a (or the degree of entrenchment of a in a belief set; see
(Boutilier 1992b)). One may define necessity measures
using the identity
A

N(a) = 1- II(--,a).
Semantically, we can model possibility measures using pos­
sibility distributions. A distribution 71" assigns to each world

464

Boutilier

ll=O

ll=.4

ll=.6

TI=l

@
@

~
�
�

Impossible

Theorem 1 (Boutilier 1992b) For any possibility model
M, the induced revision function* satisfies the AGM pos­
tulates. For any AGM revision operator* and belief set K,
there is a possibility model M that induces *·

Possible

A distribution determines a possibility measure II as fol­
lows:
II(A) =max{1r(w): w I= A}.

but
Epistemically
Impossible

Epistemically
Possible

Figure 1: A Possibility Model
in V a degree of possibility from the interval [0, 1]. This
can be viewed as a ranking of worlds, with w being at least
as possible as v just when 1r(w) � 1r(v) . This corresponds
precisely to the relation w� v in a CO-model.

Definition 1 A possibility model is a triple M = (V, W, 1r}
where
(a) V is the set of worlds suitable for LcPL;
(b) 1r maps V into [0, 1]; and
(c) W ={wE V: 1r(w) > 0}.
Figure 1 illustrates a possibility model. W is the set of
possible worlds, those assigned a non-zero degree of pos­
sibility. Epistemically possible worlds are those assigned
possibility 1. We can also define truth conditions for a belief
operator B and a subjunctive conditional ::} .

Definition 2 Let M be a possibility model.
(a) World w is epistemically possible iff 1r(w) = 1.
(b) M induces the belief set K, where K is character­
ized by IIKII ={wE W : 1r(w) = 1}.
(c) M F= BA iff A E K
(iff {wE W : 1r(w) = 1} � II AII ).
(d) The set of plausible (or most possible) A-worlds
is denoted Pl(A), where w E Pl(A ) iff w I== A and
1r(w) � 1r(v) for all vI= A.
(e) M F= A ::} B iff Pl(A) � IIBII·
(t) K.A = {B : MFA::} B}.
The model in Figure 1 captures the belief set K =
Cn( {-,A, B} ). The conditional A ::} B is true, while nei­
ther A ::} C nor A ::} -,C hold. This is because B holds
at all of the most plausible A-worlds (those with possibility
.6), while C and -,cdo not. We can show that the class of
revision function* induced by possibility models is exactly
the class of AGM revision functions.3
3Technically, we require that the possibility model be "com­
plete" in the sense that V = W, that is, all worlds are possible.

In other words, the degree of possibility of A is just that
of the most possible A-worlds (i.e., those worlds in Pl(A)).
The model in Figure 1 admits -,A, B, C and ...,cas serious
possibilities (e.g., II( C) = 1), while A and -,B are not
(II(A) = .6 and II( -,B) = .4). Notice that -,B A ...,c is
impossible: II( -,B /1. -,C) = 0. Assuming that 1r(w) = 1
for some wE V,4 II determines a consistent belief set K.
Furthermore, we have the following obvious relationships:
(a) A E K iff N(A) > 0 iff II(-.A) < 1. Such a
sentence is said to be accepted. If -,A E K, A is
said to be rejected.

(b) A f/:. K iff II( -,A) = 1. If neither of A or -,A is
in K, A is said to be indeterminate.
(c) M I= A ::} B iff II(A /1. B) > IT(A /1. -,B) or
II(A) =0.
We note that possibility rankings can be given a probabilis­
tic interpretation using c:-semantics (Adams 1975; Pearl
1988). We can associate ��:-rankings (Goldszmidt and Pearl
1991) with degrees of possibility and take 7r ( w) > 7r(v) to
mean that world w is arbitrarily more probable than v. In
this manner, we can ensure that the conditional probabil­
ity P(BIA) can be made arbitrarily high if A ::} B holds
(Adams 1975).
3

Counterfactual Probabilities

The notion of epistemic state introduced in the last section
certain drawbacks. In particular, the serious possibili­
ties held by an agent cannot be distinguished according to
their degree of certainty or belief. The epistemic status of
a proposition A is one of acceptance, rejection or indeter­
minacy. Indeterminate propositions reflect an uncertainty
about their truth, but among indeterminate propositions, no
distinctions can be made with respect to degree of uncer­
tainty. Notice that possibility theory has nothing to offer
in this regard: if neither A nor -,A are believed then both
have degree of possibility 1 and degree of necessity 0.
has

3.1

Semantics

One would like to be able to express, for a given belief set
K, the degree of belief associated with uncertain possibil­
ities. W hile neither of A or -,A may be sufficiently likely
to warrant full acceptance, evidence may render one more
If we drop that restriction, a simple modification of the AGM

postulates will suffice.
4
Throughout, we will assume that W � V is nonempty. These
proper possibility models will correspond to nonempty (consis­
tent) epistemic states.

The Probability of a Possibility: Adding Uncertainty to Default Rules

probable than the other. We would like to say, for example,
that an agent associates probability . 75 with A (or that A
is believed to degree .75). Semantically, this is easily ac­
complished. In the usual fashion, we can assign a non-zero
probability weight to each epistemically possible world,
taking epistemically impossible worlds (1r(w) < 1) to have
probability 0. In this manner, all full beliefs (accepted
sentences) have probability 1 arid only serious possibilities
have non-zero probability.
While this provides degrees of belief for epistemic possibil­
ities, it does nothing to determine counterfactual probabili­
ties (e.g., P(BIA) where II(A) < 1). While the possibility
distribution 1r distinguishes worlds according to their de­
gree of possibility, worlds within each possibility rank are
indistinguishable. However, we can apply the same idea
and assign, within each possibility rank, relative weights
to worlds. Of course, we need not use a different weight
assignment function for each value in the range of 1r. We
can simply assign weight to all worlds and compare only
the weights of worlds with the same degree of possibility.
Definition 3 A counterfactual probability model (CPM)

has the form M = (V, W, P, 1r) where
(a) (V, W, 1r) is a possibility model; and
(b) P maps W into (0, 1]

As before, 1r(w) is the degree of possibility assigned to
world w E V and W is the subset of "possible" worlds
in V. P(w) is the probability weight assigned to possible
world w. This weight must be non-negative, for we assume
that only impossible worlds (V - W) can have no weight.
The definition of the categorical belief set I< and the truth
conditions for the conditional connective => are exactly as
for a possibility model (Definition 2). The definition of a
revised belief set I<.A also remains unchanged.
As stated earlier, an agent's epistemic state is captured by
those worlds w such that 1r(w) = 1. Furthermore, should an
agent come to accept A, its revised belief state is captured
by the set of most possible A-worlds Pl(A). Given this
belief state, the degree of belief accorded some sentence B
ought to be the relative weight of all B-worlds in this set.
This leads to the following definitions.
Definition 4 Let M = (V, W, P, 1r) be a CPM. The coun­
terfactual probability of B given A (w.r.t. M) is

P(B

i

A)

=

l:{P(w): wE Pl(A) and w p B}
l:{P(w): wE Pl(A)}

465

the usual notion of degree of belief, where only epistemic
or serious possibilities have non-zero probability.
Proposition 3 P(A)

=

1 iff AE I<.

We define factual conditional probability in the usual way:
Definition 6 P(BIA)

P(A) > 0.

=

P�(�))

for all A such that

Our goal is now to describe a method for an agent to move
from one epistemic state to another during the course of
revision. In particular, we must describe the new factual
probability function P.A that results when the agent's orig­
inal epistemic state P is revised by A. This revision will
proceed by means of counterfactual conditionalization.
Definition 7 Let P be the factual probability function determined by M. The revised factual probabilityfunc­
tion P.A is given by

Pl(B)

=

P(B j A)

The (objective) epistemic state of an agent after such a
revision is characterized by P.A. We can show the following
key results. First, Pl determines a valid epistemic state:
Proposition 4 lfii(A) > 0 then Pl is a probabilityfunc­
tion.

We also have that the revised probability function respects
the truth conditions for our conditional connective, and
hence corresponds precisely to the belief set I<.A:
Theorem

5

M f:: A => B (i.e., BE I<.AJ iff P_4(B) = 1.

Given the representation result Theorem 1, we can show
that this model forms a proper extension of the AGM theory
of revision. For any CPM M, let the * denote the revision
function induced by theM (i.e., K.A = {B : P_4(B) = 1} ).
Corollary 6 The induced revision function * satisfies the
AGMpostulates,· andfor any I< andAGM revisionfunction
*• there is a CPM that induces *·

Finally, it's not hard to see that Pl respects the usual notion
of conditionalization when this is applicable:
Theorem 7 lfP(A) > 0 then P_4 (B)

=

f(BIA).

Proposition 2 For any CPM M, the factual probability
function P is a probabilityfunction.

Thus CPMs can be viewed in several different ways. First,
they extend the AGM theory of revision (and hence condi­
tional theories of default reasoning) with the power to ex­
press uncertain conclusions probabilistically. Second, they
can be thought of as a means of representing counterfactual
probabilities and extending the notion of conditionalization
to conditions with zero probability. Third, they unify pos­
sibility and probability theory in a way that highlights the
orthogonal roles they have to play in the representation of
uncertain information and inference.

We take the unconditional, factual probability function P
to define the objective epistemic state of the agent. This is

Notice that while we have specified here an updated factual
probability function, we have said nothing about the new

Since P is defined only on worlds in W, this term is unde­
fined iff A is impossible (i.e., if 1r(A) = 0).
Definition 5 The factual probability of A (w.r.t. M) is

P(A)

=

P(A i T)

466

Boutilier

counterjactual probabilities an agent should adopt upon

learning A. There are several ways in which one might
proceed. We discuss this issue in the concluding section.
3.2

Using Factual Probabilities

Given this semantics for counterfactual probabilities, the
question remains: how should one compute the result of
updating a belief set? Given that one has standard tech­
niques for dealing with probability measures, these can be
used in (at least) two ways to simulate this model of coun­
terfactual probabilities. The first fairly obvious method is
to assign a unique probability function Pk for each degree
of possibility in the range of 1r (i.e., for eachk = 1r(w )
for some w ) 5 The functions Pk in this sequence need only
satisfy the property that no two distinct functions assign
positive probability to the same maximal conjunction of lit­
erals. In other words, if Pk(w ) > 0 then Pi (w ) = 0 for
all j f k. Call such a sequence of functions admissible.
The most possible junction for sentence A in this sequence,
denoted PA, is the function Pk where
.

k = max { i: Pi(A) > 0}
When revising by A, we simply find the most possible
function for A, and condition on A. It's not hard to see the
following:
Proposition 8 For any CPM there is an admissible se­
quence of probability junctions such that PA.(B) =
PA(BIA). For each admissible sequence, there is a CPM
such that the same relation holds.

Clearly, this definition of admissible sequence relies cru­
cially on the fact that there are a finite number of worlds.
However, it suggests an obvious generalization of ourCPMs
to deal with infinite languages. We simply postulate a se­
quence of arbitrary indexed probability functions suitable
for the language in question. The most possible function in
the sequence represents the agent's current epistemic state.
Revision by A is simply a matter of finding the most pos­
sible function that satisfies A, then conditioning by A with
respect to that function. In order to mimic the structure of
CPMs, we would have to insist that "maximal conjunctions"
or possible worlds have positive probability for no more that
one function. This is impossible to impose logically since
worlds correspond to "infinite conjunctions." It toms out,
however, that imposin1 such a constraint has no effect on
the results of revision. In essence, allowing worlds to be
assigned more than one possibility value (i.e., permitting
"duplicate worlds") has no effect on revision, since only
the most possible value will ever have an influence on our
5Using a sequence of probability functions is suggested infor­
mally by Lewis (1976).
6To see this, imagine that two distinct functions Pi and Pk were
such that each assigned positive probability to some possible world
(infinite conjunction) w. (We assume j < k.) The probability
assigned to w by the less possible function Pi can influence the
result of revision by A only if: a) Pi is the most possible function
for A; and b) w I= A, for the updated function is given by
PA.(B)
Pj(BIA). But if w I= A then Pk(A) > 0 also,
contradicting the fact that Pi is most possible for A.
=

deliberations. Thus, specifying an arbitrary sequence of
probability functions, ordered by degree of possibility, is
a sound (and very general) representation mechanism for
counterfactual probabilities.
There is a second method one might use to reason with
counterfactual �robabilities using standard probabilistic
representations. We can combine the sequence of probabil­
ity functions into one function if the set of worlds assigned
to any degree of possibility is finitely characterizable. This
simply means that each cluster of equally possible worlds
corresponds to some finite theory, or sentence a. In the case
of our finite language, this must be true.8 In such a case, we
need only index each possibility value by its characterizing
sentence and incorporate this sentence during conditional­
ization. Formally, we require a sentence ak. fork > 0,
such that
llakll = { w: 1r(w ) =k}
An arbitrary sequence of sentences is admissible iff the
elements of the sequence are pairwise disjoint: a i 1- ..,ak
iff j f k. We can assign an arbitrary positive probability
weight to each possible world, defining a single probability
function P. To revise by A, we need to find the most
possible characterizing sentence consistent with A: the ak
such that
k = max { i: ai If ...,A}
We denote this sentence aA. To revise by A, we must
condition on A; but we are only interested in the most
possible A-worlds, those that satisfy aA. It's not hard to
see the following:
Proposition 9 For any CPM there is an admissible se­
quence of sentences and a probabilityjunction P such that
PA.(B) = P(BIA A aA)· For each admissible sequence
and probability function P, there is a CPM such that the
same relation holds.

Notice that the single probability function P used to simu­
late the counterfactual probability function cannot be given
a reasonable intuitive interpretation. Indeed, P assigns less
than certain probability to full beliefs; and it may make im­
possible sentences more probable than full beliefs! Func­
tion P should be understood as simply a technical device to
allow "non-counterfactual" probabilistic reasoning meth­
ods to be applied. Thus, one need not define new reasoning
mechanisms to deal with counterfactual probabilities.
4

Generalized Imaging9

Lewis ( 1976) proposed a method for probabilistic updat­
ing known as imaging that generally gives results different
7
Thank:s to Fahiem Bacchus for suggesting this representation.
8
For arbitrary languages and finite conditional KBs, this will
be the case should one choose, say, a unique most compact model
of KB. For example, Pearl's (1990) SystemZ has this property, as
does the most compact possibility ranking of (Benferhat, Dubois
and Prade 1992). Furthermore, there will be only a finite number
of possibility values assigned to possible worlds.
9In this section, we present a technical result that is somewhat
orthogonal to the rest of the paper.

The Probability of a Possibility: Adding Uncertainty to Default Rules

from those for conditionalization. In a possible worlds
framework, the distinction can be understood as follows.
We assume a probability function P is determined by an as­
signment of weight to a finite set of possible worlds. When
an epistemic state is updated by sentence A through condi­
tionalization, the weight assigned to ...,A-worlds is retracted
and the remaining weight (assigned to A-worlds) is normal­
ized. This can be thought of as taking the totality of weight
P( -,A) and redistributing it among the A-worlds: each A­
world gets a share of this total in accordance with its relative
weight among all A-worlds. Notice that conditionalization
by A is undefined if P(A) = 0, for the relative weight of
individual A-worlds has no meaning in this context.
Lewis's imaging can be thought of as a different way of ef­
fecting the minimal change of P. Each world w is assumed
to have a unique most similar A-world, denoted f(w, A),
that is most like w in relevant respects and satisfies A.
The function f is a selection function that picks out this
most similar A-world. As with conditionalization, when
an update A is to be achieved, weight must be appropri­
ated from -,A-worlds and assigned to A-worlds. However,
Lewis claims that it is reasonable to expect that the weight
taken away from a -,A-world not be arbitrarily distributed
among all A-worlds. Rather one should assign the weight
taken from w to its most similar counterpart satisfying A,
namely f(w, A). It is clear that typically such a method
of update will yield results different from conditionaliza­
tion. It is also clear that imaging by A is meaningful even
when P(A) = 0. Notice that one need not distinguish
A-worlds from -,A-worlds in the redistribution of weight.
If we insist that the selection function be centered, that is
if f(w, A) = w whenever w f:: A, then we simply redis­
tribute the weight from every world w to f(w, A). Iff is
centered, A-worlds (in effect) keep their own weight.
Gardenfors (1988) describes a slightly more general form
of imaging known as generalized imaging. This form of up­
date proceeds as with imaging, except that the most similar
A-world for w need not be unique. Instead, we let/(w, A)
denote a set of A-worlds, those that are most similar to
w. W hen imaging by A, the weight taken from some -,A­
world is redistributed in the appropriate proportions among
the worlds in f(w, A). This clearly adheres to the spirit and
intent of Lewis's notion. Formally, we have:
Definition 8

Let V be a (finite) set of worlds and P map
V into [0, 1]. We let P also denote the probability
function (on sentences) induced by this mapping of W.
A selection function is a mapping f from W x LCPL
into 2w .10 An revision function * is a generalized
imaging function iff there exists a selection function f
such thatP,:(w) =

""'
L.J

vEW

P(w)
. w f( A)}
{P(v)
. l:{P(u): u E f(v, A)} . E v,

Our method of update using counterfactual probabilities
can be viewed as a generalized imaging function simply
10
Typically we impose restrictions on f (e.g., so that se­
mantically equivalent formulae determine the same most similar
worlds), but these are of no concern here.

467

by taking the set Pl( A ) to denote the set f(w, A) for each
world w. If we wish, we can also use a centered selection
function defined as f(w,A) = {w} for all A-worlds and
f(w,A) = Pl( A) for-,A-worlds. With this we see:
Theorem 10 Let M be a CPM that induces factual prob­
ability junction P and revision operator * (that is, the re­
vision of P by A is given by P_.:). Then* is a generalized
imagingfunction.
Together with Theorem 7 this shows that a generalized
imaging function can be constructed in such a way that
it accommodates conditionalization. This stands in sharp
contrast with the claim of Gllrdenfors (1988, Ch.5) that con­
ditionalization and generalized imaging are fundamentally
incompatible. Our method of revision using counterfac­
tual probabilities, in fact, embraces both approaches. We
explore the full implications of this unification in a longer
version of this paper.
5

Concluding Remarks

We have presented a semantics for default reasoning and
belief revision that admits degrees of belief. Our system
incorporates the key aspects of both qualitative and quan­
titative methods, capturing the statics of representation and
the dynamics of revision. It extends both AGM revision
and conditionalization, and can be viewed as a form of gen­
eralized imaging. It can also be seen as a unification of
probability and possibility theory.
One issue that remains unaddressed in this paper is the
derivation of new counterfactual probabilities after update,
and how to iterate the process of revision. The updated
function p_.: is specified only for factual probabilities, and
determines the new objective epistemic state. Counterfac­
tual conditional probabilities P.A ( C j B) remain unspec"
ified when p_.: (B) = 0. So imagine one updates P by
A. If P,:(B) = 0, then the result of updating p_.: by B
is cannot be determined. There are several directions in
which one might proceed. One method extends the quali­
tative natural revision model of (Boutilier 1993c). In this
approach, the worlds in Pl( A) become most possible while
all other worlds retain the same (relative) ranking of pos­
sibility. If the relative probability weight of each world
remains unchanged, this model provides a method of up­
dating counterfactual probabilities in which as few counter­
factual probability values as possible are altered. A some­
what different mechanism would adopt the method of ]­
conditioning proposed by Goldszmidt and Pearl (1992) for
updating conditional rankings. However, such a method
involves the updating the possibility distribution so that
worlds that originally had different degrees of possibility
now can have the same degree. How to reconcile the rela­
tive weights of such worlds in this case is not clear. Related
to these proposals is the model of arbitrary conditional re­
vision proposed in (Boutilier and Goldszmidt 1993). Such
a model, if extended, would allow one to update counter­
factual probabilities without changing factual probabilities.
Another issue that remains unaddressed is how factual prob-

468

Boutilier

abilities can influence or determine counterfactual probabil­
ities. This is a difficult problem, even in qualitative belief
revision. The impact of the AGM theory (and our model
here) is to suggest that, in general, one must permit arbi­
trary changes. Practically speaking, this is unsatisfying,
and practical constraints on updating probabilities must be
investigated. For example, if A is "unrelated" to B and
C, and P is updated by A, we would like the conditional
probability P( CIB) to influence (perhaps determine) the
new probability P_A(C!B), even if P(A) = 0.
We are currently exploring the use of counterfactual proba­
bilities in model-based diagnosis. In (Boutilier and Becher
1993), we have embedded logical approaches to diagno­
sis in the qualitative conditional framework. Conditional
defaults allow one to completely (but defeasibly) discount
potential candidate diagnoses. Attaching (counterfactual)
probabilities to such rules allows one to represent the fact
that certain of the remaining candidates are more likely
than others. This provides a semantics that might underly
methods of logical diagnosis that incorporate probabilistic
information (de Kleer 199 1 ; Poole 1993).

Acknowledgements

I would like to thank Fahiem Bacchus, Moises Goldszmidt,
Keiji KanazawaandDavid Poole for their helpful comments
and suggestions. This research was supported by NSERC
Research Grant OOP0121843.

References
Adams, E. W. 1975. The Logic of Conditionals. D.Reidel, Dor­
drecht.
Alchourr6n, C., Giirdenfors, P., and Makinson, D. 1985. On the
logic of theory change: Partial meet contraction and revision
functions. Journal of Symbolic Logic, 50:510-530.

Boutilier, C . 1993c. Revision sequences and nested conditionals.
In Proceedings ofthe Thirteenth International Joint Confer­
ence on Artificial Intelligence, Chambery. (to appear).
Boutilier, C. and Becher, V. 1993. Abduction as belief revi­
sion: A model of preferred explanations. fu Proceedings of

the Eleventh National Conference on Artificial Intelligence,
Washington, D.C. (to appear).
Boutilier, C. and Goldszmidt, M. 1993. Revision by conditional
beliefs. fu Proceedings ofthe Eleventh National Conference
on Artificial Intelligence, Washington, D.C. (to appear).
Cheeseman, P. 1985. In defense of probability. In Proceedings of

the Ninth International Joint Conference on Artificial Intel­
ligence, pages 1002-1009, Los Angeles.
de Kleer, J. 1 99 1 . Focusing on probable diagnoses. fu Proceed­

ings of the Ninth National Conference on Artificial Intelli­
gence, pages 842-848, Anaheim.
Dubois, D. and Prade, H. 1988. An introduction to possibilis­
tic and fuzzy logics. In Shafer, G. and Pearl, J., editors,
Readings in UncertainReasoning , pages 742-761 . Morgan­
Kaufmann, San Mateo. 1990.
Giirdenfors, P. 1988. Knowledge in Flux: Modeling the Dynamics
ofEpistemic States. MIT Press, Cambridge.
Goldszmidt, M. and Pearl, J. 1 99 1 . On the consistency of defea­
sible databases. Artificial Intelligence, 5 2 : 1 2 1-149.
Goldszmidt, M. and Pearl, J. 1992. Reasoning with qualitative
probabilities can be tractable. fu Proceedings of the Eighth
Conference on Uncertainty in AI, pages 1 12-1 20, Stanford.
Harman, G. 1986. Change in View. MIT Press, Cambridge.
Kraus, S., Lehmann, D., and Magidor, M. 1 990. Nonmonotonic
reasoning, preferential models and cumulative logics. Arti­
ficial Intelligence, 44:1 67-207 .
Kyburg, Jr., H. E. 1 96 1 . Probability and the Logic of Rational
Belief Wesleyan University Press, Middletown.
Levi, I. 1 980. The Enterprise of Knowledge. MIT Press, Cam­
bridge.
Lewis, D. 1976. Probabilities of conditionals and conditional
probability. Philosophical Review, 85:297-3 15.

Third International Conference on Principles ofKnowledge
Representation and Reasoning, pages 673-684, Cambridge.

Makinson, D. and Giirdenfors, P. 1990.
Relations between
the logic of theory change and nonmonotonic logic. fu
Fuhrmann, A. and Morreau, M., editors, The Logic ofTheory
Change, pages 185-205. Springer-Verlag, Berlin.

Boutilier, C. 1990. Conditional logics of normality as modal
systems. fu Proceedings ofthe Eighth National Conference
on Artificial Intelligence, pages 594-599, Boston.

Pearl, J. 1988. Probabilistic Reasoning in Intelligent Systems:
Networks of Plausible Inference. Morgan Kaufmann, San
Mateo.

Boutilier, C. 1 992a. A logic for revision and subjunctive queries.
In Proceedings ofthe Tenth National Conference onArtificial

Pearl, J. 1 990. System Z: A natural ordering of defaults with
tractable applications to default reasoning. In Vardi, M., ed­

Benferhat, S., Dubois, D., and Prade, H. 1992. Representing
default rules in possibilistic logic. fu Proceedings of the

Intelligence, pages 609-615, San Jose.
Boutilier, C. 1992b. Modal logics for qualitative possibility and
beliefs. fu Proceedings ofthe Eighth Conference on Uncer­
tainty in AI, pages 1 7-24, Stanford.
Boutilier, C. 1992c. Normative, subjunctive and autoepistemic
defaults: Adopting the Ramsey test. fu Proceedings of the

Third International Conference on Principles ofKnowledge
Representation and Reasoning, pages 685-696, Cambridge.
Boutilier, C. 1993a. Conditional logics of normality: A modal

approach. Artificial Intelligence. (to appear).

Boutilier, C. 1993b. Unifying default reasoning and belief revision
in a modal framework. Artificial Intelligence. (to appear).

itor, Proceedings ofTheoreticalAspects ofReasoning about
Knowledge, pages 1 21-135. Morgan Kaufmann, San Mateo.
Poole, D. 1993. The use of conflicts in searching Bayesian net­
works. fu Proceedings of the Ninth Conference on Uncer­
tainty in AI, Washington, D.C. (to appear).
Stalnaker, R. C. 1968. A theory of conditionals. fu Harper, W.,
Stalnaker, R., and Pearce, G., editors, /fs, pages 41-55. D.
Reidel, Dordrecht. 198 1 .
Stalnaker, R . C . 1970. Probability and conditionals. fu Harper, W.,
Stalnaker, R., and Pearce, G., editors, lfs, pages 107-128. D.
Reidel, Dordrecht. 1 98 1 .

