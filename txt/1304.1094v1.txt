106

I
I
Reducing Uncertainty in Navigation and Exploration

I

Kenneth Basye*

I
I
I
I
I
I
I

Moises Lejtert

Department of Computer Science
Brown University
Box 1910, Providence, RI 02912

Abstract
A significant problem in designing mobile robot con­
trol systems involves coping with the uncertainty
that arises in moving about in an unknown or par­
tially unknown environment and relying on noisy or
ambiguous sensor data to acquire knowledge about
that environment. We describe a control system
that chooses what activity to engage in next on the
basis of expectations about how the information re­
turned as a result of a given activity will improve
its knowledge about the spatial layout of its environ­
ment. Certain of the higher-level components of the
control system are specified in terms of probabilis­
tic decision models whose output is used to mediate
the behavior of lower-level control components re­
sponsible for movement and sensing.

I
I
I
I
I
I
I
I
I

Keiji Kanazawat

1

Introduction

We are interested in building systems that construct
and maintain representations of their environment
for tasks involving navigation. Such systems should
expend effort on the construction and maintenance
of these representations commensurate with expec­
tations about their value for immediate and antic­
ipated tasks. Such systems should employ expec­
tations about the accuracy of the information re­
turned from sensors to assist in choosing activities
that are most likely to improve the accuracy of its
representations. Finally, such systems should em­
ploy expectations about the time required to carry
out a given activity in order to make appropriate
tradeoff's regarding other activities whose expected
return value depends on when they are completed
or how long they take.
*kjbCcs.brown.edu
tmlmCcs.brown.edu
lkgkCcs.brown.edu

An architecture for the above sort of systems must
be able to generate hypotheses, reason about the
impact of actions designed to confirm or refute those
hypotheses, and revise its hypotheses in the light of
new information. In the remainder of this paper, we
will describe a particular robot control system, hut
the discussion focuses on the issues and the specific
decision making technologies that we have chosen to
address those issues.

2

Exploration and Navigation

We start with the premise that having a map of your
environment is generally a good thing if you need
to move between specific places whose locations are
clearly indicated on that map. The more frequent
your need to move between locations, the more use­
ful you will probably find a good map. If you are not
supplied with a map and you find yourself spending
an inordinate amount of time blundering about, it
might occur to you to build one, but the amount of
time you spend in building a map will probably de­
pend upon how much you anticipate using it. Once
you have decided to build a map, you will have to
decide when and exactly how to go about building
it. Suppose that you are on an errand to deliver a
package and you know of two possible routes, one of
which is guaranteed to take you to your destination
and a second which is not. By trying the second
route, you may learn something new about your en­
vironment that may turn out to be useful later, but
you may also delay the completion of your errand.
Suppose you come to an intersection that looks
familiar; the intersection that you recall had a store
belonging to a chain of department stores on one
of the corners. Establishing that there is indeed a
store from the same chain on one of the corners of
the the present intersection is not enough to deter­
mine that the present and recalled intersections are
the same, but it will certainly strengthen the hy­
pothesis that they are the same. There might be

107

other information that you could gather in an effort
to confirm or deny the hypothesis. For instance you
might recall that two blocks west of the recalled in­
tersection there is a certain restaurant. On the basis
of how much time you have and how important it
is for you to establish your location with regard to
that recalled intersection, you will have to choose
whether or not it is worth your while to look for the
restaurant; such information could be very costly if
you're not sure which direction is west or there is
danger of getting lost in a maze of one-way streets.
Our robot, Huey, has strategies for checking out
many simple geometric features found in typical of­
fice environments; we refer to these strategies as fea­
ture detector&. The complete set of feature detectors
used by Huey and the details concerning their imple­
mentation are described in [Randazza, 1989]. Each
feature detector is realized as a control process that
directs the robot's movement and sensing. On the
basis of the data gathered during the execution of a
given feature detector, a probability distribution is
determined for the random variable corresponding
to the proposition that the feature is present at a
specific location.
Huey is designed to explore its environment in
order to build up a representation of that environ­
ment suitable for route planning. In the course
of exploration, Huey induces a graph that cap­
tures certain qualitative features of its environ­
ment [Kuipers and Byun1 1988, Levitt et a.l., 1987,
Basye et al., 1989]. In addition to detecting geo­
metric features like corners and door jambs, Huey is
able to classify locations. In particular, Huey is able
to distinguish between corridors and places where
corridors meet or are punctuated by doors leading
to offices, labs, and storerooms. A corridor is de­
fined as a piece of rectangular space bounded on
two sides by uninterrupted parallel surfaces 1.5 to
2 meters apart and bounded on the other two sides
by port& indicated by abrupt changes in one of the
two parallel surfaces. The ports signal locally du­
tinctive place& (LOPs) (after [Kuipers, 1978 ]) which
generally correspond to hallway junctions. Uninter­
rupted corridors are represented as arcs in the in­
duced graph while junctions are represented as ver­
tices. Junctions are further partitioned into classes
of junctions (e.g., L-shaped junctions where two cor­
ridors meet at right angles, or T-shaped junctions
where one corridor is interrupted by a second per­
pendicular corridor). Huey is given a set of junction
classes that it uses to classify the locations encoun­
tered during exploration, and label the vertices in
its induced graph to support route planning.

I
I

T

------tl---4�

�'I

I

---_____
_____

,_....

!
.

Figure 1: A map and the underlying grid

3

I
I
I
I

Value of Exploration

There are many ways to design a decision model for
allocating time to exploration and errand running.
Our treatment here is meant to provide an example
of the sort of decision models used in Huey.
For the simple model presented here, we assume
that the system of junctions and corridors that make
up Huey's environment can be registered on a. grid
so that every corridor is aligned with a grid line and
every junction is coincident with the intersection of
two grid lines. In the following, the set of junction
types, J, corresponds to all possible configurations
of corridors incident on the intersection of two grid
lines. Intersections with at least one incident corri­
dor correspond to LOPs. Since we also assume that
Huey knows the dimensions of the grid (i.e., the
number of :z: andy grid lines), Huey can enumerate
the set of possible maps M = {M11 M2,
, Mm},
where a map corresponds to an assignment of a junc­
tion type to each intersection of grid lines. For most
purposes, we can think of a map as a labeled graph.
Figure 1 shows a junction assignment and the asso­
ciated grid.
•

•

•

We restrict M by making an assumption about
office buildings of the sort that Huey will find itself
in, that all the LOPs are connected. However, for
most situations, this restriction does not reduce the
size of M sufficiently; in the next section we discuss
several strategies for restricting M to a manageable
size. We now turn to the details of the decision
model used for exploration.
In the simple model considered here, we assume
that some paths for completing a task are known,
but they may all be longer than necessary. Huey has
to choose between taking the shortest path through
known territory, and trying the shortest path con­
sistent with what is known. In the latter case, Huey
will learn something new, but it may end up taking

I
I
I
I
I
I
I
I
I
I
I
I
I

108

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

F igure 2: The probabilistic model used for reasoning
about tradeoffs
longer to complete its task.
Let L be the set of all locally distinctive places in
the robot's environment,C = {G1,G2,..., Gn} be
a set of equivalence classes that partitions L, and F
be a set of primitive geometric features ( e.g., con­
vex and concave corners, fiat walls). Each class inC
can be characterized as a set of features in F that
stand in some spatial relationship to one another.
As Huey exits a port, a local coordinate system is
set up with its origin on the imaginary line defined
by the exit port and centered in the corridor. The
space about the origin enclosing the LDP is divided
into a set of equi-angular wedges W. For each fea­
ture/wedge pair (!,w) in F x W, we define a special­
ized feature detector dJ,w that is used to determine
if the current LDP satisfies the feature f at location
w in the coordinate system established upon enter­
ing the LDP, and a boolean variable of the form,
XJ,w• used to represent whether or not the feature
f is present at location w.
Let H be a random variable corresponding to the
actual configuration of the environment; H takes on
values from M. Let 1:,11 be a random variable cor­
responding to the junction type of the intersection
at the coordinates, (z, y), in the grid; 1:,11 can take
on values from the set C. Let Xf,w be as above,
a boolean variable corresponding the presence of a
feature at a particular position. Let S:,11 be a ran­
dom variable corresponding to a possihle sensing ac­
tion taken at the coordinates, (z, y), in the grid. Let
S correspond to the set of sensing actions taken thus
far. The complete probabilistic model is shown in
F igure 2.
In our simple model,Huey has to decide between

the two alternatives, PK and Pu1 corresponding to
paths through known and unknown territory. To
compute Bel(H) = Pr(HIS), Pr(H) is assumed to
be uniform, Pr(J:,11IH) and Pr(XJ,w 11:,11) are de­
termined by the geometry, and Pr(S:,11IXJ,w) is de­
termined experimentally. Let T = {T1,T2,. . . , Tr}
denote the set of all tasks corresponding to point­
to-point traversals, and E(IT;I) denote the expected
number of tasks of type To. Let Cost(To,M;,M.�:)
be the time required for the task 1i using the map
M;, given that the actual configuration of the en­
vironment is M.�:; if M; is a subgraph of M.�:, then
Cost(To,M;,M.�:) is just the length of the shortest
path in M;. For evaluation purposes, Huey assumes
that it will take at most one additional exploratory
step. Let T* denote Huey's current task, and M*
the map currently used for route planning. In the
simplest model, Huey correctly classifies any loca­
tion it passes through, and M* is the minimal as­
signment consistent with what it has classified so
far.
To complete the decision model, we need a means
of computing the expected value of PK and Pu. In
general, the value of a given action is the sum of
the immediate costs related to T * and the costs for
expected future tasks. Let
T

Futures(M;,I)

=

L E(IT;I)Cost(T;,Mj,M;),

i=l

where Mj

=

M argmax; Pr(M;II)·

If classification is perfect, Huey correctly classifies
any location it passes through, and M£ is the mini­
mal assignment consistent with what it has classified
so far. In this case, the expected value of PK is
Cost(T*,M*,-) + Futures(-,£).
If classification is imperfect, the expected value of
PK is
m

L Pr(M; 1£) [Cost(T*,M*,M;) + Futures(M;,£)] .

j:l

Handling Pu is just a bit more complicated. Sup­
pose that Huey is contemplating exactly one sensing
action that will result in one of several possible ob­
servations 01,...,On, then the expected value of
Puis
m

L Pr(M; 1£)Cost(T*',M*,M;) +
n

j=l

I:
i=l

m

Pr(O;)

L Pr(M;IO;,£)Futures(M;,[0;,£])
j=l

109

where T•' is a modification of T* that accounts for
the proposed exploratory sensing action.
We use Jensen's variation of Lauritzen and
Spiegelhalter's algorithm [Jensen, 1989, Lauritzen
and Spiegelhalter, 1988] to compute the belief func­
tion, and compute I:�=l E(ITtl) Cost(TA:, M,, Mi)
once for all pairs (Mi, M;) E M x M, storing the
results in a table.
The time required to compute the belief function
is determined by the size of the sample spaces for the
individual random variables and the connectivity of
the network used to specify the decision model. In
the case of a singly-connected 1 network, the cost of
computation is polynomial in the number of nodes
and the size of the largest sample space-generally
the space of possible maps. The network shown in
Figure 2 would be singly-connected if each feature,
XJ,w, had at most one parent corresponding to a
junction, Jz,11• In the case of a multiply-connected
network, the cost of computation is a function of
the product of the sizes of the sample spaces for the
nodes in the largest clique of the graph formed by
triangulating the DAG corresponding to the original
network. In this case, the multiply-connected net­
work is more appropriate than the singly-connected
one because the presence of a feature at one junc­
tion can affect the classification of a neighboring
junction. Because these networks have very large
cliques, they can require long computations, or may
even exceed space limitations.
In the singly-connected case, the only stumbling
block is the size of the hypothesis node. We can get
around this problem by limiting the number of alter­
native hypothesis actually considered at any given
time. In this case the space of possible maps cho­
sen may not include the map corresponding to the
actual configuration of the environment. To detect
this occurance, we include in the state space of the
hypothesis node a value which represents the prob­
ability that none of the other maps is correct; we re­
fer to this as the none of the t�bove, or NOTA state.
The conditional probabilities for any junction node
given this state are uniform over all the possibili­
ties for the junction. That is, the NOTA state pro­
vides no information about any junction. Adding
evidence which is consistent with one or more maps
in the hypothesis node causes the posterior proba­
bility of the NOTA state to fall. Only when evidence
is added which conflicts with t�ll maps in H can the
NOTA state become more probable. If the value of
1 A network ia Aid to be aingly-connected if there ia at
moat one directed path between any two nodea; otherwiae, it
ia aaid to be multiply connected [Pearl,

1988).

Size
of H

Length of
Exploration

10
10
10
10
20
20
20
20
30
30
30
30

4
6
8
10
4
6
8
10

4
6
8
10

Time
(seconds)

Cost of
Largest Clique

92.2
35.6
8.8
14.6
148.0
73.6
28.9
14.3
238.3
129.7
65.4
12.8

88064
41728
7424
12992
147456
73728
26240
13152
245760
150528
64512
10944

Table 1: Average results for 10 runs on a 4

x

4 grid.

the NOTA state exceeds the values of all the other
states in H, we dynamically adjust the model by
generating a new set of maps to replace the old set.
The new set is chosen to be as consistent as possible
with the current evidence. If enough evidence has
been collected, the new set may be exhaustive, oth­
erwise the procedure is repeated until an exhaustive
set is possible. In the non-exhaustive cases, includ­
ing the initial case, the hypotheses are generated
randomly, but not uniformiy. All of the hypotheses
will be completely connected, as discussed above. In
addition, we use the ratio of the number of edges in
the hypothesis to the number of total possible edges
as a measure of density, and we prefer to generate
maps of medium density over very sparse or very
dense maps.

In the case of multiply-connected networks, an
additional source of complexity arises in the connec­
tions between the junctions and the feature detec­
tors. Any large, unexplored block of space will re­
sult on a large block of multiply connected junction
nodes, which will in turn in a large clique after tri­
angulation. Table 1 shows how exploration and the
size of the hypothesis node affect the time to update
the network and the product of the state spaces for
the largest clique. By exploring only a little more,
this critical product can be reduced substantially.
The next section outlines an approach that allows
Huey to reduce the connectivity of the network used
to encode the decision model through the use of a
hierarchy of ever-more-detailed networks.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

1 10

I
I

as the decision network described in Section 3. Each
of the other networks up the hierarchy consists of
an abstracted version of its subordinate network.
Each of the decision networks up the hierarchy cor­
responds to an increasingly coarser description of
the world.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

Figure 3: Grid Hierarchy

4

Decision Models for Early
Exploration

The approach outlined in Section 3 attempts to rea­
son about the best alternative path to follow at
any one time based on an analysis of the informa­
tion known about the whole map. Although this
approach allows us to compute optimal (or near­
optimal) decisions, it has some drawbacks. In par­
ticular, if too little information about the world is
known when we attempt to evaluate the decision
network that algorithm builds, the number of possi­
bilities that must be taken into account blows up ex­
ponentially, making the evaluation impossible. The
larger the size of the world the robot finds itself in,
the more likely this situation will be. Two simple
strategies exist to deal with this problem: one is to
guarantee that enough information will be available
by the time the robot attempts to evaluate the deci­
sion network described above; the other, to try and
limit the size of the network our algorithm will have
to analyze. In [Dean et al., 1990], we outline a solu­
tion to this problem based only on the first of these
two strategies. A better solution, which employs
both strategies, is outlined here.
Our solution consists of analyzing the robot's cur­
rent situation using a hierarchy of decision networks
of increasing degree of abstraction, as illustrated in
Figure 3. The bottom, most detailed, network in
the hierarchy is the one corresponding to an accu­
rate representation of the real world. It is the same

The structure of each abstract decision network is
similar to that of the decision network used to model
the real world. The root of the network is a hypoth­
esis node whose values range over all possible maps
corresponding to the degree of abstraction repre­
sented by that the decision network. The root node
has a set of children, each one an abstract vertex,
corresponding to a region (set of neighbor vertices)
of the decision network immediately below in the
hierarchy. The values for each of these range over
all possible vertex configurations, just as they did in
our original formulation. Each node corresponding
to an abstract vertex has a set of children, corre­
sponding to the abstract edges leaving that vertex.
Each abstract edge represents the fact that there
exists some edge in the lower, less abstract decision
network, that allows the robot to travel between the
two regions represented by the two endpoints of the
abstract edge.
Figure 3 represents a sample hierarchy: it is made
up of three rows, each one displaying a grid repre­
senting the world at some level of abstraction along
with its corresponding decision network. At the top
level, the world is represented by four connected
regions (1, 1)1, (1, 2)!, (2, 1}!, (2, 2)!. Four abstract
edges a, b, c, d represent the connectivity between
these four regions. At the next level in the hier­
archy, we find a more detailed version of the world:
Each of the four regions present in the previous grid
has been expanded into four abstract regions of its
own. In particular, note the two abstract edges e, f
connecting (1, 2)2 to (1, 3)2 and (2, 2)2 to (2, 3)2,
respectively. The abstract edge a linking regions
(1, 1h, (1, 2)1 exists iff one of e, f exists as well. At
the next level down, we simply have the grid and
decision network representing the real world, as de­
scribed in Section 3. Note that abstract edge e de­
pends on the presence of certain features in the real
world (those that allow the robot to conclude one
of two paths actually exist).
The computation of the possible values for each
of the nodes in each of the decision trees in this
hierarchy is straightforward, as is the computation
of the conditional probabilities for each of the nodes.
The same algorithms used to compute these on our
original formulation can be used here.
One issue that arises in this approach is that of

111

The approach uses a weighting scheme o n edges

deciding when to switch to a more detailed level

1 to every
0 to every

of reasoning, that is, a more precise decision model.

in the grid. We assign a weight of

edge

An obvious alternative would be to make this switch

known to exist and a weight of

edge

when the robot has explored sufficiently to deter­

known not to exist. For edges whose existence is not

mine uniquely the value for the hypothesis node in

known, we can use the maps in the hypothesis node,

the decision network currently in use. However, it is

H, to generate intermediate values as follows: for

not clear that the number of possible values for the

each edge, e, let m be the number of maps in which

hypothesis node at the next, more detailed level will

e

have been reduced sufficiently by then to allow the

allow us to compute a value for any path in the grid

robot to evaluate that more detailed network.

exists. The weight for e is then

IHf+\ .

This scheme

In

by taking the product of the edges which make up

fact, for large spaces this seems very unlikely. An­

the path. A path consisting of all known edges has

other alternative would then be, to make the switch

value

1,

while a path which includes an edge known

to the next more detailed level when it has shrunk

to be non-existent has value

to a manageable size. However, for large spaces it

a particular location, the robot takes a step along

is not yet clear how much exploration this would

the path with the highest value, with shortest path

require.

0.

Given a task to reach

Our current approach involves staying at

length used to break ties. Any information gained

a given level of abstraction until the complexity of

by taking this step is included in the robot's map,

the next more detailed level falls under a thresh­

and this process is repeated until the destination

old value; this approach may still require that Huey

is reached.

adjust dynamically the set of maps under consider­

trying some shortest path even when the territory

ation for any given decision network, as mentioned

3.

in Section

Other methods might include simply

it crosses is unknown, deliberately avoiding known
territory while trying to reach the goal, and random
exploration.

The actual decision model used for each of the
levels in this hierarchy is similar to that of Sec­
tion

3,

modulo some differences introduced by the

fact that the networks represent abstractions of the
real world.

The most important difference has to

do with the definition of the cost functions used
for the abstract decision networks. The cost func­
tion defined in Section

3

was defined in terms of

the traversal of actual edges between point locations

(the

LDPs in the world) . The cost functions for the

Each one of these methods will have some asso­
ciated cost, but unlike the simple model of the pre­
vious section, the actual cost may not be known
for some methods before hand. We therefore antic­
ipate the need to develop estimation functions for
the costs of using each method.

Using these esti­

mations, we can make reasonable decisions between
various methods based on their value both in reach­
ing the goal and in providing new information.

abstract decision network must take into account
both the actual traversal of the edge and some es­
timate of the cost of traversal inside the abstract
regions represent by the nodes in the network. Ad­
ditionally, in the early stages of exploration, we can­
not assume that a path is know for each pair of lo­
cations in the graph. In this case, the cost of com­
pleting

a

task depends not only on the world, but

also on how the robot gets to the destination. That
is, there must be some method the robot uses for
finding locations it does not have a path for, and
this method gives rise to a cost function for tasks.
The decision to be made is which method should
be used.

Presumably, some methods will rely

as

5

An Approach to Designing
Robot Control Systems

Our approach to designing Huey's control system is
outlined as follows. We begin by considering Huey's
overall decision problem, determining an optimal
decision procedure according to a precisely stated
decision-theoretic criteria, neglecting computational
costs. We use an influence diagram to represent the
underlying decision model and define the optimal
procedure in terms of evaluating this model.

much as possible on known edges in an attempt to

Huey's overall decision problem involves several

reach the destination quickly, but will add a min­

component problems associated with specific classes

imal amount of new information.

Other methods

of events occurring in the environment. These com­

may be biased toward exploration, but take longer

ponent decision problems include what action to

to complete a given task. We are currently consider­

take when approached by an unexpected object in a

ing various methods, and describe one of the former

corridor, what sensor action to take next when clas­

kind here.

sifying a junction, and what path to take in combin-

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

112

I
I
I
I
I
I
I
I

ing exploration and task execution.

Each of these

Problems involving what sensor action to take in
classification or what path to take in navigation are

to a minute, so the robot has that amount of time
to decide what the next action should be if it wishes
to avoid standing idle lost in computation. The fre­
quency with which choices concerning what path to
take occur is dependent on how long Huey takes to
traverse the corridor on route to the next LOP. W ith
the current mobile platform operating in the halls of
the computer science department, moving between
two consecutive LOPs takes about four minutes. The

and

Future

Work

predictably recurrent. For instance, during classifi­

This paper emphasizes two decision processes: one
responsible for reasoning about the uncertainty in­
herent in a completely unfamiliar environment (Sec­
tion

4),

and a second responsible for assessing the

expected value of various exploratory actions after
some initial exploration has been done. (Section

3).

Both processes must deal with noisy and ambiguous
sensor data.

problem of deciding what to do when approached by

Our use of influence diagrams and Bayesian deci­

an unexpected object occurs unpredictably, and the

sion theory was inspired by recent work on decision­

time between when the approaching object is de­

theoretic control for visual interpretation and sen­
sor placement [Cameron and Durrant-Whyte, 1988,

tected and when the robot must react to avoid a
collision is on the order of a few seconds.

Hager,

By making various (in)dependence assumptions
and eliminating noncritical variables from the over­

I
I

of the sets of component problems are solved by

I

Conclusions

6

cation each sensor action takes about thirty seconds

all complex decision problem, we are able to de­

I

nificantly from such attempts at optimization.

problems is recurrent.

compose the globally optimal decision problem into
sets of simpler component decision problems. Each
a separate module. The computations carried out
by these modules are optimized using a variety of

1988,

Levitt et al.,

1988].

The design of

the geographer module was based on the work
of Kuipers [Kuipers and Byun, 1988] and Levitt
[Levitt et o.l.,

1987]

on learning maps of large-scale

space, and our own extensions to handle uncertainty
[Basye et al., 1989]. The design of the module re­
sponsible for coordinating exploration and errand
running was based on an application of information
value theory [ Howard, 1965].

techniques to take advantage of the expected time
available for decision making [Kanazawa and Dean,

Given that the complexity of Huey's exploratory
strategy is largely determined by the number of pos­

1989].

sible maps IMI, we are looking for properties of the

The different decision procedures communi­

cate by passing probability distributions back and

environment other than its global spatial layout that

forth. For instance, the module responsible for mak­

provide useful information for path planning.

ing decisions regarding exploration and the module

have also come to realize that for Huey's sensors

We

responsible for classifying LOPs pass back and forth

and the type of environments the robot is designed

I

distributions regarding the junction types of LOPs.

for, the most critical tradeoffs involve the cost of

I

statistical

I
I
I
I
I

Our justifications for making (in)dependence

as­

sumptions and eliminating variables are sometimes

( e.g.,

based on some type of sensitivity

analysis), but, more often than not, we take the
expedient of simply trying something out and see­
ing if performance is adversely affected.

We have

considered the compilation methods of Beckerman,
Breese, and Horvitz [Beckerman et o.l., 1989], but,
so far, the combinatoric& have made their decision­
theoretic compilation methods impractical for our
application. In our current approach, we make use
of fixed-time decision procedures, and attempt to

LOP classification and map regi&tro.tion: determining
the robot's position with regard to its global map.
Map registration is carried out by the geographer
module, and losing registration
can be quite costly for Huey.

( i.e.,

getting lost)

In the current sys­

tem, we assume that there exist some small number
of globally distinctive places, landmarks, that Huey
can use for map registration.

By carefully classi­

fying LOPs, Huey can avoid costly registration. We
are working on a decision model for exploration that
allows for tradeoffs involving map registration and
LOP classification.

minimize the time the robot spends standing about
just thinking.

We are also looking at the use of

variable-time decision procedures and doing run­
time allocation of processor time [Boddy and Dean,

1989], but Huey's task does not appear to profit sig-

References
[Basye et o.l.,

1989]

Kenneth Basye, Thomas Dean,

113

and Jeffrey Scott Vitter. Coping with uncertainty
in map learning. In Proceedings IJCAI 11, pages
663-668. IJCAI, 1989.
[Boddy and Dean, 1989] Mark Boddy and Thomas
Dean. Solving time-dependent planning prob­
lems. In Proceedings IJCAI 11, pages 979-984.
IJCAI, 1989.
(Cameron and Durrant-Whyte, 1988]
Alec Cameron and Hugh F. Durrant-Whyte. A
bayesian approach to optimal sensor placement.
Technical report, Oxford University Robotics Re­
search Group, 1988.
[Dean et al., 1990] Thomas Dean, Kenneth Basye,
Robert Chekaluk, Seungseok Hyun, Moises
Lejter, and Margaret Randazza. Coping with
uncertainty in a control system for navigation
and exploration. In Proceedings AAAI-90. AAAI,
1990.
[Hager, 1988] Gregory D. Hager. Active reduc­
tion of uncertainty in multi-sensor systems.
Ph.D. Thesis, University of Pennsylvania, De­
partment of Computer and Information Science,
1988.
[Beckerman et al., 1989]
David E. Beckerman, John S. Breese, and Eric J.
Horvitz. The compilation of decision models. In
UW89, pages 162-173, 1989.
[Howard, 1965] Ronald A. Howard. Information
value theory. IEEE 7ransactions on Systems,
Man, and Cybernetics, 2:22-26, 1965.
[Jensen, 1989] Finn V. Jensen. Bayesian updating
in recursive graphical models by local computa­
tions. Technical Report R 89-15, Institute for
Electronic Systems, Department of Mathemat­
ics and Computer Science, University of Aalborg,
1989.
[Kanazawa and Dean, 1989] Keiji Kanazawa and
Thomas Dean. A model for projection and ac­
tion. In Proceedings JJCAI 11, pages 985-990.
IJCAI, 1989.
[Kuipers and Byun, 1988] Benjamin J. Kuipers and
Yung-Tai Byun. A robust, qualitative method for
robot spatial reasoning. In Proceedings AAAI-88,
pages 774-779. AAAI, 1988.
[Kuipers, 1978] Benjamin Kuipers. Modeling spa­
tial knowledge. Cognitive Science, 2:129-153,
1978.

[Lauritzen and Spiegelhalter, 1988]
Stephen L. Lauritzen and David J. Spiegelhalter.
Local computations with probabilities on graphi­
cal structures and their application to expert sys­
tems. Journal of the Royal Stati6tical Society,
50(2):157-194, 1988.
[Levitt et al., 1987] Tod S. Levitt, Daryl T. Law­
ton, David M. Chelberg, and Philip C. Nelson.
Qualitative landmark-based path planning and
following. In Proceedings AAAI-87, pages 689694. AAAI, 1987.
[Levitt et al., 1988] Tod Levitt, Thomas Binford,
Gil Ettinger, and Patrice Gelband. Utility-based
control for computer vision. In Proceedings of the
1988 Workshop on Uncertainty in Artificial In­
telligence,

1988.

[Pearl, 1988] Judea Pearl.

Pro babilistic Reasoning

in Intelligent Systems: Networks of Plausible In­
ference.

Morgan-Kaufman, Los Altos, California,

1988.
[Randazza, 1989] Margaret J. Randazza. The fea­
ture recognition module of the ldp system for
the robot huey. M.Sc. Thesis, Brown University,
1989.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

