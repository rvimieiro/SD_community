TIAN & PEARL

512

UAI2001

Causal Discovery from Changes

Jin Tian and Judea Pearl

Cognitive Systems Laboratory
Computer Science Department
University of California, Los Angeles, CA 90024

{jtian, judea } @cs. ucla.edu

1

Abstract

cussed a Bayesian method of causal discovery from a
mixture of observational and experimental data.

We propose a new method of discovering
causal structures, based on the detection
of local, spontaneous changes in the un­
derlying data-generating model. We ana­
lyze the classes of structures that are equiv­
alent relative to a stream of distributions
produced by local changes, and devise algo­
rithms that output graphical representations
of these equivalence classes. We present ex­
perimental results, using simulated data, and
examine the errors associated with detection
of changes and recovery of structures.

We propose a new method of discovering causal rela­
tions in data, based on the detection and interpreta­
tion of local spontaneous changes in the environment.
While previous methods assume that data are gener­
ated by a static statistical distribution, our proposal
aims at exploiting dynamic changes in that distribu­
tion. Such changes are always present in any realistic
domain that is embedded in a larger background of
dynamically changing conditions. For example, nat­
ural disasters, armed conflicts, epidemics, labor dis­
putes, and even mundane decisions by other agents,
are unexpected eventualities that are not naturally
captured in distribution functions. The occurrence of
such eventualities tend to alter the distribution un­
der study and yield changes that are markedly dif­
ferent from ordinary statistical fluctuations. Whereas
static analysis views these changes as nuisance, and
attempts to adjust and compensate for them, we will
view them as a valuable source of information about
the data-generating process. A controlled experimen­
tal study may be thought of as a special case of these
environmental changes, where the external influence
involves fixing a designated variable to some predeter­
mined value. In general, however, the external influ­
ence may be milder, merely changing the conditional
probability of a variable, given its causes. Moreover,
in marked contrast to controlled experiments, we may
not know in advance the nature of the change, its lo­
cation, or even whether it took place; these may need
to be inferred from the data itself.

Introduction

In recent years, several graph-based algorithms
have been developed for the purpose of inferring
causal structures from empirical data. Some are
based on detecting patterns of conditional inde­
pendence
relationships
[Pearl and Verma, 1991,
Spirtes et al., 1993], and some are based on
Bayesian approaches [Cooper and Herskovits, 1992,
Heckerman et al., 1 995]
These discovery methods
assume static environment, that is, a time-invariant
distribution and a time-invariant data-generating
model, and attempt to infer structures that encode
dynamic aspects of the environment, for example, how
probabilities would change as a result of interventions.
This transition, from static to dynamic information,
constitutes a major inferential leap, and is severely
limited by the inherent indistinguishability (or
equivalence) relation that governs Bayesian networks
[Verma and Pearl, 1990].
.

One way of overcoming this basic limitation is to
augment the data with partial causal knowledge, if
such is available. [Spirtes et al., 1993], for exam­
ple, discussed the use of experimental data to iden­
tify causal relationships. [Cooper and Yoo, 1999] dis-

The basic idea has its roots in the economic literature.
The economist Kevin Hoover (1990) attempted to in­
fer the direction of causal influences among economic
variables (e.g., employment and money supply) by ob­
serving the changes that sudden modifications in the
economy (e.g., tax reform, labor dispute) induced in
the statistics of these variables. Hoover assumed that
the conditional probability of an effect given its causes

TIAN & PEARL

UAI2001

remains invariant to changes in the mechanism that
generates the cause, while the conditional probability
of a cause given the effect would not remain invariant
under such ch anges. This asymmetry may be useful in
disting ui shi ng cause and effect.
Today we understand more precisely the conditions
under which such asymmetries would prevail and how

to interpret such asy mmet ries in the context of large,
multi-variate systems. Whenever we obtain reliable in­

formation (e.g., from historical or institutional knowl­
edge) that an abrupt local change has taken place
in a specific mechanism that constrains a given fam­
ily of variables, we can use the observed changes in

the marginal and conditional probabilities surround­
ing those variables to determine the direction of causal
influences in the domain. The statistical features that
remain invariant under such changes, as well as the
causal assumptions underlying this invariance, are en­
coded in the causal diagram at hand, and can be
used therefore for testing the validity of a given struc­
ture. Lik ewise, conflicts between observed and pre­
dicted changes can be used for automatic restruct uring
of the topology of the structure at hand.

513

mechanism and is subjected to change without influ­
encing other mechanisms. We form ally define mecha­
nism change as follows.

Definition 1 (Mechanism Change)

change to a causal model M
Vi is a transformation of

Mv,

=

<G,

M

A

8a>

mechanism

at a variable

that produces a new model,

8(;, ='II� U (8a \ ii";)

and

ii�

those in 1li;.

We assume in this paper that the parent set Pa; does
not change in a mechanism change. An intervention
that fixes v; to a particular value is a special case of

Let P(V) be the distribution

a mechanism change.

generated by M, as in Eq. (1). Then the distribution

generated by Mv, is given by

Pv,(v)

=

e�;;p a;

II Bv;;pa;­

(2)

#i

We will call (P, Pv,) a transition pair (TP) and Vi the
focal variable of the transition. Assume that a series of
mechanism changes o ccurred successively to a causal

<G, 8�>, and let F

=

=

(Vi1,

• • •

, Vi�)

de­

note the corresponding sequence of focal variables. We

Causal Models and Mechanism

use Pr8 = (P0, Pl, ..

Change

. , pk)

to denote the sequence of

distributions generated by such a series, and call the

Let our problem domain be a set of discrete ran­

{V1, .. . , Vn}· We assume that
V is a pair M = <G,
where G is a DAG over V, called a causal diagram,
and
is a set of probability parameters. We as­
sume that each variable Vi can take values from a
finite domain, Dm(Vi) ={vi!,··· ,Vir.}, where r; is
the number of states of V;. We use Pai to repre­
sent the s et of parents of Vi in a causal diagram G
and Dm(Pai) to re present the set of states of Pa;.
Let Bv,;pa., v; E Dm(V;),pa; E Dm(Pa;) denote the

dom variables V

=

8a>,

a causal model over

8a

multinomial parameter corresponding to the condi­
tional probability
ing notations:

where

<G,

is a set of parameters having values that differ from

model M
2

8(;,>,

=

P(v;lpai)· We

�a,

{Bv;;pa; !vi

=

will use the follow­
E Dm(Vi)},

lli;

=

Assuming
Upa;EDm(Pa;) e;,a,,
8a
ur=l V;.
the Causal Markov condition [Spirtes et al., 1993], a
causal model M = <G, 8a> generates a probability
distribution

P(v)

=

A probability distribution

II Bv,;pa;·

(1)

pair

(Prs, F) a

transition sequence

(TS).

As oracles for cause-and-effect relations, causal mod­
els can predict the effects t h at any external or sponta­
neous changes have on the distributions. Conversely,
by detecting how probability distributions change un­
der various mechanism changes, we obtain information
on the structure of the model generating those distri­
butions. In this paper, we assume th at we are given a
TS

(Prs, F)

corresponding to some causal diagram G,

and our task is to recover G. We will then assume that
we have a sequence of datasets IIJ.I.rs
{D0,
, Dk},
=

where

each Di

tribution

pi,

. . •

is a set of random samples from a dis­

such that each pair

(Pi-1, Pi)

is a TP

with focal variable v;i, and our task will be to recover
a causal diagram (or a set of diagrams) that can gen­
erate

li}ys.

First, we study what can be learned from

a TS.

3

Indistinguishability of Causal
Diagrams

ble with a causal diagram G if P(V) can be generated

In this section, we study the classes of causal structures
that are indistinguishable (or "equivalent") relative to

by some causal model

a TS.

P(V)

M ==

<G,

is said to be compati­

8a>.

The factorization in Eq. (1) obtains causal character

The statistical information provided by any causal di­

through the assum ption of modularity; each family in

agram is completely encoded in the independence rela­

the causal diagram represents an autonomous physical

tionships among the variables. Therefore, two causal

514

TIAN & PEARL

diagrams are statistically indistinguishable given one
static distribution if and only if they are independence
equivalent. The graphical conditions for independence
equivalence are given by the following theorem.

A
A
��
�A�
�A�
��
B\ �c� a\ �c� a\ /c"' B\ �c�
D

E

causal diagrams are independence equivalent if and
only if they have the same skeletons and the same sets

of v-structures, that is, two converging arrows whose

E

D

E

D

(d)

(c)

/A�
p,'A"'
/A"'
/c� a\ /c� a\ /c"'

'

D

(Verma and Pearl

E

D

E

D

(f)

(<)

1990).
Now assume that we have a TP with focal variable
V;. A causal diagram G is said to be compatible with
a transition pair (P, Pv,) if P can be generated by
a causal model M = <G, 0a> and Pv, can be gen­
erated by a causal model Mv.
<G, 00> resulted
from a mechanism change to M at V;;. Note that
a causal diagram could be compatible with both P
and Pv, but not compatible with the TP (P, Pv;).
Among those independence-equivalent diagrams com­
patible with both P and Pv., a TP (P, Pv,) can dis­
tinguish those that can generate Pv, from P with a
single mechanism change from those that can not.
Two causal diagrams G1 and G2 are called transi­
tion pair equivalent with respect to a TP with focal
variable V;, or Vi-transition equivalent, if every TP
(P, Pv,) compatible with G1 is also compatible with
G2. Two causal diagrams are statistically indistin­
guishable given a TP (P, Pv.) if and only if they are
Vi-transition equivalent.

D

(b)

(a)

Theorem 1 (Independence Equivalence) Two

tails are not connected by an arrow

UAI 2 001

®,

E

(g)

"
a\ /c'·
..
/

�

D

E

(h)

=

Theorem 2 (Transition Pair Equivalence) Two

causal diagrams G1 and G2 are V; -transition equiva­
lent if and only if they have the same skeletons, the
same sets of v-structures, and the same sets of parents
for V;;.
Proof" Let G1 be compatible with a TP (P, Pv.). G2
must have the same skeletons and the same sets of v­
structures as G1 to be compatible with P (and Pv.)
by Theorem 1. We have the following decomposition:

P(v) P(v;ipaD II P(vj Jpa}) P(v;Jpat} II P(viJpaJ),
=

Ni

=

#i

(3)

where Pa: and Paf are parents of V; in G1 and G2
respectively. G1 is compatible with the TP (P, Pv.),
hence can generate Pv. from P by a mechanism change
at Vi:

Pv, (v)

=

Pv, (vdpa}) IT P(vilpa}).
#i

(4)

Plugging the expression for f1#i P(vilpa}) from
Eq. (3) into Eq. (4), we have
1
Pv. ( v) = Pv, (v;lpa;)

P(v;lpat) II (
2
P
P(V;·Ipa,�) j#i v3lpai).

(5)

Figure 1: TS equivalence. Assuming (a) is the ac­
tual causal diagram. (a)-( d) are independence equiva­
lent. (e)-(g) are B-transition equivalent. A mechanism
change on A determines a unique causal diagram (h).
G2 is also compatible with the transition pair (P, Pv.)
if and only if

Pv,(v) =Pv,(vilpa;)IT P(vilpa�).

(6)

#i

Eqs. (5) and (6) lead to

.

P
Pv. (v, I pai1) (v;l·Ipa1;))
P(v, pai

=

Pv, (v; I pai2 ) ,

(7)

which holds for any distribution P and Pv. if and
only if G1 has the same parent set for Vi as G2
(Pa}
Pat); if G1 has a different parent set for Vi
with G 2, Eq. (7) will impose some constraints between
P and Pv,, and will not hold for arbitrary possible
D
transition pair (P, Pv. ) .
=

A TS is simply a series of TP's. Accordingly, we say
that a causal diagram is compatible with a transition
sequence Prs = (P0, P1, .. . , pk), F = (Vi., . . . , Vi�o)
if it is compatible with each TP (Pi-l, Pi) in the se­
quence. Likewise, two causal diagrams G1 and G2 are
called transition sequence equivalent with respect to a
TS (Prs, F), or F-transition equivalent, if every TS
(Prs,F) compatible with G1 is also compatible with
G2. Two causal diagrams are statistically indistin­
guishable given a TS (Prs, F) if and only if they are
F-transition equivalent.
Theorem 3 (Transition Sequence Equivalence)

Two causal diagrams are F-transition equivalent if
and only if they have the same skeletons, the same
sets of v-structures, and the same sets of parents for
variables in

F.

E

UAI 2001

515

TIAN & PEARL

Theorem 3 says that a TS determines the directions of
the edges between the focal variables and their neigh­
bors (among the set of independence-equivalent dia­
grams). Figure 1 shows an example ofTS equivalence.
Given a TS, the most we can expect to recover is a set
of causal diagrams that are TS-equivalent, as defined
by Theorem 3. We may find this equivalence class
by detecting independence relations and distribution
changes.

tive causal order in the causal diagram. We may put
wi th the same
tag, denoted by Ba 1···a � . Clearly, since we have no in­
formation on causal relations among variables within
the same bucket, all variables in a bucket stand in
the same ordering relation to all variables in another
bucket. Focal variables need special treatment since
they carry more information, and we will put each fo­
cal variable into an individual bucket called a focal
bucket, denoted by B[1 · a� .
all such variables into a bucket labeled

. .

4

Learning Causation by Detecting
Changes

In this section, we identify the causal information that
can be learned by detecting various changes in the
probability distributions, in particular, changes in the
marginal probability of each variable. The following
theorem is obvious.
Theorem 4 A mechanism change at a variable

X

to
a causal model M = <G, So> may alter the marginal
probabilities of the descendants of X in G and can not
alter the marginals of nondescendants of

X.

It is possible of course that, for some peculiar parame­
ter changes, the marginal probabilities of some descen­
dants of X would not change. When recovering causal
information from distributional changes, we assume a
restriction on a TS called influentiality.
Definition 2 (infiuentiality) A

TP (P, Px)

gener­

ated by a causal model <G, 0a> is said to be influen­
tial if for every descendant Y of X in G, the marginal
distribution

Px (Y)

is different from

P(Y).

A TS is

influential if every TP in the sequence is influential.
Given a TP (P, Px) , and assuming that we can test
each variable for marginal distribution change, we can
draw the following inferences. If the marginal of a
variable Y has changed, we conclude that Y is a de­
scendant of X. If the marginal of a variable Z has
not changed, we conclude that Z is a nondescendant
of X. We thus conclude that Z < X < Y should be a
causal order consistent with the causal diagram. Next
we discuss how to piece together ordering information
of this kind, as obtained from a TS.

We classify variables into buckets with the following
algorithm.

Algorithm 1 (Partitioning Variable)
Input: a TS PTs, F = (Vi1 ,
, Vi�o)·
Output: A set of buckets, each associated with a tag
• • •

a1

. .

. a,., and each containing a set of variables.

Put all variables in a bucket

B.

For the ith mechanism change, i = 1, ... , k,
For each bucket Ba1···a;_1 including focal buckets

if it contains the i th focal variable, put it in a
focal bucket B 1...a,_11.
put other changing variables in Ba 1···a,_11·

!

put non-changing variables in

Partitioning the variables

Given a TS PTS, F
(Viu .. , Vi.), each variable
can be characterized by a sequence of 1's and O's, a
tag a1, ... , a,_, where a1 reflects whether the marginal
of that variable changed (a; = 1) or not (ai = 0) in the
ith transition of the sequence. Non-focal variables that
are given the same tags cannot be distinguished by the
TS (through detecting marginal changes), and no in­
formation can therefore be extracted about their rela=

.

..•

We show the partitioning process by an example. As­
sume that the actual causal diagram is the DAG
shown in Figure 2(a) and that we are given a TS
(P, Px, Py ) . In the first transition, with X as the fo­
cal variable, P(Y) does not change, hence B0 = {Y};
P(X),P(Z),P(W),P(Q) do change, hence we form
B1 = {Z, W,Q}, B{ = {X }. Note that a focal vari­
able is put into an individual bucket. In the second
transition, withY as the focal variable, P(Y) changes,
giving B£1 = {Y}; P(Z) and P(W) change, giving
B11 = {Z, W }; P(Q) and P (X ) do not change, giving
Bw = {Q} and B{0 ={X}. As a result, the variables
are partitioned into four buckets: B{0 = {X},B61 =

{Y},B10

=

{Q}, Bn

=

{Z, W}.

Extracting causal information

4.2

We shall now discuss what causal information we can
extract from the tags attached to buckets. Consider
any two buckets B a1... 0�< and Bb1 h. If there exists
a bit such as ai < bi (i.e., ai = 0 and bi = 1), it
must be that, in the ith transition, the marginals of
variables in Ba1 ...a� did not change and the marginals
of variables in Bb1...b� did. Therefore, no variable in
Ba1 0� is a descendant of any variable in Bb1 bh On
the other hand, if there exists another bit such that
aj > bi (aj 1, bj 0), then no variable in Bh ·b�. is
a descendant of any variable in Ba1 . ak, which means
that there exists no directed path, in particular no
edge, between any variable in Ba1 · ak and any vari.

4.1

Ba1 a,_1o.

.

.

...

···

=

=

.

..

.

. .

.

516

TIAN & PEARL

able in

Bbt .. b�<
·

The equality a;

.

=

b;, i

=

1, . .. , k

transition and ac = 1 or Ba1 ... a, is a focal bucket
for the lth transition and b1 = 1 then "unknown",
else "NDP".

can

only happen if one of the buckets is a focal bucket, in
which case the focal variable is an ancestor of all the
variables in the other bucket. In summary, the relation
between two buckets

Ba

as follows:

R1 a; � b;, i

t

.. -a.,

1, ... , k

=

and

Bb1 ... b.,

is determined

and 3j, ai < b1: variables in

Ba1 ...a�< are nondescendants of variables in Bb1 ...b�< ,
< Bh .. h
denoted b y B
at"·a•

R2 a;;::: b;,i
Bat·"ak

=

·

·

1, ... ,k and 3j,ai >

b1: Bb1• ..bn <

·

R3

There exist two bits i =/: j such that a; <

b;

and a1 > b1: there can be no directed path be­
tween any variable in Bat .. -a• and any variable in

B&, .. -b.,

R4 a;

=

·

b;, i

=

1,

.. . ,

k, one of the buckets, say

Bt . . a�<, is a focal bucket:

all variables in

Bb, ...h

must be descendants of the focal variable in

= b;, i = 1, .. . , k:
if both buckets are focal
buckets then "unknown", else let the focal bucket
be st. ...a., then B t1 ...a�< < Bbt .. .h.

4- a;

Consider the binary relation "<" on the set of buckets
as defined in the Algorithm 2. We have the following
theorem.

Proof:
and

have that all variables in

B &, ...b�<

=

hence it is applied only in

determine a relation. However, in practice, due to im­
perfect statistical tests, there may be conflicts between
them. For example, we may determine that there is

Bat ... a�< and Bbt ...h by R3 and in the
Ba1.. . a. is a focal bucket for the jth transi­
bj = 1. These conflicts signal mistakes in the

no edge between
same time
tion and

statistical tests, and whenever there are conflicts, we
will declare the relation as "unknown". We summarize
the above discussions with the following algorithm.

Input: two buckets Ba1 ...ak and Bb1 ... h.
Output: the relation between the two buckets, could be
"< ", "no-directed-path (NDP) ", or "unknown".

a;� b;,i

= 1, ... ,k and 3j,ai < b1: ifBb1 .. . b�<
is a focal bucket for the lth transition and ac 1
then "unknown", else Ba1 .. a• < B bt ...b., .
=

·

2.

a; ;::: b;, i

1, .. . , k and 3j, ai > bi: if B(w .. a�<
is a focal bucket for the lth transition and bt = 1
then "unknown", else Bb1 . ..h < Ba1 .. . a•.
=

ai

>

bj: if Bb1 ...b,

-:j:.

such that a; < b; and
is a focal bucket for the lth

3. There exist two bits i

j

Ba 1 ... a. < Bb1 ...b.
� b; � c;, i

we have a;

=

=

1, then bz
Bbt ...b.

=

c1, which contradicts

<

c;,

i

=

1, ... , k.

Then

a;

Bbt ...b, is not one
Bat . < Bb1 ...
Bbt .. ·h < Bct·"Ck·

&.,

. · a•

<

=

c;, i

=

which then contradicts

The relation is antisymmetric. If

Bb1 ... h

b;

in order to have the re­

and

and

=

Ba1 ... a. has to be a focal bucket

B a 1 ...a.,

then a;

Ba1 ...a. < Bbt ...h
b;, i = 1, ... , k.

=

Since they cannot both be focal buckets, they must
D

be the same bucket.

A partially ordered set can be represented by a DAG.
We construct a graph with both directed and undi­
rected edges, called an

order graph (OG),

as follows:

a node represents a bucket; for each pair of buckets
and

B',

there is a directed edge

there is an undirected edge

B
B-B'

�

B'

if

B

<

B
B1;

if the relation be­

tween them is "unknown". If we had a perfect statis­

Algorithm 2 (Extracting Relation)

1.

=

lation

are descendants of

R1R4 when R1-R3 cannot

a;

1, ... , k, and then

v;, since their marginals changed in the jth transi­

R3,

Bc1- . .c�<,

B Ct"'Ck'

we

tion. This rule is consistent with the above rules

<

1 since az � b1 �

Let

1,

&.

bucket for the lth transition and az

be a focal bucket containing the focal vari­

bi

B&1 . ..

on the set of

1. 3j, ai < Cj. If Bc1 ... c. is not a focal bucket, then
we have Ba1 ... a. < Bc1... c.. If Bct ...ck is a focal

2.

B at .. ·a•

The relation is transitive. If

1, ... ,k.

Bb, .. ·b•·

able Vi; for the jth transition. Then if

"< "

The binary relation
buckets is a partial order.

Theorem 5

B£1.. -a�<, which is a stronger relation than that in
R1 and R2 but will still be denoted by B[t . ..a., <
The focal buckets convey more information.

UAI2001

tical test for distributional changes, an OG would be
a DAG. For the causal diagram shown in Figure 2(a)
and the TS (P, Px, Py), the ideal OG is given in Fig­
ure 2(b).
In an OG, when

B

---t

B is a focal bucket, a directed edge
B' asserts that there exists a directed path from

the focal variable contained in
in

B'.

B

to all the variables

Hence, if there is no other

mixed directed path,

a path that could contain undirected edges but no di­
rected edges in the reverse direction, from
in the OG, there must be an edge from
one variable in

B'

B

in the causal diagram.

this type of edges as B �

B1,

B

to

B1

to at least
We mark

to distinguish them

UAI2001

TIAN & PEARL

517

3. No edge between B and B': there is no directed

path, in particular no edge, between any variable
in B and any variable in B' in the causal diagram.
(«)

w

(b)

(c)

Figure 2: (a) A causal diagram; (b) The order graph
for the TS (P,Px, Py); (c) The marked order graph.
from those that only represent potential edges in the
causal diagram. This information is useful when the
child bucket B' contains only one variable; we then
assert that the edge B � B' must exist in the causal
diagram. We will call an OG with marked edges a
marked order graph (MOG); an example is shown in
Figure 2(c).
An algorithm for constructing a MOG is given in the
following.
Algorithm 3 (Constructing MOG)
Input: an influential

TS with

known focal variables.

Output: a marked order graph.

1. Put variables into buckets using Algorithm 1.
2. Extracting relations among buckets using A lgo­
rithm 2.
3. Let each bucket be a node.
..{.. For each pair of nodes B and B'
If B < B', add an edge B � B'.

If B' < B, add an edge B' ---+ B.
If the relation is "unknown", add an edge B-B'.

5. For each focal bucket Bf and each of its child B

If there is no other mixed directed path from Bf

to B, mark the edge as Bf �B.

In summary, the information conveyed by a MOG is
as follows:
1.

An unmarked edge B � B': All variables in B
can be ordered before all variables in B' in the
causal diagram, in other words, there are no di­
rected paths from variables in B1 to variables in
B. When B is a focal variable, there exists a di­
rected path from B to each variable in B' in the
causal diagram.

2. A marked edge B � B': There exists a directed
path from B to each variable in B'. In the case
that both B and B' contain one single variable,
the edge B ---+ B' must exist in the causal dia­
gram.

4.3

Limitation of detecting marginal changes

Can we fully recover a causal diagram by detecting
marginal distribution changes alone? To fully recover
a causal diagram, we must construct a MOG in which
each bucket contains only one variable and every edge
is marked. This may not, in general, be achieved.
Considering a causal diagram G containing a path
X ---+ Z ---+ Y, it is clear that we can never de­
termine if there is an edge X ---+ Y in G, since all
marginal changes produced by transitions would be
the same after adding that edge. What is the best we
can get then by detecting marginal changes?
Given a DAG G, if we remove an edge X --t Y when­
ever there is a directed path from X to Y, we get the
transitive reduction of G. The transitive reduction of
a DAG G is the graph G' with the fewest edges such
that the transitive closure of G' is equal to the transi­
tive closure of G. The transitive closure of a DAG G
is the graph G11 such that an edge X --t Y is in G11 iff
there is a directed path from X toY in G. By detect­
ing marginal changes in TS's, the best we can hope
to get is the transitive reduction of the actual causal
diagram. Since to mark an edge X ---+Y, X must be
a focal variable, it follows that every node except leaf
nodes must be a focal variable in order to mark ev­
ery edge in the transitive reduction graph. To further
make each bucket contain only one variable, every leaf
node having the same set of parents as another leaf
node must be a focal variable.
In conclusion, by detecting marginal distribution
changes, the best we can learn is the transitive reduc­
tion of the causal diagram, and we can achieve it by
a TS in which every variable has had its mechanism
changed.
4.4

Unknown focal variables

In this section we discuss si�uations where we know
that a mechanism change has occurred at a single vari­
able but we do not know the identity of that variable.
We first note that, without knowing the focal vari­
ables, variables can still be partitioned into buckets
using Algorithm 1, and the relations between pairs
of buckets will be determined by rules Rl-R3 of Sec­
tion 4.2. Second, an order graph can be constructed
as follows: for each pair of buckets B and B', there is
a directed edge B ---+ B' if B < B'. For the causal
diagram of Figure 3(a) and the TS (P,Px,Py), the
variables are partitioned into three buckets: B10
{X,Q},Bol
{Y},Bu = {Z, W}, and the OG is
=

=

TIAN & PEARL

518

810

=

{X, Q}

��
B11

(a.)

Bot

w

=

"'

{Y} Bo1

{Z, W}

(b)

=

{X, Q} Bto

'\.1
Bu

=

=

{Y}

{Z, W}

(c)

Figure 3: (a) A causal diagram; (b) The order graph
for the TS ( P, Px, Py) without knowing the focal vari­
ables; (c) The marked order graph.
shown in

Figure J(b).

Finally, we may be able to find to which bucket a focal
variable belongs using the following theorem, assuming
influentiality and perfect statistical tests. (We still call
such a bucket a "focal bucket", because it behaves as
a focal variable with the information at hand.)
Theorem 6 Let Si be the set of buckets for which
ai = 1 in their tags a1 . . . ak, then the focal bucket
pi for the jth transition is in Sj and for any other
bucket BE Si, pi< B.
Proof: Let the focal variable X for the jth transition

be tagged as a1 ak, then ai == 1, since P(X)
must change in this transition. All other variables
in the set of buckets Si must be descendants of X
since all their marginals changed in the jth tran­
sition. Therefore, whenever P(X) changes, their
marginals must change too, that is, if ai = 1 then
bi = 1 f or any variable tagged as b1 ... bk in Sj,
which leads to ai � b;, i == 1, ... , k. Hence for
any bucket Bbt . b& E Si not containing X, we have
D
Ba1 a� < Bb, bk·
. . •

.

•

..

.

. ..

In practice, Theorem 6 may fail to identify a focal
bucket when (due to imperfect statistical tests) there
exists no bucket pi in Sj satisfying pi < B for any
other bucket B E Si. In the case that an identified
focal bucket contains only one variable, we actually
identify a focal variable. For the OG in Figure 3(b),
the focal buckets for the first and second tr ansitions
can be found as B1 0 {X, Q} and B01 = {Y} respec­
tively, and we actually identify Y as the focal variable
of the second transition.
=

Finally we can get a MOG by marking edges as in
Algorithm 3. For our working example, the ideal MOG
is shown in Figure 3(c).
4.5

TSs absent of influentiality

If we allow for the possibility that a mechanism change
at X may not alter the marginal probabilities of some
of X's descendants, then detecting no change in P(Y)

UAI 2 001

provides no information on the causal relation between
X and Y. The information we may obtain is that de­
tecting a change in P(Y) means that Y is a descendant
of the focal variable X. First we partition variables
into tagged buckets using Algorithm 1. Then the re­
lationship among buckets is determined as: let Bi be
the focal bucket for the ith transition; Bi < Ba1 ... a�
if ai = 1, where "<" represents that all variables in
Ba1 Cik are descendants of the focal variable B'. Fi­
nally we compute the transitive closure of <: relation,
denoted by <*, to get more information. Simultane­
ous B <* B' and B' <* B would mean change detec­
tion errors and the relation between B and B' will be
declared as unknown. The information conveyed by
B <• B' is that all variables in B' are descendants of
the focal variable B in the underlying causal diagram.
•••

It is clear that if the identities of the focal variables
are not given, we can not get any order information
from a TS by detecting marginal changes.
5

Combining Static and Dynamic
Information

In Section 4, we discussed how to extract causal infor­
mation given a TS by detecting distributional changes.
In this section, we briefly describe how to comb ine
this information with that obtained from independence
tests.
Given data from a static stable distribution, we

can recover (partially directed) causal diagrams us­

ing conditional independence tests. Several such
algorithms have been developed, including IC al­
gorithm [Pearl, 2000, section 2.5] (initially intro­
duced in [Pearl and Verma, 1991]) and PC algo­
rithm (Spi rtes et al., 1993]. The output of these algo­
rithms is a partially oriented graph representing an
independence-equivalence class as defined by Theo­
rem 1.
To recover a causal diag ram from a TS, we first extract
causal information by detecting distribution changes
as described in Section 4, then run the IC algorithm
using the causal information as prior knowledge. Note
that since a TS is composed of a series of different dis­
tributions, we need to test independence relationships

across all distributions.
We may obtain three types of causal information as
shown in Section 4: causal order among certain vari­
ables, no edges between certain variables, and cer­
tain directed edges. The last two types (no-edge and
determined-edge) can be incorporated directly. Causal
order information can be used to restrict the search of
candidate conditional sets and thus reduce the com­
plexity of the IC algorithm. Causal order information

UAI2001

TIAN& PEARL

can also be used to orient more edges: any undirected

edge X-Y can be oriented as X --+ Y if X is ahead
of Y in the causal order. These methods of incorpo­

Modularity,

et al., 1993,

Section

=

5.4.5].

i#i2

(P(w7� !G, t;,) II o(w7 w;-1)),

ground knowledge, the output of the IC Algorithm
would be a partially oriented graph representing the
TS equivalence class as defined by Theorem

3.

· · ·

algorithm are complete

with respect to any consistent background knowledge.
If the identity of a focal variable is not given or iden­

(10)

-

i#iJo

This

is due to a theorem in [Meek, 1995] which says that

w?))

(PCwr2IG,€) II 6(�Pr- wD)

after incorporating these causal information as back­

IC

-

i#il

W hen the identities of all focal variables are known,

the orientation rules in the

and we assume the following prior:

P(2aiG�F,t;,)
P(B�!G, t;,) (P(wt !G, t;,) II <5(�Pi

rating background knowledge have been discussed in
[Spirtes

519

o(x)

where

is the Dirac delta function, and we have

used the notation

Eq. (10)

says that

eb-1

eb

Uf;l w{ I j
the set of parameters
=

0,

=

. . ' k.
.

eb differs
IP{i, and we have
of parameters w{.

tified as in Section 4.4, the edge directions between

with

this focal variable and its neighbors may not be fixed,

made an assumption that the set

hence the output graph is not maximally oriented, and

after a mechanism change is independent of the previ-

we have not obtained all the information implied by a

ous set of parameters

TS. Algorithms for identifying focal variables are cur­

only by the parameters in

distribution:

rently under investigation.

�P{i-1.

J

We assume the

P(o;,a; I€) Dir(o;,a, IBpa;),
{ ;pa; lv; E Dm(V.)}

Dirichlet
(11)

=

6

where Opa;

The Bayesian Approach

In the Bayesian approach, we compute the posterior
probability of a causal diagram
as:

P(GID '�t: )
where

t;,

D

tribution,

closed

form

derived

been

C:tv;

denotes the

suming that the set of parameters after a mecha­
nism chan�e have the s�e prior distribution as be­
fore:

P(wf.IG,{)
'

=

P(�f-1jG,�),
'

and that mecha-

nism changes occurred at different variables, let I =
{i1,
,i�;} be the set of indexes for focal variables,
• . .

(8)

represents our background knowledge.

the case that the dataset
have

G given a dataset D

P(DIG, t;,)P(Git;,)
P(DI€)
'

=

=

set of parameters for the Dirichlet distribution. As­

and we obtain

For

is from a static dis­

expressions

for

P(DIG, €)

[Cooper and Herskovits,

1992,

Beckerman et al., 1995]. In this section, we gave a
closed form expression for
For detailed

P(�s IG,t;,).

derivation, see [Tian and Pearl, 2001].
Let the sequence of datasets

llll-rs

Uf=oeh.

be generated With parameters
tively, and let

3a

is computed as

P(JDl.rsiG,F,t;,)

=

=

{D0 ,Dt, ... , Dk}

e�l .. e2.
=

.

I

respec­

The marginal likelihood

J P(lihs\2a,G,t;,)P(2aiG,F,t;,)d3a.
( 9)

We have put

F

(12)
where ro is the Gamma function, O:pa;
1-1

.

"

I

Mv.;.,pai = L.... N�i,P4i,Mv,,pai
i�

M!a;

=

E M!;,pa;>
Vi

=

(Vi1

, • • •

,

Vi�) as a condition to re­

flect the fact that the sequence of focal variables are
known. The term
01
is computable as

P(IThrs l2a1 €)

the probability of the data given a Bayesian network.

For the parameter priors P(2aiG, F, t;,), we use the
assumptions given in (Beckerman et al., 1995]: Global
and Local Parameter Independence, and Parameter

and

NLva;

for which

V.

Mpa.;

=

=

Hl

=

Ev. O:v;;pa.,
"'

I

M-v,,pa,,Lv,,p4i

==

"'"'
�N�;,,pai'
.

j�

L Mv;,pa;, L�a.; L L�;.Pa;>
=

tii

Vi

is the number of cases in the dataset

Di

takes the value Vi and its parents Pa;

takes the value pai.
We

will call the

P(Drs, GIF, €)

above Bayesian scoring metric

with parameters au,;po.; specified as re­

quired by the BDe metric in [Beckerman

et

a.l.,

1995]

TIAN & PEARL

520

the BDe_TS metric. A marginal likelihood P(IDl/ G, �)
is said to satisfy the property of F -transition likelihood
equivalence if for two F-transition equivalent causal di­
agrams G1 and G2 , P(IDIGt , �) = P(IDl/G2 , 0 -

UAI 2001

'·'

09

0.1

..�

Theorem 7 The BDe_ TS metric i s F -transition like­

----...

lihood equival ent.

&

We use x2 test to detect distribution changes. Let D 1
and D2 b e two datasets, consisting of N1 and N2 cases
respectively. Let N1z and N2 x be the number of cases
in D1 and D 2 respectively in which a variable X takes
the value x. To test the hypothesis that X has the
same distribution in the two datasets, we compute the
quantity

N1 N2 "'
L....
:r;

1
Nlx

+

( N1x

N1
N2 x -

-

Nx 2
2
1
N2 ) , ( 3)

which is asymptotically a x2 distribution with rx - 1
degree of freedom, where r:r: is the number of states of
X. Let the significance level be o:. If x2 > x! then we
decide "change" , else we decide "no-change" .
A mechanism change at a variable Vi is simulated as
follows. Consider parameters in �a; . If 8v,1;pa; ::;
·
0.5 then let Ov' .1·pa · = Bv-1 ·pa + o , else let Ov'.... . ·pa
,
1Bvn;pa; - o, where o is a parameter for adjusting the
change magnitude. The rest of the parameters in �a,
are changed in proportional to their original values
as: O�,;;pa,
o:O v , j ;p a . , j
2, . . . , r; , where o: = (1 0�n;paJ /(1 - 0v,1 ;pa. ). When we simulate a mechanism
change at Vi, we change parameters in �a, as above
for each pa; E Dm (Pa; ) .
=

t

=

1

t

\

'

,.

=

In our experiments, we used data generated from
a known network, the Alarm Bayesian network1
[Beinlich et al., 1989]. Samples used in the experiment
were generated from the network using a demo version
of Netica API developed by Norsys Software Corpo­
ration. We used equal sample sizes for all datasets
in a TS, that is, a sample size N represents that N
cases were generated for each dataset Di in lilTs =
{Do, . . . , D k } .
7.1

Errors in detecting changes

There are two types of errors in detecting changes: (i)
mistaking "no-change" for a "change" , known as type I
error and denoted NC2C, and (ii) mistaking "change"
as "no-change" , known as type II error and denoted
C2NC . Let G be the causal diagram used for gener­
ating samples. When a mechanism change occurs at
1
We used the version downloaded from the web site of
Norsys Software Corporation, http : / jwww .norsys.com.

o_J

--·--· ...
1

(a)

Experimental Results

::

i 0.5
� '·'

0.1- 0.2 O.l O.oil 0.5 0.6 0.1 0.1 O.it

7

"

(b)

Figure 4: Type I and Type II errors of x2 statistics.
a variable Vi , if our test statistics is perfect, all Vi 's
descendants in G should be identified as "change" and
Vi's nondescendants as "no-change" . Let Deci be the
number of descendants of Vi in G and N D eci be the
number of nondescendants of Vi . Let c2nci be the
number of descendants of Vi identified as "no-change"
by the x2 test, and let nc2ci be the number of nonde­
scendants of Vi identified as "change" . nc2ci a,nd c2nc;
represent the number of type I and type II mistakes
made by the x2 statistics. In any one run, we simulate
a mechanism change at each node Vi , i = 1 , . . . , n, rel­
ative to the original network, and compute the C2NC
error rate as Li c2nc; j L; Deci and the NC2C error
rate as Li nc2c; j L; NDec;. We computed an aver­
age error rate over 5 runs.
We varied the change magnitude o, the sample size,
and the significance level o:, and the results are shown
in Figure 4. We see that the NC2C (type I) error
rate is nearly the same as the o: value for different
change magnitudes and sample sizes, as expected. The
C2NC (type II) error could be large when the a value
is small or the change magnitude is small. This sug­
gests that we should consider using a two-tailed x2 test
[Silverstein et al., 2000] to control the C2NC error, es­
pecially when the sample size is not large. In a two­
tailed x2 test, we use another threshold o:1 > a such
that we decide "no-change" only when x2 < X�, , but
we have to decide "unknown" when x!, < x2 < x! ­
We will not discuss this method in this paper.
7.2

Errors in order graphs

In an OG, an edge B ---+ B' represents that all vari­
ables in B can be causally ordered before the vari­
ables in B' . We call this type of information "order
claims" . No edge between B and B1 represents the
absence of directed paths, in particular edges, between
variables in B and those in B1; this information will
be called "no-directed-path (NDP) claims" and "no­
edge claims" respectively. An edge B-B' only signals
mistakes in the statistical tests and will be called "un­
known claims" . We performed the following experi-

UA1 2001

Table

1:

can be overcome by restricting the order information

Errors in order graphs. k: the number of focal

extracted to close neighborhoods of the focal variables.

variables. m: the number of buckets. Eo : percentage

Ep: percentage error of NDP
Ee : percentage error of no-edge claims. u:

error of order claims.
claims.

521

TIAN & PEARL

Acknowledgements

number of unknown claims.

This research was supported in parts by grants from
NSF, ONR and AFOSR and by a Microsoft Fellowship

N = 500
order claim

k
5
5
5
5
10
10
10
10

'If

m

8
11

275
355

Eo

0.13
0.12

7

137
241

354

0.026

N = 5000
order claim

?I

k

&

0:

m

5

0.1

0.01

5
5
5

0.1

0.05

0.5

0.05

10
12
1
12

406

10
10

0.1
0.1
.5
0.5

19
23
1

364
334

10
10

0.01
0.05
. 1
0.05

23

'If

37
88
8
111

391
335
360
323

to the first author.
NDP claim

'Eo

274

E.

u

0.049
0.039
7

0
3
1

0 . 03

5

0.044

1
11
5
19

0.044
7
0.29

0.032

NDP claim

?I

Ep

E.

A. Beinlich, H. J. Suermondt,

monitoring system.

The ALARM

In

Proceedings of the second
European conference on Artificial Intelligence in
Medicine, 1989.
1992]

G.

F.

Cooper

104

0.26

0.027

0.28
0.28

0.02
0.033

6
20

77
334

265

0.26

0.03

22

and

A Bayesian method for the induc­

tion of probabilistic networks from data.

207
260
1 1

80
109

et al., 1989] L

R. M . Chavez, and Cooper G . F.

E. Herskovits.

0.025
0.031
. 1

0 . 044
0.051

[Beinlich

[Cooper and Herskovits,

0.3
0.3

369
393

References

Machine

Learning, 9:309-347, 1992.
7

[Cooper and Yoo,

1999]

G. F. Cooper and C. Yoo.

Causal discovery from a mixture of experimental
and observational data. In
[Beckerman

et al., 1995]

Proceedings UAI, 1999.

D. Beckerman, D . Geiger,

and D.M. Chickering. Learning Bayesian networks:
The combination of knowledge and statistical data.
ments: for certain 8,

a,

sample size, and focal vari­

ables, we generate datasets, construct an OG, count
the claims, and check against the true network to com­
pute percentage errors for each type of claims.2
The results are shown in Table 1 for various sample
size N, number of focal variables k, mechanism change

magnitude 8, and significance level a. From Table 1 ,
we see that the NDP claims have a high percentage of
error; however, if those claims are interpreted as rep­
resenting no-edge only, then the error rates are much
lower. As expected, the error rates are lower when 8,

the change magnitude, is larger, and a TS with more
focal variables produces more no-edge claims.

Machine Learning, 20:197-243, 1995.
[Hoover,
ence.
[Meek,

1990] K .D . Hoover. The logic of causal infer­
Economics and Philosophy, 6:207-234, 1990.

1995]

C. Meek.

Causal inference and causal

explanation with background knowledge.

[Pearl and Verma,

1991] J.

Conclusion

Spontaneous local changes offer the potential of ex­
tracting causal information that is undetected by
static methods.

This potential is limited by several

factors, the most significant are violation of influential­
ity (in large networks) and the reliance on the locality
of the changes. We believe that the former problem
2 Claims are counted between pairs of variables not be­
tween pairs of buckets. Numbers vary with the focal vari­
ables picked, hence we did 100 runs, each time randomly
picking a sequence of k variables as focal variables, and
computed average numbers.

Pro­

Pearl and

theory of inferred causation. In

T. Verma. A
Proceedings KR '91.

2000] J. Pearl. Causality: Models, Reasoning,
and Inference. Cambridge University Press, NY,
2000.

[Pearl,

[Silverstein

et al., 2000]

C.

Silverstein,

R. Motwani, and J. Ullman.

8

In

ceedings UAI, 1995.

S.

Brin,

Scalable techniques

for mining causal structures.

Data Mining and
Knowledge Discovery, 4(2/3) :163-192, 2000.

[Spirtes

et al., 1993] P. Spirtes, C. Glymour, and
Causation, Prediction, and Search.
Springer-Verlag, New York, 1993.
R. Scheines.

[Tian and Pearl,

2001] J.

Tian and J. Pearl.

Causal

discovery from changes: a Bayesian approach. Tech­
nical Report

R-285,

[Verma and Pearl,

UCLA,

1990]

T.

2001.

Verma

and

J.

Pearl.

Equivalence and synthesis of causal models. In

ceedings UAI, 1990.

Pro­

