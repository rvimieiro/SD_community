223

Models and Selection Criteria for Regression and Classification

David Heckerman and Christopher Meek

Microsoft Research
Redmond WA 98052-6399
heckerma@microsoft.com, meek@microsoft.com

Abstract

W hen performing regression or classification,
we are interested in the conditional probabil­
ity distribution for an outcome or class vari­
able Y given a set of explanatory or input
variables X. We consider Bayesian models
for this task. In particular, we examine a spe­
cial class of models, which we call Bayesian
regression/classification (BRC) models, that
can be factored into independent conditional
(ylx) and input ( x ) models. These mod­
els are convenient, because the conditional
model (the portion of the full model that we
care about) can be analyzed by itself. We
examine the practice of transforming arbi­
trary Bayesian models to BRC models, and
argue that this practice is often inappropri­
ate because it ignores prior knowledge that
may be important for learning. In addition,
we examine Bayesian methods for learning
models from data. We discuss two criteria
for Bayesian model selection that are appro­
priate for repression/classification: one de­
scribed by Spiegelhalter et al. ( 1993), and an­
other by Buntine (1993). We contrast these
two criteria using the prequential framework
of Dawid (1984), and give sufficient condi­
tions under which the criteria agree.

Keywords: Bayesian networks, regression, classifica­
tion, model averaging, model selection, prequential cri­
teria
1

Introduction

Most work on learning Bayesian networks from data
has concentrated on the determination of relationships
among a set of variables. This task, which we call Joint

1
analysis ,

has applications in causal discovery and the
prediction of a set of observations. Another important
task is regression/classification: the determination of
a conditional probability distribution for an outcome
or class variable Y given a set of explanatory or input
variables X. When Y has a finite number of states we
refer to the task as classification. Otherwise we refer
to the task as regression.
In this paper, we examine parametric models for the
regression/classification task. In Section 2, we exam­
ine a special class of models, which we call Bayesian re­
gression/classification (BRC) models, that can be fac­
tored into independent conditional (ylx) and input (x)
models. These models are convenient, because the con­
ditional model (the portion of the full model that we
care about) can be analyzed alone. In Section 3, we ex­
amine the practice of transforming arbitrary Bayesian
models to BRC models, and argue that this practice is
often inappropriate because it ignores prior knowledge
that may be important for learning.
Also in this paper, we discuss Bayesian methods for
learning models from data. In Section 4, we compare
Bayesian model averaging and model selection. In Sec­
tion 5, we discuss two criteria for Bayesian model selec­
tion that are appropriate for regression/ classification:
one described by Spiegelhalter et al. (1993), and an­
other by Buntine (1993). We contrast these two crite­
ria using the prequential framework of Dawid (1984),
and give sufficient conditions under which the criteria
agree.
The terminology and notation we need is as follows.
We denote a variable by an upper-case letter (e.g.,
X, Y, X;, 8), and the state or value of a correspond­
by that same letter in lower case (e.g.,
We denote a set of variables by a bold­
face upper-case letter (e.g. , X, Y, X;). We use a cor­
responding bold-face lower-case letter (e.g., x, y, x;)
to denote an assignment of state or value to each vari-

ing variable

x, y, x;, (}).

1

This task is sometimes called density estimation.

224

Beckerman and Meek

able in a given set. VvTe say that variable set X is
in configuration x. We use p(X = xJY = y) (or
p(xly) as a shorthand) to denote the probability or
probability density that X = x g ive n Y
y. We
also use p(xjy) to denote the probability distribution
(both mass functions and density functions) for X
given Y = y. Whether p(xjy) refers to a probabil­
ity, a probability density, or a probability distribution
will be clear from context.

•

=

We use m and Bm to denote the structure and pa­
rameters of a model, respectively. When (m, B m) is a
Bayesian network for variables Z, we write the usual
factorization as

N
.
(
=
.
.
p zt'
' ZNIOrn' m) rrp(z; Jpa;, Bm' m)
i=l

(1)

Figure 1: ( a) A naive Bayes model for classification.
(b) A linear soft max regression model that has the
same conditional distribution for Y.

I(xl} is the indicator variable that is equal to 1
if and only if x; = xl. Consequently, we have

where

where Pa; are the variables corresponding to the par­
ents of Z; in m. We refer to p(z; Jpa;, B m,m) as the
local distribution function for Z;.
2

Regression/ Classification

In this section, we examine various parametric mod­
els for the task of regression/ classification. Mod­
els for this task are of two main types: conditional
models and joint models. A conditional model is
of the form p(yjx, em, m). A joint model is of the
form p(y, xJe m, m). We use a joint model for re­
gression/ classification by performing probabilistic in­
ference to obatin p(yjx, em' m).
Examples of joint models include Bayesian networks.
F igure la shows the structure of a naive Bayes model
in which the variables X are mutually independent
given Y. Suppose Y has r states y1 , ... , yr, each X;
is binary with states x} and xl, and each local distri­
bution function is a collection of multinomial distribu­
tions (one distribution for each parent configuration).
For this example, it is not difficult to derive the corre­
sponding conditional model (see, for example, Bishop,

Akx

_
=

Chapter 6). Namely, we have
p(yklx, Bm, m)

log ( l
)
P Y jx, em, m

1
_

(4)

eAix
+ '\"'�
0J=2

softmax(.Atx, ... , A x)

k

where each Akx is a linear function of I( xi), . . . , I(x�).

Models for

1995,

(b)

(a)

=

Ox

B(yk) � log ( ;jyk)
loge-+
(Y 1 ) L..,
O(x,-J Y 1)
i=l

(2)

for k = 2, . . . , r. After some algebra, Equation 2 be­
comes

(3)

This conditional model p(yix, em, m) is a type of
generalized linear model known as a linear softmax
2
regression. We can display the structure of this con­
ditional model as a Bayesian n etwork, as shown in Fig­
ure lb. In the figure, the input nodes X are shaded to
indicate that we observe them and hence do not care
about their joint distribution.
Now let us specialize our discussion to Bayesian mod­
els for regression/classification. In the Bayesian ap­
proach, we encode our uncertainty about Om and m
using probability distributions p(emlm) and p(m), re­
spectively. Thus, the Bayesian variant of a joint model
takes the form

p(y,x,em,m) =p(m) p(emjm) p(y,xJ8m,m)

(5)

We refer to this model as a Bayesian joint (BJ) model.
We define a Bayesian analogue to a conditional model
as follows. Suppose that em can be decomposed into
parameters (Bx, eYI x) such that

p(y,xJem,m) =p(xJBx,m) p(yjx,eyJx,m)

(6)

(7)
p(em Jm) = p(exJm) p(8yJxlm)
In this case, given data D = ((Yt,xt), ... ,(yN,XN)),
assumed to be a random sample from the true distri­
bution of Y and X, we have

p(em IY, x, m)
2 Although

{p(xJ8x,m)p(8xJm)}
· { p(yjx,eyJx1 m )p(eyJxlm)}

Y has a finite number of states, this model

is commonly referred to

as a

regression.

Models & Selection Criteria for Regression

Consequently, we can analyze the marginal
conditional

(ylx)

(x)

and

225

(B', ,m')

terms independently. In particular, if

we care only about the conditional distribution, we can
analyze it on its own. We call this model defined by
Equations

6 and

(BRC) model.

7 a Bayesian regression/classification

Simple examples of BRC models in­

clude ordinary linear regression (e.g., Gelman et al.,

1995,

ChapterS), and generalized linear models (e.g.,

Bishop,

1995,

Chapter

10).

Note that our Bayesian analogue to the conditional
model is a special case of a BJ model.

One could

imagine using a Bayesian model that encodes only the
conditional likelihood
tribution for

Bm

and

p(ylx, Bm,m)
m. However,

and a joint dis­
this approach is

flawed, because it may miss important relationships
among the domain variables or their parameters that
are important for learning. In the following section,
we consider an example of this point.

3

Figure
model.
to
to

A BERC model obtained from a naive-Bayes

Y is an ancestor
Xn ,+ l , ... , Xn.

as follows:

·p(ylpay,Om,m) ·(.IT p(xdpai,fJm,m))
o:;:n,+l

where

lowing observation.

X1, .. ., Xn

p(y,xiOm,m) = (}]p(x;lpa;,Bm,m))

Y does

Pa; in the
p(ylx , Om, m) ,

not appear in any parent set

first product.
A special class of BRC models is suggested by the fol­

of each of the nodes corresponding
Given this ordering, we can factor

the joint distribution for Y,

Embedded Regression/Classification
Models

2:

Normalizing to obtain

taking a ratio, and canceling like terms, we obtain

For many BJ models, the con­

ditional likelihood p(y lx, Om, m) is a simple function

x, whereas the expression for the input likelihood
p(xiOm, m) is more complicated. For example, given a

(8)

of

naive-Bayes model in which the variables

X are

mutu­

where
=

pa7

1, .. . , r.

ally independent given Y, the conditional likelihood is

k

lihood is a mixture distribution. Thus, assuming we

Equation

a simple generalized linear model, but the input like­

is a configuration of
(Depending on

m,

Pa.;

in which

y = yk,

some of the terms in

the sum may cancel as well.) We can trivially rewrite

8 as

are interested in the task of regression/classification,
we can imagine extracting the conditional likelihood
from a B.J model, and embedding it in a BRC model.
In particular, given a BJ model
ate a BRC model

p(ylx,Om,m).

(B:n, m' )

(Bm,m),

we can cre­

in which p(ylx,

We say that

(8:n,m')

e:n, m') =

is a Bayesian

embedded regression/ classification (BERC) model ob­
tained from

( e:n' m' ) .

Several researchers have suggested using BERC mod­
els, at least implicitly (see Bishop, 1995, Chapter

10,

and references therein). An example of a BERC model

Equation 9 shows that an BERC model is a poly­
nomial softmax regression on the indicator variables
I ( xI ) , ... , I ( Xn ) . Note that there are polynomial soft­

max regressions that cannot be obtained from any
Bayesian network.

Although BERC models are convenient, we find non­

obtained from a naive Bayes model is shown in Fig­

trivial BERC models to be problematic.

ure

lar, consider a BERC model (8:n,m') obtained from

2.

If a BERC model (8:n, m') is obtained from

a model which is itself a BERC model, we refer to

(O:n,m')

as a trivial BERC model. The BERC model

is Figure 2 is non-triv ial.
For any Bayesian network with finite-state variables,
it is not difficult to obtain its corresponding BERC
model. Let X1, ... , Xn,, Y, Xn,+l, . . . , Xn be a total

m,
Y appears as late as possible in the ordering.

a non-BERC model

(Om, m).

W hereas in the BERC

model, observations of X are necessarily uninformative
about Bylx• such observations may be informative in
the original model

(Om, m). Thus, in

constructing the

BERC model, we may be ignoring parts of our prior
knowledge that are important for learning.

ordering on the variables that is consistent with

To illustrate this point,

such that

model for binary variables Y,

The latter condition says that the node corresponding

In particu­

ping from

Bm

to

Bx

consider the naive-Bayes

XI' x2, x3.

is shown in F igure 3.

The map­
It is not

226

Heckerman and Meek

B(y1) B(xUy1) B(x�IY1) B(x1IY1) + ll(y2) B(x)ly2) B(x�ly2) B(x1lv2)
B(y1) B(xijy1) B(x�IY1)(1- B(x1lv1)) + B(y2) B(xijy2) B(x�ly2)(1- B(x1IY2))
(l(xJx�x1)

B(y1) B(x)ly1) B(x�ly1) B(x1IY1) + B(y2) B(x)IY2) B(x�IY2) B(x1lv2)

B(xix�x�)

B(y1) B(x)ly1)(1- B(x1IY1))(1- B(x1IY1)) + B(y2) B(xJiy2)(1- (l(x�ly2))(1- B(x1IY2))

B(xix1x1)

B(y1)(1- B(x)ly1)) (l(x1IY1) B(x1IY1) + B(y2)(l- B(xJiy2)) B(x�ly2) B(x1IY2)

B(xrx�x�)

B(y1 )(1- B(xJ IY1)) B(x�ly1)(1- B(x1IY1)) + B(y2)(l- B(xj IY2)) B(x�ly2)(1- B(x1IY2))

O(xrx�x1)

B(y1 )(1- B(xj IY1)) B(x�IY1) B(x1IY1) + ll(y2)(1- B(xJiy2)) B(x�ly2) B(x1IY2)
Bm to Bx for the naive-Bayes model where Y renders X 1, X , and X3 mutually in­
2 and p ; , Bm, m),
(l(y), O(xl, xz, xs), and B(x ;ly) to denote p(yiBm, m), p(x , xz, x31Bm, m),
(x ly
1

Figure 3: The mapping from

dependent. We use
respectively.

difficult to show that the rank of the Jacobian ma­

observations of X often will influence the estimate of

Bm) for almost all values of
8m (see, e.g., Geiger et al., 1996). It follows that, for
almost every point e:n in Bm, there is an inverse map­
ping from Bx to Bm in a neighborhood around e:n .3
Consequently, the possible values that Bm (and hence
Byjx) can assume will depend on the value of Bx, and
observations of X will inform By]x through Bx.

ferred to as regression/classification models-should

trix

8f}x/8Bm is full

(i.e., equal to the number of non­

redundant parameters in

More generally, conditional models-often re­

By]x ·

not be used without consideration of variational de­
pendencies that may arise from the joint model.

Learning Regression/Classification

4

Models: Averaging Versus Selection

In general, given two variables (random or otherwise)

Now that we have examined several classes of models

A and B, if the possible values that can be assumed
by A depend on the value of B, then A is said to be
variationally dependent on B. In our example, 0y]x

for the regression/classification task, let us concentrate

is variationally dependent on

8x.

Such variational

dependence is not limited to this example. For any
model

(Bm, m),

if the rank of the Jacobian matrix

Bm to Bx is full, then E>m (and
0yjx) is variationally dependent on Bx. Geiger
al. (1996) conjecture that, for naive-Bayes mod­

for the mapping from

on Bayesian methods for learning such models.

First, consider model averaging. Given a random sam­

ple

D from the

most everywhere full.

and Geiger et al.

Bm

(1996)

(1974)

could identify only one naive­

Hayes model in which the Jacobian matrix was not of
full rank almost everywhere.

Bm

p(Bmlm) p(DIBm, m)
p(8 m ID ,m) =
p(Dim)

to fix is al­

In addition, Goodman

and

p(m) p(Dim)
p(miD) =
l:m' p(m') p(Dim')

els in which all variables are binary, the rank of the
Jacobian matrix for the mapping from

m

using Bayes' rule:

hence
et

true distribution of Y and X, we com­

pute the posterior distributions for each

where

Thus, the use of non­

trivial BERC models-at least those obtained from

most naive Bayes models-is suspect.

With these quantities in hand, we can determine the

Note that our remarks extend to non-Bayesian anal­
yses.

For example, in a classical analysis, a poly­

nomial softmax regression should not be substituted

for
and

a Bayesian network. In the former model, 8y]x

E>x

are variationally independent.

model, 8y]x and

E>x

In the latter

are variationally dependent, and

3The pa.rameters Om are said to be locally identifiable
given observations of X (e.g., Goodman, 1974).

conditional distribution for Y given X in the next case

to be seen by averaging over all possible model struc­
tures and their parameters:

p(ylx,D)=
p(ylx, D,m) =

L P(miD) p(ylx, D, m)
m

(10)

j p(ylx,8m, m) p(BmiD, m)dBm

(11)

Models & Selection Criteria for Regression

Note that joint analysis is handled i n

essentially

the

The term

P(Yt, XtiYl, x1, ... , Yt-1, Xt-1, m) is the pre­
(Yt, xi ) made by model structure m after

same way. For example, to determine the joint dis­

diction for

tribution of Y and X in the next case to be seen, we

averaging over its parameters (Equation

use

p(y, xJD)

p(y,xJD,m)

=

=

LP(mJD)p(y, xjD, m)
m

227

13).

The log

of this term can be thought of as the utility for this

(12)

Jp(y,xJ11m,m) p(BmJD,m)dem

(13)

Model averaging, however, is not always appropriate
for an analysis . For example, only one or a few models
may be desired for domain understanding or for fast
prediction. In these situations, we select one or a few

prediction.5 Thus, a model structure with the highest
log marginal likelihood is also a

model

structure that

is the best sequential predictor of the data
logarithmic utility function.

Let

D given the

us now consider local criteria that are more ap­

propriate for the task of regression/classification. To

keep the discussion

brief, we discuss only the

logarith­

mic utility function, although other utility functions
may

be

more reasonable for a given problem. At least

"good" model structures from among all possible mod­

two prequential criteria are reasonable. In one situa­

cedure is known as model selection when one model is

As a result, we obtain a criterion that

els, and use them as if they were exhaustive. This pro­

chosen, and selective model averaging when more than

tion, we

imagine that we see

(1993)

al.

call a

one model is chosen. Of course, model selection and
selective model averaging are also useful when it is im­

practical to average over all possible model structures.
W hen our goal is model selection, a "good" model
for joint analysis may not be a good model for re­
gression/classification, and vice versa. Scores that de­

c

N

CNM(D,m)

Llogp(y,Jxi,Y1,x1,···,Yt-1,xt-1,m)
1=1

=

(14)

In another situation, we imagine that we first see all of

the input data x1,

... , XN,

sequentially.

criteria. A criterion commonly used for joint analy­

class sequential criterwn:

logp(DJm).

=

logp(m) +

This criterion is global in the sense that it

CSC(D,m)

N

L logp(ydy1, . . . , Yl-11 x1, . . . , XN,m)
1=1

=

is equally sensitive to possible dependencies among all

variables. Criteria for regression/classification, should
be local in the sense that they concentrate on how well
X classifies Y.

In the following section, we examme

two such criteria.

The criteria that we discuss

or

terms

of Dawid's

prequential method.

To simplify

the

(1984)

can

be

understood

predictive sequential

A simple example of this

Let us consider this example

discussion, let us assume that that

i:s uniform, so that the joint-anaiysis criterion

reduces to the log-marginal-likelihood

logp(DJ m) .4

From the chain rule of probability, the log marginal
likelihood is given by

logp(DJm)

L logp(yt, XtiY1, XJ, ... ,Yl-1,Xt-1, m)
1=1

4The generalization
straightforward.

et

al.

(1993)

describe

parameter

a

set

of

independence

tion of the class sequential criterion is exponential in

the

sample size N.

to non-uniform model priors is

Monte-Carlo or asymptotic tech­

niques can be used to perform the computation for

large N (see, e.g., Heckerman,

1995).

We have applied both criteria to small Bayesian net­
works and small data sets chosen

arbitrarily.

In all

cases, we have found that the two criteria differ.
Nonetheless,

there are conditions

under which the two

criteria are the same. In particular, we can rewrite the

two

criteria as follows:

CNM(D,m)

N

=

Spiegelhalter

Under these same assumptions, the exact computa­

first.

p(m)

decision-tree structures.

monitor can be computed efficiently in closed form.

method, applied to joint analysis, yields the posterior­
probability criterion.

(15)

used this criterion for selection among

and Dirichlet priors-under with the conditional node

Regression/Classification

in

(1993)

assumptions-essentially,

Prequential Criteria for

5

Buntine

and then see the class data

Consequently, we obtain the following

sis is the logarithm of the relative posterior probabil­

logp(m, D)

( YI, Xt) sequentially.
Spiegelhalter et

on ditional node monitor:

fine "good" model structures are commonly known as

ity of the model structure

pairs

N

=

L log P (Yt,XtlYl, x1, .. . , Yt-1, Xt- 1 , m)
1=1

p(xtiY1, x1,

·

·

·

, Yl-1, Xt-1, m)
(16)

5The utility log x is also known as a scoring rule.
Bernardo (1979) shows that this scoring rule has several
desirable properties.

228

Heckerman and Meek

CSc(D,m ) =log

P(YJ, .. ,yN,XJ, ... ,xNim)
p( x1, ...,XN Im)

(17)

.

Friedman, N. and Goldszmidt, M. (1996). Building
classifiers using Bayesian networks. In Proceed­

Therefore, the two criteria will agree when

p(x1JY1, XJ, . .. , Yl-l, Xi-1, m)

=

ings AAAI-96 Thirteenth National Conference

p(xt!XJ, ... , Xi-J, m)

(18)
for l = 0, . , N 1. It is not difficult to show that
Equation 18 holds whenever (Bm, m) is a BRC model.
Thus, the two criteria agree for BRC models.
. .

theory. The prequential approach (with Discus­
sion). Journal of the Royal Statistical Society A,
147:178-292.

-

on Artificial Intelligence,

Portland, OR, pages

1277-1284. AAAI Press, Menlo Park, CA.

Geiger, D., Beckerman, D., and Meek, C. (1996).
Asymptotic model selection for directed net­
works with hidden variables. In Proceedings of
Twelth Conference on Uncertainty in Artificial

6

Intelligence,

Discussion

Several researchers have demonstrated that Bayesian
networks for both the joint analysis and regres­
sion/ classification tasks provide better predictions
when local distribution functions are encoded with
a small number of parameters, as is the case with
the use of decision trees, decision graphs, and causal­
independence models (e.g., Friedman and Goldszmidt,
1996; Chickering et a!., 1997; Meek and Heckerman,
1997). Despite our theoretical objections to the use
of BERC models, they offer another parsimonious pa­
rameterization of local distribution functions, and may
lead to better predictions in practice. For example,
polynomial softmax regressions may be useful when
a node and its parents are discrete. Experiments are
needed to investigate these possibilities.

Portland, OR. Morgan Kaufmann.

Gelman, A., Carlin, J., Stern, H., and Rubin, D.
(1995). Bayesian Data Analysis. Chapman and
HalL
Goodman, L. (1974). Exploratory latent structure
analysis using both identifiable and unidentifi­
able models. Biometrika, 61:215-231.
Beckerman, D. (1995). A tutorial on learning Bayesian
networks. Technical Report MSR-TR-95-06, Mi­
crosoft Research, Redmond, WA. Revised Jan­
uary, 1996.
Meek, C. and Beckerman, D. (1997). Structure and
parameter learning for causal independence and
causal interaction models. In Proceedings of
Thirteenth Conference on Uncertainty in Artifi­
cial Intelligence,

Acknowledgments

We thank Max Chickering for useful discussions.
References

Bernardo, J. (1979). Expected information as expected
utility. Annals of Statistics, 7:686-690.
Bishop, C. (1995). Neural networks for
nition. Clarendon Press, Oxford.

pattern recog­

Buntine, W . (1993). Learning classification trees. In
Artificial Intelligence Frontiers in Statistics: AI
and statistics Ill.

Chapman and Hall, New York.

Chickering, D., Heckerman, D., and Meek, C. (1997).
A Bayesian approach to learning Bayesian net­
works with local structure. In Proceedings of
Thirteenth Conference on Uncertainty
cial Intelligence,.

Providence, RI. Morgan Kauf­

mann.

m

Providence, RI. Morgan

Artifi­
Kauf­

mann.
Dawid, P. (1984). Present position and potential
developments: some personal views. Statistical

Spiegelhalter, D., Dawid, A., Lauritzen, S., and Cow­
ell, R. (1993). Bayesian analysis in expert sys­
tems. Statistical Science, 8:219-282.

