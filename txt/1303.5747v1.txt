339

On the Generation of Alternative Explanations with Implications
for Belief Revision

Eugene Santos Jr.

Department of Computer Science
Brown University
Providence, RI 02912

Abstract
In general, the best explanation for a given
observation makes no promises on how good
it is with respect to other alternative explana­
tions. A major deficiency of message-passing
schemes for belief revision in Bayesian net­
works is their inability to generate alterna­
tives beyond the second best. In this pa­
per, we present a general approach based on
linear constraint systems that naturally gen­
erates alternative explanations in an orderly
and highly efficient manner. This approach
is then applied to cost-based abduction prob­
lems as well as belief revision in Bayesian net­
works.
1

INTRODUCTION

We are constantly faced with the problem of explain­
ing the observations we have gathered with our senses.
Our explanations are constructed by assuming certain
facts or hypotheses which support our observations.
For example, suppose I decide to phone my friend Tony
at the office. After several rings, no one has answered
the phone. From this, I conclude that Tony is not at
the office. Our observation in this case is that no one
answered the phone. Our explanation for this is that
Tony is not at the office. The reasoning process we
have just used is called abductive e:cplanation (Char­
niak & Shimony [1990]; Hobbs et a!. [1988]; Peng &
Reggia [1990]; Selman & Levesque [1990]; Shanahan
[1989]). It is often formalized as the process of find­
ing certain hypotheses which can explain or prove the
things we observe.
Although we used the word "conclude" in our story,
our confidence in our solution may not be absolute.
Suppose that I also know for a fact that Tony some­
times disconnects the phone to take a nap in the of­
fice. Now, I have an alternative explanation for why
the phone was not answered. In general, there are
many possible explanations for any given observation,

but yet, we often express confidence in one explanation
over the others and choose it to be our solution. It is
this fact that distinguishes abductive reasoning from
deductive reasoning.
In current approaches to modeling abduction, confi­
dence in an explanation is defined by some measure
on the set of hypotheses it represents. Such measures
include minimal cardinality (Genesereth [1984]; Kautz
& Allen [1986]), parsimonious covering theory (Peng
& Reggia [1990]), most-probable explanation (Pearl
[1988]) and minimal cost proofs (Charniak & Shimony
[1990]; Hobbs et a!. [1988]; Stickel [1988]). These ap­
proaches provide us with a model for choosing a "best"
explanation.
In particular, we are interested in minimal cost proofs
found in the cost- based abduction model ( Charniak &
Shimony [1990]).1 Under this model, costs are asso­
ciated with individual hypotheses. The use of a hy­
pothesis in an explanation incurs the cost associated
with the hypothesis. Thus the cost of an explanation is
simply the sum of the costs of the individual hypothe­
ses used. These costs now represent our confidence in
each explanation and establishes an ordering on the
explanations.
Since cost-based abduction has been shown to be an
NP-Hard problem (Charniak & Shimony [1990]), the
runtime of standard searching techniques grows ex­
ponentially with the size of the problem. In (Santos
[1991a]; Santos [1991b]; Santos [1991c]), it was shown
that any cost-based abduction problem may be trans­
formed into an equivalent linear constraint satisfac­
tion problem, and the latter may be solved by utilizing
the highly efficient optimization tools of operations re­
search. Indeed, empirical studies in (Santos [199la];
Santos [1991c]) showed that the approach is compu­
tationally practical and superior to search style tech­
niques. Our linear constraint satisfaction approach ac­
tually exhibited a subexponential growth rate.
'Cost -based

abduction is a

abduction ( Hobbs et a!.

[1988];

minor variant of weighted
Stickel [1988])

340

Santos

Now suppose that we further know that my friend
Tony spends nearly all of his time in the office work­
ing, sleeping, and eating. This knowledge will signifi­
cantly increase the likelihood of the phone being dis­
connected as an alternative explanation. Even though
our measures may still choose the initial explanation,
they in general make no promises on how good this
choice is with respect to our alternative. This issue is
especially important in domains such as medical diag­
nosis where careful consideration of alternative diag­
noses/explanations is necessary. Thus, the ability to
generate alternative explanations should exist in any
complete model of abductive reasoning.
In this regard, a major deficiency of message-passing
schemes (Pearl (1988]) for belief revision in Bayesian
networks is its inability to generate alternative expla­
nations in an ordered manner beyond the second best.
By considering the equivalent problem in terms of con­
straint systems, we can generate the consecutive next
best explanations. In this paper, we present an ap­
proach based on our linear constraint systems to gen­
erate alternative explanations in order of cost.
In Section 2, we present an overview of constraint
systems and cost-based abduction. In Section 3, we
present our approach to generating alternative expla­
nations. In Section 4, we consider how our constraint
systems may be applied to belief revision in Bayesian
networks. Finally, in Section 5, we conclude our dis­
cussion and give some final thoughts concerning alter­
native explanations.

We now present a brief overview of the formulation of
cost-based abduction problems as constraint systems.
Details and complete proofs can be found in (Santos
(1991a]; Santos (1991c]).
NoTATION.

!R denotes the set of real numbers.

DEFINITION 2.1. A WAODAG (or weighted AND/OR di­
rected acyclic graphj2 is a 4-tuple ( G, c, r, 5), where:

1.

G is a directed acyclic graph, G =(V, E).

2.

c

9.

is a function from V
the cost function.

x

{true, false} to !R, called

r is a function from V to {AND,OR}, called the
label. A node labeled AND is called an AND-node,
etc.

4. S is a subset of nodes in V called the evidence
nodes.
NoTATION. VH is the subset of nodes with zero indegree
called the hypothesis nodes.

(

2Slight generalization of Charniak

& Shi mony

nodes.

DEFINITION 2.2. A truth assignment for a WAODAG
W = ( G, c, r, 5) where G = (V, E) is a function e
from V to {true, false}. We say that such a function is
valid iff the following conditions hold:

1.
2.

For all AND-nodes q, e(q) =true iff for all nodes
p such that (p, q) is an edge in E, e(p) = true.
For all OR-nodes q, e(q) =true iff there exists a
node p such that (p, q) is an edge in E and e(p) =
true.

Furthermore, we say that e is an explanation iff e
valid and for each node q inS, e(q) =true.

CONSTRAINT SYSTEMS

2

FIG. 2.1. Tony's office habits. phone-disconnected
is the only AND-node, pho ne-no a nsweris the only
OR-node and the re maining nodes are hypothesis

[1990]).

DEFINITION
e

for W

=

lS

2.3. We define the cost of an explanation
(G, c, r,S) where G = (V, E) as

C(e) =L c(q, e(q)).
qEV
An explanation e which minimizes C
explanation forW.

lS

called a best

Consider the WAODAG representing the situation with
our friend Tony (see Figure 2.1). We first assume that
there is no cost for assigning a node to false. Next,
assume that assigning Tony-in, To ny-sl ee pi ng and Tony­
out to true have costs 5, 4 and 8, respectively, and that
the costs of assigning true to all non-hypothesis nodes
is zero. The minimal cost proof for this WAODAG is
the hypotheses set {Tony-out} with a cost of 8.
We now define constraint systems as follows:
NoTATION.
For each node q in V, let Dq
{Pi(p,q) is an edge in E}, the parents of q. IDq I is the
cardinality of Dq.

2.4. A constraint system is a 3-tuple
(r, I, 'lj;) where r is a finite set of variables, I is a fi­
nite set of linear inequalities based on r, and 'lj; is a

DEFINITION

On the Generation of Alternative Explanations with Implications for Belief Revision

function from r X {true,false} to !R. Given a WAODAG
W =(G, c,r,S) where G =(V, E), we can constMJ.ct a
constraint system L(W) =(r, I, ..P) where:
r is a set of variables indezed by v' that is, r =
{x9lqE V}.
2. .,P(x9,X) = c(q,X) for all q E V and X E
{true, false}.
3. I is the collection of all inequalities of the forms
given below:
1.

X

q

�XpE I for each pE D9 if r(q) =AND (1)

L

Xp-ID91+1�x9Eiifr(q) =AND (2)

It follows from Theorems 2.1 and 2.2 that0-1 solutions
for constraint systems are the counterparts of explana­
tions for WAODAGs. Thus, by augmenting a WAODAG
induced constraint system with a cost function, the
notion of the cost of an explanation for a WAODAG can
be transformed into the notion of the cost of a 0-1
solution for the constraint system.
DEFINITION 2.6.
Given a constraint system L =
(r, I, .,P), we construct a function eL from variable as­
signments to !R as follows:

eL(s) =

L {s(x9).,P(x9, true)+ (1- s(x9)).,P(x9, false)}.

z.,er

pED9

L Xp 2: x9E I if r(q) =OR
pED9
x9 2: Xp E I for each pE D9 if r(q) = OR

(3)
(4)

We say that L(W) is induced by W. Furthermore, by
including the additional constraints:
X

q

=1 if q ES,

(5)

we say that the resulting constraint system is induced
evidentially by W and is denoted by LE(W).
2. 5. A variable assignment for a constraint
system L =(r, I, ..p) is a function s from r to lR. Fur­
thermore,

DEFINITION

1.
2.
3.

If the range of s is {0, 1} , then s is a 0-1 assign­
ment.
If s satisfies all the constraints in I , then s is a
solution for L.
If s is a solution for L and is a 0-1 assignment,
then s is a 0-1 solution for L.

Given a 0-1 assignment s for L(W), we can construct
a truth assignment e for W as follows:
1. For all q in V, s(x9) =1 iff e( q) =true.
2. For all q in V, s(x9) =0 iff e(q) =false.
Conversely, given a truth assignment e for W, we can
construct a 0-1 assignment s for L(W).
NOTATION. e, and s. denote, respectively, a truth as­
signment e constructed from a0-1 assignments, and a
0-1 assignment s constructed from a truth assignment
e.

We can show that all explanations for a given WAODAG
W have corresponding 0-1 solutions for LE(W) and
v1ce versa.
2.1. If e is an explanation for W, then s. is
solution of L(W).

THEOREM
a

If s is a 0-1 solution of LE(W), then e,
is an explanation for W.

THEOREM 2.2.

eL is called the objective function of L.
2.7. An optimal 0-1 solution for a con­
straint system L = (r, I, .,P) is a 0-1 solution which
minimizes 8L.

DEFINITION

Clearly, Definition 2.6 is identical to Definition 2.3.
Thus, it follows from Theorems 2.1 and 2.2 and the
relationship between node assignments and variable
assignments that an optimal 0-1 solution in LE(W)
is a best explanation for W and vice versa.
As we observed in (Santos (1991a); Santos (1991c)), I
and 8L are the elements of a linear program in op­
erations research (Nemhauser, Kan & Todd (1989)).
Extremely efficient and practical optimization tech­
niques such as the Simplex method and Karmarkar's
projective scaling algorithm (Nemhauser, Kan & Todd
(1989]) are available for use in minimizing 8L with
respect to the constraints in I.
Although solving the linear program was sufficient to
obtain an optimal 0-1 solution for most of our test
problems in (Santos (1991a); Santos (1991c)), it was
sometimes necessary to employ a branch and bound
technique using the linear program to compute lower
bounds. Complete details concerning the branch and
bound algorithm can be found in (Santos (1991a);
Santos (1991c)). This technique enables us to avoid
searching through all possible solutions by utilizing
the lower bounds computed by the linear program as
a guide. Experiments performed in (Santos [1991a);
Santos (1991c]) shown the practicality and efficiency of
this approach for solving cost-based abduction prob­
lems. Also, it can be applied to any constraint system
regardless of whether or not they are WAODAG induced.
3

GENERATING ALTERNATIVE
EXPLANATIONS

In abductive explanation, having alternative explana­
tions is often useful and sometimes necessary. Having
the 2nd best, 3rd best, and so on, can provide a useful
gauge on the quality of the best explanation. In this

341

342

Santos

section, we present techniques for extracting alterna­
tive explanations in order of their associated costs.
To generate the alternative explanations, we solve a se­
quence of constraint systems. This sequence consists
of constraint systems each of which are derived from
the constraint systems earlier in the sequence. The
initial constraint system is the original constraint sys­
tem which determines the first optimal solution. The
subsequent constraint systems are generated using the
following schema: Consider L1 = (r,I11 ,P), our initial
constraint system. Let s1 be the optimal 0-1 solution
of L1. We define a new problem L2 as the successor
of L1. L2 is identical to L1 except for the additional
constraint
L:; F (s1,xq):::; lfl-1
x"Er
where for each Xq E r,

Note that the new problem does not have s1 as its op­
timal 0-1 solution since the variable assignment would
violate the new constraint.
Let s2 be the optimal 0-1 solution, if any, to L2• This
will be the second best 0-1 solution. To continue the
search for the next best explanation, we simply define a
successor to the last constraint system, in this case, L2.
When the current constraint system does not yield any
solution, all possible explanations have been generated
and we are finished.
ALGORITHM 3.1.
Given a constraint system L =
(r,I,,P), generate all the 0-1 solutions for L in order
of cost.

1.

(Initialization} Seth :=I, L1 := (r,h, .P) and
k := 1.

2.

Compute the optimal 0-1 solution for Lk . If there
is no feasible solution, then go to step 7. Other­
wise, let Sk be the solution.

3.

k := k

+ 1.

4· Let h := Ik - 1 U Ck-1 where Ck -1 contains the
single constraint

L:;
:z: ..

Er

F(sk - 11 xq):::; If I- 1

where for each Xq E r,
F(sk -1, xq) =

{ (i

Constraint system Ln in Algorithm
determines the n-th best 0-1 solution for L.

THEoREM 3.1.

_

xq)

if Sk-l(Xq) = 1
if Sk -1(Xq) = 0

6.
7.

(Solutions) Print s1, s2, . . . , •k-1·

3.1

The algorithm we have just presented can be applied
to any constraint system. However, there are certain
situations where generating all possible explanations
may not be particularly desirable. Returning to our
friend Tony above, consider the following additional
information: Tony is as likely to be awake as be asleep
at any time since he can always get to sleep in any en­
vironment. This implies that for the hypothesis that
Tony is awake, the difference in the cost of being true
and it being false is 0. If we look at our original expla­
nation that Tony is not in the office, we must augment
it with our guess as to whether he is asleep or not.
With our assumptions, there is no way to choose be­
tween asleep and awake. However, since Tony is not
in the office, the hypothesis involving his consciousness
has no impact towards explaining the observation (see
Figure 2.1).
If the algorithm first chooses that Tony is asleep, then
the next alternative would be the same set of assign­
ments except for Tony being awake. However, this new
alternative explanation is uninteresting. In general, it
may be the case that we may run into an overly large
number of these types of uninteresting explanations.
We now proceed to present an approach to deal with
this problem.
Given a WAODAG W = (G,c,r,S)
where G =(V, E) and H c;; VH, an explanation e for
W is said to be consistent with H iff for all h in H,
e(h) = t rue. The base set H(e) of e is the subset of
VH consisting of all h in VH where e(h) =true .
DEFINITION 3.1.

In WAODAGs, finding the best explanation is tanta­
mount to finding the best set of hypotheses we need
to assume.
DEFINITION 3.2. The support-set K(e) of an explana­
tion e is the set consisting of all nodes m in V such
that e(m) =true.
PROPOSITION

Let Lk :=(f,h,,P).
Go to step 2.

5.

(6)

The method we have just described can be classi­
fied as a cutting plane method in operations research
(Nemhauser, Kan & Todd [1989]). Since each de­
rived constraint system differs only in an additional
constraint from some previously solved problem, effi­
cient incremental techniques such as the dual simplex
method can be applied here in a fashion similar to the
one which is used in the branch and bound algorithm.

3.2.

H(e) =K(e) n VH.

For every explanation e for W,

The following propositions follow immediately from
the properties of WAODAGs:
3.3. Let e1 and e2 be explanations forW.
H(e2) iff K(q) =Kh).

PROPOSITION

H(e!)

==

On the Generation of Alternative Explanations with Implications for Belief Revision

3.4. Let e be an e:r.planation forW. For
each H(e) � H � Vn, there e:r.ists an e:r.planation e'
forW such that H(e')= H.

PROPOSITION

THEOREM

1.
2.

3.5. Let e1 and e2 be e:r.planations forW.

H(e1) � H(e2) iff K(e1) � Kh)·
Hh) C H(e2) iff K(e1) C K(e2).

3. 6. There e:r.ists a 1-1 and onto mapping be­
tween 2vH and the set of all possible truth assignments
forW.

terns.
Similar to Algorithm 3.1, the best cardinal explana­
tion, 2nd best, 3rd best, etc. may be generated by con­
structing a sequence of constraint systems L1, L2,
Instead of introducing the additional constraint (6) to
Lk, we introduce
•

I:

3.7. If e is an e:r.planation forW, then there
ezists at least 21VH-H(•)I e:r.planations forW which are
consistent with H(e).

In general, we see that there are an exponential num­
ber of explanations for a given WAODAG. However,
from Theorem 3.7, it seems that the majority of these
explanations are formed from a possibly small number
of "simpler" and more interesting explanations which
utilize smaller numbers of hypotheses. The following
question naturally arises: Do these additional expla­
nations provide any new or important information?
DEFINITION 3.3. A WAODAG W is monotonic iff for ev­
ery two ezplanations e1 and e2 forW, K(e!) � K(e2)
implies C(e1) :S: C(e2) . W is strictly monotonic iffW
is monotonic, and for every two ezplanations e1 and
e2 forW, K(e1) C Kh) implies C(e!) < C(e2).
PROPOSITION 3.8. If c(v, true) 2': c(v, false ) for all v in
V, then W is monotonic. If c(v, true) > c(v, false ) for
all v in V, thenW is strictly monotonic.

3.9. A WAODAGW is monotonic iff for every
two ezplanations e1 and e2 for W, H(e1) � H(e2)
implies C(e1) :S: C(e2). W is strictly monotonic iffW
is monotonic, and for every two ezplanations e1 and
e2 forW, H(e1) C Hh) implies C(e1) < C(e2).
THEOREM

Proposition 3.8 and Theorem 3.9 together show that
in a monotonic WAODAG, "simpler" explanations are
preferred due to the lower associated costs. The as­
sumption of monotonicity is reasonable in many cases
as pointed out by (Charniak & Shimony (1990]) and
characterized in (Charniak & Goldman (1988]). Our
goal is to generate these explanations in order of cost
without having to consider the remaining exponential
number of explanations.
3.4. e is cardinal iff there are no ezplana­
tions e' such that H(e') C H(e) .

DEFINITION

Intuitively, a cardinal explanation is among the "sim­
plest" of explanations we wish to consider.
3.10. If W is strictly monotonic, then any
best ezplanation forW is cardinal.

THEOREM

All the definitions given above involving WAODAGs can
be carried over to WAODAG induced constraint sys-

..

:ll q:::: IH(sk-1) 1- 1.

ZqEH(••-d

THEOREM

THEOREM

.

LEMMA 3.11. Let W be strictly monotonic. If sn is
the optimal 0-1 solution for the constraint system Ln,
then Sn is a cardinal 0-1 solution for L.
3.12. LetW be strictly monotonic. The con­
straint system Ln determines the n-th best cardinal 0-1
solution.

THEOREM

Our notion of cardinal explanations is very similar to
the notion of irredundancy found in parsimonious cov­
ering theory for modeling medical diagnosis (Peng &
Reggia (1990]). A diagnostic problem (Peng & Reggia
(1990]) is a two-layer network consisting of a layer of
manifestations which are causally affected by a layer
of disorders. Given a subset of the manifestations as
evidence, a subset of disorders must be chosen to best
explain the manifestations based on parsimonious cov­
ering theory. A collection of disorders which can ex­
plain the manifestations is called a cover. A cover is
said to be irredundant if none of its proper subsets is
also a cover.
A limitation of parsimonious covering theory as
pointed out by Peng and Reggia (Peng & Reggia
(1990]) is the large number of covers which are con­
sidered "best". In order to further select from these
potential explanations, some additional criteria must
be used. Basic parsimonious covering theory is ex­
tended to incorporate probability theory. The poten­
tial of an explanation is now measured by some prob­
ability. With the addition of probabilities, care must
be taken in choosing which covers are to be inspected.
For example, consider the following analogous prob­
lem in cost-based abduction: A set of disorders D
can adequately explain manifestations M. Let d be
a fairly common disorder which explains manifesta­
tion m. Assumed is not in D but m is present in M.
Furthermore, assume c(d, F )> c(d, T). Thus, D U {d}
is a better explanation than D, despite the fact that
D U {d} is a superset of D.
Although this modified algorithm works only forW be­
ing strictly monotonic, we can modify any non-strictly
monotonic problem to make it applicable. In essence,
the strict monotonicity simply implies that we should
always have a preference for a false assignment over a
true assignment. By introducing an arbitrarily small
positive difference between the cost for true and the
cost for false in the original problem, we can now deter­
mine the cardinal solutions of the new problem which

343

344

Santos

turns out to be identical to those of the original.
BAYESIAN NETWORKS

4

Bayesian network$ have become an important tool in
modeling probabilistic reasoning. The inherent rep­
resentational power of these networks provides a very
promising approach. In particular, belief revision in
Bayesian networks is the process of finding the best
interpretation for some given piece of evidence. This,
of course, is a cornerstone of abductive explanation.
Since we are interested in abduction, existing effec­
tive algorithms for belief revision should be considered.
One such algorithm is given by Pearl in (Pearl [1988])
which is based on a message passing scheme. How­
ever, except for simple networks such as polytrees, the
method is rather complicated to apply. Also, as Pearl
points out in Chapter 5 in (Pearl [1988]), this algo­
rithm cannot guarantee the generation of alternative
explanations beyond the second best.
Our goal in this section is to apply our linear constraint
satisfaction approach to Bayesian networks. This en­
tails constructing a constraint system which is com­
putationally equivalent to the Bayesian network. Al­
though this could be done by first transforming the
Bayesian network into a cost-based abduction graph
(Charniak & Shimony [1990]) and then transforming
the graph into a constraint system (Santos [1991a);
Santos [1991c]), a more natural and straightforward
method will be given below. We will show how to di­
rectly transform a Bayesian network into an equivalent
constraint system.
We first observe that a Bayesian network can be com­
pletely described by a finite collection of random vari­
ables (or simply, r.v.s) and a finite set of conditional
probabilities based on the r.v.s. 3
NoTATION. Throughout the remainder of this paper,
upper case italicized letters such as A, B, . . . will rep­
resent r.v.s and lower case italicized letters such as
a, b, . . . will represent the possible assignments to the
associated upper case letter r.v., in this case, A, B, . . ..
Subscripted upper case letters which are not italicized
are variables in a constraint system which explicitly
represent the instantiation of the associated r.v. with
the item in the subscript. For example, Aa denotes
the instantiation of r.v. A with value a.
NoTATION. Given a r.v. A, the set of possible values
for A called the range of A will be denoted by R(A).

Given a Bayesian network, we can construct an or­
dered pair (V, P) where V is the set of r.v.s in the
network and P is a set of conditional probabilities asso3

We c onsiderpri or probabilities t o be de gener
ate

of c onditi onal probabilities, i.e.,
wher
e <P is the e mpty set.

P(A

=a

)

=

P(A

cases
=a

l<f!)

ciated with the network. P(A = a[C1 = c1, . . . , Cn =
en)E P iff C1, ..., Cn are all the immediate parents of
A and there is an edge from C; to A for i = 1, .. . , n in
the network. We can clearly see that (V, P) completely
describes the Bayesian network.
DEFINITION 4.1. Given a Bayesian network B = (V, P),
an instantiation is an ordered pair (A, a) where A E V
and a E R(A). {An instantiation (A, a) is also denoted
by A = a and Aa.) A collection of instanti .. tions w is
called an instantiation-set iff are no two instantiations
(A, a), (A, a') in w such that a -=ft a'.

An instantiation represents the event when a r.v. takes
on a value from its range. Given an instantiation-set,
we can define the notion of the span of an instantiation­
set.
DEFINITION 4.2. Given an instantiation-set w for a
Bayesian network B = (V, P), we define the span
of w, span(w), to be the collection of r.v.s in the
first coordinate of the instantiations. Furthermore, an
instantiation-set w is said to be complete iff span ( w) =
v.

NoTATION. For each r.v. A and each a in R(A), vA
a
is the set of all conditional probabilities in P of the
form P(A = a[C1 = q, .. . , Cn = en)· For each r.v.
A, we define co n d(A) as follows: B E co n d(A) iff there
exists a conditional probability in P of the form P(A =
a[ . . . , B = b, ...).
DEFINITION 4.3.
Given an instantiation-set w
{(A1, a1), . . . , (An, an)} for a Bayesian network B
(V, P), we define the probability of w to be
P(w) = P(A1 = a1, . .. , An:::: an)·

The goal of belief revision on Bayesian networks is to
determine the complete instantiation-set which maxi­
mizes the associated probability under certain condi­
tions. In general, these conditions, called evidence, im­
poses restrictions on what instantiations may be made.
The instantiation-set satisfying the evidence with the
highest probability is said to be the most probable ex­
planation for the evidence. We now formalize this as
follows:
DEFINITION 4.4. Given a Bayesian network B = (V, P),
evidence e for B is an instantiation-set for B.
DEFINITION 4.5. Given instantiation-sets w1, w2 for a
Bayesian network B, w2 is said to be consistent with
W1 iff W1 <;; W2.
DEFINITION 4.6. Given evidence e for B, a complete

instantiation-set w for B is an explanation for e iff
w is consistent with e. Furthermore, w is said to be a
most probable explanation for e iff for all explanations
w' -=ft w for e, P(w') :<::: P(w).
Our basic approach in constructing a constraint sys­
tem from a given Bayesian network is to represent and

On the Generation of Alternative Explanations with Implications for Belief Revision

enforce the constraints that exist between any two or
more r.v .s.
Given a Bayesian network B = (V, P), we construct a
constraint system L(B) = (r, I, ,P) as follows:
1. For each r.v. A in V , let R(A) = {a1, ... ,a,.}
and construct the variables Aa.,..., Aa� in r, set
,P(Aa., false) = ,P(Aa., true) = 0 and add the fol­
lowing constraint to I:
FIG. 4.1.

"

LAa, = 1.

(7)

i=l

2. For each r.v.A and some a in R(A), for each con­
ditional probability P(A =aiC1 = c1, ... , C,. =
c,. ) in v
Aa , construct a variable q[Aa I C1 =
c1, ... ,C,. = c,.] in r such that (for nota­
tional convenience, we will denote q[Aa I C1 =
c1, ...,C,. = c,.] by q in the next two conditions)
(a) ,P(q, false) = 0, ,P(q, true) = -log(P(A
aiC1 = c 1, ... , C,. = c,. )) , and,
(b) Add the following constraint to I:
"

q � Leke,
k=l

+ Aa

-n.

(8)

3. Let YAa be all the variables q constructed by vAa
in step (2). For each r.v. A and some a in R(A),
add the following constraint to I:
Aa =

L

qETA
a

q.

( 9)

DEFINITION 4.7. L(B) constructed above is the con­

straint system induced by B.

As we can clearly see, our construction is straight­
forward and is done in time linear to the size of the
Bayesian network. The next theorem show the com­
plexity of our induced constraint system with respect
to the Bayesian network.
= (V, P) be a Bayesian network
and L(B) =(f, I, ,P) be the constraint system induced
by B. Then

THEOREM 4.1. Let B

1.
2.

lfl =IPI + l:AE V IR(A)I and
III= lV I + IPI + l:AEv IR(A)I.

In our construction, (7) guarantees that any r. v. takes
on exactly one value. (8) and ( 9) guarantee that the
probability of any complete instantiation-set will be
computed with the appropriate set of conditional prob­
abilities. Variables of the form q[Aa I cl c, ' ... ' CncJ
are called conditional variables in that they explicitly
represent the dependencies between r. v.s and will be
the mechanism for computing the probability for any
instantiation-set.

Si mple

Bayesian network.

The distri­

bution isasf
ollows:

P(C =true lA =true, B =true)= p,
P(C =true lA =true, B =false)= P2
P(C =true lA =false, B =true)= p3
P(C =true lA =false, B =false)= P•
P(A =true)= Po)
P(B = true)= P1o)

For example, consider the simple Bayesian network in
Figure 4.1. When we have the instantiations {A =
true, B = false, C =true}, its associated probability is
P2 * pg * (1 - Pw). In the induced constraint system,
we expect our variables assignments to be Atrue =
1, Bfalse = 1, Ctrue = 1, q[Ctrue I Atrue> Bfalsel = 1,
and all remaining variables to be 0. Since the only
costs are associated with the variables Atrue1 Bfalse
and q[Ctrue I Atrue1 Bfalsel, the cost of this assignment
is -log(pg) -log(1-pw)-log(p2) which is equivalent
to -log(p2 * pg * (1- Pw)).
NoTATION. For each r.v. A, let �(A) be the set of
variables in the induced constraint system constructed
for A.
4.2. Given a 0-1 solution s for L(B), for
each set of variables �(A), there ezists some Aa in
�(A) such that Aa = 1 and Aa• = 0 for all Aa• # Aa
in �(A).

THEOREM

4.3. Given a 0-1 solution s for L(B), for all
variables q[Aa I cl =C), . .. ,Cn =en], if Aa =clc, =
... = Cnc = 1, then q[Aa I cl =C), ... ,Cn =Cn] =1.
�

THEOREM

Theorems 4.2 and 4.3 above verifies our expectations
on the legitimate variable assignments. However, Aa =
C1c ' =.. . = Cnc� =0 does not necessarily imply that
q[Aa I C1 = c1, . . . , Cn = en] = 0. We could remedy
the situation by introducing the following additional
constraints:
q[Aa I cl =C), ...,Cn =Cn]::; Aa,

q[Aa IC1 = C), . . .,Cn =en] :S C; c, fori= 1, . . . , n .
Instead of increasing the number of constraints, we
will show that this can be solved through simple re­
strictions and modifications to the algorithms applied
to general constraint systems.
DEFINITION 4.8. A 0-1 solution s for L(B) is said to be
permissible if for all variables q[Aa I cl = Cj,... ,Cn =

345

346

Santos

For the following theorems, assume that L is in­
duced by a Bayesian network B, w is a complete
instantiation-set forB, and s is a permissible 0-1 solu­
tion for L(B).

q[Aa I cl = cl, . .. ' Cn = Cn ] = 1 only if
Aa= C1c = . . . = Cncft = 1.
,
Thus our goal is to consider only those 0-1 solutions
for L(B) which are permissible. We must now show
that calculations on the constructed constraint system
are equivalent to those on the Bayesian network for
belief revision.

THEOREM 4.10. 8L(s,) = - log(P (w)).

There e:�:ists a constant a, such
that for all e:tplanations W for e, 8L.(s,) = a, ­
log(P(wle)).

THEOREM 4.11.

THEOREM 4.12. w is a most probable e:�:planation for e

Given a 0-1 solution s for L(B), we can construct a
complete instantiation-set w, forB as follows: s(Aa) =
1 iff (A, a) E w,. To convert from a complete
instantiation-set to a 0-1 solution is slightly trickier.
Given a complete instantiation-set w for B, construct
a 0-1 solution s, for L(B) as follows: (A, a) E w iff
s, (Aa) = 1. For each conditional variable q in T A a,
set the appropriate value according to w.

Theorem 4.11 guarantees that the probabilistic order­
ing of instantiation-sets is exactly reversed from the
cost ordering imposed on permissible 0-1 solutions.
Furthermore, computing the cost for a permissible 0-1
solution immediately determines the probability of its
associated instantiation-set.

THEOREM 4.4. If s is a

THEOREM 4.13. If 1/J(q, true) > 0 for all conditional

0-1 solution for L(B), then w,
is an instantiation-set for B.

THEOREM 4.5. If w is a complete instantiation-set for
B, then s, is a permissible 0-1 solution for L(B).

From our construction of instantiation-sets from 0-1
solutions, we notice that more than one 0-1 solution
can construct the same instantiation-set. This arises
from our previous observation that our expectations
are not completely met (Theorem 4.3).
CoROLLARY 4.6. There is a

and onto mapping be­
tween permissible 0-1 solutions for L(B) and complete
instantiation-sets for B.
1-1

This corollary states that we only need to consider the
permissible 0-1 solutions in our calculations of com­
plete instantiation-sets for the Bayesian network.
DEFINITION 4.9. Let e be some evidence for B= (V, P).

We construct L,(B)= (r,J,, 1/J) from L(B)= (r, I, 1/J)
as follows: Let I, = I U I' where the constraint Aa= 1
is in I' iff (A, a) E e. We say that L,(B) is induced
by B with evidence e.
PROPOSITION 4.7. II. I= III+ l ei.
THEOREM 4.8. If s is a

0-1

is an e:�:planation for e.

solution for L,(B), then w,

THEOREM 4. 9. If w is an e:�:planation for e, then s,

a permissible

0-1

solution for L,(B).

u

When there is some set of evidence given to be ex­
plained, we only want to consider those instantiation­
sets which are consistent with the evidence. Theo­
rems 4.8 and 4.9 above guarantee that the evidence
also properly restricts the set of possible permissible
0-1 solutions we wish to consider. Now, we must show
that the costs associated to each permissible 0-1 solu­
tion are directly related to the probability of the cor­
responding instantiation-set.

iff s, is an optimal

0-1

solution for L,(B).

variables q in L,(B), then any optimal
for L,(B) is permissible.

0-1

solution

The condition required in the above theorem can be
easily met by increasing the cost of conditional vari­
ables with 1/J(q, true) = 0 to 1/J(q, t rue) = 8 where 8 is
an arbitrarily small but positive value. This still guar­
antees proper ordering of the permissible0-1 solutions
as compared to the instantiation-sets.
Similarly, we must guarantee that any alternative 01 solutions generated must also be permissible. We
can accomplish this by modifying the Algorithm 3.1.
Again, instead of introducing the new constraint (6)
into Lk we introduce

L

F(sk,Aa) :S 1 �1 -1

AaEl>.
where � = {:cl:c E V and

:c

E

�(A) for some r.v. A}.

THEOREM 4.14. Ln generates the n-th best permissible

optimal

0-1

solution for L,(B).

With the transformation of belief revision problems
into constraint systems, we now have an alternative
approach to solving for the best explanation as well
as the consecutive next best. With our linear con­
straint satisfaction approach, we can utilize the highly
efficient computational tools of operations research on
the NP-Hard problem of belief revision and explana­
tion generation. Furthermore, unlike message-passing
schemes requiring preprocessing such as clustering on
non-polytree topologies, our approach can be directly
applied to any Bayesian network.
5

DISCUSSION

Linear constraint satisfaction has been shown to be
an effective and computationally practical approach

On the Generation of Alternative Explanations with Implications for Belief Revision

to solving cost-based abduction (Santos [1991a]; San­
tos [1991c]). Experimental results comparing our con­
straint system against existing search style techniques
have shown it to be the superior approach.
In this paper, we have presented an approach to gen­
erating alternative explanations within our framework
of constraint systems. This approach naturally incor­
porates the computational tools of operations research
in an efficient manner. We have also shown how to ap­
ply the generation of alternative explanations to cost­
based abduction and belief revision in Bayesian net­
works.
The necessity of having alternative explanations can
also be readily seen in natural language processing.
Proper handling of problems such as ambiguity re­
quires access to the possible explanations in order of
best to worst. For example, the WIMP system (Gold­
man [1990]; Goldman & Charniak [1991]) uses alter­
native explanations in order to resolve lexical ambi­
guities. Our approach is especially well suited to this
problem since it is characterized by low prior proba­
bilities making it monotonic within our framework.
Acknowledgments

This work has been supported by the National Sci­
ence Foundation under grant IRI-8911122 and by the
Office of Naval Research, under contract N00014-88-K0589. Special thanks to Eugene Charniak for critical
comments and suggestions. Also, thanks to Solomon
Shimony, Glenn Carroll and Moises Lejter for careful
review of this paper.
References

Charniak, Eugene & Goldman, Robert [1988], "A
Logic for Semantic Interpretation," Proceed­
ings of the AAAI Conference.
Charniak, Eugene & Shimony, Solomon E. [1990],
"Probabilistic Semantics for Cost Based Ab­
duction," Proceedings of the 1990 National
Conference on Artificial Intelligence.
Genesereth, Michael R. [1984], "The Use of Design De­
scriptions in Automated Diagnosis," Artificial
Intelligence.
Goldman, Robert P. [1990], "A Probabilistic Approach
to Language Understanding," Department of
Computer Science, Brown University, Ph.D.
Thesis.
Goldman, Robert P. & Charniak, Eugene [1991],
"Probabilistic Text Understanding," Proceed­
ings of the Third International Workshop on
AI and Statistics, Fort Lauderdale, FL.

Hobbs, Jerry R., Stickel, Mark, Martin, Paul & Ed­
wards, Douglas [1988], "Interpretation as Ab­
duction," Proceedings of the 26th Annual
Meeting of the Association for Computational
Linguistics.
Kautz, Henry A. & Allen, James F. [1986], "Gener­
alized Plan Recognition," Proceedings of the
Fifth Conference of AAAI.
Nemhauser, G. L., Kan, A. H. G. Rinnooy & Todd, M.
J. [1989], in Optimization: Handbooks in Op­
erations Research and Management Science
Volume 1,

North Holland.

Pearl, Judea [1988], in

Probabilistic Reasoning in In­

telligent Systems: Networks of Plausible Infer­
ence,

Morgan Kaufmann, San Mateo, CA.

Peng, Y. & Reggia, J. A. [1990], in

Abductive Infer­

ence Models for Diagnostic Problem-Solving,

Springer-Verlag.
Santos, Eugene Jr. [1991a], "A Linear Constraint Satis­
faction Approach to Cost-Based Abduction,"
Department of Computer Science, Brown Uni­
versity, in preparation.
Santos, Eugene Jr. [1991b], "Cost-Based Abduction,
Linear Constraint Satisfaction, and Alterna­
tive Explanations," to appear in Proceedings
of the AAAI Workshop on Abduction.
Santos, Eugene Jr. [1991c], "Cost-Based Abduction
and Linear Constraint Satisfaction," Depart­
ment of Computer Science, Brown University,
Technical Report CS-91-13.
Selman, Bart & Levesque, Hector J. [1990], "Abduc­
tive and Default Reasoning: A Computational
Core," Proceedings of the Eighth National
Conference on Artificial Intelligence.
Shanahan, Murray (1989], "Prediction is Deduction
but Explanation is Abduction," IJCAI-89.
Stickel, Mark E. [1988], "A Prolog-like Inference Sys­
tem for Computing Minimum-Cost Abductive
Explanations in Natural-Language Interpreta­
tion," SRI International, Technical Note 451.

347

