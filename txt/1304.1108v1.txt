220

I
I
Equivalence and Synthesis of Causal Models*

I
I

<

I

TS Vermat

verma@cs.ucla.edu

I
I
I
I
I
I
I
I
I
I
I
I

Judea Pearl

judea@cs.ucla.edu >

Cognitive Systems Laboratory

Cognitive Systems Laboratory

Computer Science Department

Computer Science Department

University of California

University of California
Los Angeles, CA 90024

Los Angeles, CA 90024

I
I

<

>

June 18, 1990

[Verma and Pearl 90]. One problem that has arisen
in the course of these studies is that of non­
uniqueness; it is quite common for two different
causal models to be experimentally indistinguishable,
hence, equally predictive. Formally, let a causal the­
ory be a pair T =< D, e >, where D is a dag, called
the causal model ofT , and e a set of parameters com­
patible with D ( i.e., sufficient for forming a probabil­
ity distribution for which D is a Bayesian network) .
We say that two causal models D1 and D2 are equiv­
alent if for every theory T1 =< D1, 81 > there is a
theory T2 =< D2, 82 > such that T1 and T2 describe
the same probability distribution, and vice versa.

Abstract

Scientists often use directed acyclic graphs (dags) to
model the qualitative structure of causal theories, al­
lowing the parameters to be estimated from observa­
tional data. Two causal models are equivalent if there
is no expirement which could distinguish one from the
other. A canonical representation for causal models
is presented which yields an efficient graphical crite­
rion for deciding equivalence, and provides a theoret­
ical basis for extracting causal structures from em­
pirical data. This representation is then extended to
the more general case of an embedded causal model,
that is, a dag in which only a subset of the variables are observable. The canonical representation
a
presented here yields an efficient algorithm for deter"-..
a
mining when two embedded causal models are equiv"'
b
alent, and leads to a model theoretic definition of
"-..
causation in terms of statistical dependencies.
·

/

b

c

Introduction

The use of dags as a language for describing causal
models has been popular in the behavioral sciences
[Blalock 71], [Duncan 75] and [Wright 34], decision
analysis [Howard and Matheson 81], [Olmsted 84]
and [Shachter 85] and evidential reasoning [Pearl 88],
and has also received extensive theoretical stud­
ies [Geiger and Pearl 89], [Geiger and Verma 90],
[Pearl and Verma 87],
[Glymour et al 1987],
[Shachter 85], [Smith 89], [Spirtes et al 90] and
*This work was supported, in part, by NSF grant
ffil-88-2144 and NRL grant N000.89-J-2007.
tsupported by an IBM graduate fellowship.

( a)

�

/
a

"'

1

/c

"-..

(b)

b

( c)

a

"' /c
b

(d)

Figure 1: Three of the four models are equivalent.
For example, consider the four causal models of
Figure 1. The parameters required for the first model
are P(a), P(bla) and P(clb). The second requires
estimations for P(b), P(alb) and P(clb). It is easy
to see that these two models are equivalent since by
Bayes law, P(a)P(bla) = P(ab) = P(b)P(bla), hence
the values obtained for the first set of parameters
completely determine the values of the second, and
vice versa. Similarly, the third model is equivalent to

221

the first two since its parameters, P(c), P(blc) and
P (a l b) can be determined from either of the first two
sets. However, the fourth model is quite different; its
parameters are P(a), P(c) and P(blac) which cannot
be determined from any of the previous sets.

lence of two models, and a canonical representation
called a pattern for describing the class of all mod­
els equivalent to a given dag. Section 3 extends this
construction to the case of embedded causal models.
Theorems will be stated without proofs, a full detail
of which can be found in [Verma 90]. In section 4,
The fact that the first three models are equiv­ the Theorems of the previous two sections are ap­
alent to each other but not the fourth is easily plied to the problem of recovery of a causal model
seen in terms of the independence information con­ from statistical data.
veyed by the corresponding dags. The first three
all represent the independence statement I(a, b, c)
which is read "a is independent, given b, of c",
Patterns of Causal Models
whereas the fourth represents the statement I(a, 0, c), 2
which is read "a is marginally independent of c".
It is known that the statistical meaning of any
It is not difficult to observe that equivalent dags have
causal model can be described economically by
common features. For example, two dags that repre­
its stratified protocol, which is a list of indepen­
sent equivalent causal models must have the same
dence statements that completely characterize the
adjacency structure. Two nodes of a dag are adja­
model [Geiger and Pearl 89], [Pearl and Verma 87]
cent, written ab if either a -+ b or a - b. That
and [Verma and Pearl 90]. Furthermore, any in­
adjacency is invariant among equivalent dags follows
dependence statement that logically follows from
from Lemma 1 which describes the principle relation­
the stratified protocol can be graphically deter­
ship between adjacency and unseparability 1 (parts 1
mined in linear time via the d-separation criterion
and 2) as well as the relationships between separa­
[Geiger and Verma 90] and [Geiger et al 89]. Thus,
bility and d-separation 2 given two particular special
the question of equivalence of causal models reduces
sets of nodes in the dags (parts 3 and 4). Let the an­
to the question of equivalence of protocols: two dags
cestor set Aab of a pair of variables a and b be defined
are equivalent if and only if each dag's protocol holds
as the union of the sets of ancestors of a and b (less
in the other [Pearl et al 89]. This solution is both in­
ab) , and similarly, the parent set Pab of the pair be
tuitive and efficient. However, it has two drawbacks;
defined as the union of the sets of parents of a and b
it is difficult to process visually and it does not gen­
(less ab).
eralize to embedded causal models.
Embedded causal models are useful for modeling
theories that cannot be modeled via simple dags.
For example, if there are unobserved variables which
cause spurious correlations between the observable
variables it may be necessary to embed the observ­
ables in a larger dag containing "hidden" variables
in order to build an accurate model. Even when
there exists a simple causal model that fits theory,
it might be desirable to embed the model in a larger
dag to satisfy some higher level constraints. For ex­
ample, suppose that every causal model that fits a
given set of data contains the link a -+ b. Further­
more, suppose that b occurs before a in time and that
causality is assumed to be temporal. Under these cir­
cumstances, the simple causal models are inconsistent
with the higher level constraints on the temporal di­
rection of causality; one way of avoiding this conflict
is to hypothesize the existence of an unknown com­
mon cause, i.e. a +- a -+ b. See Figures 3 and 4 for
examples of the use of hidden variables.
This paper is organized as follows. Section 2 pro­
vides an efficient criterion for deciding the equiva-

Lemma 1 Let a and b be two nodes of a dag D; the

following four conditions are equivalent:
(1} a
{2} a
{3) a
(.1) a

and b
and b
and b
and b

are
are
are
are

adjacent in D
unseparable in D
not d-separated by Aab in D
not d-separated by Pab in D

Proof: (Sketch) That (1) implies (2) follows from
the fact that a link is a path which cannot be de­
activated; and (2) trivially implies (3) since unsep­
arability means the lack of d-separation in any con­
text, including Aab· Since every path activated by
Pab is also activated by Aab, it follows that (3) im­
plies (4). The final implication, that (4) implies (1)
follows from the observation that if a and b are not
d-separated given Pab1 then there must be an active
path between them. If this path contains a node,
other than a or b, it would have to contain at least one
1two variables

are

unseparable just in case there is no set

that d-separates them.

2the predicate ID { ·) denotes d-separation in the dag D.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

222

I
I
I
I
I
I
I
I
I
I
I
I
I

head-to-head node since it is active given the parents
of a and b; and for the same reason, the head-to-head
node nearest to a on the path would be a descendant
of a, similarly the one nearest b would be a descen­
dant of b. Both of these head-to-head nodes would
have to be in or be an ancestor of a node in Pab for
the path to be active, but the one nearest a could
not be an ancestor of a, hence both it and a would
be ancestors of b. Similarly, both band the head to
head node nearest it would have to be ancestors of a,
hut this would imply the existence of a directed loop,
hence the path cannot contain any nodes other than
a and b. Therefore the nodes are adjacent. D
The major consequence of this lemma is that adja­
cency is a property determined solely by d-separation,
hence remains invariant among equivalent dags.

I
I

Together, these lemmas form a necessary and suf­
ficient condition for equivalence, previously stated in
[Pearl et al 89]:

I

Theorem 1 Two dags are equivalent if and only if

I
I

Since the two invariant properties of a dag identi­
fied in the lemmas are a sufficient condition for equiv­
alence, they lead to a natural canonical representa­
tion of its equivalent class. Simply construct a par­
tially directed graph by removing the arrowheads from
any link of the dag that is not identified by Lemma
2. This partially-directed graph will be called the
rudimentary pattern of the causal model. Since the
rudimentary pattern can be defined solely in terms
of d-separation, it follows that each equivalence class
of causal models has a unique pattern; hence, two
causal models are equivalent if and only if they have
the same pattern. This is a useful view of the prob­
lem since the patterns can be constructed efficiently

A set of equivalent dags possesses another impor­
tant invariant property, namely the directionality of
the uncoupled head-to-head links (i.e. a - b - c
are uncoupled if a and c are not adjacent). There 3
are other links whose directionality remains invariant,
Lemma 2 only identifies some of the invariant ar­
but these can easily be determined from the uncou­
pled head-to-bead links. The following lemma sum­ rowheads of a causal model, but since identification of
marizes this important class of links with invariant this class is sufficient for deciding equivalence, it fol­
directionality.
lows that the remainder of the invariant arrowheads
are completely determined by this class. It is not
difficult to identify the remainder of the invariant ar­
Lemma 2 If the nodes a, c , b form the chain acb rowheads as some of the undirected links of a rudi­
while a and b are not adjacent, then c is head-to­ mentary pattern cannot be arbitrarily directed with­
head between a and b if and only if a and b are not out either (1) creating a new uncoupled head-to-head
separable by any set containing c. That is, for any node or (2) creating a directed loop. Since these undi­
dag D, acb ED and ab rJ. D �
rected links are essentially constrained to a certain
direction, it is desirable to define a completed pattern
[a-c-b ED <==> -,JD(a, Sc, b) Vs�U-obc]
in which they are directed as constrained. The com­
pleted pattern reflects each and every invariant arrow
The proof of this lemma relies upon the inherent head. Furthermore, both rudimentary patterns and
differences between a head-to-head junction and the completed patterns offer a compact summary of each
other types of junctions (tail-to-tail and head-to-tail). and every dag in an equivalence class.

The major ramification of Lemma 2 is that the direc­
tionality of a certain class of links can be determined
from d-separation alone. The implications this may
have on the prospects of inferring causal relationships
from independence statements are briefly discussed in
section 4 and in detail in [Verma 90].

I

The proof of this theorem is based on the lemmas
along with an inductive step showing that every ac­
tive path in one dag has a corresponding active path
in the other. The importance of Theorem 1 is that the
equivalence of two causal models can be determined
by a simple graphical criterion.

they have the same links and same uncoupled head­
to-head nodes.

(a )

(b)

(c)

(d)

(e)

Figure 2: Equivalence class of models.
1 Note that comparison of patterna is polynomial since the
nodes are labeled

223

For example, in Figure 2, the rudimentary pattern
(d) and the completed pattern (e) each summarizes
the dags in the equivalence class { (a), (b), (c)}. Any
extension of either pattern into a full dag that does
not create new uncoupled head-to-head nodes will be
a dag in the equivalence class. There are three such
extensions in the example of Figure 2.

3

a

d

'xb / 'xc / ""'b
( a)

Figure 3: The representation of
cause.

·c

---

/

(b)

a

over the variables UD, of which Uo � UD are ob­
servable, the rudimentary pattern P of D restricted
to Uo is defined as the hybrid graph with fewest ar­
rowheads that satisfies the following conditions:
-

d

a

Definition 1 (Embedded Pattern) Given a dag D

(1} ab E P

Embedded Causal Models

Partially-directed graphs offer an excellent tool for
describing the equivalence classes of causal models;
it would be desirable to find a similar structure for
embedded causal models. Such a structure requires
the ability to represent a direct non-causal correla­
tion between two variables. In a simple dag, when­
ever two variables are unseparable, there must be a
directed link between them, dictating that either the
first causes the second or the second causes the first.
There is no way to represent the existence of an un­
known common cause, as illustrated in the following
embedded causal model (Figure 3 (a)). Assume a, b,
c and d are the observables and a is unobservable.
There is no dag that can represent the dependen­
cies between a, b, c and d using these variables only.
However, the hybrid graph (Figure 3 (b)) which con­
tains a bi-directional link does represent these depen­
dencies. (Under a natural extension of d-separation
[Verma 90]).
a

patterns of embedded causal models according to the
following definition.

¢::::?

-.

ID (a, S, b) VS � Uo- ab

{2} ab if3c E Uo such that: abc E P, ac ft P
and -.ID(a, Sb, c) VS � Uo -abc

Rudimentary embedded patterns can be extended
into completed embedded patterns (or simply, em­
bedded patterns) in much the same way that simple
patterns are completed. The same constraints can be
used for the completion, namely, no arrow head can
be added to the pattern that would (1) create a new
uncoupled head-to-head node or (2) create a strictly
directed cycle. However, note that a strictly directed
cycle contains only singly directed arrows.
While this defines a unique pattern for embedded
every dag, it does so in terms of d-separation con­
ditions over subsets all of Uo, which, in principle,
might require an exponential number of tests. The
next two lemmas show that patterns can be formed
in polynomial time. Lemma 3 delineates the rela­
tionship between adjacency in the pattern and un­
separability in the causal model (parts 1 and 2) and
provides a practical criterion for determining separa­
bility in terms of a simple d-separation test (part 3)
and a graphical test (part 4). The graphical test is
defined in terms of an inducing path:
Definition 2 (Inducing Path) An inducing path be­

tween the variables a and b of an embedded causal
model is any path p satisfying the following two con­
ditions:

hidden common (1} Every observable node on p is head-to-head on p.
{2} Every head-to-head node on p is in Aah•

For hybrid graphs, the notation ab denotes the existence of a link with at least an arrow head pointing
at b, namely either a - b or a +-+ b, while ab de­
notes the existence of a link without any constraints
on its orientation. Thus, for example, when applied
to a dag, ab means a - b or a +- b; while in hybrid
graphs ab denotes the existence of any of the four
possible types of links, (namely, a- b, a- b, a+- b
and a +-+ b). Hybrid graphs can be used to represent

Lemma

Let P be the pattern of a dag D with re­
spect to the observables Uo C UD and a, b E Uo be
two observables; the following statements are equiva­
lent:
{1} a
{2} a
{3} a
(I) a

3

and b
and b
and b
and b

are
are
are
are

adjacent in P
unseparable in D (over Uo)
not d-separated by A..6 n Uo in D
connected by an inducing path in D

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I

224

I
I
I
I
I
I
I
I
I
I
I
I
I
I

Proof: (Sketch) By definition, (1) is equivalent to
(2) and (2) implies (3). To show that -.J(a, Aab n
Uo, b) implies the existence of an inducing path, con­
sider that this dependency implies the existence of
a path p, between a and b which is active given
Aab n Uo. Since Aab n Uo only contains ancestors
of a and bit follows that every head-to-head node on
p must be in Aab· Thus any observable node on p
that is not head-to-head would be in Aab n Uo and
would serve to deactivate the path, so every observ­
able node on p must be head-to-head. Therefore p is
an inducing path.
To show that the existence of an inducing path im­
plies unseparability relative to Uo hence finish the
proof, consider any two nodes a and b which are con­
nected by an inducing path p. To show a and b are
not d-separated in any context of Uo, consider any
contextS which deactivates p (if p is active for every
context, then the two nodes are unseparable). Since
the only observable nodes of p are head-to-head, only
head-to-head nodes could serve to deactivate p. Each
head-to-head node on p must be in Aab and at least
one must be inactive, given S (otherwise the path
would be active givenS). If all inactive head-to-head
nodes are ancestors of a then consider the one closest
to b, call it y. The portion of p between y and b is ac­
tive, and the ancestry path from y to a can be added
to form an active path between a and b givenS. On
the other hand, if any of the inactive head-to-head
nodes is ancestor of b then pick the head-to-head an­
cestor of b which is closest to a on p and call it z.
Every inactive head-to-head node between a and z
must be an ancestor of a (if any exist), hence there
must be an active path between a and z (either the
portion of p between A and X, or the ancestry path
from the head-to-head node between a and z which is
closest to z concatenated with the portion of p from
that node to z ). Since z is an ancestor of b, the an­
cestry path from z to b can be concatenated to the
path from a to z to form an active path between a
and b givenS. Thus A and Bare unseparable. D

rithm for constructing the characteristic pattern of
any embedded causal model. The final theorem com­
pletes the original task of deciding equivalence.
Theorem 2 Two embedded causal models are equiv­

alent if and only if they have the same pattern.

Thus, Theorem 2 gives validity to the notion of a
pattern as a characteristic representation of an em­
bedded causal model. An interesting consequence of
this theorem is given by the following corollary:
Corollary 1 There are fewer than siUol� distinct
embedded causal models containing IUol variables,·
moreover, every embedded causal model is equivalent
to a simple dag with fewer than 1Uol2 variables.
Part 1 follows from the fact that every embedded
causal model is equivalent to its pattern, and every
pattern contains fewer than I Uo I edges (there are four
types of edges). The second part stems from the fact
that a bi-directional link a +-+ b in a pattern can be
represented by a single hidden common cause ex of
the observable variables, namely, a - ex -+ b.

.�,

I
I

Lemma

I
I
I

'

a

(3

a

d

(b)

e

b

a

c

'A/
(b')

(3

a

b

a

d

c

'A/
( )

( a)

Lemma 3 describes how links are induced in P by a
paths of D. The next lemma will describe how to
determine the directionality of these links in terms of
the inducing paths.

-

b

a

( c)

e-

c

"V'/
e
d

( c' )

For any pattern P, ab if and only if there
is a node c adjacent to b but not to a (in P) such Figure 4: The patterns reveal which two models are
that both edges ab and be were induced by paths (of equivalent.
D) which ended pointing at b.
Figure 4 contains three embedded causal mod­
Lemmas 3 and 4 provide a polynomial time algo- els (a), (b) and (c) over the observable variables
4

225

{a, b, c, d, e} as well as their completed patterns (a'),
(b') and (c') respectively. The patterns indicate
that the first two causal models are equivalent to
each other but not to the third; while a and b are
marginally independent in (e) they are dependent in
both (a) and (b). Figure 4 (b) demonstrates that
a hidden common cause is not equivalent to a bi­
directional link since it is important to recognize the
paths they may induce.

4

Applications to the Synthe­
sis of Causal Models

The problem of deciding the equivalence of (embed­
ded) causal models is fundamental to causal reason­
ing and theory building, as it allows us to determine
which structural properties of the model (e.g. con­
nectivity or directionality) can be substantiated by
data and which serve merely for representational con­
venience. The canonical representations presented
in this paper offer an efficient solution to this prob­
lem since they can be constructed (from the causal
models) in polynomial time. They can also be used
to solve the broader problem of model subsumption
[Verma 90).
The construction of these canonical representations
is based on (conditional) independence relationships,
thus suggesting the possibility of extracting causal
models directly from statistical information. Such
application meets with the difficulty that, in general,
probability distributions do not define unique graph­
ical models. In other words, given that the data is
generated by some causal theory T =< D, e >, it
is always possible to contrive the parameters e to
yield spurious independencies, not shown in D, that
fit another theory T' =< D', e' >, with D' not equiv­
alent to D. [Spirtes et al 90) show that, under some
reasonable assumptions, the occurrence of such spu­
rious independencies is a rare event of measure zero,
and therefore argue that it is natural in causal mod­
eling to assume that the underlying distribution is
dag-isomorphic 4, albeit allowing for the inclusion of
unobserved variables.

I

covery algorithm is proposed in [Spirtes et al 90] and
several alternatives are discussed in the sequel.
The basic algorithm has three parts; the first part
is an application of Lemma 1 that identifies the links
of the pattern. The second part of the algorithm is
an application of Lemma 2 which adds directionality
to some of the links, thus forming the rudimentary
pattern. The final part of the algorithm consists of
completing the rudimentary pattern into a full pat­
tern (if desired).

Recovery Algorithm
1. For each pair of variables

arating set

Sab.

a

and

(i.e. such that

If there is no such

Sab.

b, search for a sep­
I( a, Sab, b) holds.

place an undirected link

between the variables.
2. For each pair of non-adjacent variables

with a common neighbor

I(a, cSab, b).

c,

a

and

b

test the statement

If the statement holds then continue.
If the statement is false, add arrowheads at

a-c-b).

c,

(i.e.

3. Complete the pattern.

The complexity of this algorithm is bounded by
the first step, which by brute force would require
an exponential search for the set Sab· It can be
greatly reduced by the generation of a Markov net­
work. A Markov network is the undirected graph
formed by linking every pair of variables a and b
that are dependent given the rest of the variables
(i.e. -.I(a, U- ab, b)). The Markov network of a
dag-isomorphic distribution has the property that the
parents of any variable in the dag form a clique in the
network. Since Lemma 1 states that any two vari­
ables a and b are separable if and only if they are
separated by their parent set Pab, the search for a
separating set can be confined to the cliques that con­
tain either a or b. Thus, the complexity is bounded,
exponentially, by the size of the largest clique in the
Markov network, and this coincides with the theoret­
ical lower bound for recovery of a dag from indepen­
dence information [Verma 90].

Under the assumption that the observed distribu­
tion is dag isomorphic, Theorem 1 pe!:'mits the recov­
One drawback of the Markov network reduction is
ery of the underlying structure uniquely, modulo the that it is not applicable to embedded causal models
equivalence class defined by its pattern. One such re- because it rests on part (4) of Lemma 1; no parallel
lemma exists for embedded models. However, the
• A probabilistic distribution is dag-isomorphic permitting
all its dependencies and independencies to be displayed in some basic algorithm stated above, by virtue of resting on
dag
Theorem 2 can be used to recover embedded causal

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

226

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

model as well. The only difference is in the output;
when the algorithm is applied to a dag isomorphic
distribution, every link is guaranteed to be assigned
at most one arrowhead (a particular arrowhead may
actually be assigned multiple times, but no link will
receive an arrowhead on both ends). However, when
the distribution is isomorphic to an embedded dag it
is possible for a link to be assigned an arrowhead on
both ends, hence the recovery of a bi-directional link.

[Spirtes et al 90] have proposed an algorithm for
identifying causal relationships which accepts many,
but not all, of the genuine and potential causes in
distributions that are isomorphic to embedded dags.
The relationships identified by [Spirtes et al 90] cor­
respond to the singly directed arrows of the rudimen­
tary pattern.
In practice, every recovery algorithm must face
the problem of inferring independence relations from
sampled data. The number of samples required to
reliably test the assertion I(a, Sab• b) grows exponen­
tia11y with the size of Sah· A reasonable approximat­
ing algorithm for recovering a dag (or embedded dag)
could be devised based upon the following redefinition
of the independence relation:

The invariant nature of the arrows in a pattern
can form the basis for a general non-temporal defini­
tion of causation; one that determines the direction of
causal influences from statistical data without resort­
ing to chronological information, and one that applies
to general distributions, including those that are not
isomorphic to embedded dags. The essence of this
definition can be articulated by taking as models of
our theory the set 'P of all patterns that are consis­ Definition 4 (Reliable Independence)
tent with, an observed distribution, namely, patterns I(a, S, b) holds reliably whenever the set of hypotheses
that are minimal I-maps of the distribution.
{P(a!S) = P(a!Sb)} is confirmed for each instanti­

Definition 3 (Genuine and Potential Cause) c
is a genuine cause of e if c causes e in every con­

S

ation of
for which a sufficient number of samples
are available to reliably test the hypothesis.

sistent model (i.e. every pattern of 'P contains the
directed arrow c -+ e). c is a potential cause of e if This notion of reliable independence is captured by
c causes e in some consistent model (i.e. some pat­ taking as a measure of dependency the (conditional)
tern of 'P contains c -+ e) and e never causes c in sample cross entrophy [Pearl 88, page 392):
any consistent model (i.e. no pattern of 'P contains
c-e).

ii(a biS) �r

'\:""'

P(a, �IS)
g P(aiS)P(biS)

P(a b S) lo

•

The vertical arrow in Figure 2 (e) is an example of
'
L...J
' '
a,b,S
a genuine cause, since this arrow cannot be emulated
by a hidden common cause of the two end points (in
any consistent embedded model). The other arrows
where P stands for the sample frequency and the
in Figure 2 (e) represent potential causes when viewed
summation ranges over all instantiations of a, b and
in the context of embedded models, because each can
S. We see that terms involving small samples (i e.,
be represented by a common hidden cause in some
low values of P(a, b, S)) are automatically discounted
equivalent causal model.
relative to those of larger samples.
Since the number of patterns over lU I variables is
One issue that has not been addressed is that of
finite, Definition 3 is operational. However, the exis­
deterministic nodes, such as those representing func­
tence of an effective algorithm which can determine
tional dependencies among variables. These nodes
causation by means other than enumerating the pat­
cannot be completely represented by the causal mod­
terns of 'P is an open question. If the observed dis­ els
considered in this paper, as they require a refine­
tribution is isomorphic to an embedded dag, then 'P
ment of d-separation studied in [Geiger et al 89] and
contains only one unique pattern; that which is gen­
[Pearl et al 89]. The issues introduced by determin­
erated by the recovery algorithm. This pattern con­
istic nodes are discussed in [Verma 90].
tains all the information required for identifying the
genuine and potential causes [Verma 90]. However, Acknowledgement
.

when applied to general distributions the arrows as­
signed in the generated pattern may or may not co­

The problem of deciding equivalence of embedded
incide with the model-theoretic definition of genuine causal models was posed by Clark Glymour and com­
and potential causes.
municated to us by Dan Geiger.

227

References
[Blalock 71] H.M. Blalock, Causal Models in The So­
cial Sciences. Macmillian, London, 1971.

[Pearl and Verma 87] J. Pearl and T.S. Verma, The
Logic of Representing Dependencies by Directed
Graphs, Proceedings, AAAI Conference, Seattle,
WA. July, 1987, pp. 374-379.

[Duncan 75] O.D. Duncan, Introduction to Structural [Shachter 85] R.D. Shachter, Evaluating Influence
Diagrams, in A.P. Basu (Eds), Reliability and
Equation Models. Academic Press, New York,
Quality Control, Elsevier, 1985, pp. 321-344.
1975.
[Geiger and Pearl 89] D. Geiger and J. Pearl, Logical [Spirtes et al 90] P. Spirtes, C. Glymour and R.
Scheines, Causality from Probability, in G. Mc­
and Algorithmic Properties oflndependence and
Kee, ed., Evolving Knowledge in Natural and Ar­
Their Application to Bayesian Networks, UCLA
tificial Intelligence, Pitman, 1990.
Cognitive Systems Laboratory, Technical Report
CSD-890035 {R-123}, February 1989. To appear
[Smith 89] J .Q. Smith, Influence Diagrams for Sta­
in Annals of Mathematics and AI, Special Issue
tistical Modeling, The Annals of Statistics, Vol.
on Statistics and AI.
17(2):654-672, 1 989.
[Geiger et al 89] D. Geiger, T.S. Verma and J. Pearl,
[Verma 90] T.S. Verma, Invariant Properties of
d-Separation: From Theorems to Algorithms,
Causal Models. In preparation.
Proceedings, 5th Workshop on Uncertainty in
AI, Windsor, Ontario, Canada, August 1989, pp. [Verma and Pearl 90] T.S. Verma and J. Pearl,
118-124.
Causal Networks: Semantics and Expressive­
ness, UCLA Cognitive Systems Laboratory,
[Geiger and Verma 90] D. Geiger and T.S. Verma,
Technical Report 870032 {R-65), June 1986. Also
Identifying Independence in Bayesian Networks,
in Uncertainty in AI 4, R. Shachter, T.S. Levitt
UCLA Cognitive Systems Laboratory, Technical
and L.N. Kana! (eds), Elsevier Science Publish­
Report CSD-890028 {R-116}, To appear in Net­
ers, 1990.
works, John Wiley and Sons, Sussex, England,
1990.
[Wright 34] S. Wright, The Method of Path Coeffi­
cients. Ann. Math. Statistics 5:161-215, 1934.
[Glymour et al 1987] C. Glymour, R. Scheines, P.
Spirtes and K. Kelly. Discovering causal struc­
ture. Academic Press, New York, 1987.
[Howard and Matheson 81] R.A. Howard and J.E.
Matheson, Influence Diagrams, chapter 8, in The
Principles and Applications of Decision Analy­
sis, Vol. II, Strategic Decisions Group, Menlo
Park, California, 1981.
[Olmsted 84] S.M. Olmsted, On Representing and
Solving Decision Problems, Ph.D. Thesis,
Engineering-Economic Systems Dept., Stanford
University, Stanford California, 1984.
[Pearl et al 89] J. Pearl, D. Geiger and T.S. Verma,
The Logic of Influence Diagrams, in R.M. Oliver
and J.Q. Smith (Eds), Influence Diagrams, Be­
lief Networks and Decision Analysis, John Wiley
and Sons, Ltd., Sussex, England 1990. A shorter
version, in Kybernetica, Vol. 25:2, 1989, pp. 3344.
[Pearl 88] J. Pearl, Probabilistic Reasoning in Intel­
ligent Systems: Networks of Plausible Inference.
Morgan Kaufmann Publishers, Inc, San Mateo,
California, 1988.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

