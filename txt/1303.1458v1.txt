40

Provan

TRADEOFFS IN CONSTRUCTING AND EVALUATING TEMPORAL
INFLUENCE DIAGRAMS

Gregory M. Provan*

Computer and Information Science Department
University of Pennsylvania
301C 3401 Walnut St. Philadelphia PA 19104-6228

Abstract

This paper addresses the tradeoff's which
need to be considered in reasoning using
probabilistic network representations, such as
Influence Diagrams (IDs). In particular, we
examine the tradeoff's entailed in using Tem­
poral Influence Diagrams (TIDs) which ad­
equately capture the temporal evolution of
a dynamic system without prohibitive data
and computational requirements. Three ap­
proaches for TID construction which make
different tradeoff's are examined: (1) tailor­
ing the network at each time interval to the
data available (rather then just copying the
original Bayes Network for all time intervals);
(2) modeling the evolution of a parsimonious
subset of variables (rather than all variables);
and (3) model selection approaches, which
seek to minimize some measure of the predic­
tive accuracy of the model without introduc­
ing too many parameters, which might cause
"overfitting" of the model. Methods of evalu­
ating the accuracy /efficiency of the tradeoff's
are proposed.
1

INTRODUCTION

This paper examines tradeoff's which need to be con­
sidered for reasoning with Probabilistic Networks such
as Influence Diagrams (IDs) [16, 26]. For large net­
works, both data acquisition and network evaluation
are expensive processes, and some means of controlling
network size is often necessary. In particular, model­
ing time-varying systems with Temporal Influence Di­
agrams (TIDs) or Temporal Bayes Networks (TBNs)
often requires large networks, especially if several time
slices are modeled. We examine three methods of lim­
iting network size, and examine the tradeoff's entailed
in each of these methods. Some formal techniques for
characterizing such tradeoff's are introduced.
*This work was supported by NSF grant #IRI92-10030,
and NLM grant #BLR 3 ROl LM05217-02Sl.

The main network type examined, the TBN, has been
used to model a variety of dynamic processes, includ­
ing applications for planning and control [11, 12] and
medicine (e.g. [2], VPnet [10], and ABDO [24]). In
such applications, the static system structure is mod­
eled using a Bayes Network (BN) or influence diagram
(ID), and the temporal evolution of the system is mod­
eled using a time series process, connecting nodes in
the BN over different time intervals using "temporal
arcs". In other words, if BN1, BN2, ... BNk are a tem­
poral sequence of Bayesian networks (called a tempo­
ral BN or TBN), these systems address a method of
defining the interconnections among these temporally­
indexed BNs. The sequence of Bayesian networks
(which evolve according to the stochastic dynamic pro­
cess) together with a corresponding sequence of man­
agement decisions and values derived from the deci­
sions defines the temporal influence diagram.
In almost all of these approaches, a Markov assump­
tion is made, due primarily to the entailed well-known
theoretical properties and relative computational fea­
sibility. However, this simple form of temporal de­
pendence is violated by many real-world processes.
Higher-order Markov processes can be embedded in
the TBN or TID to capture longer-term stochastic pro­
cesses, but at the expense of adding more temporal
arcs, thereby increasing data requirements and com­
putational demands of network evaluation. 1 Similarly,
other temporal processes, such as dynamic linear mod­
els (DLM) [29], can be embedded into temporal BNs
or IDs [9, 10, 18].
Some difficulties which arise in large, complicated do­
mains, (e.g. for domains in which large TIDs are con­
structed [9, 17, 18, 24]), include:
•

Given that exact network evaluation is NP-hard
[6], and the approximation task is also NP-hard
[8], limiting the size of networks is often the only
way to ensure computational feasibility. Hence,
during model construction, one needs to trade off

1 Modeling time-series processes other then first-order
Markov processes can be computationally infeasible for
large systems [23].

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

•

•

a utility-maximizing model for parsimony (and
computational feasibility).
It is difficult to evaluate time-series processes for
models which contain many variables. In addi­
tion, the data collection/storage requirements for
large models can be prohibitive.
Due to certain conditional dependencies among
variables, it may make more sense to model the
temporal evolution of only the subset of variables
which are in fact evolving, and use these processes
to drive the changes in the dependent variables.

This paper addresses the tradeoff's inherent in con­
structing TIDs which adequately capture the tempo­
ral evolution of the system without prohibitive data
and computational requirements. Three approaches
for TID construction which make different tradeoff's
are introduced: (1) knowledge-base construction ap­
proaches, which tailor the network at each time inter­
val to the data available (rather then just copying the
original Bayes Network for all time intervals) [23]; (2)
domain-specific time-series approaches, which model
the evolution of a parsimonious subset of variables
(rather than all variables); and (3) model selection ap­
proaches, which seek to minimize some measure of the
predictive accuracy of the model without introducing
too many parameters, which might cause "overfitting"
of the model. The second and third approaches are the
main contribution of this paper: the second approach
is a new analysis of TIDs, and the third approach is
the first application tb probabilistic networks of trad­
ing predictive accuracy for model parsimony.
The tradeoff's made by these parsimonious approaches
are quantified using various methods, and illustrated
using a medical diagnosis example. In addition, some
Bayesian approaches to model selection are also exam­
ined.
2

TEMPORAL BAYESIAN
NETWORKS

2.1

Static Model Structure

We characterize a BN or TID model M using the pair
(9, 9), where 9 refers to the graphical structure of the
model and IJ refers to the set of parameters associated
with 9, such as conditional probability distributions
assigned to arcs in g.
The qualitative structure Q(V, A) consists of a directed
acyclic graph (DAG) of vertices V and arcs A, where
A � V X V. Each vertex corresponds to a discrete
random variable t/J with finite domain O.p. Arcs in the
BN represent the dependence relationships among the
variables. Arcs into chance nodes represent probabilis­
tic dependence and are called conditioning arcs. The
absence of an arc from node i to j indicates that the
associated variable t/Ji is conditionally independent of
variable t/Ji given t/Ji 's direct predecessors in the DAG

41

Q(V,A).
For a static model (i.e. a single time slice) the quanti­
tative parameter set IJ consists of the conditional prob­
ability distributions necessary to define the joint dis­
tribution P('rh, t/12, ... , '1/Jn)· The required distributions
are given by P(t/J) for every node t/J with no incoming
arcs, and by the P(t/Ji 1'1/Ji) for the nodes t/Ji, t/Ji joined
by an arc in the DAG. Note that the structure g unam­
biguously defines the parameter set 8 which is neces­
sary to specify the joint distribution P(t/11 , t/12, .. . , t/Jn),
and the structure g of a BN is implicit in the para­
metric description.
2.2

Example: Acute Abdominal Pain Model

Provan and Clarke (24, 23] have developed an ID model
for the diagnosis and treatment of acute abdominal
pain (AAP). A common cause of acute abdominal pain
is appendicitis, and in many cases a clear diagnosis
of appendicitis is difficult, since other diseases such
as Non-Specific Abdominal Pain (NSAP) can present
similar signs and symptoms (findings).
Figure 1: Influence diagram for diagnosis and treat­
ment of acute abdominal pain

In this model, a BN models the physiology of the
system, and decision and value nodes represent the
actions taken and corresponding utilities of such ac­
tions respectively. Figure 1 presents an example of
the type of network created for the diagnosis of AAP
for a single time slice. In this figure, chance, deci­
sion and value nodes are represented diagrammati­
cally by ovals, rectangles and diamonds respectively.
For example, the chance node for Inflammation (In­
fiamm) is conditionally dependent on the chance nodes
for Perforated-Appendix (Perf-App) and Appendicial­
Obstruction (A-Obs). Some possible diseases studied
in the model are Appendicitis (App) and NSAP. In
this single time-slice ID there is one decision node d
and one value node V. The shaded nodes in this di­
agram represent observable variables X, e.g. Absent
Bowel Sounds (ABS), Right-Lower-Quadrant Tender­
ness (RLQ-T), Nausea (N), Vomiting (V), etc.
2.3

Dynamic Model Structure

A temporal BN (or ID) consists of a sequence of BNs
(IDs) indexed by time, e.g. 90, 91> ... , 9t, such that

42

Provan

temporal arcs connect gi with gi, with the direction
of the arcs going from ito j if i < j.2 A temporal arc
Ar(t) connecting networks for time slices t- 1 and t
is a subset of the inter-network edge set Ain t(t), given
by

Figure 2: TID for patient X over 2 time intervals, with
new findings of anorexia (A) and muscular guarding
(G) in the second time interval, as shown by shaded
n des
. . .. . .

.. .. .. .... . .....

{(a, ,B) Ia E V(t- 1), ,8 E V(t),
(a, ,8) E V(t- 1) x V(t)}.

Inter-lemp<lral arc

If we index the BN by time, i.e. gt = (V(t), A(t)),
then the full temporal network over N time slices
(which may be intervals or points), is given by gN =
(VN , AN ) , where
N

U V(t),

vN

AN

t=O

=

N

U A(t)

t=O

lntra·temporal arc

and
u

N

U Ar(t).

t=l

Each temporal arc connects a pair of vertices
The temporal node set connected over time slices t- 1
and t is given by

VP(t) = {Vi(t- 1) u Vj(t)IAr(t)
2.4

c

Vi(t- 1)

X

vj(t)}.

Example: Temporal Model for Diagnosis

Temporal reasoning for AAP is important due to the
difficulty of diagnosis and treatment based on data
from just a single time slice. Appendicitis progresses
over a course of hours to days, and one might be
tempted to wait until the complex of signs and symp­
toms is highly characteristic of appendicitis before re­
moving the appendix. However, the inflamed appendix
may perforate during the observation period, causing a
more generalized infection and raising the risk of death
from about 1 in 200 cases to about 1 in 42 [21]. Thus,
the tradeoff is between the possibility of an unneces­
sary operation on someone whose findings are simi­
lar to early appendicitis and a perforation in someone
whose appendicitis is allowed to progress.
Given that data over time can greatly simplify the di­
agnostic process, a TID is used for this domain. As
an example, consider a simple situation in which 2
temporal intervals are modeled for the AAP domain
as shown in Figure 2. Dashed lines indicate the arcs
joining nodes from two different time slices.
2.5

Parametric Specification

The probability distributions to be specified for a TID
can be classified into two types: (1) time-series process
distributions for temporal arcs Ain t(t) ; and (2) distri­
butions for the network for each time slice, g1, g2, ....
For example if Figure 2 represents graphs for two time
2This notation is adapted from [18).

slices, g1 and g2, then a sample of temporal arc distri­
butions includes: P(V(2)IV(1)), P(RLQ(2)IRLQ(1)),
P(ABS(2)IABD(1)), P(App(2)1App(1)), P(Perf­
App(2)1Perf- App(1)), etc. A sample of distribu­
tions within a single time slice includes: P(V(1)1
lnflamm(1)), P(RLQ(1)1Inflamm(1)), P(ABS(1)1
P(App(2)1App(1)), P(Inflamm(1)1
Perit(1)),
NSAP(1)).
3

TID CONSTRUCTION FROM
KNOWLEDGE BASES

TIDs (or TBNs) are typically constructed (e.g. [11])
by replicating the ID for the initial time slice over the
succeeding N- 1 time slices (i.e. gi, i = 0, 1, ... , N are
all the same), and then joining the networks over suc­
cessive time slices using a Markov assumption. This
approach is relatively inflexible, as it does not allow
the network to be altered over time. In addition, if
the network's size changes over time, many redundant
variables will be present as the stati<> network is repli­
cated for future time slices, since the first network will
need to incorporate all potentially relevant structure
over future time slices.
A recent approach to reduce (static) Bayes network
complexity, tailoring networks to data [15, 28], of­
fers the potential to improve network evaluation costs
for such networks. This approach entails construct­
ing a knowledge base (KB) for the domain in ques­
tion. Given a particular set 0 of observations, this
approach does not construct a network corresponding
to the entire KB, but instead tailors a model to the
observations 0 from the KB.
This approach has been extended to the construction

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

of TIDs in [24], where a first-order Markov assumption
was made in defining the temporal arcs Ar(t). For
example, Figure 2 represents a TID for two time slices.
Note that even though the KB for the acute abdominal
pain domain covers over 50 findings, 20 intermediate
disease states and 4 diseases [24], the network !h for
the first time slice is significantly simpler, and covers
only 7 findings, 4 intermediate disease states and 2
diseases.3 Evaluating this smaller network can be done
much more efficiently. Note also that this approach
can model how the findings change over time during
the evolution of the underlying disease by altering the
Q;'s over time. For example, in Figure 2, the network
!h for the second time slice introduces variables not
contained in �h, representing findings present in time
slice 2 but absent in time slice 1.
·

For complex domains like the diagnosis of AAP, the re­
duction in network size afforded by the automatic net­
work construction approach improves computational
efficiency, but not enough to allow modeling complex
time-series processes like higher-order Markov pro­
cesses. Some other techniques, such as the one dis­
cussed below, are also necessary.
4

DOMAIN-SPECIFIC
TIME-SERIES MODELS

In this section we propose two new domain-specific
heuristics for cases in which even tailoring the net­
work to the observations does not produce an easily­
evaluated BN or ID. For TIDs, a promising heuristic
is to model the temporal evolution of only a subset
of variables. Two different models for which variables
should evolve are possible: "driving" variables or ob­
servable variables. These are discussed below.
4.1

Parsimonious Modeling of System
Temporal Evolution

Driving Variables: This approach entails a domain­
dependent identification of the system variables which
are actually evolving, driving changes in other system
variables. To this effect, we partition the system vari­
ables tjJ into a set V of dynamic or evolving variables
and a set S of variables ,which are either constant or
whose changes are due to some x E V. For complete­
ness, we assume a set 'Y of variables which are inde­
pendent of the variables x E V. Under this partition,
we have t/J = V U S U 'Y.

Using this partition, an appropriate stochastic process
is associated with each x E V. In a TID, this is repre­
sented by .an appropriate set of temporal arcs for each
such stochastic process.
This partition should be made to trade off model ac­
curacy for computational efficiency. In some domains,
3 A network like this is constructed for a particular case
in which 7 findings are presented.

43

there may be techniques to govern which variables may
be modeled as static, and which must be dynamic.
In other domains, in order to make the appropriate
tradeoffs, heuristics must be used. Section 5 presents
some ways to formally evaluate the tradeoffs which are
made.
Observed Variables: This approach seeks to model
the observables (findings) X which are the evidence of
the internal evolution of the system. Typically, when
one is monitoring the system, there exists data (over
time) for these variables. However, if these variables
are not the ones that are driving the process under
study, then one is estimating the values of the driving
variables V from the observables, using the model to
relate the two classes of variables.

We now present an example of the modeling of acute
abdominal pain to demonstrate this temporal arc se­
lection process.
4.2

Example: Acute Abdominal Pain Model

The AAP model has three variable types: observ­
able, intermediate (latent) and disease variables, de­
noted X, V, W respectively. The current method for
modeling AAP over time is to use a TID in which a
semi-Markov process governs the evolution of all sys­
tem variables [23].4 This entails defining a large num­
ber of temporal arcs. Figure 2 shows a simple situa­
tion in which 2 temporal intervals are modeled. For
just a first-order Markov assumption, the large num­
ber of temporal arcs in Figure 2 is immediately obvi­
ous. Model evaluation is consequently very expensive.
More importantly, the true temporal processes for
this domain are not adequately captured by this first­
order Markov assumption [22]. Hence, a higher-order
Markov model is required to capture this more com­
plex system evolution. However, this should be em­
bedded without introducing significantly more tempo­
ral arcs (with their entailed data and computational­
resource requirements).
One solution is to model the evolution of a subset of
the variables. Two approaches to developing a model
in which only a subset of the variables evolve over time
include:
Driving Variables: This approach models the un­
derlying physiology which is driving the evolution of
the system. Consider the set of causal relationships:
App --+ A-Obs--+ Inflamm--+ V.
If we assume that once a case of appendicitis is initi­
ated by an appendicial obstruction (A-Obs), and that
the obstruction does not change, then the only vari­
able which changes is the inflammation. Vomiting (V)
changes in response to the degree of inflammation.

4In this semi-Markov model, data is available to es­
timate transition distributions for the findings variables,
and transition distributions are estimated based on expert
opinion for the remaining variables. Dr. J.R. Clarke is the
surgeon providing the expert opinion.

44

Provan

A similar analysis can be done to identify the set of
variables 'D which drive the system evolution. This
partitions the variables into static S and dynamic 'D
variables: tf;(t) = S U 'D(t). The set V(t) consists of
latent variables, as shown in Figure 3. The findings,

Figure 4: Reduced version TID for patient X over
2 time intervals with temporal arcs for both findings
(observable variables) and latent variables

•

··················

lnter-tomporol..

Figure 3: Reduced version TID for patient X over 2
time intervals, with just disease and latent variables
evolving temporally

lnln-tomporolac

....................

1--lomporot ..

lnln-tomporot ..

5

MODEL SELECTION
APPROACHES

5.1

which also change over time, are conditionally depen­
dent on the x E 'D(t), and are an observable reflection
of the internal physiological changes over time.
The drawback to this approach is that 'D(t) consists
of latent variables, for many of which detailed tem­
poral physiological models do not exist. For example,
insufficient information about the progressive inflam­
mation of the appendix is known to create a parame­
terized model, nor can direct measures of the degree
of inflammation be made, except possibly using white
blood count (WBC); instead, this process is typically
inferred from the findings which accompany it.
Observable variables: This approach models the
observables (findings) X which are the evidence of the
internal evolution of the system. A large body of data
exists for these variables (24], as data collection is sim­
plest for these variables. An example of such a network
is shown in Figure 4.

The drawback to this approach is that the observables
X(t) may not necessarily predict the underlying dis­
eases W(t) as reliably as the latent variables V(t), if the
latent variables V(t) are assumed to be static.5 A sec­
ond drawback is that there are relatively more observ­
able than finding variables, so this approach is more
computationally expensive than using latent variables
alone.
5 A more accurate model might include both latent and
finding variables as dynamic variables.

Specifying Tradeoffs

If the topology and probabilities of the TID are
changed, then some measure of how the changes affect
the predictive accuracy of the output, or of the "qual­
ity" of the decision-making provided by the network,
needs to be computed. In this analysis, we assume
that there is some utility function which is used as a
measure the network "accuracy" or "decision quality"
for different models. 6
The effectiveness of any decision rule is measured us­
ing a loss function L(8, 8). This is interpreted as mea­
suring the loss L( 8, 8) associated with taking action 8
when the world state is parameterized by 8. Given a
prior probability estimate 1r(8) of the world state 8,
the risk function provides a measure of the expected
loss under varying values of the observable variables
X, and is given by R(8, 8) = E�[L(8, 8(X)).
The Bayes risk of a decision rule 8, with respect to a
prior distribution 11' on the entire parameter space e,
is defined as r(1r, 8) = E.,.-[R( 8, 8)]. This averages over
the risk functions given all priors that can be assigned
to 8.
A decision rule 81 is preferred to a rule 82 if
r(1r, 81) < r(1r, 82). A Bayes rule is a decision rule
which minimizes r(1r, 8), and is thus optimal.
This paper proposes a variety of techniques for ana6We use a loss function, to maintain consistency with
much of the decision theory literature (e.g. [3]); utility and
loss, for the purposes of this paper, are duals to each other.
Hence, one seeks either to maximize the expected utility,
or minimize the expected loss.

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

lyzing the tradeoffs made during model selection, in­
cluding risk-based as well as purely probabilistic cri­
teria. Although a utility measure is desired, proba­
bilistic criteria can be used in a variety of situations
(e.g. [4, 27]). Many probabilistic criteria are simpler
to compute, and do not require a prior distribution
11"(8).
For example, in the medical example described earlier,
the utility function measures the utility of the treat­
ment given what disease is actually present. Thus an
unnecessary appendectomy will have low utility, and a
necessary appendectomy will have relatively high util­
ity. So if the loss L(8,, 61) associated with decision 61
under parameter set 8, is less than that under model
82, i.e. L(81, 61) < L(82, 61), this means that model
81 allows you to provide better treatment under the
same decision rule 61 than 9 • For the purposes of
2
medical treatment one needs to determine if the dif­
ference is significant.
In addition to the loss function, one may want to trade
off decreased model utility for increased computational
efficiency. The model parameter penalty g(1) to be in­
troduced in equation 1 can be used to provide a mea­
sure of computational expense based on the number of
model parameters. Alternatively, one can incorporate
into the loss function a computation penalty function
��: (8), which measures the computational resources nec­
essary to evaluate a model with parameters denoted by
8.
5.2

the quality of the model for prediction. The selection
procedure criteria can be defined using the following
equation:
(1)
1(8,/) = !(8,/) + g('Y),
where f(8, 1) is a measure of predictive error, and
g('Y) is a penalty for the number of model parame­
ters. One widely-studied approach is to choose some
In E f that jointly minimizes the sum of predictive
error8 and parametric penalty, setting the predictive
error measure to be the sum of squared error (SSE)
[13]:
arg min[SSE-y + l1lu2II],
(2)
-rer
where II � 0 is a pre-specified constant, Ill is the num­
ber of nonzero components o£1, and SSE= 18-r -8J2.
In the right-hand-side of equation 2, the first term de­
notes the predictive error, and the second term is a
penalty function on the number of parameters in the
model. Hence this equation can capture a wide vari­
eties of approaches which trade off predictive accuracy
and model size. For example, for known u2, the Akaike
Information Criterion (AIC) [1] is the special case of
In when II = 2, and the BIC approach [25] is the
special case of In when II = /ogn. A third approach,
called the risk inflation (RI) approach [13], is defined
with respect to a "correct" model parameter set 1*
(e.g. as determined by an oracle). The risk inflation
measure RI('Y), is
In =

Rl('Y)

Statistical-E�timation Model Selection
Approaches

Consider the case where there are p total observable
parameters (predictors) {fh, 82, •.• , Bp}, of which some
subset q < p is to be selected to estimate a latent
variable y. Possible measures of predictive accuracy
based on a parameter estimate 8 are:
Sum of Squared Error (SSE)
Log likelihood
Predictive Risk

18- 812
log(8- 8)
E8 18- 812

Corresponding to the p parameters, we introduce a set
of p indicator variables given by 1 = {11 , 12, ... , /p},
where 'i'i is defined as follows:
Is .

_

{ 01

if B; is to be estimated by 0
otherwise.

Definer as the set of all p-tuples 'i'· 1 can be thought of
as an indicator vector denoting which parameters are
considered in a model, and r as the set of all possible
models over 8.
The model-selection procedure then consists of select­
ing some 1 E f and then estimating 8 by 8-y.7 Various
criteria for this process have been used to compute
7Details for computing 0-r are given in [22].

45

=

E l8 - 812
sup 9
,
8 E8J8- 8-r·l2

R(8,8)
R(8, 8-r•)

The selection procedure with smallest risk inflation
will be minimax with respect to the ratio function
RI(1) [13]. The risk inflation criterion calibrates the
risk of a model selection estimator against the risk of
an ideal model selection procedure.
5.3

Bayesian Model Selection Approaches

The Bayesian approach to model selection is based on
computing the posterior probabilities of the alternative
models, given the observations. Two Bayesian analy­
ses of the model selection process applied to BNs have
been published recently. One method focuses on av­
eraging over all possible BN models to select a model
with improved predictive ability [20, 19]. Since the
space of all possible models is potentially enormous,
two approximation techniques are proposed: (1) use
Markov chain Monte Carlo simulation to directly ap­
proximate the model selection process [20]; and (2)
select a subset of the set of all models by excluding
all models which receive less support from the data
then their simpler (in terms of number of parameters)
counterparts [19]. Both studies indicate that model
averaging improves predictive performance.
8 u2 denotes the variance of the random predictive error
in the estimation process.

46

Provan

Given a large model space (as denoted by r), the
model space pruning heuristics proposed in [19] can be
crucial to the model selection process, given no prior
knowledge about alternative models. In contrast, here
we present model selection techniques which are useful
when a small set of alternative models is being consid­
ered (i.e. the entire model spa�e is not considered) .
A second approach examines BN structure purely from
the viewpoint of predictive accuracy [7]. This ap­
proach computes a logarithmic score for alternative
models, ignoring the number of parameters in the
model. Given a discrete random variable y whose value
is to be estimated from a model denoted by the pa­
rameter set 8, the scoring rule used is -logP(yj8).
This approach is thus a restriction of equation 1 to
the case where /(8, 1) = -logP(yj8), and g(l) = 0.
In addition, this selection process is sequential, in
that scores are summed over a set of M cases: if
S m = -logPm(yj8) is the score on the mth case, the
total score for a particular model is given by

as follows. The AIC criterion selected the 1•t-order
Markov model. The BIC and Risk Inflation criteria
selected the observable parameter model. The BIC
with II = 0 criterion selected the 2nd-order Markov
model by a narrow margin over the canonical model;
without a penalty for model size this criterion sug­
gests that a 2nd-order model may actually best fit this
data. In contrast, imposing a penalty for model size on
this BIC test selects a simpler model, indicating that
the cost of adding parameters for the 2nd-order model
outweighs the increased predictive accuracy (given the
chosen penalty II).
Although this analysis is informative, further analysis
is clearly necessary. The selection of the observable
parameter model over the driving parameter model
may be due to the availability of better data for the
observable parameters than the latent parameters. 11
Further, this analysis needs to be done for a large nm�­
ber of cases; however, this pilot study has shown the
promise of these model evaluation criteria.

M

S

=

2: -logPm(YI8).

m=l
This approach allows monitoring of the performance
of models as new data becomes available (by updating
the score S), facilitating model adaptation over time.
Several related scoring rules are also analyzed in [7].
6

EVALUATING TRADEOFFS

We now present results from a simple AAP pilot study
which applies these different model selection criteria
to a set of models. In the following, we assume we
know the true state of the world, as represented by
the canonical model 8"'. The goal is to compare to 8"'
alternative models 8i, i = 1, ... , k, where the models
differ by the time-series process parameters for tem­
poral arcs Aint ( t) .
The BN model analysed is a network consisting of
5 copies of the BN portion of the ID presented in
Figure 1, joined together by temporal arcs based on
four temporal models: (1) 1't-order Markov; ( 2) 2nd_
order Markov; (3) driving parameters; (4) observable
parameters.9 The canonical model was assumed to
be the 18t-order Markov model, even though the long­
term nature of the disease evolution may violate this
1'1-order Markov assumption. This choice was made
because this model has been studied most carefully to
date.
Measures for these models were computed using four
different criteria: (1 ) AIC; (2) BIC; (3) Risk Inflation;
(4) BIC with II= 0. 1 0
Due to space limitations, the full details of this pi­
lot analysis are omitted. A summary of the results is
9Data for this AAP domain was briefly discussed in [24].
10This last criterion is similar to the Bayesian criterion
presented in [7].

7

RELATED LITERATURE

The methods of analyzing networks presented here are
orthogonal to the approach proposed by Goldman and
Breese [14]. Goldman and Breese describe methods
of integrating model construction and evaluation dur­
ing the process of automated network construction.
The main thrust of the work presented here is exam­
ining alternative network structures. However, some
of the model selection criteria examined here can be
used during automated network construction to pro­
vide scoring rules for whether nodes and/or arcs should
be added to a partially-constructed network.
Of the work in temporal probabilistic networks, the
most closely associated work is that of Dagum et al.
[10, 9]. The system proposed in [10] is primarily in­
terested in the statistical process underlying temporal
Bayesian networks. To this end, the paper focuses
on computing inter-temporal conditional dependence
relations; in other words, if BN1, BN2, ... BN1c are a
temporal sequence of Bayesian networks, Dagum et
al. address a method of defining the interconnections
among these temporally-indexed BNs. In [9] an addi­
tive BN approximation model is proposed. Parameter­
estimation is done using the Kullback-Liebler measure,
which is a restriction of Equation 1 to g(1) = 0.
Related issues of tradeoffs in belief network construc­
tion are discussed in [5]. These dynamic network refor­
mulation techniques can be used to identify the opti­
mal resources devoted to network evaluation, and may
help define the computation resource measures intro­
duced in Section 5.1. These techniques may also be
pertinent to facilitating the network construction ap­
proaches discussed here.
11

Many latent parameters are rough subjective esti­
mates. Further data collection and analysis is planned to
rectify this problem.

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

8

CONCLUSIONS

[11] T. Dean and K. Kanazawa. A Model for Reasoning
about Persistence and Causation. Computational In­
telligence, 5(3):142-150, 1989.
[12] T. Dean and M. Wellman. Planning and Control. Mor­
gan Kaufmann, 1992.
[13] E.I. George and D.P. Foster. The Risk Inflation Cri­
terion for Multiple Regression. Technical Report 95,
University of Chicago, Graduate School of Business,
1992.
[14] R. Goldman and J. Breese. Integrating Model Con­
struction and Evaluation. In Proc. Con/. Uncertainty
in Artificial Intelligence, 1992.
[15] H. Keshavan (guest editor). PAMI special issue on
Model Construction from Databases. IEEE Transac­

This paper has proposed several approaches for con­
structing parsimonious TIDs for systems which evolve
over time, where the state of the system during any
time interval is modeled using a Bayesian network.
Possible approaches to modeling the dynamic struc­
ture of the system have been examined, and the trade­
offs entailed in adopting particular approaches quan­
tified using a variety of metrics. As an example, these
techniques are applied to the medical management of
acute abdominal pain.
In addition, this paper has proposed methods for se­
lecting models with better predictive accuracy, and for
trading off predictive accuracy for simpler models. Es­
pecially for complex domains such as temporal reason­
ing, limiting network size without compromising pre­
dictive accuracy too much can play an important role
in ensuring computational tractability.

tions on Pattern Analysis and Machine Intelligence,

[16]

[17]

Dr. J.R. Clarke provided the
medical expertise necessary for this research. Selecting
a parsimonious subset of parameters for time series
modeling was suggested to me by G. Rutledge. This
work has also been influenced by discussions with D.
Foster and M. Mintz, and by the anonymous referees.
Acknowledgements:

[18]

[19]

References

[1] H. Akaike. A New Look at the Statistical Model Iden­
tification. IEEE Trans. Automatic Control, 19:716723, 1974.
[2] S. Andreassen, R. Hovorka, J. Benn, K. Olesen, and
E. Carson. A Model-Based Approach to Insulin Ad­
justment. In Proc. Con/. on AI in Medicine, pages
239-248. Springer-Verlag, 1991.
[3] J.O. Berger. Statistical Decision Theory. Springer
Verlag, 1985.
[4] J.M. Bernardo. Expected Information as Expected
Utility. Annals of Statistics, 7:686-690, 1979.
[5] J. Breese and E. Horvitz. Ideal Reformulation of Be­
lief Networks. In Proc. Con/. Uncertainty in Artificial
Intelligence, pages 64-72, 1990.
[6] G.F. Cooper. The Computational Complexity of
Probabilistic-Inference Using -Belief--Networks, Arti­
ficial Intelligence, 42:393-405, 1990.
[7] R. Cowell, A. Dawid, �nd D. Spiegelhalter. Sequen­
tial Model Criticism in Probabilistic Expert Systems.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 15(3):209-219, 1993.

[8] P. Dagum and M. Luby. Approximating Probabilistic
Inference in Belief Networks is NP-hard. Artificial
Intelligence, to appear, to appear.
[9] P. Dagum, R. Shachter, and L. Fagan. Dynamic Net­
work Models for Forecasting. In Proc. Con/. Uncer­
tainty in Artificial Intelligence, 1992.
[10] P. Dagum, R. Shachter, and L. Fagan. Modeling Time
in Belief Networks. Technical Report STAN-KSL-9149, Stanford University, Knowledge Systems Labora­
tory, November 1991.

47

·

[20]
[21]

15, March 1993.
R.A. Howard and J.E. Matheson. Influence diagrams.
In R. Howard and J. Matheson, editors, The Princi­
ples and Applications of Decision Analysis, pages 720762. Strategic Decisions Group, CA, 1981.
K. Kanazawa. Logic and Time Nets for Probabilistic
Inference. In Proc. AAAI, 1991.
Uffe Kjrerulff. A computational scheme for reason­
ing in dynamic probabilistic- networks. In Proc. Con/.
Uncertainty in Artificial Intelligence, pages 121-129.
Morgan Kaufmann Publishers, San Mateo, California,
1992.
D Madigan, A. Raftery, J. York, J. Bradshaw, and
R. Almond. Strategies for Graphical Model Selection.
In Proc. Con/. Uncertainty in Artificial Intelligence,
pages 331-336, 1993.
D Madigan and J. York. Bayesian Graphical Models
for Discrete Data. submitted,1992.
H.I. Pass and J.D. Hardy. The appendix. In Hardy's
Textbook of Surgery, pages 574-581. J.B. Lippincott
Co., 2nd edition, Philadelphia, 1988.

[22] G. Provan. Tradeoffs in Constructing and Evaluating
Probabilistic Networks. 1993, in preparation.
[23] G.M. Provan. Model Selection for Diagnosis and
Treatment using Temporal Influence Diagrams. In
Proc. International Workshop on AI and Statistics,

pages 469-480, January 1993.
[24] G.M. Provan and J.R. Clarke. Dynamic Network Con­
struction and Updating Techniques for the Diagnosis
of Acute Abdominal Pain.1EEE_Transactions on Pat­
tern Analysis and Machine Intelligence, 15, (to ap­
pear) March 1993.
[25] G. Schwarz. Estimating the Dimension of a Model.
Annals of Statistics, 6(2):461-464, 1978.
[26] R. Shachter. Evaluating Influence Diagrams. Opera­
tions Research, 34:871-882, 1986.
[27] S. Sherman. Non-mean-square Error Criteria. IRE
Trans. Inform. Theory, IT-4 (3):125-126, 1958.
[28] M. Wellman, J. Breese, and R. Goldman. From
Knowledge Bases to Decision Models. Knowledge En­
gineering Review, 7(1 ), 1992.
[29] M. West and J. Harrison. Bayesian Forecasting and
Dynamic Models. Springer-Verlag, NY, 1989.

