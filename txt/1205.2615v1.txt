514

SHPITSER & PEARL

UAI 2009

Effects of Treatment on the Treated: Identification and
Generalization

Ilya Shpitser
Department of Epidemiology
Harvard School of Public Health
ishpitse@hsph.harvard.edu

1

Judea Pearl
Department of Computer Science
University of California, Los Angeles
judea@cs.ucla.edu

Abstract

differently to a reduced dosage x than a randomly selected patient would.

Many applications of causal analysis call for
assessing, retrospectively, the effect of withholding an action that has in fact been implemented. This counterfactual quantity,
sometimes called “effect of treatment on the
treated,” (ETT) have been used to to evaluate educational programs, critic public policies, and justify individual decision making.
In this paper we explore the conditions under
which ETT can be estimated from (i.e., identified in) experimental and/or observational
studies. We show that, when the action invokes a singleton variable, the conditions for
ETT identification have simple characterizations in terms of causal diagrams. We further give a graphical characterization of the
conditions under which the effects of multiple
treatments on the treated can be identified,
as well as ways in which the ETT estimand
can be constructed from both interventional
and observational distributions.

The second problem involves a policy maker considering the termination of an ongoing job-training program, seeking to estimate the anticipated reduction in
future earning of those enrolled in the program. This
calls for comparing the future earning of the program’s
graduates to their hypothetical earning had they not
been trained. Again, because those who enroll in the
program have special needs and qualities, comparison
to the population at large will not be adequate.

Introduction

Consider the following two problems, involving personal decision and program evaluation, respectively.
The first concerns a painful treatment that consists
of administering a dose x′ of a serum to the bloodstream of patients who are judged to need such treatment. A patient who agreed to take the recommended
treatment is wondering whether it was worth the discomfort, namely, what his chances of recovery would
have been had he taken a lower dose of serum, say x.
This counterfactual quantity seems to defy empirical
measurement because we can never rerun history and
administer a different level of treatment for those who
already received it at level x′ ; the latter might possess
distinct needs and dispositions that make them react

In both examples, we ask for the value of an outcome
variable Y after setting the value of another variable
X to x, but also knowing that X attains value x′ naturally. Letting Yx be a random variable representing
the behavior of Y after X is set to value x, each of
the two queries can be represented by the expression
P (Yx = y|x′ ), often called the effect of treatment on
the treated (ETT) [1]. Modeling and identification issues which arise in these queries have received some attention in the literature [6]. In subsequent sections, we
introduce the machinery of causal inference necessary
to define such expressions precisely using causal diagrams as carriers of background knowledge, and show
that, if X is a singleton and Y is a set, ETT can be
computed from the observational distribution if the
causal diagram satisfies a simple graphical criterion.
Finally, we show that if X is a set, the identification
of ETT hinges on a more complex graphical criterion
which, nevertheless, yields a simple way of constructing the ETT estimand.

2

Preliminaries

In this paper, we formalize counterfactual expressions
using the Structural Causal Model (SCM) defined in
[4], Chapter 7. Such models have a marked advantage over the potential-outcome approach of [2] and
[7] in that they permit background knowledge to be
expressed in the ordinary scientific language of cause-

UAI 2009

SHPITSER & PEARL

effect relationships instead of the artificial language
of counterfactual independencies required by the latter. The SCM consists of a set of observed variables
V and unobserved or latent variables U. Without
loss of generality, it is usually assumed that the unobserved variables are exogenous and random, and the
observed variables are endogenous, whose values are
obtained from the values of other variables by means
of unknown functions. Unobserved variables are drawn
from a joint distribution P , and this distribution, together with the functional mapping onto the endogenous variables, defines an observed distribution P (v).
Each causal model induces a directed graph, called
a causal diagram. In such a graph, each variable in
model is represented by a vertex, and a vertex corresponding to a variable Vi has arrows incoming from
every variable whose value is used to determine the
value of Vi by its determining function. In such a
graph exogenous variables have no incoming arrows,
e.g. have no parents in the graph. In this paper we restrict our attention to acyclic causal diagrams. We will
use the standard graph-theoretic family abbreviations
for graph relations, e.g. An(X)G , De(X)G , P a(X)G ,
Ch(X)G stand for the set of ancestors, descendants,
parents and children of X in G, not including X.
The value of causal diagrams is their ability to display
conditional independence among variables in terms of
path-separation criterion known as d-separation [3].
Two sets of nodes X, Y are said to be d-separated by a
third set Z if every edge path from nodes in one set to
nodes in another are “blocked” where blockage occurs
when one of the following triples occurs on the path:
X → Z → Y , X ← Z → Y , and X → W ← Y , where
Z ∈ Z, and neither W nor any descendant of W is in
Z. Paths (or node sets) that are not d-separated are
called d-connected. A d-connected path starting with
an outgoing arrow is called a frontdoor path, while a
d-connected path starting with an incoming arrow is
called a backdoor path.
If many of the variables in a causal diagram are latent,
it can be inconvenient to consider long path stretches
containing nothing but latent variables. One graphical
representation that avoids this is the latent projection
[14]. A latent projection of a causal diagram is a mixed
graph containing directed and bidirected arcs, where
there is a vertex for every observable node, and two
observable nodes X, Y are connected by a directed arrow if there is a d-connected path from X to Y in the
original causal diagram containing only arrows pointing away from X and towards Y , and each node on
this path other than X and Y is latent. Similarly, X
and Y are connected by a bidirected arrow if there is
a d-connected path from X to Y in the original causal
diagram which starts with an arrow pointing to X and

515

ends in an arrow pointing to Y . D-separation generalizes in a straightforward way to latent projections [5],
and latent projections preserve all d-separation statements of the original causal diagrams. In the remainder of the paper we will use latent projections, and
refer to them as graphs or causal diagrams.
Since endogenous variables in a causal model are
causally determined via functions, causal diagrams or
alternative representations such as latent projections
encode more than just conditional independence statements, they also encode direct causal relationships between variables. This additional layer of meaning allows causal diagrams to represent not only probabilistic operations such as marginalization or conditioning,
but causal operations such as interventions.
An intervention, denoted by do(x) in [4], is an operation where values of a set of variables X are set to x
without regard of how values of X are ordinarily determined in the model via functions. The responses of
the remaining observable variables other than X to the
intervention are represented by an interventional distribution denoted as P (v \ x|do(x)) or Px (v \ x). The
response of a single observable variable Y to do(x) is
sometimes denoted by a counterfactual variable Yx .
Once we fix the value of every exogenous variable in
the model, the remaining variables become deterministically fixed. This allows us to use the distribution
P over exogenous variables to define joint distributions over counterfactual variables, even if the interventions which determine these variables disagree with
each other. In other words,
P (Yx11 = y 1 , ..., Yxkk = y k ) =

X

P (e)

{e|Y 11 (e)=y 1 ∧...∧Y kk (e)=y k }
x

x

where E is the set of exogenous variables in the model.
Note that the queries mentioned in the introduction
can all be represented by the expression P (Yx = y|X =
x′ ), which is a conditional distribution obtainable from
a counterfactual joint distribution of the type defined
above. In practice, we cannot use this definition to
evaluate these distributions directly since some exogenous variables may not be observed, in which case P (e)
cannot be estimated, and functions which determine
various variables are not generally known either, which
means evaluating joint response of the same variable
to different interventions becomes difficult.
Furthermore, it’s unclear how to design an experimental study to estimate counterfactual quantities. This
is because counterfactuals of the kind we are interested in involve conflicts in value assignments which
do not correspond in an obvious way to any exper-

516

SHPITSER & PEARL

imental regime we can impose. An alternative way
of obtaining estimates of counterfactual quantities is
to express them in terms of the observable distribution P (v), given causal and probabilistic constraints
encoded by a causal diagram. A counterfactual γ expressible in this way is called identifiable from P (v) in
causal diagram G, (written P (v), G ⊢id γ), and determining which queries γ are expressible in this way is
known as the identification problem [4].

3

Effects of Single Treatment on the
Treated

In this section, we consider identification of queries
of the form P (Yx1 = y 1 , ..., Yxk = y k |X = x′ ), which
we will abbreviate as P (Yx = y|x′ ), where Y =
{Y 1 , ..., Y k }. We will assume X has a causal influence on some outcomes, in other words X ∈ An(Y)G .
The identification of causal effect queries, P (y|do(x)),
require two graphical models, one governing the preintervention distribution, and one governing the postintervention distribution. The latter is represented by
the original causal diagram with all arrows pointing
towards X removed, since interventions severe the influence of the parents on X. We will denote such a
graph obtained from G as Gx .
Counterfactual queries involve a mixture of events
representing multiple hypothetical worlds, where each
world corresponds to an interventional regime of a single counterfactual antecedent, and is represented by a
copy of the original causal diagram, with the appropriate arrows removed. Furthermore, each of these
worlds are assumed to share history up until the intervention. This sharing is modeled by each copy sharing
the exogenous variables. If the values of some observable variables are known or observed, some otherwise
distinct vertices in different copies may end up being
the same due to the axiom of composition [4]. The
resulting graph containing these copies is known as a
counterfactual graph [10].
Causal effect expressions, e.g., P (y|do(x)) = P (Yx =
y) and in fact all expressions in do-calculus can be
evaluated from experimental studies because they belong to a class of counterfactual sentences in which
all quantities refer to the same hypothetical world,
specified by the counterfactual antecedent. For example, P (y|w, do(x), do(z)) translates to the counterfactual P (Yxz = y|Wxz = w), in which all subscripts
are the same. The ETT expression P (Yx = y|X = x′ ),
on the other hand, involves quantities in two different worlds; a post-treatment quantity Yx and a pretreatment quantity X – the latter changed by treatment.

UAI 2009

For this expression, the counterfactual graph is fairly
straightforward. One possible world, corresponding to
variables Yxi , will be represented by the causal diagram with arrows incoming to X cut. Another possible world, corresponding to the variable assignment
X = x′ , will contain the original causal diagram. Since
our causal diagrams are latent projections, we can assume without loss of generality that all exogenous variables shared by these two worlds are latent. Furthermore, because we aren’t interested in any descendant
of X in the second world, no such nodes need to be
added to the graph representing the second world. Finally, since intervening on X cannot influence nondescendants of X, the non-descendants of X in both
of the possible worlds are the same random variables,
and so can be merged. As a result, we can prove the
following theorem.
Theorem 1 P (Yx = y|x′ ) is identifiable in G if and
only if P (y|w, do(x)) is identifiable in G′ , where G′ is
obtained from G by adding a new node W with the
same set of parents (both observed and unobserved)
as X, and no children. Moreover, the estimand for
P (Yx = y|x′ ) is equal to that of P (y|w, do(x)) with all
occurrences of w replaced by x′ .
Proof: Using above reasoning, we established that
the counterfactual graph for identifying P (Yx = y|x′ )
contains a copy of G with the arrows into X removed,
and another copy of G, and that the non-descendants
of X in both copies are shared, while descendants of
X in the second copy can be marginalized away. The
resulting graph is precisely G′ .
First we show the if and only if part of the theorem.
W either has a backdoor path to Y or not. If it does
not, then W is d-separated from Y in G′x , the graph
obtained from G′ by cutting all arcs incoming to X.
This implies P (y|w, do(x)) = P (y|do(x)). If it does,
P (y|w, do(x)) is identifiable iff P (y, w|do(x)) is. In
the former case, we are done, since if P (y|do(x)) is
not identifiable, then P (Yx |x′ ) isn’t either. This is
because results in [10] imply P (Yx = y|x′ ) is identifiable iff either P (y|do(x)) or P (Yx = y, X = x′ )
is.
In the latter case there is a hedge H [9] for
P (y, w|do(x)) in G′ . In this case, it is possible to
convert two counterexample models witnessing nonidentification of P (y, w|do(x)) into two counterexample models witnessing non-identification of P (Yx =
y|x′ ) by taking the values of X in the new models to
be the Cartesian product of the values of X and W in
the old models (modifying the functions determining
X appropriately).
Next, we show that the estimand expression is correct.

UAI 2009

SHPITSER & PEARL
w

u
x

z

y

x

(a)

x’

u
z

y

x

(b)

u
z

y

s

u

z

x

y

w

(a)

(c)

Figure 1: (a) A causal diagram G. (b) A graph G′
(from Theorem 1) such that P (v), G ⊢id P (Yx = y|x′ )
iff P (v), G′ ⊢id P (y|w, do(x)). (c) The counterfactual
graph for P (Yx = y|x′ ) in G.

517
s

u

z

x

y

(b)

Figure 3: (a) A causal
diagram G where P (y|do(x)) is
P
P (y,x|z,s)P (s)
identifiable (as Ps P (x|z,s)P (s) ), but P (Yx |x′ ) is not
s
(U is unobserved). (b) A graph G′ derived from G
using Theorem 1 where a new node W has the same
parents as X but no children. This graph illustrates
the difficulties of identifying P (y|w, do(x)).

w
x

y

Figure 2: A causal diagram where P (y|do(x)) is identifiable, but P (y|w, do(x)) is not.

First, we note that since the counterfactual graph is
just a causal diagram (with some nodes possibly being
copies of each other), the estimand of P (y|w, do(x)) is
correct for P (Yx = y|x′ ) up to variable renaming of
certain copies. But W is just a variable copy of X,
thus we are justified in replacing values w by x′ .

We illustrate the application of Theorem 1 by considering the graph G in Fig. 1 (a). The query P (Yx = y|x′ )
is identifiable by considering P (y|w, do(x)) in the
graph G′ shown in Fig. 1 (b), while the counterfactual
graph for P (Yx = y|x′ ) is shown in Fig. 1 (c). Identifying P (y|w,
G′ using the algorithm in [8],
Pdo(x)) inP
we
get
x P (y|z, w, x)P (w, x)/P (w).
z P (z|x)
′
Replacing
w
by
x
yields the expression
P
P
′
′
′
x P (y|z, x , x)P (x , x)/P (x ). Note that
z P (z|x)
′
P (y|z, x , x) equals 0 for any value of x other than
x′ . Simplifying
we get that our query P (Yx = y|x′ ) is
P
equal to z P (y|z, x′ )P (z|x).
Theorem 1 states that identifying P (Yx = y|x′ ) is
equivalent to identifying conditional causal effects like
P (y|w, do(x)). Conditional causal effects can be more
difficult to identify compared to ordinary causal effects
P (y|do(x)). For instance, in Fig. 2, P (y|do(x)) is identifiable, while P (y|w, do(x)) is not, since conditioning
on W opens a confounding path between X and Y . As
a more complex example, consider the graph shown
in Fig. 3 (a), where we are interested in identifying
P (Yx = y|x′ ). Note that in this graph, P (y|do(x)) is
identifiable, while P (y|w, do(x)) in the graph shown in
Fig. 3 (b), arising from the application of Theorem 1,
is not. The reason is that conditioning on W opens a
confounding path X ↔ S ↔ Y .

3.1

Corollaries

We will discuss two important consequences of Theorem 1.
The first is that the expression for
P (Yx = y|x′ ) can be derived from the expression for
P (y|do(x)) if the Backdoor Criterion [4] holds for some
set Z (this criterion entails “conditional ignorability”
in the language of [7]).
Corollary 1 (Backdoor Criterion for ETT) If a
set Z satisfies the Backdoor Criterion relative to
(X,P
Y), then P (Yx = y|x′ ) is identifiable and equal
to z P (y|z, x)P (z|x′ ).
Proof: If the backdoor criterion holds in G, it
also holds in G′ where W is added. By construction,
Y ⊥
⊥ W |Z in G′x . Thus
P P (y, w|do(x)) =
P
P
(y|z,
do(x))P
(w,
z)
=
z P (y|z, x)P (w, z).
z
Thus,
P
(y|w,
do(x))
=
P
(y,
w|do(x))/P
(w) =
P
P
(y|z,
x)P
(z|w).
The
conclusion
follows.

z
This corollary is important in practice because adjustment for covariates is valid only if Z satisfies the Backdoor Criterion.
The second corollary concerns the so called additive
intervention operation, denoted by do(x′ + q), which
represents adding a quantity q to a treatment variable
X that is currently at level X = x′ . Clearly, the effect
of the increment on Y is given by the ETT expression
P (Yx |x′ ), with x = x′ + q which we may denote as
ET T (Y ; x, x′ + q). Likewise, the policy do(X + q) of
adding q to X regardless of its current value calls
for evaluating the counterfactual expression P (YX+q =
y), where X is a variable. This latter quantity can be
estimated as follows

P (y|do(X + q)) =

X
x′

P (YX+q = y|x′ )P (x′ ) =

518

SHPITSER & PEARL

X

P (Yx′ +q = y|x′ )P (x′ ) = Ex′ ET T (Y ; x′ , x′ + q)

x′

(1)
Corollary 2 The effect of the additive intervention
do(X+q) is identified if ETT is identified and, moreover, its estimand is given by Equation 1.
Clearly, this result generalizes to any modifier do(g(x))
where g(x) is an arbitrary function of x. Moreover, the
effect of the conditional policy do(g(x) if X = x) can
be assessed using the estimand given in Theorem 1.
It is interesting to note that, in general, the analysis of
additive operators cannot be reduced to that of fixing
operators, i.e., causal effects. In Figure 3, for example,
the effect of fixing X at x′ + q is identified while that
of increasing X from x′ to x′ + q is not. The reason
is that the operator do(x′ + q) does not make use of
the information provided by the observation X = x′ ,
which may be significant. For example, a patient with
a low serum level may react differently to increasing
that level than a patient whose serum levels are already
high.
Finally, we can use Theorem 1 to establish a simple
graphical criterion which characterizes identification
of ETT queries in terms of the original causal diagram, rather than the counterfactual graph. Before
doing so, we introduce some helpful terminology. A
C-component [12] of a latent projection is a maximal
set of nodes pairwise connected by bidirected paths.
Each causal diagram has a unique partition into Ccomponents. A Q-factor [13] for a C-component in
G consisting of a set Y, denoted by Q[Y]G
v , is defined as P (y|do(v \ y)), where V is the set of all
observable nodes. Note that in this notation, v denotes the set of values to which variables are fixed,
(or whose probabilities we are trying to calculate if
the variables are in Y). If the set v in the subscript
of a Q-factor changes, the corresponding probability
will also change. We will drop G if it is obvious. It
is known [13] that Q[Y]G
v is identifiable and equal to
Q
(i−1)
i (i−1)
), where Y i are elements of Y, Yπ
i P (y |yπ
are elements preceding Y i in some fixed topological ordering π consistent with the causal diagram, and values appearing in the above expression are consistent
with the subscript v. A C-forest [9] is a graph with
nodes forming a C-component, such that every node
has at most one observable child. The set of nodes in
a C-forest without children is called its root set. We
will denote graphs consisting of a vertex subset X of
G as Gx . We are now ready to prove the main result
of this section.
Theorem 2 P (v), G ⊢id P (Yx = y|x′ ) if and only

UAI 2009

if there is no bidirected path from X to a child of
X in Gan(y) . Moreover, if there is no such bidirected path, the estimand for P (Yx = y|x′ ) is equal
P
P (an(y)) ′
to
v\(y∪{x}) Q∗P (x′ ) Q , where Q is the Q-factor of
Gan(y) corresponding to the C-component containing
X, and Q′ is that same Q-factor with all occurrences
of x are replaced by x′ .
In other words, the estimand for P (Yx = y|x′ ) is almost the same as the estimand for P (y|do(x)) (from
[13]), except rather than summing out x from the expression for Q′ , we replace x by x′ in Q′ , and divide
by P (x′ ).
Proof: See the extended technical report [11].



Theorem 2 says that in order to identify P (Yx |x′ ), it
must be the case that the graph ancestral to Y contains no bidirected paths from X to a child of X, and
this effect is then identifiable by taking the product
of the Q-factors of this graph, replacing all occurrences of the value x in the Q-factor corresponding
to the C-component containing X with the value x′ ,
and marginalizing and conditioning on the appropriate
variables to get the conditional distribution of interest.
Note the difference between this result and the one in
[13]. Tian noted that the effect of a singleton do(x)
on a subset Y of V cannot be fully characterized by
bidirected paths to a child of X in Gan(y) because such
a path may go through a node ancestral to X (and
so this path isn’t ancestral to Y if we cut incoming
arrows to X). This abnormality cannot occur in our
graph, since every node ancestral to X in the original
graph will be ancestral to the observable copy of X in
the counterfactual graph. In particular, in the graph
shown in Fig. 3, P (y|do(x)) is identifiable but P (Yx |x′ )
is not, since as we saw earlier, conditioning on W ,
creates confounding paths between X and Y . Thus,
in some sense the effect of treatment on the treated
is an easier quantity to characterize (but not identify)
than singleton effects.
We illustrate the application of Theorem 2 with an
example. Consider the graph shown in Fig. 1
(a), where X, Y, Z are observable, U is latent, and
we are interested in P (Yx = y|x′ ). Since U is
unobserved, we can drop its node from the graph
and consider the path from X to Y through U
as a single bidirected edge. Since X has no bidirected paths to its descendant Z in the latent projection, this query is identifiable. There are two Ccomponents in Fig. 1 (a), {X, Y } and {Z}. The
Q-factor for the first C-component is P (x, y|do(z)) =
P (y|z, x)P (x), while the Q-factor for the second Ccomponent is P (z|do(y, x)) = P (z|do(x)) = P (z|x).
Applying Theorem 2, we obtain the following identity:

UAI 2009

SHPITSER & PEARL

P
′
′
′
′
P
P(Yx = y|x ′) = ( z P (y|z, x )P (x )P (z|x)) /P (x ) =
z P (y|z, x )P (z|x). Note that this expression agrees
with the expression we obtained using Theorem 1.

4

Experimental Evaluation of ETT
and the Effect of Multiple
Treatments

While ETT cannot in general be estimated from experimental studies (see counterexample in Figure 4
(a)), background knowledge can facilitate such estimation. For example, if the treatment is known to be
binary, we immediately have: P (Yx = y) = P (Yx =
y|x′ )P (x′ ) + P (y|x)P (x) which permits us to express
ETT in term of the causal effect P (Yx = y). For nonbinary treatments, the causal diagram may provide the
knowledge needed.
To this end, we will generalize the queries we consider to be of the form P (Yx1 = y 1 , ..., Yxk = y k |x′ ),
where {Y 1 , ..., Y k } = Y, and the set X is rule 3 minimal. In other words, there is no element X ∈ X such
that rule 3 of do-calculus [4] applies to X, resulting in
P (y|do(x)) = P (y|do(x \ {x})). This condition is simply a generalization of the requirement in the previous
section that X be ancestral to Y. Since we consider
effects of multiple “treatment” variables, we want to
require that they are all causally relevant to Y. We
will abbreviate these queries as P (Yx = y|x′ ), and call
them the effects of multiple treatments on the treated.
The multiple treatment case is more complex in that
rather than handling identification from P (v) directly,
it is more convenient to characterize identification
from all possible interventional distributions first, that
is from the set P∗ = {Px (v \ x)|X ⊆ V}.
We first give a theorem which characterizes a set of
causal diagrams where ETT is definitely not identifiable in general.
′

Theorem 3 Let P (Yx = y|x ) be as above, and X be
partitioned into sets Z, W, such that every element X
of Z has a backdoor path to Y in Gx\{x} , and every
element X of W does not. Then P∗ , G 6⊢id P (Yx =
y|x′ ) if there exists a C-component F in Gzw ancestral
to Y ∪ Z such that either
• There is W ∈ X which has directed paths to both
Y and Z in Gzw , such that the first node (after
W ) in both paths is in F .
• There is Z ∈ Z which is both a member of F , and
would have had a directed path to Y in Gzw with
first node (after Z) on the path in F , but for the
removal of it’s outgoing arcs.

x

519

z

w
(a)

y

x1

x2

w

y

(b)

Figure 4: (a) P (Yx |x′ ) is not identifiable from P∗ . (b)
P (Yx1 ,x2 |x′1 , x′2 ) is not identifiable from P∗ .
Proof: See the extended technical report [11].



We illustrate how Theorem 3 can be used to conclude
non-identification with two examples. Consider graphs
in Fig. 4 (a) and (b). We already know from Theorem
2 that P (Yx |x′ ) is not identifiable from P (v) in Fig. 4
(a) since there exists a bidirected path from X to Z.
In fact, even if we are allowed to use all interventional
distributions in P∗ , P (Yx |x′ ) remains non-identifiable
in this graph due to Theorem 3. Since X has a backdoor path to Y , it belongs to the set Z in the statement of Theorem 3. But there exists a C-component
({X, Y, Z}) ancestral to {X, Y } in Gx such that X
both belongs to it, and has a path to Y through the
C-component but for the removal of the outgoing arc
in Gx . Similarly, P (Yx1 ,x2 = y|x′1 , x′2 ) is not identifiable in Fig. 4 (b). In this graph W = {X1 }, and
Z = {X2 }, and there exists a C-component in Gx1 x2 ,
specifically {X2 , Y }, which is ancestral to {Y, X2 }, and
there is an element of W, namely X1 , which is a parent of this C-component and has a frontdoor path to
both Y and X2 through this C-component.
As stated, Theorem 3 is not a complete result. We
are going to argue that whenever it fails to hold, the
corresponding treatment on the treated query is identifiable. The first step to showing this is the construction of a counterfactual graph. Fortunately, for queries
where Theorem 3 fails, the counterfactual graph is relatively easy to construct from Gzw .
Theorem 4 Let γ = P (Yx = y|x′ ) and G be such
that Theorem 3 does not hold, and X be partitioned
into sets Z, W, such that every element X of Z has a
backdoor path to Y in Gx\{x} , and every element X of
W does not. Then the counterfactual graph Gγ can be
obtained from Gzw by the following operations:
• Split any node W ∈ W that contains frontdoor
paths to Y and Z in Gx into W1 and W2 , where
the former inherits frontdoor paths to Y, and the
latter inherits frontdoor paths to Z.
• Copy any node Z ∈ Z that contains frontdoor
paths to Y in Gx such that the new copy Z ′ contains all outgoing arrows of Z in G.
• Remove all non-ancestors of Y and Z.

520

SHPITSER & PEARL

Proof: See the extended technical report [11].



We are finally ready to show that if Theorem 3 does
not hold for G and γ, then γ is identifiable.
Theorem 5 Let γ = P (Yx = y|x′ ) and G be such
that Theorem 3 does not hold, and X be partitioned
into sets Z, W, such that every element X ∈ Z has a
backdoor path to Y in Gx\{x} , and every element X of
W does not. Then P∗ , G ⊢id γ and γ is equal to
P

v′ \(y∪z)

Q

v′ \z

i

P

Q

G

i

Q[Si ]vγγ
G

Q[Si ]vγγ

where Si is the set of C-component of Gγ , V′ are the
observable unfixed nodes in Gγ , and vγ is defined such
that free variables in the product are consistent with
value assignments in γ.
Proof: See the extended technical report [11].



Identification of γ in terms of P (v) can be ensured by
using existing identification algorithms [12] to check
that each Q-factor in the expression in Theorem 5 is
identifiable from P (v). In fact, since Theorem 5 ensures there are no conflicts among variable assignments
in the Q-factors, it is possible to generalize Theorem
1 and Theorem 2 to this case.
Theorem 6 Let γ = P (Yx = y|x′ ) and G be such
that Theorem 3 does not hold, and X be partitioned
into sets Z, W, such that every element X of Z has
a backdoor path to Y in Gx\{x} , and every element
X of W does not. Then P (v), G ⊢id γ if and only if
P (v), G ⊢id P (y|z, do(w)).
Moreover, we can obtain the expression for γ by running the IDC algorithm [8] on P (y|z, do(w)) and P (v)
in G, and replacing the values x by values x′ in expressions for Q-factors Q[S]G , for all nodes in S which are
also in Z, or for those nodes in X which are parents
of S and have a frontdoor path to Z through S in Gzw .
Proof: See the extended technical report [11].



Note that Theorem 6 is consistent with the expression obtained
P in the previous section, if we express
P (y|x) as
w P (y|w, x)P (w|x) first. In general, in
order to render Theorem 6 consistent with previous
results, IDC requires a slight modification where degenerate inputs of the form P (y|z) which contain no
interventions are not returned as is, but instead are
returned in the form
P

v\(y∪z)

Q

v\(z)

i

P

Q

i

P (si |do(v \ si ))

P (si |do(v \ si ))

UAI 2009

where Si are the C-components of the corresponding
graph, and each term P (si |do(v \ si )) is identifiable
Q
(j−1)
(j−1)
is the set of
), where Xπ
[13] as xj ∈si P (xj |xπ
nodes preceding Xj in some topological order π consistent with the graph.
We illustrate Theorems 4, 5 and 6 with an example.
Consider the graph shown in Fig. 5 (a). It’s easy
to see that Theorem 3 does not apply to the query
P (Yx1 ,x2 = y|x′1 , x′2 ) in this graph. Furthermore, X2
has a backdoor path to Y and X1 does not. Thus,
the graph from which the counterfactual graph is to
be constructed is Gx1 x2 . We add a copy of X2 with
outgoing arrows only (e.g. an arrow to W ). Furthermore, since X1 contains frontdoor paths to both X2
and Y in Gx1 ,x2 , we copy X1 as well, and have the
copy corresponding to the event do(x1 ) inherit all outgoing arrows corresponding to frontdoor paths to Y
(in this case there’s only one such arrow – to W ), and
the copy corresponding to the event X1 = x′1 inherit
all outgoing arrows corresponding to frontdoor paths
to X2 (in this case there’s only one such arrow – to
X2′ ). The resulting counterfactual graph is shown in
Fig. 5 (b). Using Theorem 5, we can now identify
P (Yx1 ,x2 = y|x′1 , x′2 ) using the Q-factors corresponding to the counterfactual graph as equal to
P
Px′ ,w (y, x′2 )Px1 ,x2 (w)
Pw 1
′
′
w,y Px1 ,w (y, x2 )Px1 ,x2 (w)

(2)

Furthermore, each of the Q-factors is identifiable in the original causal diagram.
Specifically, Px1 ,x2 (w) = P (w|x1 , x2 ), and Px′1 ,w (y, x′2 ) =
P (y|w, x′2 , x′1 )P (x′2 |x′1 ). Thus, P (Yx1 ,x2 = y|x′1 , x′2 ) =
P
P (y|w, x′2 , x′1 )P (x′2 |x′1 )P (w|x1 , x2 )
Pw
′
′
′
′
w,y P (y|w, x2 , x1 )P (x2 |x1 )P (w|x1 , x2 )
P
′
′
which is just equal to
w P (y|w, x2 , x1 )P (w|x1 , x2 )
after canceling. Note that this expression coincides
with the output of IDC identifying Px1 (y|x2 ) in G,
where the values x1 , x2 in expressions for the Q-factors
containing X2 are replaced with values x′1 , x′2 , as we
would expect from Theorem 6. We note also that the
addition of a bidirected arc from X1 to X2 in Fig. 5
(a) renders the query P (Yx1 ,x2 = y|x′1 , x′2 ) identifiable
from P∗ (by 2) but not from P (v), which means Theorem 5 does not entail Theorem 6 in all graphs.

5

Conclusions

We have formulated the problem of estimating the
counterfactual probability P (Yx = y|x′ ) as a problem of estimating a distribution under conditional intervention. We have shown that if only a single in-

UAI 2009

x1

SHPITSER & PEARL

x2

w
(a)

y

x′1

x′2

x1

x2

521

[3] Judea Pearl. Probabilistic Reasoning in Intelligent
Systems. Morgan and Kaufmann, San Mateo, 1988.

w

y

(b)

Figure 5: (a) A causal diagram where P (Yx1 ,x2 =
y|x′1 , x′2 ) is identifiable from P∗ (and P (v)). (b) A
counterfactual graph for P (Yx1 ,x2 = y|x′1 , x′2 ) created
using Theorem 4.
tervention is performed, identification of such queries
in terms of the observable distribution has a simple
characterization in terms of the causal diagram. This
characterization permits the evaluation of additive interventions (e.g., do(X + q)), and produces immediate
estimands for ETT whenever causal effects can be estimated by covariate adjustment.
We further showed that, for multiple interventions
it is possible to characterize identification in terms
of experimental distributions by using the original
causal diagram, rather than having to construct additional graphical representations of multiple hypothetical worlds implicit in such queries [10]. Finally, we
show that identified expressions for the queries we consider can be obtained by value replacement operations
performed on identified expressions of ordinary conditional effects of the form P (y|w, do(x)) which contain
no value conflicts.
We speculate that, since ETT measures whether an actor should regret having taken an action do(x) (prior to
observing the outcome), its identification should play
a role in robot learning applications. Regret is the
fundamental mechanism behind the evolution of ethical behavior in humans; it should therefore govern the
development of collaborative societies of robots.
Acknowledgments
The authors thank anonymous reviewers for helpful comments. This work was supported in part by
the Office of Naval Research (contract/grant number:
1053729), and NIH grant #R37AI032475.

References
[1] J. J. Heckman. Randomization and social policy evaluation. In: Evaluations: Welfare and Training Programs, Cambridge, MA: Harvard University Press,
1992.
[2] J. Neyman. Sur les applications de la thar des probabilities aux experiences Agaricales: Essay des principle. Excerpts reprinted (1990) in English. Statistical
Science, 5:463–472, 1923.

[4] Judea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, 2000.
[5] Thomas Richardson and Peter Spirtes. Ancestral
graph markov models. Annals of Statistics, 30:962–
1030, 2002.
[6] James M. Robins, VanderWeele Tyler J., and
Thomas S. Richardson. Comment on causal effects
in the presence of non compliance: a latent variable interpretation by antonio forcina. METRON,
LXIV(3):288–298, 2006.
[7] D. B. Rubin. Estimating causal effects of treatments
in randomized and non-randomized studies. Journal
of Educational Psychology, 66:688–701, 1974.
[8] Ilya Shpitser and Judea Pearl. Identification of conditional interventional distributions. In Uncertainty in
Artificial Intelligence, volume 22, 2006.
[9] Ilya Shpitser and Judea Pearl. Identification of
joint interventional distributions in recursive semimarkovian causal models. In 21st National Conference
on Artificial Intelligence, 2006.
[10] Ilya Shpitser and Judea Pearl. What counterfactuals
can be tested. In 23rd Conference on Uncertainty in
Artificial Intelligence. Morgan Kaufmann, 2007.
[11] Ilya Shpitser and Judea Pearl. Effects of treatment on
the treated: Identification and generalization. Technical Report R-349-L, Cognitive Systems Laboratory,
University of California, Los Angeles, 2009.
[12] Jin Tian. Studies in Causal Reasoning and Learning.
PhD thesis, Department of Computer Science, University of California, Los Angeles, 2002.
[13] Jin Tian and Judea Pearl. A general identification
condition for causal effects. In 18th National Conference on Artificial Intelligence, pages 567–573, 2002.
[14] T. S. Verma and Judea Pearl. Equivalence and synthesis of causal models. Technical Report R-150, Department of Computer Science, University of California,
Los Angeles, 1990.

