ELIDAN & FRIEDMAN

1 44

UAl2001

Learning the Dimensionality of Hidden Variables

GaiEiidan

Nir Friedman

School of Computer Science & Engineering, Hebrew University

{gale[, nir}@cs.huji.ac.il
Abstract
A serious problem in learning probabilistic mod­
els is the presence of

hidden variables. These

variables are not observed, yet interact with sev­

(a)xE

eral of the observed variables. Detecting hidden
variables poses two problems: determining the

{ l, . . . ,n}

(b)xE

{ l, . ..,(n-l)Un}

Figure 1: Illustration of the change in a network that might

relations to other variables in the model and de­

results from the merging of two states of a parent variable.

termining the number of states of the hidden vari­
able. In this paper, we address the latter problem
in the context of Bayesian networks. We describe

child variables are no longer separated from their ances­

an approach that utilizes a score-based agglomer­

tors by X, and so additional edges are needed. We can see

ative state-clustering. As we show, this approach

that the correct determination of the cardinality of a hidden

allows us to efficiently evaluate models with a

variable can affect the complexity of the learned network,

range of cardinalities for the hidden variable.

which in tum has important ramifications on robustness of

We show how to extend this procedure to deal
with multiple interacting hidden variables.

learned parameters, and complexity of inference.

We

In this paper, we propose an agglomerative, score-based

demonstrate the effectiveness of this approach by

approach for determining the cardinality of hidden vari­

evaluating it on synthetic and real-life data. We

ables. Our approach starts with the "maximal" number of

show that our approach learns models with hid­

states possible and merges states in a greedy fashion. At

den variables that generalize better and have bet­

each iteration of the algorithm, it maintains for each train­

ter structure than previous approaches.

ing instance a "hard" assignment to the hidden variable.
Thus, we can score the data using

1

Introduction

In the last decade there has been a great deal of research fo­
cused on the problem of learning Bayesian networks from
data (e.g., [11]). An important issue is the existence of

complete data scoring

functions that are orders of magnitude more efficient than

hid­

den (latent) variables that are never observed, yet interact
with observed variables. Hidden variables often play an im­
portant role in improving the quality of the learned model
and in understanding the nature of interactions in the do­
main. A crucial problem is the question of how to deter­
mine the dimensionality of a hidden variable. This issue is
relevant both when learning with fixed structure (e.g., one
assessed by an expert) and in cases where the learning al­
gorithm attempts to introduce new variables.
The number of states a hidden variable has can have sig­
nificant effect on the performance of the model and also on
its complexity. For example, Figure 1 demonstrates a com­
mon phenomenon: When states of a parent variable X are
merged, X's children may no longer be conditionally in­
dependent given X. As a consequence, more complicated

standard EM-based scores for incomplete data. The proce­
dure progresses by choosing the two states whose merger
will lead to the best improvement (or least decrease) in
the score. These steps are repeated until all the states are
merged into one state. Based on the scores of intermedi­
ate stages, we choose the cardinality of the hidden vari­
able. We show that networks learned from the intermediate
stages are also good initial starting points for EM runs that
fine-tune the parameters.
We then move on to consider networks with multiple hid­
den variables. As we show, we can combine multiple invo­
cations of the single-variable procedure to learn the interac­
tions between several hidden variable. Finally, we combine
our method with the structural detection of hidden variables
of Elidan et

al. [7] and show that this leads to learning bet­

ter performing models, on test and real-life data.

2

Background

networks, where there are edges among children, might be

2.1

needed to describe the domain. This phenomenon is more

Consider a finite set

pronounced when the variable X also has parents.

dom variables where each variable Xi may take states from

The

Learning Bayesian Networks

X

=

{X1,

• • .

,

Xn} of discrete ran­

UA12001

ELIDAN & FRIEDMAN

a finite set, denoted by

Val(Xi). A Bayesian network is an

annotated directed acyclic graph that encodes a joint prob­
ability distribution over X. The nodes of the graph corre­
spond to the random variables

145

of each event in the data.

N[Xi, Pax.] is called
family P(Xi I Pax.).

a

The vector of the counts

sufficient statistic vector for the

Each node is

Once we specify the scoring function, the structure learn­

annotated with a conditional probability distribution (CPD)

ing task reduces to a problem of searching over the combi­

that represents

denotes the

natorial space of structures for the structure that maximizes

B specifies a

the score. The standard approach is to use a local search

parents of

Xi

X1, ... , Xn.

P(Xi I Pax,),
in G.

where

Pax,

A Bayesian network

unique j oint probability distribution over X given by:

procedure, such as greedy hill-climbing, that changes one
edge at a time.

n
P(Xt, ... , Xn)

=

The learning problem is different when the training data

IT P(X;IPax.)

is

i=l

The graph G represents conditional independence prop­
These are the

erties of the distribution.

Markov Inde­

pendencies: Each variable Xi is independent of its non­
descendants, given its parents in G. One implication of the

Markov independencies is that a variable
rectly only with its

Xi

interacts di­

Markov Blanket. This blanket includes

Xi's parents, children, and spouses (additional parents
of children of Xi). We denote by MBx, the variables in
the Markov Blanket of Xi.
the

We are interested in learning Bayesian networks from
examples.

training set D
X, that were sampled

=

Assume we are given a

{ x[l], ... , x[ M]}

of instances of

from an unknown distribution. We want to find a network

B that best matches D. If the structure of the network is

given to us, we can use the maximum likelihood approach
to estimate the parameters. A more challenging problem
is to learn the structure of the network. The common ap­
proach to this problem is to introduce a scoring function
that evaluates candidate networks with respect to the train­
ing data, and then to search for the best network accord­
ing to this score. A commonly used scoring function to

learn Bayesian networks is the Bayesian scoring (BDe)
metric

[12] which we denote by Scoreane- This scoring

metric uses a balance between the likelihood gain of the
learned model and the complexity of the network structure
representation.
An important characteristic of the score function we use
is that when the data is

complete (that is, each training in­
stance assigns values to all the variables) the score is de­
composable. More precisely, the score can be rewritten as
the sum
Score(G:

D)

= L FamScorex, (Pax,

work score depends only on the states of

Xi

the training instances. Assuming Pax,

U,

:

(

reo ..)
"
L..... u log f(N(u}+cr,.)
The terms

au

and

a;o, ,u

D)

=

+"

=

IogP(Pax1

I
L..... x; og

N[xi, u]

are

can use the

Expectation Maximization (EM) algorithm to

search for a (local) maximum likelihood (or maximum a
posteriori) parameter assignment

[5, 14].

In the presence of incomplete data, scoring candidate
structures is more complex. We cannot efficiently evaluate
the marginal likelihood and need to resort to approxima­
tions. A commonly used approximation is the Cheeseman­
Stutz (CS) score [3, 4], which combines the likelihoods
of the parameters found by EM, with an estimate of the
penalty term associated with structure. The
algorithm of Friedman

structural EM
[8] extends the idea of EM to the

realm of structure search. Roughly speaking, the algorithm
uses an E-step as part of the structure search.
rent

The cur­

model - structure as well as parameters - is used

for computing expected sufficient statistics for other can­
didate structures. The candidate structures are then scored
based on these expected sufficient statistics. The search al­
gorithm moves to a new candidate structure. We can then
apply EM again for the new structure, to get the desired
expected sufficient statistics and score new candidate struc­
tures. This algorithm converges to a "local" maximum. The
search space of this algorithm contains many such conver­
gence points, and so care should be taken in choosing the
initialization point.

2.2

Detecting hidden variables in Bayesian networks

As mentioned in the introduction, we are interested both in
cases where the hidden variable is given but its dimension­
For this purpose, we will use the method for detecting hid­

Pax;

in

et al. [7]. We

now briefly review this method.
The general idea of the method is to detect hidden vari­
ables by finding

structural signatures in a Bayesian net­
As Elidan et

work learned over the observed variables.

U)+

f(N[x;,u]+cr.i·"l
r(cr.,,u)

)

al. show, the "signature" formed by removing a hidden
H. How­

variable H is a clique over the children of

ever, when reconstructing the network from data, we might
miss some edges. Thus, instead of searching for perfect

are hyper-parameters of the prior

cliques, the

FindHidden algorithm searches for approxi­

N[u]

mate cliques (relaxation on the number of neighbors) called

counts of the number of occurrences

semi-cliques. A semi-clique is a set of variables such that

distributions over the parameterizations. The terms
and

is both computationally and concepttJally much harder. In
order to learn parameters for a given network structure, we

den variables that was suggested by Elidan

and

=

den variables that are not observed. In this situation the task

ality is unknown and in constructing new hidden variables.

: D).

where the contribution of each variable Xi to the total net­

FamScorex, (Pax,

incomplete, that is, some of the states in the training data

are missing, or when we learn a network that contains hid­

146

ELIDAN & FRIEDMAN

UAI2001

each variable has an edge to at least half of the variables in
the set.
Once a semi-clique S is found, a new hidden variable
is proposed. To evaluate this variable, the algorithm con­
structs a network, with a new variable Hs. This variable is
made a parent of the variables in S. In addition, all edges
among these variables are removed. Then, the algorithm
applies a constrained version of structural EM to adapt the
structure with Hs and to estimate parameters for the new
network. The score of the learned network is then com­
pared to the score of the original one. The change in score
reflects the utility of introducing the hidden variables.
The results of Elidan et al. show that this algorithm is
successful in introducing hidden variables and improves
performance on test data.

3

Choosing the Cardinality of a Hidden
Variable

Figure 2: Trace of the agglomeration process in a simple
synthetic example. We sampled 1000 instances from the

We now address the following problem. We are given train­
ing data D of samples from X= {X1,
, Xn}, and a net­
work structure Gover X and an additional variable H. We
need to determine what cardinality of H leads to the best
• • .

scoring network.
A straightforward way to solve this problem is as fol­
lows: We can examine all possible cardinalities of H up to
a certain point. For each cardinality k, we can apply the
EM algorithm to learn parameters for the network contain­
ing H with k states. Since EM might get stuck in local
maxima, we should perform several EM runs from differ­
ent random starting points. Given the parameters for the
network, we can approximate the score of the network with
k states for H using, say, the Cheeseman-Stutz approxima­
tion [3]. At the end of the process, we return the cardinality
k that received the best score.
This approach is in common use in probabilistic clus­
tering algorithms, e.g., [3]. The central problem of this
approach is its exhaustiveness. The EM algorithm is time

Alarm network, and then hid the observations of the vari­
able HYPOVOLEMIA in the data. We then attempted to
reconstruct its cardinality. Each leaf in the tree is anno­
tated with the values of the variables in the Markov Blanket

(LVEDVOLUME,LVFAILURE and STROKEVOLUME).
Nodes correspond to states that result from merging oper­
ations. They are numbered according to the order of the
merging operations and are annotated with the change in
score incurred by the merge operation. Note that at each
stage, the merge chosen is the one that produces the largest
increase (or smallest decrease) to the score. Diamond­
shaped nodes correspond to the final cardinality chosen.

completed by 17. Next, we merge two states of H to form
a variable with smaller cardinality. This leads to a new as­
signment function. We then reevaluate the network with
respect to this new assignment, and so on. These steps are

we strive to find a method that finds the best scoring cardi­
nality (or a good approximation of it) significantly faster.
We now suggest an approach that works with hard as­
signments to the states of the hidden variables. This ap­

repeated until H has a single state. We return the number of
states k that received the highest score. Figure 2 shows a
concrete example of the tree built during such an agglomer­
ation process. We now consider in more the detail the steps
in the process.
We start with the initialization point of the algorithm, that
is setting the initial states for the variable H. Recall that the
Markov blanket MBH of H separates it from all other vari­
ables. This implies that two instances in which MBH has

proach is motivated by agglomerative clustering methods
(e.g., [6]) and Bayesian model merging techniques from the
HMM literature [17].
The general outline of the approach is as follows. At each
iteration we maintain a hard assignment to H in the train­
ing data. We can represent this assignment as a mapping
17H from 1, . .. , M, to the set Val(H). The assignment,
17H(m) is the state that H holds in the m1th instance. We
initialize the algorithm with a variable H that has many
states (we describe the details below). We then evaluate
the score of the network with respect to the dataset that is

the same state, are identical from H's perspective. Thus,
the largest number of states that are relevant for a given
data sets, is the number of distinct assignments to MBH
in the data. We initialize H to have a state for each such
assignment. In the example of Figure 2 only 13 assign­
ments (out of 16 possible) were observed in the data. We
then augment our training data with these assignments to
H. That is, for each assignment u E Val(MBH), we have
a state hu and for each instance m we set 17H (m) to be the
state hu consistent with the Markov blanket assignment of
instance m.

consuming as it requires inference in the Bayesian network.
For simple Naive-Bayes networks that are used in cluster­
ing, this cost is not prohibitive. However, in other network
structures the cost of multiple EM runs can be high. Thus,

147

ELIDAN & FRIEDMAN

UAI2001

Once we set

an(), we need to evaluate its usefulness.
an() assigns a specific state of H for each instance,
completes the training data an(D). Thus, we can ap­

Since,
it

ply a standard complete data score function (e.g., BDe) to

-1.505

our now completed data set. Recall that when the data is
complete, Score8ne can be evaluated efficiently as a closed

form formula. Moreover, the score depends only on the s uf­
ficient statistics vectors. Each such vector counts the num­

- :.

:.-:.

:-..�

�
..

-1.51

�l!! -1.515

ber of occurrences of each assignment to a variable and its
parents. We denote by

-------- - --- -------

�_
::""_

1 52

N[X;, Pax.] the sufficient statistics

- .

that correspond to the family (the node and its parents) of

xi which we denote by Familyx,· To evaluate
only need to consider families that contain H:

and Familyc for each child C of H.

CTH, we

-1.525

FamilyH

L_
o ----�15
s
____-:1'::-t.�o _____.__
number of states

At each iteration of the algorithm we choose to merge
two states of H, such that the resulting set of states has
the best Scoresoe· Now, suppose that hi and hi are two
states of H that we want to merge. This means that for all
instances where His assigned h; or hi, we now assign H

to a new state, say h;.i. Formally, we define a new function

a�. so that a�(m) = hi·i if an(m) = h; or if CTn(m)
h1, otherwise, a� (m)
an(m). We can then evaluate CT�
and compare its score to the score of an. This difference
=

=

is the improvement (or loss) of the merge operation.

Figure 3: Typical behavior of the score as a function of the
number of states in an agglomeration run. BDe score of the
agglomeration method, CS score based on an EM run that

starts at agglomeration output, and CS score based on the

best EM run from multiple starting points. These results
shown are for recovering the STROKEVOLUME variable
in the Alarm network.

We note that when merging states we actually do not
need to modify the training data. Instead, we simply apply

associated with

the merging operation on the sufficient statistics that corre­

spond to H and its children. That is, we set N[h;.i, paH] =
N[hi. paH] + N[hJ, paH] for each assignment paH to the

3. When H has many states, it can provide better pre­

diction of its children. In fact, in our initialization

parents of H. Similarly we compute the sufficient statistics

point, H's children are a deterministically determined

for H's children and their families.

by H's state (since H has a state for each joint assign­

To determine the best merge operation, the algorithm
considers all pairs of states of H.

ment to the Markov Blanket). When the number of

This can potentially

states is reduced, the predictions of H's children be­

lead to cubic running time (since each iteration require

come more stochastic and their likelihood is reduced.

quadratic amount of computation). However, with suitable

Thus, after a merge, the likelihood of H's children

choice of prior, we can show that the BDe score (and the

will decrease.

MDL score, as well) are locally decomposable. To make
this more precise, suppose that

a� is the result of merg­
an. Define Ll;,j = Score(G :
H U an). The score is locally decom­

ing the states h; and hi in

H U aH-) -Score (G :

posable if Ll;,J does not depend on other states of H. Thus,

once we compute this change in score as a result of merg­
ing i and j, we do not need to recompute it in successive
iterations.

A closer look at the properties of the score reveals the be­
havior we can expect to see when applying our procedure.
Recall that the scoring function trades-off between the like­
lihood of the data and the complexity of the model. When
we consider plots of score vs. H's cardinality, we observe
three effects that come into play.
l. When merging states of H, the number of p arameters

FamilyH improves after each merge

operation.

This suggests that the score will increase rapidly due to
the contribution of the first two effects, will then slow down
but still increase due to the steady contribution of the first
effect, and finally decrease and, as we approach a single
state, indeed "plunge" due to the third effect.
Figure 3 shows an example of the graph we get when
we track the score during iterations of the algorithm. This
figure also shows the relations between the score our algo­
rithm assigns to each cardinality k and the one assigned by
the standard traditional method that runs EM at each car­
dinality. In Section 5 we analyze in more detail the two
methods.

4

Deciding the Cardinality of Several
Hidden Variables

in the network is reduced. This gives a positive contri­
bution to the score since the complexity of the model
is reduced.

In the previous section we examined the problem of de­

2. When H has fewer states, the probability of H's state

happens if our network contains several hidden variables?

given its parents is larger. Thus, the likelihood term

We start by noting that in some cases, we can decouple

ciding the cardinality of a single hidden variable. What

ELIDAN & FRIEDMAN

1 48

the problem:

If a hidden variable H is d-separated from

16

all the other hidden variables by the observed variables,
then we can learn it independent of the rest.
cisely, if

MBH

More pre­

- oonect ca.rdine.lity
missing a single state
- · • collapsed to single state

14

--

consists of observable variables only, we

do not need to worry about

H's interactions with other hid­

UAI2001

12

den variables.
However, when two or more hidden variables interact
with each other the problem is more complex. A decision
about the cardinality of one hidden variable can have ef­
fect on the decisions about other hidden variables. Thus,

I

s

we need to consider a joint decision for all the interact­

,
'
I

....

l

...

•

.......
.. -

.

- -·-

\------ ... _
---

ing variables. The standard EM approach mentioned at the

- --

-

... - ...

beginning of the last section becomes more problematic
here since the cardinality space grows exponentially with

-- ---

���1�ooo
�2=o ���
�oo���oo--�so�oo-- woo
oo
��ro�oo�o
e �

oo�oo�oo��
1 o ooo

number of instances

the number of hidden variables. We now describe a simple
heuristic approach that attempts to approximate the cardi­
nality assignment for multiple variables. The ideas are mo­
tivated by a similar approach to multi-variable discretiza­

Figure

tion

glomeration method from the true cardinality for

The basic idea is to apply the agglomerative procedure of

4: Deviations of the predicted cardinality of the ag­
24 vari­
ables in the Alarm network as a function of the number of

the previous section in a round-robin fashion. At each iter­

instances. Shown are curves for true cardinality, collapse

[9].

ation, we

fix the number of states and the state assignment

to instances for all the hidden variables but one. We ap­

into a single states and a single missing state (other devia­
tions were rare).

ply the agglomerative algorithm with respect to this hidden
variable. At the next iteration, we select another variable
and repeat the procedure. It is easy to check that we should

•

•

For 2 variables, the estimated cardinality had one state
less than the true cardinality.

procedure until no hidden variable has changed its cardi­
nality and state assignment.

15 variables, the agglomerative procedure recov­

ered the correct cardinality.

reexamine a hidden variable only after one of the variables
in its Markov Blanked has changed. Thus, we continue the

For

•

For

2 variables, the estimated cardinality had one ad­

ditional state. Examining the network CPDs suggest

One crucial issue is the initialization of this procedure.
We suggest to start in a network were all hidden variables

that children of these two variables are stochastic in

have one state. Thus, in the initial rounds of the procedure,

some states of the parents (with almost uniform prob­

each hidden variable will be "trained" with respect to its

ability). Initial steps in the agglomeration attempted

observable neighbors. Only in later iterations, the interac­

to model this distribution, which lead to sub-optimal

tions between hidden variables will start to play a role.

aggregate states in later phases of the agglomeration.

It is easy to see that each iteration of this procedure will
improve the score of the "completed" data set specified by
the state assignment functions of the hidden variables. It
immediately follows that it must converge.

•

For

5 variables, the agglomerative procedure sug­

gested a complete collapse into a single state. This
is equivalent to removing the variable. A close look
at the probabilities in the network shows that these
variables have little effect if any on their children and

5

Experimental Results and Evaluation

thus they indeed seem almost redundant. In order to

We set out to evaluate the applicability of our approach in
various learning tasks. We start by evaluating how well
our algorithm determines variable cardinality in synthetic
datasets where we know the cardinality of the variable we
hid. We sampled instances from the

Alarm network [1],

and manually hid a variable from the dataset.

We then

confirm this claim, for each of the five variables and
for each cardinality, we ran EM from multiple start­
ing points to find the best scoring network. For all the
variables, the best score was achieved when the vari­
able was collapsed to a single state.
To summarize, for

19 of 24 of the variables we got the cor­

gave our algorithm the original network and evaluated its

rect or near-perfect prediction of cardinality. For the other

3

5 variables, the characteristics of the data are two weak to

ability to reconstruct the variable's cardinality. Figure

shows a typical behavior of the ScoresDe vs. the number of
states. We repeated this procedure with

24 variables in the

Alarm network. (We did not consider variables that were

reach statistically significant results.
Next, we tested the effect of the training set size on these
decisions. We applied the agglomeration method for all the

either leafs or had few neighbors.) Using training sets with

above variable on training sets with different sizes. Figure 4

I 0,000 instances, the predictions of cardinality can be bro­

shows the deviation from the true cardinality as a function

ken down as follows:

of the training set size. We see that even for small sample

UAI2001

EUDAN & FRIEDMAN

(a) original network

(b) learned with agglomeration

149

(c) learned with binary states

Figure 5: Performance of the agglomeration algorithm on a network with several interacting hidden variables. Comparison
of the model learned with agglomeration (b) to the model learned with binary values (c) demonstrates the importance of
determining the cardinality of hidden variables. (dashed light edges are edges that were removed, thin edges are edges that
were added)

---;

sizes, the predictions for most variables are either perfect or
underestimates the cardinality by I. This can be expected
since the training set does not manifest rare assignments
to the Markov blanket of each variable and less states are
needed to explain the data.
We then compared our approach to the standard method
of evaluating different cardinalities using EM. We com­
pared two variants of EM. The first, performed multiple
EM runs from 5 different random starting points. The sec­
ond variant performed a single EM run starting from the
parameters we learn from the "completed" data during the
agglomeration step. Figure 3 compares the scores assigned
to different cardinalities by the agglomerative approach and
these two EM variants for one variable. Note that for all
methods the case k = 3, which is indeed the correct car­
dinality, received the highest score. Also note that the two
EM variants give similar scores. This suggests that the ag­
glomerative approach finds useful starting points for EM.
In terms of running time, each EM run for each cardinal­
ity in this example takes over 250 seconds. The agglomera­
tion procedure takes a little over one second to agglomerate
the 15 initial states. One might claim that for determin­
ing cardinality, it suffices to run only few iterations of EM,
which are computationally cheaper. To test this, we run EM
with an early stopping rule. This reduced down the running
time of EM about 60 seconds for each run. However, this
also resulted in worse estimates of the cardinality, which
were worse than these made by the agglomerative method.
We conclude that significant time can be saved by using
our method to set the number of states and then apply EM
for fine-tuning. This typical behavior was observed in sim­
ilar comparisons when we hid other variables in the Alarm
network.
Next we wanted to evaluate the performance of our al­
gorithm when dealing with multiple hidden variables. To
do so, we constructed a synthetic network, shown in Fig­
ure 5(a)), with several hidden variables and generated a
matching data set with the appropriate variables hidden.
Using the true structure as a starting point, we applied our

agglomerative algorithm followed by structural EM. As a
strawman we also apply a structural EM with binary val­
ues for all hidden variables. Because of the flexibility of
Structural EM and the challenging structure of our network,
we can expect that a learning algorithm that is not precise,
will quickly deviate from the true structure. The results are
summarized in Figure 5 where hO, hl, h2 and h3 have 3,
2, 4, and 3 states, respectively, and the visible nodes are
all binary. It is evident that the agglomeration method was
able to effectively handle several interacting hidden vari­
able. The cardinality was close to the original cardinality
with extra states introduces to better explain stochastic re­
lations that do not look stochastic in the training data. The
structure learned using the binary model emphasizes the
importance of determining the cardinality of hidden vari­
ables as suggested in the example of Figure 1. In terms of
log-loss score on test data, the model learned with agglom­
eration was superior to the original model that was better
then the model learned with binary values.
We now tum to the incorporation of the cardinality deter­
mining algorithm into the hidden variable discovery algo­
rithm of Elidan et al. [7] (see Section 2). Given a candidate
network, FindHidden searches for semi-cliques and offers
candidate hidden variables. It then applies our method to
the candidate network to determine the cardinality of the
hidden variable. Finally, we allow Structural EM to fine­
tune the candidate network.
We applied this to several variables in the synthetic
Alarm network. We also experimented on the following
real-life data sets: Stock Data: a dataset that traces the
daily change of 20 major US technology stocks for several
years (15 16 trading days). These states were discretized
to three categories: "up", "no change", and "down". TB:
a dataset that records information about 2302 tuberculosis
patients in the San Francisco county (courtesy of Dr. Peter
Small, Stanford Medical Center). The data set contains de­
mographic information such as gender, age, ethnic group,
and medical information such as HIV status, TB infection
type, and other test results. News: data set that contains

ELIDAN & FRIEDMAN

150

•

FindHidden

0'
u

�

�
.:t

e
�
.Q
..,
.Q

learned with the integration of our agglomerative method.

D withAgglomeration

0.1

0.41-----1

0.06

0.31-----1

0.02

Original

Figure 6) but does indeed define 4 separate populations:

l!l

0.08

0.04

The model does not only perform better on test data (see

0.5 ,....-----,

�

D
D
•

n
...

US born, under 30 or over 60, HIV-negative; US born, be­
tween 30 and 60 years, with higher probability of HIV;
Foreign-born, Hispanics, with some probability of HIV;
and Foreign-born, Asians, HIV-negative.

0.21-----1

•

0.11----1

0

UAI2001

Discussion and Future Work

6

•

•

"'
:r:

In this paper, we proposed an agglomerative, score-based
approach for determining the cardinality of hidden vari­
ables. We compared our method to the exhaustive approach
for setting the cardinality using multiple EM runs and
showed its successfulness in generating competing learn­
ing models. The importance and plausibility of using the

Find­
Hidden algorithm with and without agglomeration on syn­

Figure 6: Log-loss performance on test data of the

thetic and real-life data. Base line is the performance of the
Original network given as an input to

FindHidden

agglomeration method as a pre-processing step to a learn­
ing algorithm is an important consequence, thus saving sig­
nificant computational effort.

The algorithm proved ro­

bust to the number of instances in the training set. It was
also able to deal effectively with several interacting hidden
variables. Finally, we evaluated the method as part of the
hidden variable detection algorithm

messages from 20 newsgroups

[13]. We represent each

message as a vector containing one attribute for the news­

FindHidden on syn­

thetic and real-life data and showed improved performance
as well as more appealing structures.

group and attributes for each word in the vocabulary. We

Several works are related to our approach. Several au­

removed common stop words, and then sorted words based

thors examined operations of value abstraction and refine­

on their frequency in the whole data set. The data set used

ment in Bayesian networks

here included the group designator and the

99 most com­

[2, 16, 15, 19]. These works

were mostly concerned with the ramifications of these op­

mon words. We trained on 5,000 messages that were ran­

erations on inference and decision making.

domly selected from the total data set.

about cardinality also appear in the context of discretiza­

Decisions

Figure 6 shows the log-loss performance of the networks

tion. Although the data is observable, the introduction of

on test data. The base line is the original network learned

a discretized variable can be modeled as adding a hidden

without the hidden variable and supplied as input to

Find­

Hidden. The solid diamonds are the score of the network

variable. For example, Friedman and Goldszmidt

[9] in­

corporated the discretization process into the learning of

with the hidden variable but no agglomeration (hidden vari­

Bayesian networks.

able is arbitrarily set to two states) and the squares are

composable score to trade-off between likelihood gain and

Like our approach, they use a de­

the network with hidden variable with the agglomeration

complexity penalty resulting from a particular discretiza­

method applied. As we can see, in all cases, the network

tion.

with the suggested hidden variable outperformed the origi­

variables is also similar to ours.

nal network. The network learned using agglomeration per­

Their approach to discretizing multiple interacting

In the context of learning hidden variables, the most rel­

[17, 18].

formed better then the learned network with no agglomera­

evant are the works of Stolcke and Omohundro

tion (excluding 2 cases where the agglomeration suggested

In these works, they learn hidden Markov models and

exactly two states and is thus equivalent to the no agglom­

probabilistic gr amma r by performing a bottom up state­

eration run).

agglomeration. Similar to our method, they start by span­

It is interesting to look at the structures found by our pro­
cedure.

Elidan

et al. [7]

found an interesting model for

ning all possible states and then iteratively merging states
using information vs. complexity measures. Our work can

One state of the hidden variable

be viewed as a generalization of their work by applying

captures two highly dominant segments of the population:

it to general Bayesian networks and combining it with the

older, HIV-negative, foreign-born Asians, and younger,

hidden variable detection algorithm.

the TB patient dataset.

HIV-positive, US-born blacks. The hidden variable's chil­

The

structural EM

algorithm of Friedman

et al. [7],

[8] followed

dren distinguished between the two aggregated subpopu­

by the work of Elidan

lations using the

all aimed toward learning non-trivial structures with hidden

HIV-result

variable, which was also an

and with this work are

ancestor of several of them. They noted that it is possi­

variables from data. The incorporation of hidden variables

ble that additional states for the hidden states might have

is essential both in improving prediction on new examples

further separated these populations. Figure 7 compares the

and to gain understanding of the underlying interactions of

model learned by the

the domain. We plan to continue this research project in

Find Hidden algorithm and the model

UAI2001

ELIDAN & FRIEDMAN

(a)

FindHidden with no agglomeration

(b)

151

FindHidden with agglomeration

7: Improvement in structure of the TB network due to incorporation of the cardinality determining algorithm into
FindHidden. The hidden variables with 4 states captures more distinct populations and improves the predictive ability of

Figure

the model.

several directions. We intend to explore additional methods
for detecting the dimensionality of hidden variables such
as estimating information theoretic measures in situations
similar to that of Figure 1. In order to deal effectively with
sparse data domains where structural signatures are weak,
further methods for the discovery of hidden variable need
to be developed. Another direction is to extend the meth­
ods for learning hidden structure in more expressive models
such as Probabilistic Relational Models

[10].

Acknowledgements
We thank Noam Lotner and Iftach Nachman for comments
on earlier drafts of this paper. This work was supported
in part by Israel Science Foundation grant number

22 4/991. Nir Friedman was also supported by an Alon fellow­
ship and the Harry & Abe Sherman Senior Lectureship in
Computer Science. Experiments reported here were run on
equipment funded by an ISF Basic Equipment Grant.

References
[1] I. Beinlich, G. Suermondt, R. Chavez, and G. Cooper. The
ALARM monitoring system In Euro. Conf on AI and Med..
1989.
[2] K. Chang and R. Fung. Refinement and coarsening of
Bayesian networks. In UAI '90, pp. 475-482. 1990.
[3] P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor, and
D. Freeman. AutoClass: a Bayesian classification system.
In ML '88. 1988.

[4] D. M. Chickering and D. Beckerman. Efficient approxima­
tions for the marginal likelihood of Bayesian networks with
hidden variables. Mach. Learning, 29:181-212, 1997.

[5] A. P. Dempster, N. M. Laird, and D. B. Rubin.

Maxi­
mum likelihood from incomplete data via the EM algo­
rithm. J. Royal Stat. Soc., B 39:1-39, 1977.

[6] R. 0. Duda and P. E. Hart. Pattern Classification and Scene
Analysis. 1973.
[7] G. Elidan, N. Latner, N. Friedman, and D. Koller. Discover­
ing hidden variables: A structure-based approach. In NIPS
13, 2001.

[8] N. Friedman. The Bayesian structural EM algorithm. In
UA/'98. 1998.
[9] N. Friedman and M. Goldszmidt. Discretization of contin­
uous attributes while learning Bayesian networks. In ML
'96, pp. 157-165. 1996.
[10] L. Getoor, N. Friedman, D. Koller, and A. Pfeffer. Learning
probabilistic relational models. In /JCA! '99. 1999.
[11] D. Beckerman. A tutorial on learning with Bayesian net­
works. In Learning in Graphical Models, 1998.
[12] D. Beckerman, D. Geiger, and D. M. Chickering. Learn­
ing Bayesian networks: The combination of knowledge and
statistical data. Mach. Learning, 20:197-243, 1995.

[13] K. Lang. Learning to filter netnews. In ML '95, pp. 331339, 1995.
[14] S. L. Lauritzen. The EM algorithm for graphical associa­
tion models with missing data. Comp. Stat. and Data Ana.,
19:191-201, 1995.
[15] K. Poh, M. Fehling, and E. Horvitz. Dynamic construction
and refinement of utility based categorization models. IEEE
Trans. Sys. Man Cyb., 24(11):1653-1663, 1994.
[16] K. Poh and E. J. Horvitz. Reasoning about the value of
decision-model refinement: Methods and application.
UAI '93, pp. 174--182. 1993.

In

[17] A. Stolcke and S. Omohundro. Hidden Markov Model in­
duction by Bayesian model merging. In NIPS 5, pages 1118. 1993.
[18] A. Stokke and S. Omohundro. Inducing probabilistic gram­
mars by Bayesian model merging. In Inter. Conf Grammat­
ical Inference, 1994.
[19] M. P. Wellman and C.-L. Lin. State-space abstraction for
anytime evaluation of probabilistic networks. In U A I '94,
pp. 567-574, 1994.

