583

Generating Graphoids from Generalised Conditional Probability

Nic Wilson
Department of Computer Science
Queen Mary and Westfield College
Mile End Rd., London El 4NS, UK
nic@dcs.qmw.uk.ac

Abstract
We take a general approach to uncertainty
on product spaces, and give sufficient condi­
tions for the independence structures of un­
certainty measures to satisfy graphoid prop­
erties. Since these conditions are arguably
more intuitive than some of the graphoid
properties, they can be viewed as explana­
tions why probability and certain other for­
malisms generate graphoids. The conditions
include a sufficient condition for the Inter­
section property which can still apply even if
there is a strong logical relationship between
the variables. We indicate how these results
can be used to produce theories of qualita­
tive conditional probability which are semi­
graphoids and graphoids.
Keywords: Graphoids, Conditional Inde­
pendence, Qualitative P robability.

This means that then independence assumptions can
be propagated using the graphoid inference rules, and
can be represented and propagated using the (both
directed and undirected) graphical methods of [Pearl,

88].
In section 2 we define independence structures, semi­
graphoids and graphoids. GCPPs are defined in sec­
tion 3, with examples and we show how they give rise
to independence structures. Section 4 considers the
Intersection property. In the literature it seems to be
generally assumed that this only holds for probability
distributions which are always non-zero; we show here
that it holds much more generally, a sufficient con­
dition being a connectivity property on the non-zero
values of the probability; exactly the same condition
is sufficient for other GCPPs to satisfy Intersection.
Section 5 considers different sufficient conditions for
GCPPs to give rise to semi-graphoids. These are use­
ful for constructing uncertainty calculi which generate
graphoids and might also be used for showing that an
uncertainty calculus gives rise to a graphoid.

1

INTRODUCTION

The importance of the qualitative features of prob­
abilistic reasoning has often been emphasised in the
recent AI literature, especially by Judea Pearl. An
i mportan t qualitative aspect of probability is given by
the graphoid properties, defined in [Pearl, 88] (see also
[Dawid, 79; Smith, 90]) which sum up many of the
properties of probabilistic conditional independence.
In this paper we look at the reasons why probabil­
ity obeys these properties, with an eye to generating
other uncertainty theories which share much of the
same structure as probability, but represent different
types of information, perhaps of a more qualitative
nature.

A fairly general family of uncertainty calculi on prod­

uct spaces is introduced, which we call Generalised
Conditional Probability on Product Spaces (GCPP),
and define two different types of conditional indepen­
dence for GCPPs. We show that under simple (and
apparently fairly weak) conditions, conditional inde­
pendence for GCPPs satisfies the graphoid properties.

In section 6 we consider another view of GCPPs: as
qualitative conditional probabilities. This view allows
graphoids to be constructed from qualitative compar­
ative judgements of probability. Section 7 briefly con­
siders computation of GCPPs, and section 8 highlights
some areas for further study.

2

INDEPENDENCE STRUCTURES

Let U be a finite set. An independence structure I on

U is defined to be a set of triples (X, Z, Y) where X, Y
and Z are disjoint1 subsets of U. We write I(X, Z, Y)
for (X, Z, Y) E I. For disjoint subsets X, Y � U, their

union

XU Y

will be written

XY.

U is intended to be a set of variables, and I(X, Z, Y) is
intended to mean that variables X are independent of
variables Y given we know the values of the variables

z.
1 A collection A of sets is sa.id to be disjoint if for ea.ch
E A, X n Y
0.

X, Y

=

584

Wilson

The Graphoid Properties of Independence
Structures

I(X, Z, 0)

(Trivial Independence)

If I(X,Z, Y) then I( Y, Z, X)

(Symmetry)

If I(X,Z, YW) then I(X, Z, Y)

If I(X,Z, YW) then I(X,ZY, W)

(Decomposition)

(Contraction)

If I{X,ZY, W) and I(X, ZW, Y) then I(X , Z, YW)
(Intersection)
where W, X, Y, Z are arbitrary disjoint subsets of U
(so, for example, I satisfies symmetry if and only if
the above property holds for all disjoint X, Y and Z).
If an

independence structure satisfies all these proper­
ties then it is said to be a graphoid; if it satisfies the
first five (i.e, all except Intersection) then it is said to
be a semi-graphoid. As we shall see in section 5, prob­
abilistic conditional independence is a semi-graphoid,
and in certain situations a graphoid.
The definitions given here for semi-graphoid and
graphoid differ from that given in [Pearl, 88], in that
we require Trivial Independence to hold. However, our
definition seems to be what Pearl intended2; it is not
implied by other properties (consider the empty inde­
pendence structure) and it is satisfied by probabilis­
tic conditional independence so it is a (rather triv­
ial) counter-example to the Completeness Conjecture3
[Pearl, 88]; also without Trivial Independence, Markov
boundaries don't necessarily exist (consider the empty
independence structure again) which makes Theorem
4 of [Pearl, 88] incorrect.
The intersection of a family of (semi-)graphoids is a
(semi-)graphoid. Hence, for any independence struc­
ture I, there is a unique smallest (semi-)graphoid con­
taining I.

GENERALISED CONDITIONAL
PROBABILITY ON PROD UCT
SPACES (GCPPs)

Uncertainty measures are usually defined on boolean
algebras. However, for our purposes of studying in­
dependence structures generated by the uncertainty
measure, a different domain is natural.
3.1

The set u· is defined to be

(Weak Union)

If I(X,ZY, W) and I(X,Z, Y) then I(X,Z, YW)

3

disjoint X, Y � U, an element of XY may be written
xy for x EX, y E Y. For disj oi nt X, Y � U we define
XIY to be the set of all pairs {xly : x EX, y E Y}.
The set ]1 is defined to be a singleton {T}. An element.
xiT of X I� will usually be abbreviated to x (we are
identifying Xl]l. with X).

THE B ASIC DEFINITIONS

U = {X1, ... , Xn} is said to be a set of variables if
associated with each variable X; E U is a finite set of
values X;. For X� U define X to be Ilx,E X;. For

X

2See, for example, the sentence before Theorem 4, p97
of [Pearl, 88].
3Fatal counter-examples are given in [Studeny, 92].

u

X,YCU
XnY =�

X IY.

A GCPP p over set of variables U is defined to be a
function p: u• _. D for some set D containing differ­
ent distinguished elements 0 an d oo such that for any
disjoint X, Y � U and x EX,
(i) p(x) = 0 if and only if for all y E Y,
and

p(xy)

= 0,

(ii) for any y E Y, p(xlv) = oo if and only if p(y) = 0.
GCPPs will be viewed as measures of uncertainty;
p(xly) may be thought of as some sort of measure
of how plausible it is that the composite variable X
takes the value x , given that Y takes the value y. The
assignment p(x IY) = 0 is intended to mean that :c is
impossible given y, i.e., X cannot take the value :1: if
Y takes the value y. The inclusion of element oo in
D is not strictly necessary; it is u sed as a notational
convenience, and can be read as 'undefined'. We re­
quire (i) because: x is possible if and only if there is
some value of Y which is possible when X takes the
value x. We require (ii) because: if y is impossible
then conditioning on y doesn't make much sense.
Note that no structure on Dis assumed; for example,
we do not assume that D \ { oo} � IR, or even that D
has an ordering on it.
The definition implies that p(T) ::}; 0, oo and
any X� U and x EX, p(J.;)::}; oo .

that

for

Definition

For GCPP p over U and disjoint X, Y � U define pXIY
to be p restricted to X IY and define px to be pXI0.
For Z � U and z E Z define Pz: (U \ Z)" -> D by,
for disjoint X, Y � U \ Z, x E X, y E Y, Pz( xly) =
p(xlyz). For disjoint X, Y � U \ Z, p;'JY is defined to
be Pz restricted to X IY, and P7 is defined to be p;'10.
GCPP p over U is said to be a full GCPP over U if
for every Z � U and z E Z such that p(z)::}; 0, p, is a
GCPP over U \ Z.
The function P.z may be thought of as p conditioned
on Z = z. It turns out that, for GCPP p, p is a full
GCPP if and only if for all disjoint X, Y � U, x E X,
y E Y , [p(xly) = 0 ¢::=::> p(xy) = 0 and p(y)::}; 0].
3.2

EXAMPLES OF GCPPS

A probability function over set of variables U is de­
fined to be a function p: u· - [ 0, 1] u { 00} such that

585

Generating Graphoids from Generalised Conditional Probability

for xJy E U*, (i) P(xJy)
(ii) if P(y) # 0, P(xJy)
P(x)::: LweU\X P(xw).

¢::::::}
P(y) == 0;
P(xy)/P(y); and (iii)

oo

The definition implies that P is a full GCPP over U
and P{T) = 1. The latter follows since P(T) is equal,
by definition, to P(TJT) so by (i) above, P(T) = 0
if and only if P(T) = oo, which implies that P (T) is
neither 0 or oo. We can now apply (ii) to get P(T) =
P(TIT) = P(T)/P(T) which implies that P(T) = 1 as
re quired.
For any (finite) set of variables U, there is a one-to-one
correspondence between probability functions P over
U and probability functions f on U, i.e., functions
f:U--> [0,1] such that LuEuf(u) = 1; P restricted
to U is a probability function on U, and conversely,
a probability function f on U extends uniquely to a
probability function over U using (i), (ii) and (iii).

A Dempster possibility function over set of variables U
[ 0, 1) u { 00} such
is defined to be a function 11": u·
that for xJy E U*, {i) 1r(xly) = oo <==:> 1r(y)
0;
(ii) if 1r(y) # 0, 1r(xly) = 1r(xy)/1r(y); and (iii) 1r(x) =
maxwEU\X 1r(xw).

include a maximal element in the range of OCFs be­
cause he desired belief change to be reversible [Spohn,
88, p130}.
Kappa f u nct ion x: can be transformed into a Demp­
ster possibility function 1r" by 1r"(¢) == oo ¢::::::}
.�e(1/;) = oon and 1r"("l/J) = 2-�<(;J;) otherwise, for
1/J E U*, where 2-oo is taken to be 0. For 1/J, ¢ E U*,
x:( 1/;) == x:( ¢) ¢::::::} 1r" (1/;) = 1r"' ( ¢). This means that,
for our purposes, kappa functions can be viewed as
s p eci al cases of Dempster p ossibili ty functions.

Shafer's pla usi bil ity functions [Shafer, 76], also give
full GCPPs; their dual functions, belief functions, and
ne ce ssi ty functions, the dual of possibility functions,
do not give GCPPs, since, for these, a value of 0 means
a lack of e vid ence , rather than 'impossible'.
3.3

INDEPENDENCE STRUCTURES OF
GCPPS

-+

=

Again, the definition implies that 1r is a full GCP P
over U and 1r(T) = 1. De mps ter possibility functions
are essentially Zadeh's possibility measures [Zadeh,78;
Dubois and P r ade , 88] and consonant plausibility fun c­
tions [Shafer, 76]; the definition of conditional possibil­
i ty is obtained from Dempster's rule, and is not the one
most commonly used, partly because it means that the
range of 1T cannot be viewed as an ordinal scale (and
most justifications of possibility theory require this).
A special case of Demps ter possibility functions are
consistency functions over U, where 1T only takes the
values 0, 1 and oo. 1r(xjy) = 1 is then int ended to mean
that, given that y is the true value of variables Y, it is
possible that x is the true value of variables X. Every
full GCPP p over U gives rise to a consistency function
p* over U defined, for 1/; E U* , by p*('l/;) = p('I/J) if
p("l/J) = 0 or oo, and p*(l/J) = 1 otherwise. Consistency
functions appear in the theory of relational databases
[Fagin, 77}, and also in [Shafer et a/., 87].
A kappa function over set of variables U is defined
to be a function K.:U*-+ {0,1, 2 , .. . ,oo,oon } (where
oo n is different from the other elements) such that
for xiy E U*, (i) K.(xly) = DOn {::::::} ��:(y) = oo;
(ii) if K(y) # oo, K(xjy) = x:(xy) - K(y); and (i ii )
x:(x) = minwEU\X K(xw).
The definition impli es that K.(T) = 0 and ,.., is a full
GCPP over U (however, the labelling of the elements
in the range of "' is confusing: the zero of D in the
definition of a GCPP is oo and the element meaning
'undefined' is oo n not oo ) . Kappa f unctions are based
on Spohn's Ordinal Conditional Fu nctions [Spohn, 88].
An important difference is that the range of kappa
f unctions has a maximum element oo; Spohn did not

For GCPP p over set of variab les U, independence
structures Ip a n d I� are defined as follows. Let X,
Y and Z be disjoint subsets of U .
Ip(X, Z, Y) if and only if p(:I:jyz) = p(J:Iz) for all
X, y EY, z E Z such that p(yz) # 0.

x

E

I�(X, Z, Y) if and only if p(:z:Jyz) = p(xly'z) for all
x EX, y,y' E Y, z E Z s11ch that p( yz) =P 0 and.
p(y'z)#O.
For set S and functions g, h: S -+ D write g =00 h if
they are equal when they are both defined, i.e., if for
all s ES, [g(s) = h(s) or g(s) = oo or h(s) = oo] . This
gives a simpler way of expressing; the two independence
structures. For disjoint. subsets X, Y and Z of U,

Ip(X, Z, Y) if and only if for ally E Y, p;jiZ

and

I�(X,Z,Y) if and
XIZ
XIZ
py
Py'
==

'
only i ffor all y,y

= ""

pXIZ,

EY,

00

To underst and the definitions, first consider the case
when Z == 0. Then Ip(X, Z, Y) if the degree of plau­
sibility of x, p(x), does not change when we condition
by any (possible) value y of Y. Thus our uncertainty
about variable X does not change by learning the value
of variable Y I�(X, Z, Y) holds if the degree of plau­
sibility of x gi ven y, p(xiy) does not depend on the
choice of (possible) value y of Y. The same 1·emarks
apply for general Z, except that. now we must consider
the degrees of plau sibilit y conditional on each value z
of Z.
We shall see in s ectio n 5 that for any GCPP p, lp
satisfies Trivial Independence and Contraction, and, if
Ip = I;, it satisfies Decomposition and Weak Union
al so .

586

Wilson

If GCPP p is non-zero on U then, trivially, U
connected, and so
satisfies Intersection.

THE INTERSECTION
PROPERTY

4

I;

This is the only one of the graphoid properties that
does not hold for all probability functions. [Pe ar l, 88,
p87] appears to suggest that it only holds for proba­
bility functions which are every where non-zero. This
turns out not to be the case, and we will see that a
sufficient condition for Intersection to hold sometimes
allows very strong logical dependencies between the
variables.
Set n is said t o be connected under relation R � n X n
if the smallest equivalence relation on 0 containing R
is the relation 0 X 0.
Let p be a GCPP over set of variables U and let Y,
W and Z be disjoint subsets of U. For z E Z.. define
(YW)t,z = {yw E YW : p(ywz) =/; 0}. We say that
(Y, W) is p, Z-connected4 if for all z E £.., (YW)t,,. is
connected under the relation R defined by
1
'
{::::::} y = y or w = w .

yw R y' w'

For GCPP p over set of variables U, we say that U if
p-connected if for all disjoint subsets Y, W, Z of U, the
pair {Y, W) is p, Z-connected.
Note that these properties only depend on the set of
elements of U for which pis zero (that is, those which
are known to be impossible).
The above concepts are not quite as obscure as they
appear at first sight. (YW)�. is the set of yw which
are not known to be impossible when we know that
Z = z. If we label Y as Y1, ... , Ym and W as
W1, ... , Wn then YW = Y x W can be viewed as the
squares of am x n chess board. Then y;Wj R Yi'Wj' iff
i = i' or j = j', i.e., iff the rook chesspiece could move
between the squares (i,j) and (i',j'). Let N, be the
set of squares corresponding to (YW)t,.. We there­
fore have that (Y, W) is p, Z-connected iff for all z, it
is possible to move between any two elements of N, us­
ing a sequence of rook moves, where each intermediate
square is also in Nz.

Let pbe a GCPP over a set of variables U.
(i) For disjoint subsets X, Y, Z and W of U,
suppose that {Y, W) is p, Z-connected and also
that 1;(x, ZY, W) and I;(x, ZW, Y).
Then
holds.

(ii) If GCPP p over set of variables U is such that U
if p-connec.ted then
satisfies Intersection. 5

I�

similar concept is important in
in [Moral and Wilson,
it guar­
antees the convergence of Markov Chain Monte-Carlo algo­
rithms, and in
ilson,
it is relevant to the justification
of Dempster's rule.
4Interestingly, a

very

Dempster-Shafer theory:

(W

94)

93)

(89)

5Milan Studeny
has found a similar result (for the
of probability functions).

case

p­

Example
Let U = {S, H1, H2}. Variable S ranges over shoe
sizes, and the correct value is the shoe size of the (un­
known) next person to walk into my office. H1 and H2
both take integer values between 0 and 3000. The cor­
rect value of H 1 is the height in millimetres rounded
down of this unknown person and the correct value of
H2 is their height to the nearest millimetre.
Let P be a Bayesian probability function on U, rep­
resenting our Bayesian beliefs about the variables. As
described above, P extends uniquely to a GCPP over
U. Now, P(ij) = 0 unless i = j or i = j- 1, where
ij means H1 = i and H2 = j. Despite the very strong
logical relationship between H1 and H2, ({HI},{H2})
is P, 0-connected, and so if we considered S to be
logically independent of {H1 , H2}, in the sense that
P(sh1h2) = 0 if and only if P(s) = 0 or P(h1h2) = 0,
then U would be P-connected. This implies that Ip
( = If, by the results of the next section) would satisfy
the Intersection axiom, and so would be a graphoid.
In any case, given knowledge of height to the near­
est millimetre, one will learn almost nothing more
about shoe size by learning height in millimetres
rounded down, so one might be tempted to make
the subjective conditional independence judgement
/p({S}, {H2}, {HI}). ( Alternatively, if one did not
know the precise meaning of H1 and H2, but had
the values of the variables for previous visitors then
it would take a vast amount of data to detect a de­
pendency.) Similarly one might be tempted to say
/p({S}, {HI}, {H2}). But these lead, using the last
proposition, to Ip({S}, 0, {H1, H2}) which is certainly
unreasonable since there is a definite dependency be­
tween shoe size and height.

This example illustrates how careful one must be
with subjective independence judgements for Bayesian
probability (or any other GCPP). It also seems to sug­
gest that GCPPs, with definition
cannot represent
'approximate independence' .

1;,

Proposition 1

I�(X, Z, YW)

IS

5

SUFFICIENT CONDITIONS FOR
GCPPS TO GENERATE
GRAPHOIDS

Here we consider simple sufficient conditions on
GCPPs for its associated independence structures t.o
satisfy semi-graphoid properties. Since probability
functions, Dempster possibility functions, kappa func­
tions and consistency functions sat isf y these proper­
ties with the exception of the conditions of proposi­
tion 4(v), these could be v iewed as explanations for
why they are semi-graphoids.

Generating Graphoids from Generalised Conditional Probability

5.1

CONDITIONAL COHERENCE

It is easy to see that for any GCPP p, Ip � I�, i.e.,
if Ip(X, Z,Y) holds then I�( X, Z,Y) must hold. Fur­
thermore if p is inten de d to represent a generalised
form of probability then a natural constraint is that
Ip = I�. T his is because a sufficient condition for
Ip = I� is the apparently reasonable condition:
Conditional-Coherence:

For any disjoint subsets

EX and z E Z, if for all y,y' EY ,
p(xiyz) = p(xly'z) (i.e., p(xlyz) does not vary with
y) then p(xlz) = p(xlyz) (i.e., p(xlz) is e qu al to that
constant v alue).
We say t hat p is weakly conditional-coherent if Ip = I�.
X,Y,Z of U,

x

Consider conditioning on a fixed z E Z. The idea
behind conditional coherence is that if the degree of
plausibility of x given y (i.e, Pz(xiy)) is not dependent
on which value y of Y we use, then one might expect
that the degree of plausibility of x ( i.e ., Pz(x)) wou ld
be equal to that constant value. The conditionals and
marginal then cohere in a particular sense.

Conditional-Coherence is a re stri cted version of the
S an d wich Prin cip le [Pearl, 90; IJAR, 92]. Pl ausi bi l­
ity /belief functions and upper /lower probability func­
tions have good reason not to obey conditional coher­
ence: see e.g., [W ilson, 92; Chunhai and Arasta, 94).
It is satisfied by probability and Dempster possibility
functions and hence by con si stency and kappa func­
ti ons.
Proposition 2

For any GCPP p over set of variables U the indepen­
dence s tru cture IP satisfies Trivial Independence and
Contraction, and lp satisfies Decomposition if and only
if it satisfies Weak Union.
Now suppose tha t p is weakly conditional-coherent.
We then have

(i) lp s at is fies Decomposition and Weak Union.
Therefore if Ip satisfies Symmetry then it is a semi­

graphoid.

(ii) If U is p-connected then Ip satisfies Intersection.
Therefore if lp satisfies Symmetry then it is a
graphoid.
Perhaps the only one of t he grap hoid properties, with
the exc epti on of Trivial Independence, which imme­
diately seems natural is Symmetry. Surprisingly, it
seems to be harde r to find natural sufficient conditions
on p for Ip t o satisfy Symmetry. The follo wi ng result
gives a fairly strong condition.
Proposition 3

Suppose that p is a full GCPP over U such that for all
Z � U and z E Z, there exists a fu ncti on o: R -+ D
for some R � D x D such that

587

(i) for al l xly E (U\Z)*, Pz(xy) = p,.(xly)<>pz(Y), and
(ii) if a o b = c <>a and

a

=f

0 t hen b

= c.

Then Ip satisfies Sy mme tr y.
5.2

DETERMINIST IC RELATIONS
BETWEEN JOINTS, CONDITIONALS
AND MARGIN ALS

If I is an independence structure let its reflection IR
be defined by IR(Y, Z,X) {::::} I(X, Z, Y). Clearly,

I satisfies Symmetry if and only if I = I R. Let
I5 = In JR be the symmetric part of I, so that for
disjoint subsets X,Y, Z of U, I5 (X, Z,Y) if and only
if I(X, Z, Y) and I(Y, Z,X).
Proposition 4

Suppose p is a GCPP o ve r set of variables U.

(i) If p(Tix) = p(T) for all X � U and x EX such
that p(x) =f 0, t h en (I�)R s ati sfies Trivial In depen ­
d en ce.
(ii) If for all disjoint W,Y,X � U there exists a func­
tion M su ch that for al l x E X, M(p!;YY) = p";
then (I�)R satisfies De com positi on .
(iii) If for all disjoint W,Y,X � U t here exists a fun c­
tion C s u ch that for all x EX, C{p!;YY) = p!;YIY
then (I�)R satisfei s Weak Union.
(iv) If p i s a full GCPP and for all disjoint W,Y,X �
U there exists a function J such that (a) for all
x E X, J(p!;YIY, p;;) = p!;YY and (b) J(g, h) =
J(g',h) whe n for all wand y, [g(wYi ) = g' ( wly)
or h(y) = 0], for functions g, g': WIY -+ D and
h: Y-+ D wit h (g,h) and (g',h) in the domain of
J. The n (I�)R sati s fies Contraction.
( v) If p is non-zero on U and for all disjoint W, Y, X �
U there exists a function S s uch that for all x EX,
S(p!;YIY, p�IW) = p!;YY then (I�)R satisfies Inter­

section.

The functi on Min (ii) can be thoughtofas a marginal­
isation op e r ator, and C in (ii i) as a conditioning op­
erator. J in (iv) gives a way of calculating the joint.
dist r ib u tion from the conditional and marginal distri­
butions; condition (b) in (iv) can be omitted if p is
non- ze ro on U; J is e ssen tia lly just pointwise multipli­
cation for probability and Dempster possibility.
The existence of M in (ii) means that for each x,
the joint distribution of Px on WY determines the
marginal distribution (of Px on Y). To see how
this condition is used , suppose I�(WY, 0,X) and
p(x), p(x') =f 0; then p!;YY = p !;I:Y sop� = p� which
leads to I�(Y, 0,X). Similar considerations apply to
(iii), (iv) and (v).
Pr op osi ti on 4 implies that if p is a full GCPP, satisfy­
ing the conditions of (i), (ii), (iii) and (iv) above, an d

Wilson

588

1;

is symmetric then

I;

is a semi-graphoid; further­

more if U is p-connected then

J� is a graphoid.

The result also leads to a way of constructing a semi­
graphoid from a GCPP even if I, and
are not sym­
metric.

I�

Proposition 5
If GCPP p over U is weakly conditional-coherent, and
satisfies the conditions of (i), (ii), (iii) and (iv) of
proposition 4 then
is a semi-graphoid. If, in ad-

If

dition, p satisfies the conditions of (v) then
graphoid.

6

If

IS

a

associated SQCPPs. The correspondences between
GCPPs and SQCPPs mean that the sufficient con­
ditions for independence structures to satisfy the
graphoid properties given in section 5 can be trans­
lated into sufficient conditions for SQCPPs (and hence
QCPPs) to generate independence structures with
those properties.

If consistent � is a full SQCPP (i.e, for all xly E u·
� 0 -¢:::::::} xy � 0 and y ';j:; 0), a sufficient condi­
I

xly

tion for I� to satisfy Symmetry is the following 'cross
multiplication' condition:
For all disjoint X, Y, Z <:;;: U, x E X, y E Y, z E �� if
xz ¢ 0 and xyzlyz �xzlz then xyzlxz � yziz,
where we have trivially extended � to elements :r:yly
of XYIY (for disjoint X, Y <:;;: U), by placing xyiy in
the same � e quivalence c las s as xly.

QUALITATIVE COND ITIONAL
PROBABILITY

-

Another way of viewing GCPPs is as Qualitative Con­
ditional Probabilities on Product spaces (QCPPs).
A Symmetric QCPP (abbreviated to SQCPP) �over
set of variables U is an equivalence relation on u· U
{O,oo} satisfying, for disjoint X, Y <:;;: U and x EX,
(i)

p(x)

� 0 if and only if for ally E Y,

p(xy) �

0,

We will ofte n want to cons truct a QCPP from a num­
ber of different types of information:

p(y) � 0.

(i) some qualitative probability relationships we ex­
pect always to hold, such as, perhaps 0 � xl11 for
all xiy E U*;

and
(ii) for any

y

E Y,

p(xly) � oo if

� is said to be consistent if 0 f.

and only if

oo.

Independence s t ru c tures I:: and 1{:, on U are defined
analogously to the definitions for GCPPs: Ir:::(X,Z, Y)
-¢:::::::} xlyz � xly for all x, y, z such that yz ¢ 0, and
I�(X, Z, Y) -¢:::::::} xlyz � xly' z for all x, y, y1, z such
that yz f. 0 f. y' z.
The framework of consistent SQCPPs is essentially
equivalent to the framework of GCPPs. For any GCPP
p over U we can define a consistent SQCPP �P over U,
by first ext endi ng p toW U{O, oo} by defining p(O) = 0
and p(oo) = oo, and then, for ¢,1/; E U"' U {O,oo},
defining t/J �P ¢ -¢:::::::} p(t/;) = p(¢). We then have
Ir:::. p = and I!.. = I '.

Ip

-p

Constructing QCPPs

p

Conversely, for consistent SQCPP � we can define

GCPP Pr:::. by letting D = (u•u{O, oo})/�, calling the
equivalence classes of 0 and oo by 0 and oo res pec ti v e ly
and, for xly E U*, defining Pr:::.(xly) = d-¢:::::::} d 3 xly.
We have I,, = Ir:::. and I� .. = I�- Also, for any
SQCPP �. we have �(p..,)= �Relation � is said to be a QCPP over set of variables
U i f it is a reflexive transitive relation on U* U {0, oo}

such that its symmetric part � (the intersection of �
and �) is a SQCPP over U.

QCPPs might be thought of as probability fun cti on s
without the numbers; a statement such as xlz � yiz
could mean 'given z, value y i s at least as prob able as

x'.

QCPPs generate independence s tru ctures via their

,

(ii) some desirable properties of=:::;, such as the above
sufficient condition for Symmetry of Ir:::., and other
conditions that imply graphoid properties;
(iii) an agent's comparative probability judgements,
e.g., statements of the form xlz =:::; x or xlz � yjz;
(iv) an agent's conditional independence judgements.
The obvious way to at t e mpting to construct a QCPP

for a particular si tu a t io n is to treat (i) and (iii) as
sets of axioms and (ii) and (iv) as sets of inference
rules, and generate the QCPP from these. H owever,
there is a technical problem: because of the condi­
tions yz ¢ 0, the conditional independence assump­
tions cannot quite be viewed as se ts of inference rules.
We can solve this by requiring that the user gives (ex­
plicitly or implicitly) a II the values u of U such that
u � 0 (that is, the set of all u which are considered im­
possible); the key point here is that the application of
the rules must not lead to any more zero values of U.
The conditional independence assumptions can now be
viewed as inference rules, since they are now closed un­
der intersection. For the same reason, we re q uire the
properties in (ii) also to be closed under intersection,
once the zeros of U are determined.
Naturally, if we have included in (ii) properties which
imply that Ir:::. is a semi-graphoid, then we can pr opa­
gate conditional independence assumptions using the
semi-graphoid prope rt ie s, or using the graphical meth­
od s described in (Pearl, 88].

Generating Graphoids from Generalised Conditional Probability

COMPUTATION OF GCPPS

7

Here we only consider computation of values of the
joint distribution of a GCPP, leaving other aspects of
computation for future work.

I

Let be an independence structure on U. For X; E U,
and W � U \{Xi} the set B � W is said to be an
/-Markov boundary of X; with respect to W if B is
minimal such that I({Xi}, B, W \B).

If I satisfies Trivial Independence then there is at least
one /-Markov boundary of X; with respect toW, and
if I satisfies Weak Union and Intersection then there
is at most one.

Proposition

6

589

to explore, as would its relationship with comparative
probability [Walley and Fine, 79]. T here may well also
be connections between GCPPs and the framework of
[Shenoy, 92] which uses a pro duct definition of inde­
pendence.
Acknowledgements

Thanks to Serafin Moral and Luis de Campos for some
useful discussions, and to Milan Studeny and the ref­
erees for their helpful comments. The author is sup­
ported by a SERC postdoctoral fellowship. I am also
grateful for the use of the computing facilities of the
school of Computing and Mathematical Sciences, Ox­
ford Brookes University.
References

Let p be a GCPP over U, whi ch is labelled X 1, .. , Xn.
S uppose there exists a function6 o: D x D - D s uch
that for all xjy E U*, p(xy) = p(xjy) o p(y). The n for
any x; E �, i = 1, . . . , n,
.

Chunhai, Y., and Arasta, F ., 94, On Conditional Belief
Functions, International Journal of Appr·oxirnate
Rea soning, 10: 155-172.
Cox, R., 46, Probability, Frequency and Reasonable
E xp ectat ion American Journal of Physics 14:1,
January-February 1-13. Reprinted in Readings in
Uncertain Reasoning, G. Shafer and J. Pearl (eds.)
Morgan Kaufmann, San Mateo, California, 1990.
,

application of o is pe rfo rmed
right-to-left, b; is x1
Xn projected onto B;, and
B; is an Ip-Markov boundary of X; with respect to
{Xt, ... ,X;_t}.
where the repeated

·

·

·

The Boundary Directed Acyclic Graph [Pearl, 88] is
formed by letting the parents of each X; be B;. The
a bove result shows that, just like fo r probability, the
values of the joint dis t ribut i o n (i.e, p on U) can be
calculated using this DAG together with, for each X;,
the matrix giving the values of p on X; conditional on
the values of the parents of X;.
If Ip is a semi-graphoid, then a result in [Verma, 86]
(also Theorem 9 of [Pearl, 88]) implies that the Bound­
ary DAG is a minimal I-map for
so that conditional
independence properties of Ip can be derived by test­
ing for d-separation in the DAG.

IP

,

Dubois, D. and Prade, H., 88, Possibility Theory: An
Approach to Computerized Pr o cessing and Uncer­
tainty, P lenum Press, New York.
Fagin, R., 77, Mu l ti valu ed Dependencies and a New
Form for Relational Databases, A CM Trans. on
Databases

2 (no. 3): 262-278.

Goodman, I. R., Ng u yen , H. T., and Walker, E. A.,
91, Conditional Inference and Logic for Intelligent
Systems: A Theor y of Meas1tre-Free Conditioning,

North

-

IJ AR,

H olland A ms terd am .
,

92, International Journal of Approximate Rea­

soning,

6, No. 3 [special issue].

S., and Wilson, N. 94, Markov Chain Monte­
Carlo A lgorit hms for the Calculation of Dempster­
Shafer Belief, submitted to AAAI-94.

Moral,

D ISCUSSION

8

The sufficient conditions we have found for GCPPs to
g enerate semi-graphoids seem natural and fairly weak.
However, we clearly we need to look for more (sensible)
examples of GCPPs that generate semi-graphoids, via
our sufficient conditions. For example, it would be
desirable to find s i mp l e such uncertainty formalisms

which take values which are not totally ordered.
For

to
consider appropriate extra axioms and inference rules
to add to the system. The relationship between Quali­
tative Conditional Probability and relations on condi­
tional objects [Goodman et al, 91] would be interesting
6

Qualitative Conditional Probability, we need

The existence of this function is very closely related to
one of the axioms in a justification of Bayesian probability
[Cox, 46].

,

Pearl , J ., 88,

Probabilistic

Reasoning in Intelligent

Systems: Ne tworks of Plausibl e Inference,

Kaufmann P ublishers

I nc

Morgan

.

Pearl, J.,

90, Reasoning with Belief Functions: An
Analysis of Compatibility, International Journal of
Approximate Reasoning, 4(5/6), 363-390.

Shafer, G., 76, A Mathematical Theor·y of Evidence,
Princeton University Press, Princeton, NJ.
Shafer, G., Shenoy, P. P., and Mellouli, K., 87, Prop­
agating Belief Functions in Qualitative Markov
Trees, I nt e rnat i o nal Journal of Approximate Rea­
soning

1 No. 4: 349-400.

P. P., Conditional Independence in Uncer­
tainty Theories, Proc. Eig h th Conference on Un-

Shenoy,

590

Wilson

certainty in Artificial Intelligence, Morgan Kauf­
mann, 284-291.

Smith, J. Q., 90, Statistical Principles on Graphs, 89120, in Influence Diagrams, Be lief Nets and Deci­
sion Analysis, R. M. Oliver and J. Q. Smith (eds.),
John Wiley and Sons.
Spohn, W., 88, Ordinal conditional functions: a dy ­
namic theory of epistemic states. In: Causation in
Decision, Belief Change and Statistics (W. Harper,
B. Skyrms, eds.), 105-134.
Studeny, M., 89, Multiiinformation and Conditional
Independence I., Research Report n. 1619, In­
stitute of Information Theory and Automation,
Prague, October 1989.

Studeny, M., 92, Conditional I n d ep end ence Rela­
tions have no F inite Complete Characterization,
in Transactions of the 11th Prague Conference on
Information Theory, Statistical Decision Functions
and Random Processes, vol B, Academia, Prague,
377-396.
Verma, T. S., 86, Causal Networks: Semantics and
Expressiveness, Technical Report R-65, Cognitive
Systems Laboratory, University of California, Los
Angeles.

Fine, T. L., 79, Varieties of Modal
(Classificatory) and C omp arati ve Probability, Syn­

Walley, P. and

these 41: 321-374.

W ilson, N., 92, How Much Do You Believe?, Interna­
tional Journal of Approximate Reasoning, 6, No.
3, 345-366.
Wilson, N., 93, The Assumptions Behind Demp­
ster's Rule, Proceedings of the Ninth Conference
of Uncertainty in Artificial Intelligence {UAI93},
David Heckerman and Abe Mamdani (eds.), Mor­
gan Kaufmann Publishers, San Mateo, California,
527-534.
Zadeh, 78, Fuzzy Sets as a Basis for a Theory of Pos­
sibility, Fuzz y Sets and Systems, 1: 3-28.

