Causality in Bayesian Belief Networks

3

Causality in Bayesian Belief Networks

Marek J. Druzdzel

Carnegie Mellon University
Department of Engineering
and Public Policy
Pittsburgh, PA 15213
marek+@cmu. edu

Abstract

·,
·

1

We address the problem of causal interpre­
tation of the graphical structure of Bayesian
belief networks (BBNs). We review the con­
cept of causality explicated in the domain of
structural equations models and show that it
is applicable to BBNs. In this view, which
we call mechanism-based, causality is defined
within models and causal asymmetries arise
when mechanisms are placed in the context of
a system. We lay the link between structural
equations models and BBNs models and for­
mulate the conditions under which the latter
can be given causal interpretation.
INTRODUCTION

Although references to causality permeate everyday
scientific practice, the notion of causation has been one
of the most controversial subjects in the philosophy of
science. Hume's critique that causal connections can­
not be observed, and therefore have no empirical basis,
strongly influenced the empiricist framework and refo­
cused the concept of causality to scientific models as
opposed to reality. A strong attack on causality was
launched in the beginning of this century by Bertrand
Russel, who, observing the developments in areas of
physics such as gravitational astronomy, argued that
causality is a "relic of bygone age," for which there is
no place in modern science.1 Philosophical attempts
to capture the meaning of causation and reduce it to
a theoretically sound and meaningful term succeeded
only in part. Although they exposed and clarified sev­
eral important issues related to the concept of causal­
ity and its use in science, no known philosophical def­
inition of causation is free from objections or exam­
ples in which it seems to fail. This has created an
atmosphere of suspicion towards the very concept. It
is, therefore, not surprising that many scientists are
rather careful in using the term causality, preferring
1 He later retreated from this extreme v iew, recognizing
the fundamental role of causality in physics.

Herbert A. Simon

Carnegie Mellon University
Department of Psychology
Pittsburgh, PA 15213
has+@a.gp. cs. emu. edu

neutral mathematical terms like "functional relation"
or "interdependence." Still, capturing the asymme­
tries implied by causality seem to be an inherent part
of scientific practice.
The confusion about the meaning of causality is clearly
seen in the domain of probabilistic and decision­
theoretic models based on Bayesian belief networks
(BBNs) (Pearl, 1988) and influence diagrams (Howard
& Matheson, 1984). On one hand, the directionality of
arcs brings into a model asymmetric relations among
variables, which some theoreticians have associated
with cause-effect relations (e.g., Pearl (1988), Lau­
ritzen and Spiegelhalter (1984)). In causal discovery
work (Spirtes et al. (1993), Pearl and Verma (1991)),
the relation between causality and probability is bound
by a set of axioms that allow for causal inference. How­
ever, the faithfulness (or minimality) assumption in
causal discovery is too restrictive for a definition of
causality: it is possible for a causal graph to produce
an unfaithful probability distribution. Some theoreti­
cians pointed out that BBNs are simply a mathemat­
ical formalism for representing explicitly dependences
and independences, and that there is no inherent re­
lation of directed arcs with causality in the formalism
(e.g., Howard and Mathesson (1984)). After all, the
arcs can be reversed simply by application of Bayes'
rule, whereas causality cannot.
There seems to be little doubt that the notion of
causality is useful in probabilistic models. There is
strong evidence that humans are not indifferent to
causal relations and often give causal interpretation to
conditional probabilities in the process of eliciting con­
ditional probability distributions (Tversky & Kahne­
man, 1977). Henrion (1989) gives an appealing practi­
cal example when a little reflection on the causal struc­
ture of the domain helps a domain expert to refine the
model. Discovery of the fact that an early version of
a model violates conditional independence of variables
(a consequence of the Markov property) leads the ex­
pert to realize that there is an additional intermediate
node in the causal structure of the system and subse­
quently to refine the model. The probabilistic conse­
quences of the causal structure, in terms of the pat­
tern of dependences, are so strong that an expert seek-

4

Druzdzel and Simon

ing to fulfill the Markov condition, in fact, often ends
up looking for the right causal model of the domain.
Even those holding the strict "probabilistic influence"
view admit that experts often construct influence di­
agrams that correspond to their causal models of the
system (Shachter & Beckerman, 1988). The same can
be said about the user interfaces to decision support
systems: having a model that represents causal inter­
actions aids in explaining the reasoning based on that
model. Experiments with rule-based expert systems,
such as Mycin, have indicated that diagnostic rules
alone are not sufficient for generating understandable
explanations and that at some level a model incorpo­
rating the causal structure of the domain is needed
(Clancey, 1983; Wallis & Shortliffe, 1984).
Usefulness for human interfaces is not the only rea­
son for capturing causality in probabilistic models.
As long as the only goal of using a model is pre­
diction of a probability distribution given some ev­
idence (this is the case in typical diagnostic tasks),
the notion of causality is technically not useful. Con­
sider, for example, a model consisting of two variables:
weather and barometer. Given the outcome of one of
the variables, we can do extremely well in predicting
the probability distribution of the other. The prob­
lems will begin when we want to predict the effect of
a "change in structure" of our system, i.e., the change
in some mechanism in the system through an external
intervention.2 Without knowing the direction of the
causal relation between the weather and the barome­
ter, we cannot tell whether a manual manipulation of
the barometer will affect the weather. If this problem
sounds unrealistic, cqnsider a public policy decision re­
garding, for example, banning products that are high
in cholesterol, given their observed probabilistic asso­
ciation with heart disease. Without the information on
the causal interaction between cholesterol intake and
cholesterol blood level, and then cholesterol blood level
and heart disease, we can at best predict the effect of
our policy decision on the amount of cholesterol in­
take but not its ultimate effect on heart disease. The
effect of a structural change in a system cannot be
induced from a model that does not contain causal in­
formation. Having the causality right is crucial for any
policy making.
One never deals with changes in structure in the do­
main of decision analysis - all policy options and in­
struments that are expected to affect a system are
explicitly included in the decision model. Whatever
causal knowledge is necessary for building this model
is assumed to be possessed by the decision maker, and
is captured in the conditional probability distributions
in the model. The decision maker is assumed to know
that, for example, manipulating the barometer will not
2This problem has been known in philosophy as the
it involves evaluation of a
counterfactual predicate: "if A were true, then B would be
the case." See Simon and Rescher (1966) for a discussion
of the role of causality in counterfactual reasoning.

"c'Bttnterlactualtonditionai,• as

affect the weather. The problem is pushed away from
the formalism to the interaction between the decision
analyst and the decision maker and, effectively, since
reference to causality seems to be unnecessary in de­
cision models, decision theorists and decision analysts
can afford to deny any connection between direction­
ality of arcs and causality.3
While one can get away with such a finesse in decision
analysis, causal knowledge needs to be made explicit in
situations where the human-model loop is less tight.
The ability to predict the effect of changes in struc­
ture is important for intelligent decision support sys­
tems that autonomously generate and evaluate various
decision options (intelligent planners). To be able to
perform this task, they need a way to compute the ef­
fect of imposing values or probability distributions on
some of the variables in a model. This can be done only
if the model contains information about the causal re­
lations among its variables.
What, in our opinion, deters decision theorists from
explicitly including causality in their models is a lack
of a theoretically sound and meaningful representation
of causality within probabilistic models. In this paper,
we propose that the meaning of causality provided by
Simon (1953) within structural equations models is ex­
tendible to BBNs and can fill the existing niche. :Jn
short, the answer given in this paper is that BB:Ns,
taken as a pure formalism, indeed have nothing in
them that would advocate a causal interpretation of
the arcs. Probabilistic independences in themselves
do not imply a causal structure and a causal struc­
ture does not necessarily imply independences. To give
the arcs a causal interpretation, additional assump­
tions are necessary. Those researchers who give BBNs
the interpretation of causal graphs are justified in do­
ing so in as much as these assumptions hold in their
graphs. We make these assumptions explicit, and we
hope that this will contribute to reconciling the two
views of BBNs.
The remainder of this paper is structured as follows.
We first review the principles underlying structural
equations models and Simon's procedure for extract­
ing the causal ordering from such models (Section 2).
Then, in Section 3, we demonstrate that any BBN
model can be represented by a simultaneous equations
model with hidden variables. Using this result, in com­
bination with the assumption of acyclicity of BBNs, we
outline the conditions under which a BBN can be given
a causal interpretation.
3Decision nodes in influence diagrams are a clear ex­
ception: both incoming and outgoing arcs can be given a

causal interpretation. The arcs coming into a d ecision node
denote relevant information, known prior to the decision,

that has impact on the decision (i.e., causes the decision
maker to choose different options). The arcs coming out
of a decision node stand for manipulation of the model's
variables or, if they go to the value node, the impact on
t he overall utility of the decision.

Causality in Bayesian Belief Networks

2

2.1

SIMULTANEOUS EQUATIONS
MODELS

Pieces of the real world that can reasonably be stud­
ied in isolation from the rest of the world, are often
called systems. Systems can be natural (the solar sys­
tem) or artificial (a car), can be relatively simple (a
pendulum) or extremely complex (the human brain).
Although systems are always interlocked with the rest
of the world, one can make a strong philosophical ar­
gument that they usually consist of strongly intercon­
nected elements, but that their connections with the
outside world are relatively weak (Simon, 1969). This
property allows them to be successfully studied in iso­
lation from the rest of the world.
Abstractions of systems, used in science or everyday
thinking, are often called models. There is a large va­
riety in the complexity and rigor of models: there are
informal mental models, simple black-box models, and
large mathematical models of complex systems involv­
ing hundreds or thousands of variables. A common
property of models is that they are simplifications of
reality. By making simplifying assumptions, a scientist
often makes it practically possible to study a system
but, on the other hand, automatically changes the fo­
cus of his or her work from reality to its model.
One way of representing models is by sets of simulta­
neous equations, where each equation describes a func­
tional relation among a subset of the model's variables.
Such models are usually self-contained in the sense
that they have as many equations as they have vari­
ables and, by virtue of the fact that they describe an
existing system, have at least one solution and at most
a denumerably infinite set of solutions. Often, equa­
tions contain so called error variables, variables that
are exogenous and usually independent by assumption,
and which represent the joint effect of other variables
that one is unwilling or unable to specify.
A generic form of an equation that will be used
throughout this paper is
(1)
where f is some algebraic function, its arguments x1,
x2, ... , Xn are various system variables, and E is an

error variable. This form is usually called an implicit
In order to obtain a variable x; (1 � x; � n)
as a function of the remaining variables, we must solve
the equation (1) for :c;. We say that the function

function.

Xi :=g (xl,X2, ... ,x;_l,Xi+l, ... ,Xn,£)

(2)

found in this way is defined implicitly by (1) and that
the solution of this equation gives us the function ex­
plicitly. Often, the solution can be stated explicitly
in terms of elementary functions. In other cases, the
solution can be obtained in terms of an infinite series
or other limiting process; that is, one can approximate
(2) as closely as desired.4
4Some implicit functions have no solutio ns in specified

5

STRUCTURAL EQUATIONS

As, in most mathematical formalisms, certain classes
of transformations are solution-preserving, any model
of a system can have many forms, equivalent with re­
spect to the set of solutions. Each such form is an
algebraic transformation of some other form.
For each natural system, there is one form that is spe­
cially attractive because of its relation to the causal
structure of the system. It is a form in which each
equation is structural, in the sense of describing a con­
ceptually distinct, single mechanism active in the sys­
tem. An example of a structural equation might b e
f = ma, where f stands for a force active i n the sys­
tem, m for the mass of a system component, and a
the acceleration of that component. Another equation
might be p = C1 - C2d, where p stands for the ·price
of a good, d stands for the demand for that good, and
cl and c2 are constants.
The concept of a structural equation is not mathemat­
ical, but semantic. Consequently, there is no formal
way of determining whether an equation is structural
or not. Structural equations are defined in terms of the
mechanism that they describe. The notion of a mecha­
nism can be operationalized by providing a procedure
for determining whether the mechanism is present and
active or not. Sometimes a mechanism is visible and
tangible. One can, for example, expose the clutch of
a car and even touch the plates by which the car's
engine is coupled with the wheels. One can even pro­
vide a graphic demonstration of the role of this mecha­
nism by starting the engine and depressing the clutch
pedal. Often, especially in systems studied in social
sciences, a mechanism is not as transparent. Instead,
one often has other clues or well-developed and empir­
ically tested theories of interactions in the system that
are based on elementary laws like "no action at a dis­
tance" or "no action without communication" (Simon,
1977, page 52). Structural equations may be formed
entirely on the basis of a theory or consist of princi­
ples derived from observations, knowledge of legal and
institutional rules restricting the system (such as tax
schedules, prices, or pollution controls), technological
knowledge, physical, chemical, or social laws. They
may, alternatively, be formed on a dual basis: a the­
ory supported by systematically collected data for the
relevant variables.
A variable is considered exogenous to a system if its
value is determined outside the system, either because
we can control its value externally (e.g., the amount
of taxes in a macro-economic model) or because we
believe that this variable is controlled externally (like
the weather in a system describing crop yields, market
prices, etc.). Equations specifying the values of ex­
ogenous variables form a special subclass in an strucdomains- the equation f(x, y) = x2 + y2 + 1 = 0, for ex­
ample, is satisfied by no real values. All implicit functions

referred to in this paper are

assumed

to have solutions.

6

Druzdzel and Simon

tural equations model. An equation belonging to this
subclass usually sets the value of a system's variable
to a constant, expressing the fact that the value of
that variable is determined outside the modeled sys­
tem, hence, the variable is exogenous to the system.
Often, the core of a simultaneous structural equations
model of a natural system will contain fewer equations
than variables, hence, forming a system that is under­
determined. Only the choice of exogenous variables
and the subsequent addition of equations describing
them makes the system self-contained and solvable for
the remaining (endogenous) variables. Whether a vari­
able is exogenous or endogenous depends on the point
of view on the system that one is describing. The
boundaries that one decides to put around the system
and one's ability to manipulate the system's elements
are ctucial for which variables are exogenous and which
are endogenous in that system. A variable that is ex­
ogenous in a simple system may become endogenous
in a larger system.
In a structural equation describing a mechanism M
fM(Xl, Xz, Xg, ... , xn, t:) = 0,
the presence of a variable Xi means that the system's
element that is denoted by x; directly participates in
the mechanism M. If a variable xi, in turn, does not
appear in this equation, it means that Xj does not
directly participate in M.
In the remainder of this paper, we will use matrix nota�
tion for presence and absence of variables in equations
within a system of simultaneous structural equations
and will call such a matrix a structure matrix.
Definition 1 (structure matrix) The
structure matrix A of a system S of n simultaneous
structural equations e1, e2, ... , en with n variables
x 1 , x2, ... , Xn is a square n x n matrix in which ele­
ment (ij) (row i, column j) is non-zero if and only if
variable xi participates in equation ei. Non-zero ele­
ments of A will be denoted by X (a capital letter X}
and zero elements by 0.

Note that the structure matrix is used for notational
convenience only and does not mean that the discus­
sion of simultaneous equations models is restricted to
linear models.
Example: The following simple model, consisting of
a set of simultaneous linear structural equations (along
with the structure matrix), describes our perception of
the interaction among the percentage of drunk drivers
on the road (d), frequency of car accidents (a), and
ratio of mortalities to the total number of people in­
volved in these accidents (m).
m a d
(ei) 0 0 X
(3)
(e2) 0 X X
(ea) X X 0
Note that each equation describes what we believe to
be a mechanism. Drinking and accidents are involved

[

l

in a mechanism- being under influence of alcohol in­
teracts with driving abilities and effectively increases
the likelihood of an accident (equation e2 ) . Mortal­
ity is involved in a mechanism with car accidents, but
not with the percentage of drunk drivers (equation es).
Our assumption here was that drinking is not involved
in a direct functional relation with mortality. Further,
as we believe that none of the variables in the model
can affect d, we made it an exogenous variable (equa­
tion el)· cl and c2 are constants (positive or nega­
tive) and error variables are specified by a probabil­
ity distribution. Note, that algebraically, this model is
equivalent to the following (we preserved for the sake of
demonstration the original constants and error terms):

{

m+ C2a+ d = £1 + £s
a+C1d=t:2
m+ C2a =£s

(4)

We do not consider this later model to be structural,
because the first equation would suggest a single mech­
anism involving drinking, accidents, and mortality.
This violates our view of the mechanisms operating in
this system and is, therefore, not structural. Still, this
model has the same numerical solution as the model
o
in (3).
Simultaneous structural equations models have been a
standard way of representing static systems in econo­
metrics (Hood & Koopmans, 1953). Structural form
is the most natural form of building a model - one
composes a system modularly from pieces based on
available knowledge about the system's components.
Yet, the main advantage of having a structural model
of a system is that it can aid predictions in the presence
of changes in structure. We will end this section with
a discussion of this important property of structural
equations models.
It is easy to observe that simultaneous structural equa­
tions models imply asymmetric relations among vari­
ables. Consider the example model given in (3). A
change in the error variable t:1 will affect the value of
d directly, and the values of a and m indirectly. A
change in t:s, in turn, will affect only variable m and
leave all other variables unchanged.
A

change in the structure of a system is modeled in a
straightforward way in a simultaneous structural equa­
tions model: one alters or replaces the equations rep­
resenting the modified mechanisms. Consider, for ex­
ample, a policy that makes seat belts mandatory. We
add a new variable b standing for the belt usage (ex­
pressed, for example, by the ratio of the drivers who
use belts after the policy has been imposed). Since
the belt use is determined exogenously with respect to
the system, we add an equation for b. By virtue of
their design, it is reasonable to assume that seat belt
usage interacts directly with accident mortality rate,
hence, the mechanism that the new policy modifies is
that described by the equation involving m. 5 The new
5If there were reasons to believe that seat belts usage

Causality in Bayesian Belief Networks

{

[hi

model will, therefore, take the following form:
m

d= E1
a+ C1d = £2
+ C2a + C3b = £4
b = £5

( e2)

( e3)
( e4)

m

0
0
X
0

a

0
X
X
0

d

X
X
0
0

jl

(5)

It follows from the modified version of the model that
a change in £5 will only affect b and then m. The
values of d and a are uniquely determined by the first
and second equations, hence, will remain unaffected
by the change in structure. This agrees with our intu­
ition that mandatory seat belts will not affect drivers'
drinking habits and the number of accidents. If the
model involved an alternative form of the equations,
such as (4), we would have been in general unable to
determine the effect of a change in the structure of the
model. As it is impossible in such a form to identify
the equations describing the altered mechanisms (note
that in (4) m and a appear in two equations), it is not
obvious which equations need to be modified and how.
2.2

CAUSAL ORDERING

This property of simultaneous structural equations
models was made explicit by Simon (1953), who
pointed out that interactions among variables in a self­
contained simultaneous equations models are asym­
metric and that this asymmetry leads to an ordering
of the variables. He developed an algorithm for ex­
tracting this ordering and argued that, if each equa­
tion in the model is structural and each variable in
the model that is assigned a constant value is an ex­
ogenous variable, then this ordering has a causal inter­
pretation. Causal ordering is a mechanical procedure
that retrieves the dependency structure in a set of si­
multaneous equations. This structure will correspond
to the interactions in the real world in so far as the
model corresponds to the real world.
The procedure of extracting the causal ordering from
a simultaneous structural equations model works
roughly as follows. A set of equations is self-contained
if it has as many equations as variables and if every
subset of equations has at least as many variables as
equations. So a set of n equations is self-contained
if it contains n unknowns and if every subset of m
equations has at least m variables. Mechanisms in
real-world systems often involve small number of ele­
ments, leading to structure matrices with many zeros.
A set of structural equations will usually contain sub­
sets that are self-contained (i.e., they also consist of
as many equations as variables). A subset of k equa­
tions with k variables is called a subset of degree k.
Simon proved that intersections of self-contained sub­
sets are self-contained, thereby proving the existence
of a minimal self-contained subset, i.e., one that does
not have self-contained subsets (in the worst case, this
was involved in the mechanism that leads to an accident,

we might have modified equation e2 as well. Similarly,
drinking might affect the probability of seat belt use and,
hence,

be

implicated in

the

equation

e4•

7

subset will be equal to the entire set). The procedure
recursively identifies minimal self-contained subsets,
solves them for the variables that they contain, and
substitutes the obtained values for each occurrence of
each variable in the remaining equations. Note that
these variables are exogenous to the subsets identified
at a later stage. The procedure stops when no self­
contained subsets can be identified. A self-contained
subset is defined to be of order k if it was identified and
solved at step k of this procedure. The order in which
the subsets were identified defines the causal ordering
of the equations and variables. Variables exogenous
to a subset are the direct causal predecessors of the
variables in that subset. It is possible to construct a
causal graph of the system by representing each vari­
able in the system by a node and drawing directed arcs
to each node from its direct causal predecessors. For
the formal description of the procedure, see (Simon,
1953).
Example: The causal ordering procedure applied to
the model described by (5) will first identify equations
e1 and e4 as two self-contained structures of degree
one. Both equations contain only one variable and,
hence, are minimal subsets of zero order. There are
no other such subsets. Solving e1 for d and e4 for b,
and substituting these values in e2 and e3, yields one
self-contained structure of degree one, notably equa­
tion e2. Since we are in step one of the procedure,
e2 is an equation of first order. Solving e2 for a and
substituting this value in e3, we are left with a sin­
gle equation as the minimal self-contained subset of
second order. The resulting causal ordering is:

b

0

Causal ordering is an asymmetric relation between
variables, determined by a collection of mechanisms
embedded in a system. It is defined formally in the
context of models of real-world systems, whose prim­
itives are equations describing mechanisms acting in
these systems. Mechanisms, as opposed to causal con­
nections, are usually perceptible and, hence, form a
sound operational basis for the approach. But none
of these mechanisms determines the causal ordering in
isolation: causal ordering is a property of a whole systern rather than of an individual equation. We will
subsequently call this view of causality mechanism­
based to reflect its reliance on the notion of mechanisms
in defining the causal structure of a system.
Causal ordering is qualitative in nature, in the sense
that it does not require full algebraic specifications of
the equations in the model. Actually, knowledge of
which variables in a model participate in which equa-

•:

8

Druzdzel and Simon

tions is sufficient. This, in turn, is equal to the knowl­
edge of whether an element of the structure matrix is
non-zero. Actual values of the coefficients (including
their signs) and the algebraic form of the equations
can remain unspecified.
No scientist will claim that a model he or she has
proposed is the true model of the real-world system
and, in that sense, the causal structure explicated by
the procedure of causal ordering is to a certain ex­
tent subjective. ·It is as good as the current state of
knowledge, as the physical, chemical, or social laws,
and as good as the real-world measurements that it
is based on and the approximations that the scientist
was willing to make. This subjectivity seems to be an
irreducible property of models, but luckily a property
that is comparable to the subjectivity of science.
A possible criticism of causal ordering might be that
it adds nothing new: whatever it produces is already
embedded in the equations. Causality, in particular,
must have been encoded in each of the equations by
the author of the model. This critique is misplaced,
however, because there is nothing in a typical equa­
tion that would suggest asymmetry. Causal ordering
of variables becomes apparent only when the equation
is placed in context. For example, the only informa­
tion captured by structural equations for a bridge truss
might be the points through which it is connected with
the rest of the bridge. It is the context, the equations
describing the remaining components of the bridge
that will determine the role of the truss in the causal
structure of the bridge and the direction of causality.
The direction of the causal relation in one system can
be easily reversed in another system. What causal or­
dering accomplishes is to explicate the asymmetry of
the relations among variables in a simultaneous struc­
tural equations model once such a context has been
provided.
The work on causal ordering originated in economet­
rics, where it was initially shown in the context of
deterministic linear models (Simon, 1953). It was
demonstrated to apply equally well to logical equa­
tions models (Simon, 1952) and linear models with
error variables (Simon, 1954). It was shown to pro­
vide an interesting basis for treatment of the coun­
terfactual conditional (Simon & Rescher, 1966). Re­
cently, the method has been extended to non-linear
and dynamic models, involving first-order differential
equations (Iwasaki, 1988) and was shown to provide a
sound basis for qualitative physics (Iwasaki & Simon,
1 986) and non-monotonic reasoning (Simon, 1991).
3

CAUSALITY IN BAYESIAN
BELIEF NETWORKS

It is often the case that, although something is known
about the qualitative and statistical properties of a
system's mechanisms, the exact functional form of the
system's interactions is unknown. BBN models rep-

resent all interactions among a system's variables by
means of probability distributions and, therefore, sup­
ply a way to model such cases.
The pure mathematical formalism of BBNs is based
on factorization of the joint probability distribution
of all variables in the model. Since this factorization
is usually not unique, many equivalent models can be
used to represent the same system, just as was the
case with the simultaneous equations models. Mod­
els are strongly preferred that represent probabilistic
independences explicitly in their graphical structure.
Such models minimize the number of arcs in the graph,
which in turn increases clarity and offers computa­
tional advantages.
Historically, BBN models were developed to represent
a subjective view of a system elicited from a deci­
sion maker or a domain expert (Howard & Matheson,
1984) . Although there are several empirically tested
model-building heuristics, there are no formal founda­
tions and the process is still essentially an art. Decision
makers are usually encouraged to specify variables that
are directly relevant probabilistically (or causally) to
a variable and influence that variable directly. These
variables neighbor one another in the graph and a di­
rected arc is drawn between them. Often, the direction
of this arc reflects the direction of causal influence, as
perceived by the decision maker. Sometimes, the di­
rection of the arc reflects simply the direction in which
the elicitation of conditional probabilities was easier.
While it is certainly not the case that every directed
arc in a BBN denotes causality, the formalism is capa­
ble of representing asymmetry among variables and,
thereby, causality. This section examines the condi­
tions under which one can reasonably interpret the
structure of a BBN as a causal graph of the system that
it represents. We will approach the problem of spec­
ifying these conditions by comparing BBNs to struc­
tural equations models. Our intention is not to replace
BBNs with structural equations models, but to inte­
grate the existing body of work on modeling natural
systems, structure, and causality.
The argument contained in this section consists of
three steps. First, we demonstrate that BBN models
can be represented by simultaneous equations models,
that is, that the joint probability distribution repre­
sented by any BBN model 8 can also be represented
by a simultaneous equations model S (Theorem 1).
We then show that the structure of 8 is equivalent to
the structure of a causal graph of S obtained by the
method of causal ordering (Theorem 2). But the struc­
ture of 8 reflects the causal structure of the underlying
system if and only if the structural model of that sys­
tem shares the structure of S (Theorem 3). So, we can
reduce the semantic constraints on the structure of 8
to the constraints on the structure of S.
The following theorem demonstrates that the joint
probability distribution over n variables of a BBN can
be represented by a model involving n simultaneous

9

Causality in Bayesian Belief Networks

y

equations with these n variables and n additional inde­
pendently distributed latent variables. We prove this
theorem for discrete probability distributions, such as
those represented by variables in BBNs. Intuitively,
it appears that this theorem should extend to contin­
uous distributions, although we leave the problem of
demonstrating that this is in<:jeed the case open.
Theorem 1 (representability) Let B be a BEN
model with discrete random variables. There exists a
simultaneous equations modelS, involving all variables
in B, equivalent to B with respect to the joint probabil­
ity distributions over its variables.
Proof:
The proof is by demonstrating a procedure
for constructing S. A BBN is a graphical represen­
tation of a joint probability distribution over its vari­
ables. This joint probability distribution is a product
of the individual probability distributions of each of
the variables. It is, therefore, sufficient to demonstrate
a method for reproducing the probability distribution
of each of the variables in B. For the sake of simplicity,
the proof is for BBNs with binary variables. Extension
to discrete variables with any number of outcomes is
straightforward. The outcomes of a variable x will be
denoted by X and X. For the sake of brevity, we will
use Pr(X) to denote Pr(x =X).
We will construct one equation for each of the vari­
a hles. Each equation will include an independent, con­
:
tmuous latent variable £, uniformly distributed over
the interval [0, 1]. Note that Vx (0 < x � 1) Pr(E �
x) = x. We start with an empty set S and then, for
each variable y in B, we add one equation to S in the
following way.
If y has no predecessors, then the probability distribu­
tion_:>£ its outcomes is the prior distribution, Pr(Y),
The following deterministic equation with a
latent variable £ reproduces the distribution of y:

if :r:l:;:: Xl, X2
or Xl = xl,
or x-1 =X1,

Y

(

=

{

Y
Y

if
if

E � Pr(Y)
E � Pr(Y)

If y does have direct predecessors x1, x2, ... , Xn, each
of the variables Xi (I :::; i � n ) having outcomes Xi

and xi' then its probability distribution is a distri­
bution conditional on all possible outcomes of these
predecessors ( values t:i are introduced for the sake of
brevity in future references to individual conditional
probabilities) .

Pr(YIX1,X2,... ,Xn) = E1
Pr(YIX1,X2,... ,Xn) = E2
Pr(YjX1,X2,... ,Xn) = E3
Pr(YIX1,X2, . . . ,Xn) = £4
Pr(YIX1,X2,... ,Xn) = E2"
The following deterministic equation with the latent
variable E reproduces the distribution of y:

/y(xl, a:2,

·

..,

Xn,

£) =

.

Xz, .. , Xn:;:: X,., t: < el

"'2 = Xz, ... , "'"=X,., t: �£a
r2 = x2, . . . , "'"= x ,., e 5£4

or x-1 = X1, r2 = Xz, ... , x-,. =X,., t:5 Ezn
=

Y

if x1:::: X .!.!.."'2

==

Xz,

.

.. , x-,.:::: X,.,£> £1

or "'1 =xl. "'2 = Xz, .. . , Xn = x .., e > f:z

.

or XI=X1, x2 =X2, . . , :r:,. =X,, C > C3

or "'1 =Xt. "'2 =X2, . . . , :r:"

..

.

:::: Xn, t: > £4

orxl =XI, "'2 =Xz, . . . , Xn =X,., e > £2"

The above demonstrates that the value of any node in
a BBN can be expressed by a deterministic function
of the values of all its direct predecessors and a single
independently distributed latent variable. For a BBN
with n nodes, we have constructed a self-contained set
of n simultaneous equations with n variables and n
independent uniformly distributed continuous latent
variables. The probability distribution of each variable
in S is identical to the distribution of a corresponding
node in B. This makes S equivalent to B with respect
to the joint probability distribution of the variables.
.

0

The construction of an equivalent simultaneous equa­
tions model S for a BBN B, outlined in the above
proof, is rather straightforward. The goal is to de­
scribe each element of the conditional probability ma­
trix of a node y in B. Each logical condition on the
right-hand side of the equations specifies one element
of this matrix by listing a combination of outcomes of
parents of y. The exact numerical value of the condi­
tional probability for that element is then given by the
probability of an event involving the latent variable £.
Let B be

Example:

X

Pr(Y).

f £)

==

or x1 = X1, "'2= X2, ... , "'"=X,, t:-< C2

a

BBN with nodes x and y.
y

o--.0
Let the distribution of x be Pr(X)
=
0.4,
_
Pr(X) = 0.6, and the conditional distribution of y
be Pr(YIX) = 0.7, Pr(YIX) = 0.2, Pr(YIX) = 0.3,
Pr(YIX) = 0.8.

A

{

simultaneous equations model for B is:
==

==

x

if t:� < 0.4

X

if ex :( 0.6

Y

1f r =X, t:y 5 0.3

,!:

�fx=X,£y50.7or'x=!!._,Cy50.2
or :c

= X , E11 c:; 0.8
0

BBNs are acyclic, which excludes self-contained struc­
tures of degree higher than one. It is, therefore, obvi­
ous that the converse of Theorem 1 is not true. For
example, models with feedback loops cannot be repre­
sented by BBNs.
The following theorem establishes an important prop­
erty of a structural equations model of a system with
an assumption of causal acyclicity. This property im­
plies that the structure obtained by the method of

10

Druzdzel and Simon

causal ordering from a structural equations model S
constructed in the proof of Theorem 1 reflects the
structure of the equivalent BBN B.

(acyclicity) The acyclicity assumption
in a causal graph corresponding to a self-contained sys­
tem of equations S is equivalent to the following condi­
tion on S: Each equation e; E S: f(x1,
, Xn, £;) = 0
forms a self-contained system of some order k and de­
gree one, and determines the value of some argument
xj (1 5 .i 5 n} off, while the remaining arguments of
f are d�rect predecessors of Xj in causal ordering over
s.
·Theorem 2

• • •

Proof: I � I Acyclicity, according to the procedure
of causal ordering, means that in the process of ex­
tracting the causal ordering from S, there is no self­
conta�n�d structure of degree higher than one (i.e.,
contammg more than one equation). We will show
that given the assumption of acyclicity, the structure
matrix A of the equations in Sis triangular. Then, by
the considerations analogous to Gaussian elimination
and by causal ordering the theorem follows.

We will transform A into a lower-triangular matrix
by a series of operations involving row interchanges
and column interchanges. Both operations preserve
�he causal ordering of .variables in S: row interchange
_
IS eqmvalent to changmg the order of equations in S·
column interchange is equivalent to renaming the vari�
ables in S. Both the order of equations and names of
variables are insignificant and do not depend on the
f�nctional form of equations. We will work along the
diagonal from the upper-left to the lower-right corner
and always rearrange rows below and columns to the
right of the current diagonal element.
Since all self-contained structures in S are all of de­
gree one, we know in the beginning (row 0 and column
0) that there will be at least one equation containing
only one variable. Suppose row i describes the coeffi­
cients of such an equation. We know that there will be
only one non-zero coefficient in this equation. If this
coefficient is located in column j, we interchange row
0 with row i and column 0 with column j. Now, the
first element on the diagonal (first pivot) will contain
a non-zero; all other elements in row 0 will be zeros.
Now we proceed with the next pivot. Processing the k­
th pivot, we are by assumption guaranteed that in the
sub-matrix [k : n; k: n] there will be at least one self­
contained structure of degree one, which means that
there will be at least one row with only one non-zero
element. Suppose, it is row i and the non-zero element
is in column j. We then interchange row k with row i
and column k with column j. Since the k-th pivot is
the only non-zero element in the current k-order self­
contained structure, all elements to the right of it are
zeros. Note also that this interchange does not affect
the zero elements above diagonal in the rows 0 to k -1
since all columns from k to n had their elements 0 t�
k 1 equal to zero.

-

By the considerations based on Gaussian elimination
each of the diagonal elements a;; is the coefficient of
some variable x;, determined by the equation e;. Each
of the other non-zero elements left of au denotes pres­
ence in the equation e; of a variable that is determined
before x;, that is a direct predecessor of x; in the causal
ordering over S.

r<==l If each equation determines exactly one variable,
itl'Oil'ows that at each level in the procedure of extract­
ing the causal ordering, there are only self-contained
structures of degree one, which in turn guarantees
0
acyclicity of the causal graph.
Each equation in the simultaneous equations model S
constructed in the proof of the Theorem 1 involves a
node in the graph representing the BBN B and all its
immediate predecessors. By Theorem 2, the causal
g�aph of S derived by the method of causal ordering
will have the same structure as B. This observation
and its implications are formalized in the following
theorem.
""
Theorem- 3

(causality in BBNs) A Bayesian be­
lief network 8 reflects the causal structure of a sys­
tem if and only if {1) each node of B and all its direct
predecessors describe variables involved in a separate
mechanism in the syste� and (2) each node with no
�"
1redecessors represents an exogenous variable.
�

By Theorem 1, there exists a simultane­
ous equations system S that is equivalent to B. Each
equation in S involves a node of B and all its direct
predecessors. We know that B is acyclic, so by Theo­
rem 2 the structure of B is equivalent to the structure
of a causal graph obtained by the method of causal
ordering from S.
Proof:

By the assumptions underlying causal ordering, B re­
flects the causal structure of the underlying system if
and only if S is a structural model of that system i.e.
if each of its equations is a structural equation and 'each
of its exogenous variables is a true exogenous variable.
0
This is what the theorem states.
4

CONCLUSION

Knowledge of causal asymmetries in a system is neces­
sary in predicting the effects of changes in the structure
of the system and, because of the role of causality in
human reasoning, is essential in human-computer in­
terfaces to decision support systems. Although many
researchers refer to the concept of causality, there
seems to be no consensus as to what causality in BBN
models means and how BBNs' directed arcs should be
interpreted. We reviewed the mechanism-based view
of causality in structural equations models and we have
shown that it is applicable to BBN models. We have
explicated the conditions that need to be satisfied in
order for a BBN to be a causal model.
Theorem 3 demonstrates that directed arcs in BBNs

i: i'.(.) �� 'f.;. �
-·� -/'1.(.\.'JOO.S !

\� ( 1\�)
ct.YI'f

£�)

'/ar;cJolt_

C!>-v\

� ��

�>\��-

Causality in Bayesian Belief Networks

play a role that is similar in its representational power
to the structure (in terms of the presence or absence of
variables in equations) of simultaneous equations mod­
els. We can view the graphical structure of a BBN as
a qualitative specification of the mechanisms acting
in a system. Similarly to the mathematical transfor­
mations on structural equations models (such as row
combination in linear models), we can obtain BBNs
that are equivalent with respect to the probability dis­
tribution of its variables by reversing network's arcs.
However, similarly to simultaneous equations models,
such transformations will lead to loss of structural in­
formation. There is only one graphical structure that
fulfills the semantic requirements stated in the theo­
rem and can be given a causal interpretation.
Our analysis shows how prior theoretical knowledge
about a domain, captured in structural equations, can
aid construction of BBNs. Given the assumption of
acyclicity, an equation involves a node and all its di­
rect predecessors, as shown in Theorem 2.. This pro­
vides valuable information about adjacencies in the
constructed network. Currently, both, the structure
and the numerical probability distributions in BBNs
are elicited from a human expert and are a reflection
of the expert's subjective view of a real world system.
Existing theoretical knowledge, if incorporated at the
model building stage, should aid human experts, make
model building easier, and, finally, improve the quality
of constructed models.
A cknowledgments

We thank anonymous reviewers for insightful remarks.
References

Clancey, W. J. (1983) . The epistemology of a rule­
based expert system - a framework for explanation.
Artificial Intelligence, 20 (3):215-251 .
Henrion, M . (1989). Some practical issues in con­
structing belief networks. In L. Kana!, T. Levitt,
& J. Lemmer (Eds.), Uncertainty in Artificial Intel­
ligence 3 (pp. 161-173) . Elsevier Science Publishers
B.V. (North Holland).
Hood, W. C. & Koopmans, T. C. (Eds.) (1953) . Stud­
ies in econometric method. cowles commission for
research in economics. monograph no. 14. New
York, NY: John Wiley & Sons, Inc.

Howard, R. A. & Matheson, J. E. (1984) . Influence di­
agrams. In R. A. Howard & J. E. Matheson (Eds.),
Th e Principles and Applications of Decision Analy­
sis (pp. 719-762) . Strategic Decisions Group, Menlo

Park, CA.
Iwasaki, Y. ( 1988) . Model based reasoning of device
behavior with causal ordering. PhD thesis, Depart­
ment of Computer Science, Carnegie Mellon Univer­
sity, Pittsburgh, PA.

11

Iwasaki, Y. & Simon, H . A. (1986). Causality in device
behavior. Artificial Intelligence, 29(1 ):3-32.
Lauritzen, S. L. & Spiegelhalter, D. J . (1984). Lo­
cal computations with probabilities on graphical
structures and their application to expert systems.
Journal of the Royal Statistical Society, Series B
(Methodological), 50 (2) : 157-224.

Pearl, J. (1988) . Probabilistic reasoning in intelligent
systems: Networks of plausible inference. San Ma­
teo, CA: Morgan Kaufmann Publishers, Inc.
Pearl, J. & Verma, T. S. ( 1 991). A theory of inferred
causation. In J . Allen, R. Fikes, & E. Sandewall
(Eds.), KR-91 , Principles of Knowledge Represen­
tation and Reasoning: Proceedings of the Second In­
ternational Conference (pp. 441-452). Cambridge,

MA: Morgan Kaufmann Publishers, Inc. , San Ma­
teo, CA.
Shachter, R. D. & Heckerman, D. E. ( 1988) . A back­
wards view for assessment. In J . Lemmer & L. Kana!
(Eds.), Uncertainty in A rtificial Intelligence 2 (pp.
317-324) . Elsevier Science Publishers B .V . (North
Holland).
Simon, H. A. ( 1952) . On the definition of causal rela­
tion. The Journal of Philosophy, 49(16) :517-528.
Simon, H. A. (1953). Causal ordering and identifiabil­
ity. In (Hood & Koopmans, 1 953), Chap. III, pp.
49-74.
Simon, H. A. (1954). Spurious correlation: A causal
interpretation. Journal of the A merican Statistical
Association, 49(267):467-479.
Simon, H. A. ( 1969) . The sciences of the a rtificial.
Cambridge, MA: The MIT Press.
Simon, H. A. ( 1 977) . Models of discovery. Dordrecht,
Holland: D. Reidel Publishing Company.
Simon, H. A. (1991). Nonmonotonic reasoning and
causation: Comment. Cognitive Science, 15(2):293300.
Simon, H. A. & Rescher, N. (1966). Cause and coun­
terfactual. Philosophy of Science, 33( 4):323-340.
Spirtes, P., Glymour, C. , & Scheines, R. ( 1993) . Cau­
sation, prediction, and search. Springer Verlag.
Tversky, A. & Kahneman, D. (1977) . Causal schemata
in judgments under uncertainty. In M. F ishbein
(Ed.), Progress in Social Psychology. Hillsdale, NJ:
Lawrence Erlbaum Associates.
Wallis, J. W. & Shortliffe, E. H. ( 1984) . Customized
explanations using causal knowledge. In B. G.
Buchanan & E. H. Shortliffe (Eds.), Rule-Based Ex­
pert Systems: The MYCIN Experiments of the Stan­
ford Heuristic Programming Project ( Chap. 20, pp.

371-388). Reading, MA: Addison-Wesley.

