250

Time-Critical Action: Representations and Application

Eric Horvitz

Adam Seiver

Microsoft Research

Critical Care Service

One Microsoft Way

Department of Surgery

Redmond, WA 98052

Stanford Medical School

horvitz@microsoft.com

Stanford, CA 94305
seiver@smi.stanford.ed u

Abstract

variables

H

that represent states of a system of inter­

est. Such states are typically not directly observable.
We review the problem of time-critical ac­
tion and discuss a reformulation that shifts
knowledge acquisition from the assessment of
complex temporal probabilistic dependencies
to the direct assessment of time-dependent
utilities over key outcomes of interest.

We

d well on a class of decision problems char­
acterized by the centrality of diagnosing and
reacting in a timely manner to pathological
processes. We motivate key ideas in the con­
text of trauma-care triage and transportation
decisions.

However, we can make inferences about the probabil­
ity distribution over states of the hypothesis nodes by
considering patterns of evidence that are influenced
by the system. As indicated by the influence diagram,
the hypothesis variable influences the values of a set
of observables, labeled as variables E. Some subset of

these evidential distinctions may be observed before

a decision is made, as indicated by the information
arcs extending from several of the observables to the
decision node.
As indicated in the influence diagram, the utility of
action is influenced by the action taken as well as by
the state of the system or world. Although we employ
a single system variable in the influence diagram to

1

represent critical aspects about the state of the world,

Introduction

the more general case of multiple hypotheses can be
represented by adding additional hypothesis nodes.

The nature and timing of actions by decision mak­
ers is often influenced by the pressures generated by
time-dependent processes. We will examine the oppor­
tunity to minimize effort expended on modeling com­
plex probabilistic dependencies over time by shifting
attention to the definition and direct assessment of
states that summarize important outcomes at future
times. After touching on the general problem of plan­
ning and action in time-critical contexts, we introduce
a set of time-critical decision problems and represen­
tational simplifications with the goal of bypassing the
handling of complex probabilistic dependencies over
time.

Finally, we will highlight the ideas in the con­

text of the real-world domain of time-critical medicine.

2.1

Temporal Processes and Sequences of
Actions

Let us now consider the problem of multiple actions
and outcomes taken over time.

In the general case,

we must consider the expected utility of outcomes in­
fluenced by different sequences of actions.

Figure 2

displays an influence diagram for a set of actions over
time. Rather than considering actions and value in an
atemporal or only implicitly temporal context, we now
index actions, observations, and states of the world by
time. As indicated in Figure 2, we seek to generate an
ideal sequence of actions or plan over time that max­
imizes expected utility, given background knowledge

2

Representations of Time-Dependent
Processes

Let us first start with a simple atemporal decision
problem.

Figure 1 displays an influence diagram for

a simple, one-shot decision problem.

Such formula­

and a set of observations seen over time. In the general
case, identifying such an ideal policy, where actions in­
clude decisions to gather information, is the challeng­
ing planning under uncertainty problem that has been

receiving increasing attention by the UAI community

[3, 4, 5, 16].

tions typically avoid making temporal relationships ex­

Let us explore the model in Figure 2 more closely.

plicit. As indicated by the dependencies, the utility of

Only some of the arcs, showing a subset of poten­

the outcome is a function of one or more hypothesis

tial dependencies among variables over time, are high-

Time-Critical Action

Plan

o o o

Figure 1: A simple decision model. Information arcs
pointing into the decision node represent information
known before action is taken. We use a single hypoth­
esis variable here to represent one or more significant
variables about the state of a system or world.
lighted in this figure. We represent in the model the
notion that the utility of outcomes is influenced by
the state of a system or the world at some t ime in the
future. Also, this prototypical model represents the
common situation that the states of the world at time
t often influence states of the world at timet+ 1, cap­
turing the notion that the current state of a system has
influence on future states Many processes that show
fluidity of change in variables of a system can be rep­
resented by this type of Markov dependency. Laying
at the foundation of such evolving dependent physical
processes is a combination of persistence in the overall
structu ra l fabric of objects and of ongoing temporal
influences; we typically take for granted such stability
and temporal influence in a large battery of physical
processes that we encounter daily.
.

As indicated by the dependencies between actions and
states, actions can directly influence states at increas­
ingly later periods of time depending on the temporal
properties of the action and states of the world. Also,
observations that are available in the present moment,
t0, may have been caused or influenced directly by
states existing at previous times. Such temporal de­
lays in the response to action and in the emitting of
evidence can lead to a variety of challenging modeling
problems. For example, in many cases, we know that
the evidence we are seeing in the present are caused by
states of the system in earlier periods. As an example,
the m odeling and assessment for the Vista decision­
theoretic monitoring application that has been used
at NASA Mission Control Center [7], took into con­
sideration the expected delay induced by the process
of processing and beaming to earth telemetry from the
Space Shuttle.
In work on Markov decision processes, utility is often
computed for sequences of states as a function of re­
wards assigned to individual states reached by a deci­
sion making agent [12, 14, 17]. In a variety of decision
contexts it can be difficult to structure the problem
to represent value as rewards on intermediate states.
Rather, it can be most appropriate and efficient to as­
se ss the utility over specific critical states as the value

251

{(A1,t,).. . (A,..t,)}

B----

0

Figure 2: Representing time and sequences of actions.
In this richer model, knowledge about time-dependent
processes is encoded in the form of variables represent­
ing the evolution of the system over time. A subset of
many of the typical dependencies are displayed.
of the future life lottery associated with these out
comes. Such outcomes are often defined in terms of
important results of actions taken in response to a set
of critical challenges.
­

3

Action and Cost
Contexts

m

Time-Critical

Timely action is often critical in facing real world chal­
lenges. Time-critical contexts are situations where the
expected value of an outcome is diminished as some
function of the delay of taking one or more actions
available to a decision maker or decision making sys­
tem. Real-world, time-critical decision problems are
typically cast in the context of an acute challenge or
opportunity which heralds the initiation of a decision
context. Challenges include a variety of processes and
influences that can threaten valued stability or equi­
libria in a system, or that reduce quantities of a valued
commodity. Opportunities include the development of
situations that are associated with new possibilities or
means to achieve a desired state of affairs.
Representations of time-dependent probability and
utility have been discussed in several communities.
There has been g rowing interest in time-dependent
utility in planning [1, 5] and automated decision
making [9]. Decision analysts working in such ar­
eas as medical decision making have considered time­
dependent probability and utility in building models
for consultation on time-pressured decisions (e.g., see
[15]). A variety of formal models of urgency and their
relationships to the value of computation is explored
in [11]. The consideration of Bayesian models con­
taining explicit temporal dependencies has been ex­
plored in detail by Dagum, et al. [2]. More recently,
researchers have been exploring a variety of methods
for efficiently solving such temporal Bayesian models
[13]. Finally, there is a rich literature exploring the
consideration of time-dependent processes in partially
observable Markov decision processes.

Horvitz and Seiver

252

of fuel and oxidizer, raising the temperature of the ex­

haust plume to a level that can destroy key engine

components.

We can gracefully introduce additional complexity into
simple pathological process models to represent criti­
cal context, as well as intermediate actions, observa­
tions, and outcomes-especially for less time-critical sit­
uation. Pathological processes can often be modeled as
broad classes of sequences of state transitions that are
parameterized by specific contexts representing spe­
Figure

3:

A formulation of a pathological-process

problem.

For this indicator model, the utilities of

states reached at system equilibrium are assessed. The
action taken influences the duration of a noxious pro­
cess on the system equilibrium.

cializations in the system and process.

Furthermore,

a variety of control actions can modulate pathological
processes.

Richer decision models can represent how

actions can diminish the effect of a pathological pro­
cess; we may wish to represent with dependencies the
influence of a variety of actions on the state of the
evolving system facing a dangerous erroneous process.

Our investigation of simplifications for time-critical
reasoning problems has been influenced by our experi­
ence with modeling and inference in the area of high­
stakes, time-critical arenas including trauma care and

[8, 6, 7].

aerospace

In particular, we have explored

simplifications for specific classes of problems, center­
ing on the definition of outcomes and on the develop­

ment of techniques for summarizing outcomes in terms
of time-dependent probability and utility.
3.1

Characterizing Time-Critical Processes

As an example, consider the case of a patient that be­
gins to hemorrhage a large quantity of blood into the
abdomen following a blunt a injury. The utility of the
outcome at equilibrium depends on the duration of the

process as well

as

on the interventional actions, such

as administering some quantity of fluids to the patient.
We will return to the case of introducing intermediate
actions that modulate a pathological process for the
trauma transportation decisions.
3.2

From Intermediate States to Key
Outcomes

Effective automated inference about ideal action may
require solving planning problems that explicitly ma­
nipulate

complex temporal dependencies

In the context of time-critical pathological processes,

and that

we can often reformulate problems of the form repre­

consider large sequences of action, observations, and

sented in Figure 2 into the simpler problem displayed

states of the world. However, in may often be appro­

in Figure

priate to assume simpler models and to expend effort

stage probabilistic dependency model and reformulat­

on the direct assessment of critical, summarizing out­

ing the problem into states or outcomes that summa­

comes.

rize complex transitions over time.

Figure

3 shows an influence diagram for a class of time­

critical decision problem we refer to
process problems.

as

pathological­

The version of the problem repre­

sented by the influence diagram in the figure captures

3

by abstracting away details of the multi­

Identifying and assessing the outcomes of interest are
important in formulating pathological process prob­
lems.

In one approach, we assess the probability of

key states or the utility over critical outcomes at some

extremely time-critical situations such as trauma-care

specific future period. In such a fixed horizon model,

transportation decision support and the propulsion­

we define a process and directly assess the probability

system problem at the

NASA

Mission Control Center.

Pathological-process problems are typically associated

of states or the utility of outcomes

n

periods from the

current moment or from the time a challenge is noted.

with well-characterized sequences of states or processes

Another approach is to model and assess the proba­

that occur over time.

Also, the expected utility of

bility or utility of states in terms of some indicator

outcomes of interest in these settings is often highly

or sentry event. When modeling outcomes with such

dependent on an initial burst of potentially correc­

indicator models, we assess the utility on the outcome

tive actions; significant losses are associated with de­

representing the future life history at the time the sen­

lay in taking appropriate action. In many time-critical

try event occurs conditioned on the state of the sys­

pathological-process contexts, an initial pattern of ev­

tem at that time.

idence is observed and a decision must be made about

ment is the utility over outcomes defined as states of

an action.

The outcome is relatively insensitive to

resources aimed at interleaving information collection
and action. An example of a pathological process rep­

An

example of this type of assess­

a system achieved when an some notion of equilibrium

is reached, following a destabilizing challenge. Such
an assessment is valuable for such realms as control­

resented in the NASA Vista system is the commence­

ling processes that may go awry but that will even­

ment of a propellant failure which changes the mixture

tually stabilize in some stable configuration or sum-

Time-Critical Action

253

view A as a single action or some sequence of actions
initiated at timet. The best action A (t) at timet is,
•

A*(t)

=

argm;xLu(A;,HJ,t)p(H JJE,�)

(1)

j

Figure 4: Direct assessment of time-dependent utility.
In some cases, it can be useful to formulate the task of
characterizing time-dependence as the direct assess­
ment of time-dependent utility on outcomes defined
by the intial state, corrective action, and duration of
a pathological process.
mary outcome. For example, the utility associated
with outcomes of pathological processes in propulsion
systems that are used to guide the Space Shuttle can
be assessed as the value of the ultimate short-term
outcome, following a set of firing and system control
actions, which lead to a new trajectory of the Shuttle
and to potential damage to systems that can provide
future propulsion actions [7].
For the fixed horizon or the indicator models, it can
be useful to assess outcomes directly in terms of the
utilities of the states of interest. As highlighted by the
model in Figure 4, rather than assessing and encod­
ing potentially complex intermediate time-dependent
changes in the probability of a system given differ­
ent actions and duration of the pathological process,
we summarize outcomes by assessing a time-dependent
utility, u(A, H, t) as a function of the action taken, the
state of the system, and the duration t of the patho­
logical process. Such direct assessment was explored
in building the NASA Vista system for providing de­
cision support for ground controllers about the best
way to react to complex telemetry. Time-dependent
utility was assessed as parameterized functions of the
state, action, and duration of the process. We found
that performing such a reformulation of the assessment
task can ease the burden of modeling and assessing de­
tails of time-dependent probabilities.

where p(Hj IE,�) is the probability of processes H,
given evidence E and background state of knowledge
�. Note that, as the system we are monitoring and
attempting to control is evolving in time, the best ac­
tion at time t, A* (t), is not necessarily equal to the
best action A" (t') at a later timet'.
In assessing time-dependent utility, we can often sum­
marize the variation in the utility over a large set of
outcomes as a function of the duration of a process
with parameterized functions that capture the basic
structure of the cost of time. Prototypical cost func­
tions include urgency, deadline, uncertain deadline,
and several variants of cost built as combinations of
these cost functions [10]. Such prototypical cost func­
tions are recurrent in many real-world applications and
arise in common interactions such as lost opportunity
and competition for limited resources. The urgency
context refers to the class of utility functions that as­
sign cost or diminishment of value as some monoton­
ically increasing function of delay. The deadline con­
text refers to cases where cost is zero or negligible until
some value of delay is reached, at which time a signif­
icant cost is incurred. The uncertain deadline is the
common situation of facing a uncertain deadline, rep­
resented as a probability distribution over a deadline.
4.1

Characterizing Losses with Delay

We can characterize the cost of delay in a decision con­
text with the expected cost of delayed action ( ECDA).
The ECDA is the difference in expected value of tak­
ing immediate ideal action, at time t0, and delaying
ideal corrective action until time t,
ECDA

=

m;x L u(A;, Hj, ta)p(H j\E,�)
j
-maxA Lu(A;,HJ,t)p(HjJE,�)

(2)

j

4

Expected Cost of Delayed Action

A useful measure for modeling and assessing outcomes
is the expected cost of delayed action. The principle
of maximum expected utility, dictated by the axioms
of utility, specifies that a decision maker should take
actions with the greatest expected utility. In time­
critical contexts, the utility of the outcomes of action
are a function of the actions and the time at which
they are taken. We shall use u(A;,Hj, t) to represent
the time-dependent utility of outcomes of actions A in
the context of time-dependent processes H. We can

We can compute the ECDA for any two moments in
time, t0 and t. We typically take t0 to be the present
moment and compute the ECDA for delays in action
until timet.
Variants of the ECDA measure have been used in ear­
lier decision support systems. The measure was first
developed for prioritizing the display of information
in the Vista-I system [8]. Beyond using the cost of
delayed action for prioritizing the display of possible
faults, Vista research also experimented with the dis­
play of an overall measure of criticality of a decision

Horvitz and Seiver

254

context, based on the rate at which the expected value

4.4

Considering Suboptimal Future Actions

of the best action is diminishing with time.
In the real world we cannot always assume that the
4.2

best action will be taken.

Modeling Uncertainty about the
Initiation of the Process

The

ECDA

is an upper

bound on the cost of delay. Unfortunately, subopti­
mal decisions may ultimately be taken in an attempt

Several specifications on ECDA can be useful. We use

to control a faulty process. We can integrate into the

to refer to the ECDA measure of

measure of the cost of delay consideration that such

loss between the time a faulty process begins and the

suboptimal decisions will take place. We term such a

comprehensive ECDA

time that corrective action is taken. However, we may
not know how long a faulty process has been underway
when it is diagnosed, or may be uncertain about the
time a faulty process began.

In such cases, even an

immediate response is associated with some compre­
hensive ECDA.

revised measure, the

dzagnosis (ECDM).

consider the probability distribution over the actions
that will be undertaken after delay,

ECDM=
m;x L

Handling the uncertainty in the initiation of a patho­

j

logical process is especially important in cases where
the losses associated with delayed action are nonlin­

ECDA

for additional delay depends on the

amount of time that has transpired since a process be­
gan. Thus, we must consider a probability distribution
over the duration of the process,
ECDA

d,

5

(4)

Example: Triage and
Transportation in Trauma Care

We will now highlight several key ideas in the con­

=

LP(io
d

=

- maxA

diE,e)[mlxLp(HJIE,Ou(A;,Hj,d)
j
LP(HjiE, Ou(A;, Hj, t)]

( 3)

j
4.3

u(A;, HJ, to)p(HjiE,e)

-LP(A;IE,0Lu(A;, Hj, t)p(HJIE,O
j

ear in the duration of a process. In such cases, com­
puting the

e xpec ted cost of delay and mis­
ECDM, we must

To compute the

text of time-critical decisions about the prioritization
of transportation and treatment for victims of trauma.
Trauma of various types and severities leads to time­
critical medical emergencies via the destabilization of
the victim's physiological machinery. Beyond the case
of trauma in a single patient, natural and man-made
disasters can lead to situations where multiple casual­

Default State of Control

ties may need medical attention at a trauma facility.

The notion of delayed action in the context of a patho­

We have explored the use of time-critical pathological

as captured in Equation 2, leaves

process models for supporting time-critical decisions

logical process

H,

implicit fundamental intuitions about default states of
control.

about trauma patient triage and transportation.

Delayed action is more explicitly character­

ized in terms of a sequence of states of control.

For

many complex systems, failures or pathologies requir­

5.1

Modeling Urgency at a Trauma Scene

ing time-critical corrective action lead to a prototyp­

One of the problems with effective triage of v ictims at

ical sequence of states over time.

a trauma scene is that skilled trauma experts are typ­

Thus, to be more

precise, we must define the cost of delay in terms of a

ically unavailable to provide assistance with diagnosis

corrective action or set of actions coming after some

and triage. As part of an effort to build an experimen­

period of a

default state of control.

tal system for assisting nonexperts with trauma-care

We can make a default state of control explicit in

ECDA computations by including a default control
context, C in the utility of action u(A; IC[t0,t], Hj, t),
where AIC[t0, t] refers to corrective action A being

taken at time t in the context of the persistence of

a default state of control active between time
time

t.

t0

and

The control context can can represent sim­

ple states of control or more complex, evolving con­
trol dynamics.

Control dynamics are defined by the

default manner a system will react in the context of
pathological process. For simplicity, we shall typically
drop the explicit specification of the default control
context, keeping in mind that it can be important to
re-introduce the specification on the default state of
control.

triage, we worked with expert trauma-care surgeons
on the construction of Bayesian models for diagnosing
pathological processes from context, signs, and symp­
toms that could be easily interpreted by paramedics
at a trauma site. As part of this work, we defined key
classes of physiological syndromes, representing patho­
logical processes arising from time-critical pathophys­
iologies. We assessed time-dependent utilities for the
classes

as

a function of delays in transporting patients

to a trauma facility. The diagnostic model and time­
dependent utilities enables us to compute measures of
ECDA that can be used to support patient transporta­
tion decisions.

A Bayesian network for generating a probability distri­
bution over pathological processes is displayed in Fig-

Time-Critical Action

90

60

Figure

5:

Delay of emergency center care (minutes)

A Bayesian network constructed to infer

the probability of key physiologic processes associated
with different urgencies from signs and symptoms ob­
served at a trauma scene.

255

Figure

6:

Time-dependent probabilities of survival.

These graphs display the expected time-dependent
change in the probability of survival as a function of
delay to treatment at a trauma center.

ure

5.

This model was simplified by defining hypothe­

ses of interest as a set of mutually exclusive and ex­
haustive primary physiological problems with trauma
patients.

The

primary

physiological problem is de­

fined as the most critical pathological process facing
the patient. Although the notion of primary problem
was useful in simplifying the model, this formulation

orrhage for a patient with a history of debilitating
heart disease would differ from the dynamics for a pa­
tient without heart disease.
For any set of findings at the trauma scene, we can

does not represent the potentially greater urgencies

employ the Bayesian criticality-assessment model to

associated with the coexistence of multiple physiologi­

compute a probability distribution,

cal problems. Findings in the model include variables

the key major physiological derangements in a patient.

p(II;IE,�) ,

over

that capture a variety of temporal notions that are

Using the probability distribution in conjunction with

useful for discriminating pathological processes such

the time-dependent utility curves allows us to compute

as observation of increasing chest retractions or

for each patient at a site an immediate urgency and

creasing perfusion over specific

5.2

de­

quantities of time.

Triaging Patients by Cost of Delayed
Treatment

an ECDA for alternate transportation actions. Trans­
portation and triage actions to move (or delay moving )

a patient to a treatment facility are associated with dif­
ferent expected delays. A pathological process model
can provide assistance to decision makers who seek to

For each syndrome, we assess from trauma experts the

maximize the response of a trauma system to multi­

time-dependent probability of a patient's survival as a

ple patients. Alternate transportation and treatment

function of the delay between the initiation of a desta­

plans can be evaluated in terms of their associated

bilizing insult to a patient's physiology and the receipt

expected costs of delay.

of attention at a center for treating medical emergen­
cies. Figure 6 displays graphs representing the assessed
change in the expected long-term survival of a patient
based in the class of injury and delayed treatment for
key classes of deranged physiology. Each injury class

defines an expected pathological process and default
control context.

Note that the decreases in survival

are nonlinear with delayed treatment. Thus, it is im­
portant to include estimates of the duration of a pro­

cess in the

ECDA

computation when there is great

uncertainty about the time of the trauma.
Additional assessment and modeling can be targeted

Figure 7 demonstrates inference with the Bayesian
model about time-critical physiologies for a set of find­
ings in a motorcycle accident patient.

Information

input about the patient in the findings worksheet in
the lower righthand corner of the screen photo show
the signs and symptoms observed about the patient.
The upper righthand portion of the photo shows the
inferred probability distribution over the pathological
processes.

The inference shows that the most likely

primary pathology in the unconscious patient is a se­
vere permanent injury to the brain.

Unfortunately,

the outcome of such injuries are not typically sensi­

at conditioning the pathological processes and default

tive to timely action.

control contexts on background physiologies. Consid­

manent severe brain injury, the system also infers that

eration of a set of default contexts describing a pa­

patient may be threatened by a time-critical patholog­

Beyond the likelihood of per­

ECDA. In

tient's pre-existing pathophysiologies can be added to

ical problems with significant high

the model.

For example, the dynamics of the long­

lar, there is a 0.1 probability of an intracranial hem­

term survival with delayed treatment of a severe hem-

orrhage. If this is the case, the patient would benefit

particu­

256

Horvitz and Seiver

In a real-world version of a trauma triage systems, dy­
namically updated traffic reports as well as informa­

Po�Cslllle Dlsord�:rs

D.•SI.SrWn Jl••d! lnjYII')'
D.D!II.Brllln ll_..a: •m:IIVuabl•

..

tion about the availability of resources at treatment

D.111.1;1r"nll..-n.t:lr�¥r'Pidly•�q�
0.01

.

_.._.. llralto

centers could be used to generate more accurate trans­

par�ct.ym.t

portation plans based on the ECDA.
Wod:sh�et
t1
•sldni�.Mian�:HNIII
•Mtdl:�����m lllllotarqod•
.ho.�ll ol COIISj! (AVPUJ: A•po��odtlo rulia
•Airw.r••,..••: Honnll
.RR: 11-20
•P'Iflph• p.llfflll;l•n J� 'l.wnds
.EMT Pulu R.C•: 100-1ZO
•Aicahal an llre.th Pr•-mt tf-)

..

Local Treatment versus Load-and-Go
Strategies

5.4

.

.

In Section 3.1, we discussed the graceful introduction

:l i6'i" 'mn
" -· =· ��b
'i'' wmm
" ' ii-.....�l

of sets of key intermediate actions to extend the sim­
ple time-critical process models. An ongoing area of
investigation in the realm of trauma care involves con­

I! II I

Lil

',1,

sideration of the merits versus the costs of pausing

I ,·,·;

at a site to initiate treatment of a patient.

Immedi­

ate treatment can provide early stabilization of patho­
Figure 7: Inference about the status of a victim of a

physiology but can also incur costs by delaying the

motorcycle accident.

transportation of the patient to a trauma center.

Findings are listed in the lower

A

righthand portion of the screen, and the leading pro­

formulation of ECDA can be employed for dynamically

cesses are ranked by probability in the upper righthand

determining the relative value of local treatment ver­

portion of the screen.

sus immediate transportation of the patient-referred

Recommended findings gener­

ated by a value-of-information computation appear on
the left side of the screen.

to as a

load-and-go

trauma transportation strategy.

In the general case, we can model the tradeoff between
various forms of treating on site and the load-and-go

from immediate transportation to a trauma center to

strategy centers on considering local attempts to stabi­

minimize the duration of the process.

lize a patient by changing the default control context.

In a multiple trauma patient setting we can harness the

tial treatment is to consider the influence of an attempt

probability distributions over pathological processes
and the expected costs of delay to support decisions
about the transportation of patients. Transportation
actions include decisions to dispatch of assets to as yet
unvisited sites, based on telemetered findings about
patients at the site. Given multiple transportation as­
sets and treatment facilities with different capacities
and capabilities, an automated system can use ECDA
computations to evaluate alternate plans.

One approach to assessing the costs and benefits of ini­
to stabilize the patient as both a means for buying ad­
ditional time as well as a way to increase the delay to
ultimate treatment.

That is, we consider the imme­

diate treatment procedures as equivalent to removing
some quantity of time from the duration of a patholog­
ical process,

te(HJ, l,t) ,

where te refers to the equiv­

alent time removed from the duration of pathologic
process H;, by employing local treatment strategy l,
applied at timet. Unfortunately, the commitment to
the local therapy will also delay the patient in getting

5.3

Modeling the Influence of Uncertainty in
Transport T imes

definitive treatment at a trauma center by adding the
time required to administer the therapy,

In the real-world of emergency medicine, transporta­
tion decisions are associated with uncertain delays in
moving the patient to a treatment facility. T here un­

m;x L P(HJIE,�)u(A;, Hj, to)

j

nate routes to transport a patient to a medical center.
Travel time depends on such critical variables as the

X,

the location of the treat­

- maxA

ment facilities, Y, and the time of day, T, which can
indicate the level of traffic on different routes.

De­

cisions about transportation requires consideration of
the probability of different transportation times
each route,

::::: lp(tiX,
t

t

- maxA

We

.
J

L:p(HJIE,�)u(A;, HJ, t)]dt
j

6

LP(HJIE, (}u(A;, Hj , t-te( H;,l, t)+t(l)) (6)
j

Summary

for

Y, T ) [ max L: p(HJIE,�)u(A;, HJ, to)
A

A for­

ECDA:::::

certainty in the amount of time it will take to use alter­

location of the patients,

t (l) .

mulation of ECDA that considers these factors is,

have

the

representation

of

time­

After reviewing more

general

making

models

for

decision

about

time­

dependent processes, we discussed pathological pro­
cesses

(5)

explored

dependent decision problems.

and

simplified

models

for

assessing

time­

dependent utility and for reasoning about time-critical
action. In particular, we investigated models that can

Time-Critical Action

be used to di agnosis and to control the duration of
pathologic processes. We re viewed the expected cost
of delayed action and discussed its use in reasoning
about losses with delay. Finally, we focused on an ap­

plication in the area of trauma care triage and trans
port ati on .

­

Acknowledgments
We are grateful to Brad Cushi ng for his assistance with

the con s tru c t i on and ass e ss ment of B ayesian mo dels
for diagno si ng classes of pathophysiology. Paul Dagum
and Serdar Uckun provi ded useful feedback on trauma­

care issues. The construction of the Bayesian model
was sup ported in part by A R PA in the cont ext of
t h e Trauma Care Information Management Systems

project. Bayesian n e twor k prototyping was performed
with KI software tools.

257

[8] E. Horvitz, C. Ruokoangas, S. Sriniva.s, and
M. Barry. A d ecision-t heore t i c approach to the
display of information for t i me -crit i ca l decisions :

In Proceedings of the Con­
ference on Space Operations and Automation and
Research, January, 1992, NASA Johnson Space
Cent er , August 1992. Nat ion al Aeronautics and
The Vista p roj ect .

Space Administration.

H orvitz and G. Rutledge. Time-dependent util­
ity and action under uncer tainty. In Proceedings
of Seventh Conference on Uncertainty in Artifi­
cial Intelligence, Los Angeles, CA, pages 151-158.

[9) E.

Morgan Kaufmann, San Mateo, CA, July 199l.
[10] E .J. Horvitz. Reasoning un d er var ying and uncer­
tain reso urce constraints. In Proceedings AAAI-88
Seventh National Conference on Artificial Intelli­
gence, Minneapolis, MN, p ages 111-116. Morgan

Kaufmann, San Mateo, CA, August 1988.

References
[1) M. Boddy and T. Dean. Solv ing t ime-dep endent
p lann ing problems . In Proceedings of the Eleventh
IJCAI. AAAI/International J oint Conferences on
Artificial Intelligence, August 1989.

[11] E.J. Horvitz .
Computation and Action Under
Bounded Resources. PhD thesis, Stanford Uni­
versity, 1990.
[12] R. Howard. Dynamic Programming and Markov
Processes. MIT Pre ss , Cambridge, MA, 1960.

[2] P. Dagum, A. Galper, E. Horvitz, and A. Seiver.
Unc ertain re asonin g and for e cast ing.
Interna­

[13] K. Kanazawa, D. K oll er , and S. RusselL St o chas­
ti c simulat ion a lgorit h m for dyn amic probabilistic

D e a rden and C. B outilier. Integrating planning

gence (UAI-95}, pages 346-351, Mont real , Que­

tional Journal of Forec as ting, 1995.

[3] R.

and exec u tion in stochastic d omains. In Proceed ­
ings of the Tenth Annual Conference on Uncer­
tainty in Ar tificial Intelligence (UA 1-94), pages
162-169, Seattle, WA, 1994.

[4) D. Draper, S. Hanks, and D. Weld. A prob ab ili s ­
tic model of action for least-commitment plann i ng
with information gath erin g. In Proceedings of the
Tenth Annual Conference on Uncertainty in Arti­
ficial Intelligence (UAI-94), pages 178-186, Seat­
tle, WA, 1994 .
[5] P. Haddawy, A. Doan, and R. Goodwin. Effic i e nt
decision-theoretic planning: Tec hniques and em­
pirical an alysis.

In Proceedings of the Eleventh

Annual Conference on Uncertainty in Artificial
Intelligence {UAI-95), pages 229-236, Montreal,
Quebec, Can ad a , 1995.

[6) E. Horvitz. Transmission and display of informa­
t ion : A decision-making perspective. Technical
Report Microsoft Technical Report MSR-T R-9513, Microsoft Research, Microsoft, March 1995.
[7] E. Horvitz and M. Barry. Display of informa­
tion for t i me- cri ti c al decision making. In Proceed­
ings of the Eleventh Conference on Uncertainty in
Artificial Intelligence, pages 296-305, Montreal,
Canada, August 1995. Morgan Kaufmann, San
Francisco, CA.

networks. In Proceedings of the Eleventh Annual
Conference on Uncertainty in Artificial Intelli­
bec, Canada, 1995.

[14) M. L. Littman, T. L.

Dean ,

and L. Pack Kael­

bli ng. On the complexity of solvi ng Markov de­
cision problems. In Proceedings of the Eleventh
Annual Conferen ce on Uncertainty in Artificial
Intelligence (UAI-95), p ages 394-402, Montreal,
Quebec, Can ada , 1995.

[15] R.A. McNutt and S.G. Pauker. Competing rates
of risk in a patient with su bara chn oid h emorrh ag e
and myocardial infarction: Its now or never . Med­
Ical Decision Making, 7(4):250-259, 1987.
[16] Mark A. Peot. Decision- Theoretic Planning. PhD
thesis, Stanford University, 1997.
[17) M.L. Puterman. Markov Decision Processes: Dis­
c rete Stochastic Dynamic Programming.
New York, NY, 1994.

W i l ey,

