ples from the nonmonotonic literature. Most
importantly, the sentences of our system can
be verified by performing an appropriate ex­
periment in the semantic domain.
1

should not be thought of as having any mean­
ing in. the sense of "most" or "typical"; they
are statements the user is prepared to accept
as part of an explanation as to why some­
thing may be true.
What, then, does a default mean? Within
the default logic camp, we know of no work
which provides a semantics for defaults, in
the sense that an experiment is described
that can be performed in the semantic do­
main to verify the truth of a default. It is
therefore compelling to view defaults as qual­
itative probabilistic statements where nu­
meric distributions are unavailable. We sur­
vey some of these views but note most re­
quire numbers, something default reasoning
intended to avoid, or have side effects.
Rather than "add semantics" to defaults,
we construct a sound non-numeric proba­
bilistic formalism called an inference graph.
We explore its mathematical properties, then
apply it to the standard examples. We con­
clude with a brief description of the imple­
mentation.

Introduction

Though default r�asoning involves reasoning under conditions of uncertainty, some
argue it is not probabilistic reasoning. Reiter and Crisculo [21] distinguish the two by
suggesting different interpretations for the
word "most" . Probabilistic reasoning gives
"most" a statistical connotation, whereas default logic gives it a prototypical sense. On
the other hand, Poole (18] claims defaults

275

2

What's in a default?

Poole et al [20] attempt to put both default
reasoning and diagnosis under a single urn­
brella by constructing a system containing a
set of facts F known to be true, a set � of
defaults, and g, a set of (possible) observa­
tions which are goals to be proved. Here we
assume F, �and g are propositional.

;

· ..

I
If D

is a subset of

FU D

I= g, and

�

Pearl shows p(flbe) � 0. Then, from

such that

FU D

is consistent.

p(flb) = p(fleb)P(elb) + p(ll-.eb)p(-.elb)

then D is an ezplanation of g. This system is
based on a theorem prover and can be used
in two ways. If g consists of observations
known to be true, we interpret g as querying
t»hy g?, and Dis a diagnosis of g. If g is not
known to be true, then g is interpreted as
querying t»hether g?, and g is a prediction of
FUD. The problem default logic runs into is
that there _is typically another D' such that
FuD' predicts -.g; this is known as the mul­
tiple eztension prob lem and is discussed be­
low. (This is a very abbreviated presentation
of default reasoning; for details on implemen­
tation and application see [15,14).)
AJJ pointed out in the introduction, de­
faults appear to have no semantics, and
many researchers study the relationship be­
tween default reasoning and uncertainty.
Rich [22) advocates adding certainty factors
to possible hypotheses to fine-tune a default
reasoning syst�m and concludes "default rea­
soning is likelihood reasoning and treating it
that way simplifies it" . While some argue
with her treatment, her conclusions seem to
be widely held. Ginsberg [4] pursues this ap­
proach.
At the 1987 Workshop on Uncertainty in
AI, Groaof suggested defaults are interval­
valued probabilities on the entire unit inter­
val. Default inference thus becomes closely
related to Kyburg's theory of interval-valued
probabilities [8,7).
In [9]; McCarthy states non-monotonic
sentences can represent statements of in­
finitesimal probability, but does not go into
detail. Pearl explores this in [12]. This inter­
pretation has some problems. Let e = emu,
b -:- bird, I = fly. If

it follows p( elb) � 0. But since a prior is
always bounded by its conditionals on any
evidence and the negation of that evidence,
we can show p(e) � 0.
Default logic also has this "property":
from no knowledge at all, we can prove -.emu
by cases from fly and -.fly using the contra­
positive forms C?f the defaults. This intro­
duces the following variant of the "lottery
paradox" (8].
Suppose kangaroos (k) are
exceptional because they have a marsupial
birth and platypusses (p) are exceptional be­
cause they lay eggs but dingos (d) have no
such exceptional traits. If
Example 2.1

ozzie-animal => e Vk V p V d,
then p( dl ozzie-animal) is close to one since
the disjunction of the other three is close to
zero. Default reasoning and circumscription
(16] suffer the same problem. Poole [17,3]
solves this by explicitly pruning the proof
tree with a set of sentences called constraints.
However, to do this, you need to know the
right answers in advance.

Besides making subclasses vanish, Pearl's
£-semantics suffers another problem: in gen­
eral, it is impossible to go out into a real
problem domain and find a set of conditional
probabilities infinitely close to one.
Bacchus[1] addresses this issue of practi­
cality and argues for thresholding, that is,
that a possible hypothesis stands for a prob­
ability greater than some threshold k > 1/2.
His system allows only a single defeasible in­
ference, since p(bla) > k and p(clb) > k do
not in general constrain the value of p (cia)
p(flb) � 1, p(fle) � O,p(ble) � 1
to be greater thank.
There seems to be no end to different prob­
(i.e., there are some non-bird emus) then
abilistic
semantics that might be added to
from
defaults or inference rules that might be in­
vented to come up with the right answers for
p(fle)_· p(flbe)p(ble) + p(fl-.be)p(-.ble)
·

276

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

the various examples. We claim it is neces­
sary to ask again what were the original goals
of formalisms such as default reasoning, in­
heritance hierarchies and semantic nets. We
should reconsider the original objections to
standard probability, and ask whether we
solve the problem in a principled way, with­
out tlie invention of new formalisms.

tic formalism based on standard probabil­
ity theory, conditional independence and sen­
rules for

Rather than give

accepting uncertain conclusions, the

inference graph allows us to make inferences
about

3.1

shifts in

contains four kinds of

inference graph

-f+. Links with double
logical links and the others
probabilistic links. Each node is labelled

links, =*, -, :;¢- and

arrows are called
are

with a name or set of names in lower case '
for example,

quaker or pacifist.

Links are at-

tached to a name or its negation at either

An inference graph is a strictly probabilis­

tences of confirmation.

An

Syntax

endpoint.

Inference graphs

3

3.2

belief.

3.3

Semantics

Nodes in an inference graph denote events.
Generally events have two mutually exclu­
sive outcomes, for example fly or

Occa­

--.fly.

sionally an event may have several mutually
exclusive outcomes, (not all of which need be
specified), for example

{hawk, dove}.

Sentences about confirmation1 are repre­

Confirmation

sented by the four kinds of links in an infer­

An interesting mathematical property of log­

ence graph:

sequent increases belief in the antecedent.

a- b

means

a=* b

means 1

a -f+ b

means

ical implication is that knowledge of the con­
That is, a =*
Rosenkrantz

mation,

b implies that p(ajb) ;:::. p(a).
(23) calls this property confir­

and we will see it has many of

the same useful computational properties as

other probabilistic formalisms.
Confirmation describes a

shift in

belief; it

seems to be the weakest probabilistic prop­
erty a default

ought to have.

This provides an

interesting venue to explore: rather than use
knowledge of the form "birds are more likely
to fly than not" , we consider knowledge of
the form "an individual is more likely to fly
once we learn that it is a bird" .

Consider Nutter's example ( 10], where in

springtime it is not true that most birds fly,
since most birds are flightless nestlings. Yet,
the information that an individual is a bird
inclines us to shift belief in favour of flying.
This

also admits an interesting kind of sen­

tence. If we say "Irish Canadians have red
hair" , we do not mean mor� than half or al­
most all Irish Canadians have red hair, even
though the stereotype is widely held.

a:;¢- b means

(Note

=

p(bla) > p(b).

p(-.b!a) > p(-.b).
1

=

p(-.b!a) > p(-.b).

that we insist on strict inequality.

This means that links such as

sky-is-blue
graph.

2+2

=

3

=*

cannot appear on an inference

For the same reason, we also insist

all events are possible. )
The topology of the inference graph carries
information about independence of events.

Definition 3.1 If

p(a!b) = (a), a
unconditionally independent.

Definition 3.2 If

and

p(a!bc) = p(a!b), a
ditionally independent of c, given b .

is

b

ar

e

con­

1Poaaibly confirmation i s too strong a term where
logical implication is not involved.

We use confir­

mation here in the sense of partial confirmation,_ or
relevance.

277

p(bja) > p(b).

I
If a

is a node, and b1, ..., bn are the nodes
directed into a, then a is conditionally inde­
pendent of all the predecessors of the b, given
the outcomes of the bi.
Thus, an inference graph may be seen as a
non-numeric influence diagram[25]. We next
explore the kinds of inferences about confir­
mation that we can make.
4

The confirmation relation

Definition 4..1 If

write conf{a,b).
4.1

p(ajb)

>

p(a), we also

Symmetry

Lemma 4..2 If

Proof:
Rule. 0

coni(a, b), then conj(b, a).

Follows immediately from Bayes'

This allows our system to be reversible; if
we observe sneeze we can confirm has-cold.
Alternately, if we know that someone has a
cold we can predict they will sneeze. Thus
we can use the same. formalism for prediction
and diagnosis.
4.2

Negation

Lemma 4..3 If coni(a, b), then

coni(-.a, -.b).

By definition, p(ajb) > p(a). Negat­
ing both sides yields p(-.ajb) < p(-.a). Then
p(bj-.a) < p(b) by Lemma 4.2 and negating
again yields p(-.bl..:.,a) > p(-.b). Another ap­
plication of Lemma 4.2 yields the desired re­
sult. 0
Thus, not only does bird increase belief in
fly, -.bird increases belief in -.fly. An inter­
esting intermediate result is that the "contra­
positive" form of a link yields a valid infer­
ence, so long as it is made from a single link.
This means use of the contrapositive form of
a link is valid, bu.t the context of such an
inference must be carefully restricted. Infer­
ence graphs also explain why default reason­
ers based on a theorem prover sometime run
Proof:

into difficulties when they apply the contra­
positive: they viola.te independence assump­
tions.
4.3

Logical Inferences

coni(a, c) and conj(b, d)
where c and d are outcomes of the same ran­
dom variable, and a f= b, then conf{c,ab).

Lemma 4..4. If

p(cjab) p(cja) > p(c), since sen­
tences of probability hold for logically equiv­
alent propositions. 0
Default reasoners produce separate argu­
ments for c and d and attempt to choose
among the arguments by appeal to "speci­
ficity" . Poole [19] calls it preferring the most
specific theory and Kirby [6] calls it choosing
the most specific extension.
W hile the default logic view seems to be
to prefer the conclusion based on the most
specific knowledge, we remark that there is
not universal agreement on this in the prob­
abilist community when statistics are not
good. Kyburg [7,8] suggests we make an
inference based on the narrowest reference
class for which we have adequate statistics.
Some Bayesians suggest that data from var­
ious subclasses be combined [2]2•

Proof:

=

I
I
I
I
I
I
I
I
I
I

b f= a, but a � b then

I

Proof:

This generalizes the property of
logical links to the rest of the graph. 0

I

4. 4

I

Lemma 4..S If

conf(b,a).

Transitive inference

Default proofs consist of more than a single
inference; part of the appeal of such reason­
ers is that they appear to create and argu­
ment by making inferences towards a goal. In
general, if a - b and b - c are links on an in­
ference graph, we cannot conclude conj(c, a).
However, if c is conditionally independent of
a given b, it can be shown that conj(c, a). In
2

Thia reference

Cheeseman.

was

pointed out to us by Peter

I
I
I
I

278

I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

Proof: p( albc) = p(alc) > p(a), from the
fact, conditional independence gives us much
more than transitivity. Not only can we re­ definition of conditional independence. 0
verse the inference, we can perform transduc­
tion, inferring evidence from other evidence. Lemma 4.9 (Relevance) Suppose conf(a,c)
and conf(b,c} and a is conditionally indepen­
We can also confirm certain conjunctions.
dent of b given c. Then conf(ab,c).
Lemma 4.6 (Probabilistic Resolution} If
there exists c such conf(a,c) and conf(b,c) Proof: conf(a,b) follows from Lemma 4.6,
and a is conditionally independent of b given and p(alb) < p(a, c) from Lemma 4.7. Then
c, then conf(a,b).
p(ablc) = p(alc)p(blc) < p(alb)p(b). 0
Proof: By contradiction. Suppose p(alb) �
p(a). From the premises and an identity of 4.5 Other inferences
probability it follows p(alb) � p(al-.,b). Then,
The following two lemmas address situations
that prove to be useful in Section 5.3. The
p(alb) p(alcb)p(clb) + p(al-.,cb)p(-.,clb).
( I
( I
proofs are straightforward and we omit them.
I
I
I
p a -.,b) p a c..., b)p(c ....,b)+p(a -,c...,b)p(...,c ....,b)
Simplify using the conditional independence LeiDDla 4.10 If coni( ...,a, b), coni(a, c), and
b � c, then coni(a, -,be).
knowledge, then subtract to obtain
=

=

0

•

p(al-.,b)- p(alb)
- (p(alc)- p(al...,c))(p(cl-.,b)- p(clb)).
�

Lemma 4.11 If

r

decessors of g, and

and e are the direct pre­

1. r I= e,
2. a I= e,
3. r is unconditionally independent
of a,
4. conj(g, e),
5. conj(-.g, r) ,

But then both terms must be positive, con­
tradicting the premise that conj(b, c). 0
Unsurprisingly, each such inference results
in a dilution of confirmation. This lemma is
needed for later results.

conf{a,b} and conf{b,c) and
then conf(g, a).
a is conditionally independent of c given b,
then p(alc) < p(alb).
Lemma 4.7 If

5

Proof:

p(alc)

p(albc)p(blc) + p(al-.,bc)p(-.,blc)
= p(alb)p(blc) + p(al-.,b)p(-.,blc)
p(alb)p(blc) + p(alb)p(-.,blc)
<
- p(alb)(p(blc) + p(-.,blc))
p(alb)o

5.1

Examples
Birds fly

=

=

I
I
I
I

The next two lemmas yield two ways of
confirming conjunctions of events.

This inference graph aims to capture a lot
of information. If something is a bird, we
Lemma 4.8 (Irrelevance) If conf(a,c) and believe it is more likely that it will fly, and
a is conditionally independent of b given c, if it flies, it is more likely to be airborn. If
something is an emu, we are less likely to
then conf(a,bc).

279

I
I

believe it flies, but if it is a flemu (flying emu)
we again change our belief. We are inclined

to believe that birds have feathers.

I

W hat

inferences can we make from this graph?

Birds fty,

emus don't

conj(fty, bird)
single

More

links

and

coni{-.fly, emu)

containing

importantly,

this

we

from the

information.

cannot

conf(fly,emu}, i.e., we do not have the
tiple extension"

Emus don't vanish
is true: we show

We

problem.

Lemma 4.4 to conclude

I

We can prove

Our

quaker in­
creases belief in dove and republican increases
belief in hawk. Since the graph contains no

prove
"mul­

can use

that

information· about the joint distribution, we

coni{-.fly, b ird/\ emu).

do not conclude either

hawk or dove if Nixon

is both.

Exactly the opposite

coni{ emu, bird).

system concludes

However,

Note that

ers

we do not accept conclusions, just increase

and

we want to

Republicans

conclude

are

political.

exelusion (S ].

Default reasoners simply add

all the links with the result that
In default reason­

.true given

ers based on theorem provers, there is typi­
cally a single proof of
the default "birds

airbom from emu using
fly". Poole (13] solves this

by accepting only what is true in every ex­

tension. The semantics of extensions are not
very well understood; it is trivial to gener­
ate probability distributions where proposi­
tions true in every extension are less likely
than those that are. not. Thus the meaning
of this conclusion is unclear, We conclude an
individual is less likely to be airborn given it
is an emu because

coni(-.airbom, -.fly)

airbom

coni( emu, -.fly)

and

independent of

emu given fly.

Feathered things fty
we can show

and

is conditionally

conj{feathers, fly) using c =

4.6,
b ird.

dove

or

-.dove[13].

political

is

It is possible

to prove that an object about which nothing
is known is a political non-emu!
We solve the problem in this formalism
by making

hawk

and

dove

mutually exclu­

sive but not necessarily exhaustive outcomes

Below is the historic example of

not

ing to draw an inference. H Dick is both a

show that

-.hawk

is confirmed by

quaker. H
po­
quaker.

we allow this, then we can confirm both

litical and

its negation given

Royal and African Elephants

This appears in

[24,5].

Intuitively, the graph

is suppose to show elephants are typically
gray, but Royal elephants are not. H Clyde is

elephants are gray. If

phant

royal is

true, then

ele­

is true and the conditional indepen­

Quaker and a Republican, we do not want to

dence assumptions shield

conclude he is a hawk or dove.

of

280

I
I
I

We use Lemma 4.11 to conclude African

want­

I

and transitive inference is not being able to

dove, we can make the desired inference using
Lemma 4.6. T he price we pay for consistency

are we to conclude about grayness?

Modified Nixon Diamond

I

I

Since

conditionally independent of

both and African and a Royal elephant what

5.2

I

political is
quaker given

of some random event.

5.3

W ith Lemma

In­

heritance sy stems cannot represent mutual

our belief in them.

Emus are not airborn

Quak­

I

african and

gray from the effect
we conclude conf(-.gray,{royal

I
I
I
I
I
I
I

I
I
I

african]). This would not be true if the links sists of a straightforward transcription of the
from royal and african to elephant were prob­ Lemmas in Section 4 into Prolog and the sys­
tem prints a readable proof of the probabilis­
abilistic.
tic inferences it makes.

I

Acknowledgements

I
I
I
I

Horty et al and Sandewall disagree on this.
We claim there are no "right" answers to
this question and we build different graphs
to model domains with different properties.
5.4.

Naive diagnosis

Consider the diagnostic dual to the "birds
fly" problem.

I
I
I

References
If we observe sneeze, a default reasoner
produces all three diseases as diagnoses. The
inference graph confirms both flu and w-flu;
of these it is easy to prefer the most probable
diagnosis confirmed by the observations. If
we observe -,sneeze only o-ftu is confirmed.
·

I
I
I
I
I
I
I
I

The research of the first author was
supported by graduate scholarships from
NSERC and the Institute for Computer Re­
search at the University of Waterloo. The
research of the second author was supported
under NSERC grant A6260. Thanks to Ro­
mas Aleliunas, Andre Trudel, Bruce Spencer,
Peter VanBeek, Jimmy Lee and Paul van
·Arragon for thorough comments on an earlier draft. Fahiem Bacchus suggested Lem­
mas 4.10 and 4.11. Thanks to the anonymous
referees for comments.

6

Conclusions

We applied the formalism to many other
default inference problems including plan
recognition and stereotyping with positive
results. In general, we obtain answers that
agree with intuition. Where we haven't, the
underlying sound probabilistic basis has al­
ways provided the tool for understanding the
structure of the particular problem.
We have implemented the system in Pro­
log. A set of input probabilistic and log­
ical arcs are compiled into a graph that
is used specifically for testing conditional
independence using Pearl's definition of d­
separability[ll]. The rest of the system con-

281

[1] Fahiem Bacchus. A Heterogeneous In­
heritance System Based on Probabilities.
Technical Report 87-03, University of
Alberta Centre for Machine Intelligence,
1987.
[2] Bradley Efron and Carl Morris. Stein's
estimation rule and its competitors:
an empirical Bayes approach. Journal
of the American Statistical Association,
68(341):117-130, March 1973.
[3] Denis Gagne.
The Multiple Extension Problem Revisited. Technical Re­
port CS-87-30, University of Waterloo
Department of Computer Science, 1987.
[4] M�tthew Ginsberg.
Non-monotonic
reasoning using Dempster's rule. In
Proceedings AAAI-84, pages 126-129,
August 1984.
[5] David S. Touretzky J .F. Horty and
Richmond H. Thomason. A clash of in­
tuitions: the current state of nomono­
tonic multiple inheritance systems. In

I
Proceedings IJCAI-87,

pages 476-482,

[16]

fault reasoning. 1987. submitted.

1987.

[6]

Bruce R. Kirby and D.L. Poole.

The

[17]

Henry

E.

class.

Philosophy of Science,

Kyburg.

- The

reference
50:374-

[18]

McCarthy.

Applications

of

AAAI Workshop on
Nonmonotonic Reasoning, pages 373-

384, 1984.

[19]

28:89-118, 1986.

cir-

explanation. In

probability. In

[20]

In Nick Cercone and Gordon McCalla,

The Knowledge Frontier: Es­
says in the Representation of Knowl­
edge, Springer-Verlag, New York, 1987.

Judea Pearl. Fusion, propagation, and

Artificial

[21]

Proceedings
Probabilistic Semantics
IJCAI-81,
pages
270-276,
1981.
for Inheritance Hierarchies with Ezcep­
·
tions. Technical Report CSD870052, [22] Elaine Rich. Default reasoning as likeli­
UCLA Computer Science Department,
hood reasoning. In Proceedings AAAI1987.
83, pages 348-351, 1983.

Judea Peart

David Poole. An architecture for abduc­

[23]

un­

Roger

D.

Rosenkrantz.

1977.

David L. Poole.

Compiling a Default [24]
as
Re oning System into Prolog. Tech­

Erik Sandewall.

nical Report CS-88-01,

tems with exceptions.

University of

ence, 1988.
David L. Poole.

Defaults and Conjec­
tures: Hypothetical Reasoning for Ez­
planation and Prediction. Technical Re­

port CS-87-54, University of Waterloo
Department of Computer Science, 1987.

282

Nonmonotonic infer­

ence rules for multiple inheritance sys­

IEEE,

[25]

Inference,

Reidel, Boston,

Method and Decision.

published draft.

Waterloo Department of Computer Sci­

[15]

Raymond Reiter and Giovanni Crisculo.
On interacting defaults. In

tive and default reasoning. 1988.

[14]

a logical reason­

editors,

Intelligence, 29:241-288, 1986.

[13]

Theorist:

ing system for 'defaults and diagnosis.

Proceedings IJCAI-1987,

structuring in belief networks.

[12]

Proceedings IJCAI-85,

David L. Poole, R.G. Goebbel, and R.
Aleliunas.

Uncertainty and

pages 373-379, 1987.

(11]

On the comparison

pages 144-147, 1985.

Artificial Intelligence,

Jane Terry Nutter.

David L. Poole.

of theories: preferring the most specific

cumscription to formalizing common­
sense knowledge.

David L. Poole. A logical system for default reasoning. In

Logical Founda­
tions of Statis·tical Inference. Kluwer

Academic, Dordrecht, Holland, 1971.

[10]

Artificial

Department of Computer Science, 1987.

Henry E. Kyburg, Jr.

J.

1988.

port CS-87-59, University of Waterloo

397, 1983.

[9 ]

A logical framework

Intelligence, to appear. Also Tech Re­

mitted.

[8]

David L. Poole.

for default reasoning.

multiple extension problem. 1988. sub­

(7] .

David L. Poole. F ixed predicates in de-

Proceedings of the

74:1345-1353, October 1986.

Ross D. Shachter.

Probabilistic infer­

ence and inftuence diagrams.
1987.

search.

Submitted to

April

Operations Re­

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

