in confounding bias if such exists. IV measurements
should therefore be discarded.
This result is far from obvious. First, an instrumental
variable meets all the statistical properties that one
normally associates with a confounder:
1. It is a pre-treatment variable, so, it is certainly
not affected by the treatment, nor does it interfere with the causal pathways from treatment to
outcome.
the treatment is said to become â€œignorableâ€ (Rosenbaum
and Rubin, 1983) or â€œunconfoundedâ€ (Pearl, 2009a). The
â€œbiasâ€ considered here is bias of identification, not estimation, and is sometimes referred to as â€œinconsistency.â€
2
The same applies to stratifying on these variables, using them for matching, using them as predictors in regression, or including them in inverse probability weighting or
in the â€œpropensity scoreâ€ function (Rosenbaum and Rubin, 1983). The asymptotic equivalence of these methods
is demonstrated in Pearl (2009a, pp. 348â€“51).
3
A previous version of this paper attributed the discovery to Wooldridge (2009), I have subsequently become
aware of the Working Paper by Bhattacharya and Vogt
(2007).
4
Roughly speaking, an instrumental variable is a variable associated with treatment but not with other factors
that may affect outcome when treatment is fixed (by intervention). See (Pearl, 2009a, p. 248) for formal definitions
and Fig. 1 for graphical representation.

2. It is related to treatment
3. It is related to outcome
4. It is related to outcome conditioned on treatment.
Thus, an IV seems to behave just like an ordinary
confounder that begs to be controlled. Although the
analysis of â€œconfounding-equivalenceâ€ (Pearl, 2009a,
pp. 345â€“6; Pearl and Paz, 2010) identifies IVâ€™s as bias
modifiers, i.e., capable of increasing or decreasing bias,
the idea that the modification always goes in the wrong
direction (i.e., increased bias), is rather surprising, and
calls for further analysis.
Second, the phenomenon stands contrary to current
practices of covariate selection, such as those employed
in propensity score methods. The prevailing practice
is dominated by the belief that adding more covariates to the analysis can cause no harm (Rosenbaum,
2002, p. 76), especially covariates that are powerful
predictors of the â€œtreatment assignment.â€ For example, a popular tutorial article by Dâ€™Agostino, Jr. (1998)
states:
â€œ...if one has the ability to measure many of
the covariates that are believed to be related
to the treatment assignment, then one can
be fairly confident that approximately unbiased estimates for the treatment effect can be
obtained.â€ p. 2267.
Rubin (2009) has further reinforced this attitude by
stating that â€œTo avoid conditioning on some observed
covariates... is distinctly frequentist and non-scientific
ad hockery.â€
This attitude relieves investigators from thinking
about cause-effect relationships in the problem but
is based on false premises (Pearl, 2009b) and leads,
as noted by Bhattacharya and Vogt (2007), to wrong
practical advice. For example, a major 2007 paper in the Journal of the American Medical Association advises investigators to include variables that are
predictive of treatment assignment without regard to
whether they are predictive of outcome (Dâ€™Agostino,
Jr. and Dâ€™Agostino, Sr., 2007). The findings of this paper prove the opposite; disregarding the outcome leads
to unwanted consequences. Whenever some residual
bias persists, the more accurately one predicts the
â€œtreatment assignmentâ€ the higher the bias. More generally, we will show that the prevailing over-emphasis
on modeling the â€œtreatment assignmentâ€ while disregarding the outcome (Rubin, 2002) is misguided; modeling the â€œoutcome mechanismâ€ is in fact a much safer
strategy for estimating causal effects in observational
studies.

In this paper we derive (Section 2) and explain (Section 3) the bias-amplification phenomenon in a structural model setting and then extend the analysis in
three directions. First (Section 4), we quantify the
condition under which a confounding variable ceases
to act as a bias reducer and instead becomes a bias
amplifier. Second (Section 5), we consider non linear systems and show that the bias-amplification potential of instrumental variables extends over to nonlinear models, though not as pervasively as in linear
models; there are cases where conditioning on an IV
reduces bias and, moreover, conditioning on instrumental variables may introduce new bias where none
existed before. Finally (Section 6), we examine the effect of instrumental variables on selection bias created
by preferential exclusion of units from the study (as
in case-controlled studies,) and show that, in general,
conditioning on an IV has no effect on such bias, unless
the exclusion depends on factors that cause the treatment. The conclusion section summarizes the main
findings of the paper and assesses their methodological
ramifications in view of the on going conflict between
the â€œexperimentalistâ€ and â€œstructuralâ€ approaches to
causal inference.

2

ANALYSIS

We will first consider a linear structural model, given
in Fig. 1 where X represents treatment, Y is the outcome of interest, U is an unobserved confounder, and
Z is an instrumental variable with respect to the causal
effect of X on Y . For simplicity, all variables will be
assumed to be zero-mean and unit-variance. We will
show that conditioning on Z is harmful, for it increases
the bias in the estimate of c0 .
We need to compare three quantities:
âˆ‚
E(Y |do(x))
âˆ‚x
âˆ‚
A2 =
E(Y |x)
âˆ‚x
âˆ‚
A3 =
E(Y |x, z)
âˆ‚x

A1 =

A1 is the incremental causal effect5 of X on Y, A2 is
the (unconditional) incremental dependence of Y on
X, given by the regression coefficient of Y on X, and
A3 is the incremental conditional dependence of Y on
X, given by the coefficient of X in the regression of Y
5
Readers versed in potential-outcome notation can identify E(Y |do(x)) with the counterfactual expression E(Yx );
both are given by the conditional expectation E(Y |x) in a
modified structural model, with c1 and c3 set to zero (see
(Pearl, 2009a)).

on X and Z. A2 is often referred to as the â€œcrude,â€ or
â€œnaiveâ€ estimate of A1 = c0 .
The unadjusted bias is given by the difference

Î± in terms of c3 and c1 . Multiplying (4) by Z and
X, taking expectations, and invoking the instrumental
assumption cov(Z, U ) = 0, we obtain:
E(U Z) =
E(U X) =

B0 = A2 âˆ’ A1
while the bias after conditioning on Z = z is given by

Î²=

Our task is to compare the magnitudes of B0 and Bz
under various assumptions about the data-generating
model.

= Î²E(XZ) + Î±E(Z 2 ) = Î²c3 + Î±
= Î²E(X 2 ) + Î±E(XZ) = Î² + Î±c3

yielding:

Bz = A3 âˆ’ A1

c1
1 âˆ’ c23

A3 = c0 + c2

U
c3

c1
X

Bz =

Y

Figure 1: Linear model with instrumental variable Z
and confounder U .

A1 = c0
(1)
A2 = c0 + c1 c2
(2)
X
âˆ‚
âˆ‚
A3 =
E(Y |x, z) =
E(Y |x, z, u)P (u|x, z)
âˆ‚x
âˆ‚x u
âˆ‚ X
=
E(Y |x, u)P (u|x, z)
âˆ‚x u
âˆ‚ X
=
(c0 x + c2 u)P (u|x, z)
âˆ‚x u
= c0 + c2

âˆ‚
E(U |x, z)
âˆ‚x

(3)

Eq. (1) follows from the definition of A1 , Eq. (2) follows from Wrightâ€™s rule of path analysis, and Eq. (3)
was derived above using the structural assumption
E(Y |x, z, u) = c0 x + c2 u.
Our next step is to evaluate the right hand side of Eq.
(3) in terms of the structural coefficients c3 and c1 .
We start with the regression of U on X and Z:
u = Î²x + Î±z + 

c1 c3
1 âˆ’ c23

(5)

c2 c1
âˆ‚
(Î²x + Î±z) = c0 +
âˆ‚x
1 âˆ’ c23

(6)

We now have A1 , A2 , and A3 evaluated, from which
we can compute the biases B0 and Bz , giving

c2
c0

Î±=âˆ’

Substituting (5) in (3) enables us to evaluate A3 , giving:

For the model of Fig. 1, we have:
Z

0
c1

(4)

where  is the residual error and Î² and Î± are chosen
so as to minimize the square error E[u âˆ’ Î²x âˆ’ Î±z]2 .
It is well known that this minimization is achieved
when cov(, x) = cov(, z) = 0 and then, if E(U |x, z)
is linear in x and z, we have E(U |x, z) = Î²x + Î±z.
Therefore, to evaluate (3) we need to express Î² and

c2 c1
,
1 âˆ’ c23

B0 = c1 c2 ,

Bz =

B0
1 âˆ’ c23

(7)

Clearly, |Bz | â‰¥ |B0 | regardless of the signs of c1 and
c2 with strict inequality holding whenever |B0 | > 0
and |c3 | > 0. The same result holds when U is a
vector of confounding variables. Thus, conditioning on
1
Z amplifies the unconditioned bias by a factor 1âˆ’c
2.
3

3

INTUITION

For intuitive understanding of this phenomenon, consider the transition from X = 0 to X = 1, assuming a
simplified equation X = U + cZ. By conditioning on
Z = z, we are comparing units for which U + cz = 0
with those for which U + cz = 1. The mean difference
in U is of course unity
E(U |X = 1, Z = z) âˆ’ E(U |X = 0, Z = z) = 1
and this difference will be transmitted to Y and translate into the bias
E(Y |X = 1, Z = z) âˆ’ E(Y |X = 0, Z = z) âˆ’ c0 = c2
If, on the other hand, we do not condition on Z but
let it vary freely, the variation in Z will â€œabsorb,â€
or â€œaccount forâ€ part of the change in X, and only
part of that change will be transmitted through E(U )
onto E(Y ). This can be seen quite clearly if we imagine that U and Z are uniformly distributed over the
unit square. For any stratum X = x, 0 â‰¤ x â‰¤ 1, U
will be uniformly distributed from 0 to x, with mean
E(U |X = x) = x/2. Therefore, the mean difference
(in U ) between units for which X = U + cZ = 0 and
those for which U + cZ = x becomes
E(U |X = x) âˆ’ E(U |X = 0) = x/2 âˆ’ 0 = x/2

which is merely half of the difference in the conditional
expectation

4

E(U |X = x, Z = z) âˆ’ E(U |X = 0, Z = z) = x
More generally, for any joint distribution of U and Z,
we can write:
E(U |x) = Î£z E(U |x, z)P (z|x)
= Î£z (x âˆ’ cz)P (z|x)
= x âˆ’ cE(Z|x)

THE LINE BETWEEN
INSTRUMENTS AND
CONFOUNDERS

We now extend this result in three directions. First
we relax the assumption that Z is a â€œperfectâ€ instrumental variable by allowing it to influence Y directly
as shown in Fig. 2. We ask for the relative values of
Z

U
c
4

from which we obtain

c
1

c
3

E(U |X = 1) âˆ’ E(U |X = 0)

c
2

= 1 âˆ’ c(E(Z|X = 1) âˆ’ E(Z|X = 0)).
X

The second term on the right is always positive, regardless of whether X and Z are positively or negatively correlated (respectively, c > 0 or c < 0).6 We
conclude therefore that mean difference in U diminishes when we refrain from conditioning on Z:

c0

Y

Figure 2: Model in which Z is both a confounder and
an (imperfect) instrumental variable relative to X, Y .

c3 and c4 that would turn Z from a bias-amplifier to
a bias-reducer. Repeating the derivation of (6) with
< E(U |X = 1, Z = z) âˆ’ E(U |X = 0, Z = z) E(Y |x, z, u) = c0 x + c4 z + c2 u leaves A3 and Bz the
same, but changes A2 to read
=1

E(U |X = 1) âˆ’ E(U |X = 0)

and the bias transmitted onto Y will likewise be reduced:
E(Y |X = 1) âˆ’ E(Y |X = 0)

A2 =

6

More formally, we have:

E(U |X = x)/x

= Cov(XU )/V ar(X)
= Cov[U (U + cZ)/V ar[(U + cZ)2]
= V ar(U )/(V ar(U ) + c2 V ar(Z)) < 1

Thus, only a fraction of the unit change in X will be transported over to U , and then to Y .

(8)

We see that Z becomes a bias-reducer when

< E(Y |X = 1, Z = z) âˆ’ E(Y |X = 0, Z = z).
The last remark worth noting in this section is that an
IV may easily exhibit Simpsonâ€™s reversal, also called
â€œsuppression effectâ€ or â€œSimpsonâ€™s Paradoxâ€ (see Pearl
(2009a) for survey and analysis). This can be seen
from Eqs. (3) and (6); if c0 and c1 c2 have opposite
signs, A2 and A3 may be of opposite signs as well.
This means that the association between X and Y in
each stratum of Z may be of opposite sign to the crude
association, taken over all strata of Z. While such reversal is usually attributed to Z being a confounder,
the analysis above shows that the reversal can just as
easily be generated by an IV. Indeed, this follows from
the fact that, if U is unobserved and X continuous,
the IV model of Fig. 1 is statistically indistinguishable from a model in which Z is a cause of both X
and Y (as in Fig. 2); every joint distribution P (x, y, z)
compatible with one model is also compatible with the
other (Pearl, 2009a, pp. 274â€“5).

âˆ‚
E(Y |x) = c0 + c2 c1 + c3 c4
âˆ‚x

Bz â‰¤ B0 = c2 c1 + c3 c4
or

c4
c2 c1
â‰¥
c3
1 âˆ’ c23

(9)

Thus, for Z to become a bias-reducer, the effect of Z on
Y must exceed its effect on X by a factor c2 c1 /1 âˆ’ c23 .
This may be a tall order to meet when c3 is close to
unity. Ironically, this means that the best predictors
(of X) are also the most dangerous bias amplifiers.
This finding should be of concern to program evaluation researchers and propensity score analysts. Pretreatment covariates should be chosen for control or
for propensity score matching, not because they are
good predictors of treatment or outcome, but because
they are deemed likely to reduce bias, when such is suspected. The analysis of this section shows that being a
good predictor of treatment assignment compromises
the bias-reducing potential of a covariate, for it tends
to amplify bias due to other, uncontrolled confounders.
One would do better therefore to rank order covariates based on their importance with respect to the
outcome variable, a strategy advocated by Brookhart
et al. (2006, 2010); Austin et al. (2007) and Hill (2008)
which, in light of Eq. (9), deserves a general endorsement.

5

A GLIMPSE AT NON-LINEAR
SYSTEMS

for Z = 0 we obtain the same bias amplification as in
the linear case (Eq. (7)).

The second extension deals with the question of
whether the amplification phenomenon described in
(7), which prevails over all linear models regardless
of parameter values extends over to non-linear models
as well. We will show that, although the phenomenon
persists in non-linear model, it is not as pervasive â€“
there are non-linear models for which |B0 | > |Bz |.
Consider the model of Fig. 1, in which the equation
determining X remains the same,
X = c3 z + c1 u +  0

(9a)

but the one for Y becomes non-linear in X:
Y = f(x) + ug(x) + 00

6
(9b)

This yields
E(Y |x, z) = f(x) + g(x)E(U |x, z)
= f(x) + g(x)(Î²x + Î±z)
= f(x) + Î²g(x)(x âˆ’ c3 z)
with Î² and Î± given in (5); and, from (9a) and (9b)
E(Y |x) = f(x) + g(x)E(U |x)

THE RESILIENCE OF
SELECTION BIAS

Our final extension concerns the effect of instrumental variables on selection bias, that is, bias induced by
preferential selection of units for data analysis which
is often governed by unknown factors including treatment, outcome and their consequences. Case control studies are particularly susceptible to such bias,
e.g., when the outcome is a disease or complication
that warrants reporting (see (Glymour and Greenland,
2008, pp. 111â€“37; Robins, 2001; HernaÌn et al., 2004)).
To illuminate the nature of this bias, consider the linear model of Fig. 3 in which S is a variable affected
by both X and Y , indicating entry into the data pool.
Such preferential selection to the data pool amounts

= f(x) + g(x)c1 x
Consequently, A1 , A2 , and A3 evaluate to
âˆ‚
âˆ‚
E(Y |do(x)) =
E(f(x) + ug(x)) = f 0 (x)
âˆ‚x
âˆ‚x
âˆ‚
A2 =
E(Y |x) = f 0 (x) + c1 (xg0 (x) + g(x))
(10)
âˆ‚x
âˆ‚
A3 =
E(Y |x, z) = f 0 (x) + Î²(xg0 (x) + g(x)
âˆ‚x
âˆ’ c3 g0 (x)z)
(11)

A1 =

and the two bias measures become

Z
UY

c3
c0
X

Y
Î²1

Î²2
S

Figure 3: A model illustrating selection bias; conditioning on S induces spurious associations between X
and Y .

0

B0 = c1 (xg (x) + g(x))
1
[c1 (xg0 (x) + g(x) âˆ’ c3 g0 (x)z)]
Bz =
1 âˆ’ c23
1
=
(B0 âˆ’ c1 c3 g0 (x)z)
1 âˆ’ c23

Equation (12) also shows that conditioning on Z can
introduce bias where none exists. This occurs when
c1 > 0 and g(x) = A/x, a condition that yields B0 = 0
and Bz > 0. This potential of instrumental variables
to produce new bias is suppressed in linear systems, as
seen in Eq. (7), but is unleashed in non-linear systems.
Still, this can only occur when Z and Y are dependent
given X (see (Pearl and Paz, 2010)); it will not occur
therefore in situations where the zero bias condition
B0 = 0 is structural, that is, where one of the structural equations x = h(z, u) or y = h0 (x, u) is trivial in
its u argument.7

(12)

Clearly, if B0 â‰¥ 0 and c1 c3 g0 (x)z > 0, we can get
|Bz | < |B0 |. This means that conditioning on Z may
reduce confounding bias, even though Z is a perfect
instrument and both Y and X are linear in U . Note
that, owed to the non-linearity of Y (x, u), the conditional bias depends on the value of Z and, moreover,

to conditioning on S, and creates spurious association
between X and Y through two mechanisms. First,
conditioning on the collider S induces spurious association between its parents, X and Y . Second, S is also
a descendant of a â€œvirtual colliderâ€ Y , whose parents
are X and the error term UY (also called â€œomitted
7
The condition g(x) = A/x that gave rise to B0 = 0
can be thought of as â€œunstableâ€ (Pearl, 2009a, Ch. 2) for
it depends critically on the exact form of the function y =
h0 (x, u).

factorsâ€) which is always present, though often not
shown.8 The first mechanism is suppressed when Î²1
is zero, while the latter is suppressed when c0 is zero;
both are suppressed when Î²2 is zero.
Writing
âˆ‚
E(Y |do(x)) = c0
âˆ‚x
âˆ‚
A2 =
E(Y |x, s)
âˆ‚x
âˆ‚
E(Y |x, z, s)
A3 =
âˆ‚x
A1 =

(13)
(14)
(15)

the bias due to conditioning on S, A2 âˆ’ A1 , can be
calculated through the usual method of expectations
(as in Eqs. (3)-(6)) and yields:
B0 = A2 âˆ’ A1 =

âˆ’Î²2 (1 âˆ’ c20 )(Î²1 + c0 Î²2 )
1 âˆ’ (Î²1 + c0 Î²2 )2

(16)

We see that B0 can be substantial and it vanishes if
and only if one of the following conditions holds:
Î²2 = 0,

c20 = 1 or Î²1 = âˆ’c0 Î²2 .

In view of the amplification effect of IVâ€™s on confounding bias, one may be tempted to surmise that a similar effect can be expected vis-aÌ€-vis selection bias. This
however is not the case. Conditioning on Z has no
effect whatsoever on selection-induced bias, formally,
A3 =

âˆ‚
âˆ‚
E(Y |x, s, z) =
E(Y |x, s) = A2
âˆ‚x
âˆ‚x

(17)

This equality can be derived, of course, from the
parametric model of Fig. 3, going through the necessary (yet painstaking) steps of algebraic manipulations. However, the validity of this equality is much
broader, for it holds in non-linear systems as well. This
can be seen immediately from the structure of the diagram of Fig. 3, which asserts that, regardless of the
functional relationships between the variables in the
diagram, Y and Z are independent given X and S,9
which entails Eq. (17).
We thus conclude that selection bias differs fundamentally from confounding bias in that the former, as distinct from the latter, is insensitive to conditioning on
an IV. This distinction can be used in practice to detect the presence of confounding bias. If one has a
8

See (Pearl, 2009a, pp. 339â€“41) for further explanation
of this bias mechanism, which seems to have escaped the
taxonomies in (HernaÌn et al., 2004) and (Schisterman et al.,
2009).
9
This is verified through the d-separation rule (Pearl,
2009a, pp. 335â€“7), which identifies the conditional independencies implied by a system of non-linear structural
equations.

solid theoretical basis to believe that a variable Z is a
valid instrument relative to the effect of X on Y , and
if data shows that the association between X and Y
changes upon conditioning on Z, chances are the study
is marred by confounding bias, and remedial steps are
necessary, possibly through covariate control. Conversely, if no such changes can be detected in the data,
chances are no confounding bias exists, though the
study can still be contaminated with selection-induced
bias, resistant to covariate control.10
The question naturally arises whether IV-sensitivity
can also be used to assess the relative magnitude of
the biases associated with two or more effect estimates,
each produced by a different method of covariate control. The answer is trivially affirmative in linear models, since all effects are identifiable in the IV model of
Fig. 1. In nonlinear models, where causal effects are
nonidentifiable, the IV-sensitivity can serve to rank estimates, but the utility of such ranking is limited; low
sensitivity, hence low bias, may as well be assessed indirectly, by measuring the degree to which Y and Z
are dependent given X.
It is important to keep in mind though that the selection bias analyzed above was â€œpure,â€ in the sense
of inducing no confounding component. In general, if
the reasons for excluding units from the study data
involves ancestors of X, confounding bias may also be
induced, as shown in Fig. 4. S3 induces â€œpureâ€ con-

U1

Z

U2
UY

X

Y
S2

S3

S1

Figure 4: Model in which conditioning on S2 induces
selection bias, conditioning on S3 induces confounding
bias, and conditioning on S1 induces both.
founding bias that would be amplified by conditioning
on Z, while S2 induces a â€œpureâ€ selection bias that
will be impervious to conditioning on Z. S1 induces
both selection and confounding bias through to the
path X âˆ’ U1 âˆ’ S1 âˆ’ Y ; the latter will be sensitive to
Z. Conditioning on U2 will eliminate the entire bias
induced by S2 , while conditioning on U1 will eliminate
10
I use the cautionary term â€œchances areâ€ to allow for
the rare possibilities that Z introduces its own bias (see
footnote 7) or that the bias will not be changed by Z.
These possibilities are not structural, in the sense that they
require fine tuning of the functional relationships in the
model.

only the confounding part of the bias induced by S1 ;
the selection-induced part, due to the association created between X and UY , cannot be eliminated by any
method. S3 induces purely confounding bias, which
can be eliminated by conditioning on either U1 or U2 .
Formally, the distinction between confounding and selection bias can be articulated thus: Confounding bias
is any X âˆ’ Y association that is attributable to paths
traversing ancestors of X (i.e., factors affecting treatment.) Operationally, the distinction may refer to experimental paradigm: Confounding bias is any X âˆ’ Y
association that can be eliminated by randomization.
The theory of causal diagrams (Pearl, 2009a; Spirtes
et al., 2000) establishes the equivalence of the two criteria.

7

CONCLUSIONS

We have examined the effect of instrumental variables
on various types of bias. We first showed that, while
in linear systems conditioning on an IV always amplifies confounding bias (if such exists), bias in nonlinear systems may be amplified as well as attenuated.
In some cases an IV may introduce new bias where
none exists. We further examined the effect of IVâ€™s
on selection-induced bias and showed that no such effect exists as long as the bias contains no confounding
component. A formal criterion for distinguishing the
two types of bias sources was introduced, and the possibility of using IV-sensitivity as a diagnostic tool for
bias detection was suggested.
From a practical viewpoint, the immediate implication of this analysis is that covariates should be chosen based on their importance with respect to the outcome, rather than the treatment. Those that have
meager effects on the outcome mechanism and strong
effects on the treatment should be discarded, to prevent bias amplification, while those that have strong
effects on the outcome mechanism should be retained
and serve as predictors in the propensity score. In the
absence of unobserved confounders, a propensity score
constructed from the direct causes of the outcome gives
the same effect estimate (asymptotically) as one constructed from the direct causes of the treatment (Pearl,
2009a, pp. 348â€“52); the former, however, is safer in the
presence of residual unobserved confounders.
The phenomenon illuminated in this paper also has
a profound methodological significance on the conflict
between the so-called â€œstructuralâ€ and â€œexperimentalistâ€ camps in causal analysis. The former requires that
every causal analysis commences with an explicit representation of the available causal assumptions behind
the study, be it in the form of structural equations
or in their non-parametric version as causal diagrams

(Pearl, 2010). The latter attempts to avoid such representation, fearing that causal assumptions, if made
transparent, would be deemed indefensible.
The consequences of avoiding structural considerations
can be seen through the ill-advised practices that the
â€œexperimentalistâ€ approach has nourished in the past
two decades. Unprincipled covariate selection is one
such practice.
Guido Imbens, for example, one of the staunchest
proponents of the â€œexperimentalistâ€ approach, recommends that variables be selected for the propensity
score as follows: â€œAfter estimating all [univariate] logistic regressions we end up with the subset of covariates whose marginal correlation with the treatment
indicator is relatively high. We orthogonalize the set
of selected covariates, and use these to estimate the
propensity scoreâ€ (Hirano and Imbens, 2001). Reluctance to consider the causal structure of the problem
and, in particular, whether candidate covariates affect
the outcome may easily invite strong predictors that
amplify, rather than diminish confounding bias.
Bhattacharya and Vogt (2007) attribute this attitude
of the experimentalist approach to the traditional
reluctance of statisticians to rely on theoretical or
judgmental assumptions. Pearl (2009b) on the other
hand attributes this reluctance to the deficiency of
the potential-outcome notation which, lacking transparency, discourages the articulation of causal assumptions, even those defensible on scientific grounds.
Whichever the case, there is no substitute to structural
knowledge in causal analysis.
Acknowledgments
This note has benefited from discussions with Jeffrey
Wooldridge, Jennifer Hill, Antonio Forcina, and Peter
Austin, and was supported in parts by grants from
NIH #1R01 LM009961-01, NSF #IIS-0914211, and
ONR #N000-14-09-1-0665.

References
Austin, P., Grootendorst, P. and Anderson,
G. (2007). A comparison of the ability of different propensity score models to balance measured
variables between treated and untreated subjects: a
Monte Carlo study. Statistics in Medicine 26 734â€“
753.
Bhattacharya, J. and Vogt, W. (2007). Do instrumental variables belong in propensity scores? Tech.
Rep. NBER Technical Working Paper 343, National
Bureau of Economic Research, MA.
Brookhart, M., Schneeweiss, S., Rothman,

K., Glynn, R., Avorn, J. and StuÌˆrmer, T.
(2006). Variable selection for propensity score models. American Journal of Epidemiology 163 1149â€“
1156.

Pearl, J. (2009b).
Myth, confusion, and
science in causal analysis.
Tech. Rep. R348, University of California, Los Angeles, CA.
<http://ftp.cs.ucla.edu/pub/stat ser/r348.pdf>.

Brookhart, M., StuÌˆrmer, T., Glynn, R.,
Rassen, J. and Schneeweiss, S. (2010). Confounding control in healthcare database research.
Medical Care 48 S114â€“S120.

Pearl, J. (2009c). Remarks on the method of
propensity scores. Statistics in Medicine 28 1415â€“
1416. <http://ftp.cs.ucla.edu/pub/stat ser/r345sim.pdf>.

Dâ€™Agostino, Jr., R. (1998). Propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group. Statistics
in Medicine 17 2265â€“2281.

Pearl, J. (2010).
An introduction to causal
inference.
The International Journal of Biostatistics
6
DOI:
10.2202/1557â€“4679.1203,
<http://www.bepress.com/ijb/vol6/iss2/7/>.

Dâ€™Agostino, Jr. R. and Dâ€™Agostino, Sr., R.
(2007). Estimating treatment effects using observational data. Journal of the American Medical Association 297 314â€“316.

Pearl, J. and Paz, A. (2010). Confounding equivalence in observational studies. Tech. Rep. R-343,
<http://ftp.cs.ucla.edu/pub/stat ser/r343.pdf>.
Forthcoming, Proceedings of UAI, 2010.

Glymour, M. and Greenland, S. (2008). Causal
diagrams. In Modern Epidemiology (K. Rothman,
S. Greenland and T. Lash, eds.), 3rd ed. Lippincott
Williams & Wilkins, Philadelphia, PA, 183â€“209.

Robins, J. (2001). Data, design, and background
knowledge in etiologic inference. Epidemiology 12
313â€“320.

Greenland, S., Pearl, J. and Robins, J. (1999).
Causal diagrams for epidemiologic research. Epidemiology 10 37â€“48.
Heckman, J. and Navarro-Lozano, S. (2004). Using matching, instrumental variables, and control
functions to estimate economic choice models. The
Review of Economics and Statistics 86 30â€“57.
HernaÌn, M., HernaÌndez-DÄ±Ìaz, S. and Robins, J.
(2004). A structural approach to selection bias. Epidemiology 15 615â€“625.
Hill, J. (2008). Comments on â€˜A critical appraisal of
propensity-score matching in the medical literature
between 1996 and 2003â€™ by Peter Austin, Statistics
in Medicine. Statistics in Medicine 27 2055â€“2061.
Hirano, K. and Imbens, G. (2001). Estimation of
causal effects using propensity score weighting: an
application to data on right heart catheterization.
Health Services and Outcomes Research Methodology 2 259â€“278.
Pearl, J. (1993). Comment: Graphical models,
causality, and intervention. Statistical Science 8
266â€“269.
Pearl, J. (1995). Causal diagrams for empirical research. Biometrika 82 669â€“710.
Pearl, J. (2009a). Causality: Models, Reasoning,
and Inference. 2nd ed. Cambridge University Press,
New York.

Rosenbaum, P. (2002). Observational Studies. 2nd
ed. Springer-Verlag, New York.
Rosenbaum, P. and Rubin, D. (1983). The central
role of propensity score in observational studies for
causal effects. Biometrika 70 41â€“55.
Rubin, D. (2002). Using propensity scores to help
design observational studies: application to the tobacco litigation. Health Services and Outcomes Research Methodology 2 169â€“188.
Rubin, D. (2009). Authorâ€™s reply: Should observational studies be designed to allow lack of balance
in covariate distributions across treatment group?
Statistics in Medicine 28 1420â€“1423.
Schisterman, E., Cole, S. and Platt, R. (2009).
Overadjustment bias and unnecessary adjustment in
epidemiologic studies. Epidemiology 20 488â€“495.
Spirtes, P., Glymour, C. and Scheines, R. (2000).
Causation, Prediction, and Search. 2nd ed. MIT
Press, Cambridge, MA.
Weinberg, C. (1993). Toward a clearer definition
of confounding. American Journal of Epidemiology
137 1â€“8.
Wooldridge, J. (2009). Should instrumental variables be used as matching variables? Tech. Rep.
<https://www.msu.edu/âˆ¼ec/faculty/wooldridge/
current%20research/treat1r6.pdf>, Michigan State
University, MI.

