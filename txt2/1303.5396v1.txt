subset of relevant variables; unmodeled influences can
lead to unexpected consequences in a dynamic process.
Of course, measurement and other errors in the obser­
vations, functional relationships among variables, and
missing data introduce additional uncertainty.
•

Also at the Palo Alto Labotatoty, Rockwell lnteina.­

tional Science Center, 444 High Street, Palo Alto, Califor­
nia. 94301.

Statisticians have developed a set of techniques known
as time-series analysis for forecasting the future val­
ues of variables. A time series is a set of observa­
tions made sequentially over time. Investigators have
sought to develop time-series methods for generating
or inducing stochastic models, which describe tempo­
ral dependencies among successive observations in a
time series.
A mature set of probabilistic time-series analysis meth­
ods has been developed and applied to a wide range of
problems [20]. However, classical time-series method­
ologies do not provide an expressive representation for
capturing the probabilistic dependencies and the non­
linearities of real-world processes. Statisticians have
wrestled complex problems into relatively simple pa­
rameterized models that can be solved with the tra­
ditional methods. Until recently, there has been rela­
tively little interaction between the statisticians inter­
ested in time-series analysis and computer-scientists
studying the representation of uncertain knowledge
with belief networks.
Figure 1 depicts a simple belief-network representa­
tion of the interactions between salient variables rel­
evant to the problem of forecasting U.S. car sales in
Japan. Briefly, the model states that Japanese de­
mand for U.S. cars depends on the price of these cars
and influences the supply of the cars. The price and
supply of the U.S. cars is influenced by the efficiency
of U.S. manufacturers. Notice that this model cap­
tures purely contemporaneous dependencies; that is,
the model represents relationships within a fixed time
frame. We refer to this model as the static network.
In this paper, we address the following problem: Given
a static belief network, such as the one depicted in
Figure 1, how can we make normative forecasts of the
future values of variables? We answer this question
by providing an expressive forecasting methodology
based on the integration of classical time-series anal­
ysis with belief-network representation and inference
techniques. Our synthesis has two immediate benefits.
First, by casting probabilistic time-series analyses as
temporal belief-network problems, we can introduce
general dependency models that capture richer, and

42

Dagum, Galper, and Horvitz

I-I

Supply
a)

b)

Figure 1: (a) A static network depicting contempora­
neous dependencies between economic variables. (b)
CARSALES: A DNM for forecasting U.S. car sales in
Japan.

more realistic, models of dynamic dependencies-as
well as the more traditional static or contemporane­
ous belief-network dependencies. Second, we can ap­
ply belief-network inference algorithms to the tempo­
ral models to do forecasting. The richer models and
associated computational methods allow us to move
beyond such rigid classical assumptions as linearity '
in the relationships among variables and normality of
their probability distributions.
In Sections 2 and 5, we discuss methods for generating
a forecasting model known as a dynamic network model
(DNM) from a static network-for example, Figure lb.
Section 3 describes how uncontrolled, unknown exoge­
nous influences can render the forecasting model ob­
solete unless the model is parameterized; an update
method described in Section 3.2 can quickly adapt the
model to observed trends. In Section 4, we present
procedures for forecasting the future value of a model
variable, based on knowledge about the time-lagged
values of itself andfor of values of related variables.
We conclude with a discussion of the advantages of
the DNM approach, and by highlighting representa­
tion and inference problems that remain to be solved.

2

DYNAMIC NETWORK MODELS

A dynamic model can be constructed from a set of
building blocks that capture the instantaneous rela­
tionships between domain variables, together with a
set of temporal dependencies that capture the dynamic
behavior of the domain variables. The building block
of a DNM is the traditional, static belief network. We
extend the static belief network displayed in Figure 1
to a DNM forecasting model by introducing relevant
temporal dependencies between representations of the
static network at different times. A DNM for reason­
ing about future U.S. car sales in Japan is depicted
in F igure lb. Nodes represent states of the domain
variables at different times. In this case, the interval
between time points is defined to be one month. We
refer to this DNM as the CARSALES model.

As highlighted in Figure lb, we distinguish between
two types of dependencies in a DNM. Contempora­
neous dependencies refer to arcs between nodes that
represent variables within the same time period. Non­
contemporaneous dependencies refer to arcs between
nodes that represent variables at different times. Thus,
the dependency between corporate health and supply
is contemporaneous, whereas the dependency between
this month's price and next month's supply is non­
contemporaenous. The DNM representation allows
us to assert and to selectively weaken independence
statements about temporal locality by learning non­
contemporaneous dependencies and modulating their
strength.
Thus far, the specification of the structure of the sim­
ple DNM has adhered to traditional belief-network
methodology. Our point of departure from the estab­
lished paradigm is in the specification of the condi­
tional probabilities of the model. As time evolves, so
do the potential influences of a plethora of unmodeled
exogenous forces that affect the state of the system.
The structure and conditional probabilities that define
a belief network at one time become obsolete with the
passage of time. Discrepancies between new observa­
tions and the values predicted by the outdated model
attest to a model's inaccuracy and inability to make
reliable forecasts. To avoid the progressive deterio­
ration of the model, an intelligent forecasting system
must update the conditional probabilities, and also the
structure when appropriate, as new evidence arrives.
In the CARSALES model, exogenous influences that
may have a significant effect on the Japanese demand
for U.S. cars include, for example, new U.S. trade
policies or a recent upset in Japanese-U.S. diplomatic
relations. In general, these influences are extremely
difficult to model adequately, and their inclusion in
the model, if done inappropriately, often leads to sys­
Furthermore, impor­
tematic errors of prediction.
tant exogenous events may be unknown to the model
builder. For example, an undisclosed pending merger­
and-acquisition by a Japanese car manufacturer might
manifest as a decrease in the corporate health of the
U.S. car industry, in spite of the seemingly unchanged
economy. An unfortunate presidential blunder during
a state dinner, left unpublicized, may also lead to dire
forecasts of model variables.
Such sensitivity to unmodeled variables highlights the
value of developing a means for updating specific con­
temporaneous and noncontemporaneous relations that
are assessed from a domain expert, as time-series
data becomes available. Any probabilistic model that
claims to forecast must possess a method of adaptively
integrating historical information with current esti­
mates of domain variables. In Section 3.2, we discuss
how this requirement imposes the principle of maxi­
mum likelihood for the update of conditional proba­
bilities.

Dynamic Network Models for Forecasting

3

BUILDING AND REFINING A
DNM

To build a DNM, an expert specifies the key contem­
poraneous variables and dependencies. Then, the ex­
pert specifies key temporal dependencies among the
variables, drawing dependencies from earlier states of
the world to variables in the contemporaneous belief
network.
Methods for dynamically updating a model specifi­
cation as new evidence becomes available are criti­
cal to techniques for forecasting the future states of
complex systems. We simplify the task of updating
the DNM model specification by the assumption that
the model structure-that is, the set of contemporane­
ous and noncontemporaneous dependencies-remains
i nvariant over time, and only the set of conditional
probabilities need to be updated as time evolves. In
other words, we assume that, although variations in
unmodeled exogenous forces will inevitably affect the
strength of the dependencies, changes in the exogenous
environment of the model do not introduce new de­
pendencies or nullify existing dependencies. For many
systems, this assumption is valid. An example that
i nvalidates the assumption, i n the context of a sim­
ple supply-demand model, occurs when an essential
commodity-that is, one for which demand is virtu­
ally fixed-is supplied by a monopolistic power. Mo­
nopolistic control of a commodity arises from a cartel
between commercial enterprises designed to fix prices
regardless of the demand.
To design a DNM that dynamically updates condi­
tional probabilities when new evidence becomes avail­
able, we need to address two crucial problems. First,
we must specify conditional probabilities that are
amenable to incremental adjustments which reflect
changes in exogenous forces-the assessment task.
T hen, we must specify how, given new observations,
we adjust the conditional probabilities without intro­
ducing biases and with minimization of the expected
error in the forecasts-the update task.
3.1

Assessing DNM Probabilities

To assess the conditional probabilities, we employ an
approach that draws on the best elements of expert­
assessment and parameter-estimation techniques. The
parametric decomposition is chosen by an expert in
anticipation of the key components of the conditional

we discuss two parameterization models for the condi­
tional probabilities. T hese models are motivated by
the methods used currently by time-series analysts.
Validity of the models has been substantiated by the
overwhelming success witnessed by three decades of
time-series analysis using these models.
To obtain probabilities for the CARSALES model, we
first assess from an expert the functional form of the
conditional probabilities. The expert may be able to
specify qualitatively the form of the conditional prob­
abilities by choosing to focus on the key determinants
of the distribution that are known to be time invari­
ant. For example, the supply of U.S. manufactured
cars will decrease i nvariably in direct proportion to
the Japanese demand. Although last month's man­
ufacture price and the U.S. car industry health will
modulate the absolute effect, the supply node's condi­
tional probability should still reflect the putative rela­
tionship between supply and demand.
Once the appropriate parameterization has been de­
fined, the conditional probabilities can be refined tore­
flect the evidence at hand. Such refinement is achieved
either through the estimation of parameter values from
data using maximum-likelihood methods or through
user specification. In either case, the advantage of this
approach is a parsimonious and adaptive representa­
tion of the conditional probabilities.
3.2

Updating the Model with Data

In time-series analyses, dynamic models adapt to
changes in system behavior through the reestimation
of model parameters when new observations are made.
The process of updating CARSALES is the iterative pro­
cess by which new observations are used to update
the maximum-likelihood estimates of the likelihood
weighting coefficients i n Equation 1. A model update of
CARSALES is an adaptive learning procedure in which
the underlying model is changed; it should be distin­
guished from a belief update. In the model update,
we use new evidence to update our prior belief in the
model specification; in contrast, in a belief update, new
evidence changes our belief in a proposition inferred
from the belief network. Both methods use maximum
likelihood to update the respective beliefs. Once the
parameters are updated, the conditional-probability
distributions of the model are reevaluated.
3.3

Beyond Two-State Models

probabilities that need to be adjusted to reflect sud­
den changes in the unmodeled exogenous environment.
The expert strives to attain a balance between an ex­
pressive and a parsimonious parameterization. The
use of a conditional probability table for each node,
with each table entry treated as an updatable param­
eter, is an expressive parameterization, yet complex
parameterization. The complexity of the assessment
procedure virtually precludes making unbiased adjust­
ments of the conditional probabilities. In Section 5

The specification of the CARSALES DNM tacitly as­
sumes that maintaining observations from two distinct
times is sufficient to provide reliable forecasts. This
simplistic model is intended only to highlight the es­
sential features of DNMs. More realistic models for
forecasting car sales in Japan might include an array
of domain variables and dependencies i ntended to cap­
ture important exogenous influences. Included among
these dependencies would be lag dependencies-that

43

44

Dagum, Galper, and Horvitz

is, dependencies between nonadjacent time points.
These dependencies can model the lagged effects of a
policy; for example, federal tax breaks for the car in­
dustry would be expected to have an effect on industry
health only in the subsequent fiscal year. Lag depen­
dencies are critical in modeling the cyclical behavior
of domain variables. The Japanese demand can be
expected to display seasonality-that is, it should fol­
low closely the seasonal behavior of unemployment. If
we are interested in the seasonal behavior of Japanese
demand, we would structure CARSALES differently.
3.4

Diagnostic Checks

If the intent of building a DNM is to provide a means
for making optimal forecasts of future values of en­
dogenous variables, observed values should be in the
immediate neighborhood of predicted values.
The
residuals of a DNM at time t denote the difference
between the one-step-ahead forecasts and the values
observed at time t. If the DNM is correctly assessed
by the expert, the residuals should be distributed nor­
mally and independently with mean zero. A plot of
the residual sample autocorrelations should not reveal
the presence of serial correlation. A serial correlation
indicates that there is some systematic aspect of the
behavior of the system that is not being detected by
the modeL Thus, diagnostic checks assess the ade­
quacy of the model and can serve to suggest appropri­
ate modifications.

4

FORECASTING: INFERENCE
WITHADNM

Ongoing implementations of complex DNMs include a
sleep apnea model and a model for surgical intensive­
care ventilator management. Validation of the per­
Here, we
formance of these models is underway.
shall highlight key phases of updating and forecast­
ing with DNMs with analytical results derived from
the CARSALES DNM.
To forecast at time t the t + 1 values of the nodes in
we scroll the model one time slice into the
future. Figure 2 depicts the process of scrolling the
model. The scrolled model uses the same values esti­
mated at time t for the likelihood weights combining
the contemporaneous and the noncontemporaneous in­
fluences on supply. Thus, the model implicitly reflects
the effects of unmodeled exogenous forces on the level
of the forecasts, thus, increasing the forecast reliabil­
ity. In general, to project I time points into the future,
a DNM at time t sequentially steps through the time
points t + 1, ..., t + l. Thus, a complete profile of the
CARSALES,

time series over the time interval from t to t + l is
constructed in the process of forecasting.
Once the projection model at time t+l has been identi­
fied, the forecasted values of the endogenous variables
at time t +I are computed by a probabilistic inference

1·2

j.]

l+l

1-2

t-1

1+1

b)

Figure 2: Forecasting with CARSALES. In going from
figure (a) to figure (b), the model is scrolled on time
slice into the future . The forecasted values at time
t + 1 are computed from the model in figure (b), while
preserving the likelihood weights computed in (a) and
the set of observations made in (a) for nodes at time
t.

algorithm. For typically complex applications, the size
and topology of the DNM may prohibit tractable exact
computation of inferences. In such cases, stochastic­
simulation algorithms designed specifically to approx­
imate inference probabilities in large belief networks
can be employed [15, 14, 1 1, 16, 9, 17, 4, 6, 7].

5

SPECIAL DNMS

We can simplify the assessment of conditional proba­
bilities for DNMs by employing special parameterized
functional forms. We shall focus on two simple para­
metric decompositions used commonly by time-series
analysts: the additive and the multiplicative decom­
positions. The additive decomposition is used com­
monly in time-series analysis for integrating predic­
tions based on current observations with predictions
based on historical observations. Additive decomposi­
tions are an integral aspect of models that purport to
forecast future values of time series, and they appear
in the form of the Kalman filter in state-space mod­
els, and in the conditional sum of squares in ARIMA
models [10]. The multiplicative decomposition is used
commonly to model log-linear systems in engineering
applications.
Both decompositions employ likelihood weights, which
provide a language for assigning measures of reliabil­
ity to information about different times. With this
approach, we consider the probabilistic dependencies
from contemporaneous sets of variables and from vari­
ables at different points in the past as providing inde­
pendent sources of information. These measures are
used to weight the contribution of the contemporane-

Dynamic Network Models for Forecasting

ous and noncontemporaneous dependencies differently.
The sum of the predictions, each weighted by its likeli­
hood, gives the final prediction. The use of likelihood
weighting allows an expert to specify the weight of the
past versus the present with ease. Such parameters
in the functional forms also allow the distributions to
be tuned adaptively as dictated by a set of current
observations.
In the CARSALES model, the supply at time t, based
on information at timet, depends on the demand and
industry health at timet, denoted by Q[s1 ld1, h1). The
supply at time t, based on information prior to time
t, depends on the price and supply at timet- 1, de­
noted by R [st IPt-1, S t-d· Let a denote the likelihood
that the supply predicted from the information prior
to time t is correct; therefore, 1 - a denotes the like­
lihood that the supply predicted from information at
time t is correct. In the additive decomposition, the
prediction of supply is given by

aQ[s,!dt, h,]
(1- a)R [sdPt-1,S t-1]·

Pr[s ,ld,, ht,Pt-1, St-li a)
+

In the multiplicative decomposition, the prediction is

NQ [s, !dt, ht]a

Pr[s,ldt ,h,,Pt-1, St-1; a]
X

R [stiPt-1, St-1 p -a

where N is a constant that normalizes the probability
to unity.
We proceed to study the adaptive behavior of the
additive decomposition given new evidence. We fo­
cus on the behavior of the CARSALES modeL Let
s;, i ::; t, denote the values of the supply nodes
observed for time points up to, and including, time
point t, and similarly, let {i, i ::; t, denote the set
of values observed for nodes d;,h;, p;. We are in­
terested in evaluating the conditional likelihood func­
tion L [s t,St-tl{t,�t-1,St-2',Pt-2'ia], predicted by our
model CARSALES, of observing St-1 and s1• From
Equation 1 the conditional probability for the supply
node depends on the chosen value of the likelihood
weight a, and we expect L to vary accordingly. If a*
maximizes L, then a" is the maximum-likelihood es­
timator of a, and it is optimal in the sense that it is
an unbiased estimator of a that achieves the Cramer­
Rao lower bound on the variance for all possible un­
biased estimators. Accordingly, predictions made by
CARSALES using maximum-likelihood estimators for
the parameters are optimal over the space of all pos­
sible unbiased estimators.
We begin by giving the expression for L in the
example,

CARSALES

L

=

X

Pr[s,ldt, h t,Pt, St-1i a)
Pr [s, ddt-1 ht-1,Pt-1, St-2; a] .
_

,

If we substitute for each conditional probability in the
preceding expression for L the expression given by
the additive decomposition, the resulting equation is

a.
2
a 6161-1
a [c5,R [st-1lst-2,Pt-2] + 6t-1R[s,lst-1,Pt-d]
(1)
R[s,_dst-2.Pt-2 ]R [s,lst-l!Pt-1]

a quadratic equation in

L
+
+

where, fori=t- 1,t,

6; = Q [s;ld;,h;]- R [silsi-11Pi-d·

(2)

Equation 1 is the equation of a parabola with ex­
tremum occurring at

6,R [st-1lst-2,Pt-2] + 6t-1R [s,lst-l,Pt-1]
2 6,6t
1
( 3)
maximum-likelihood estimator a" must lie in the

am=-

-

The
interval [0, 1). The constraint leads to the following
two cases: (1) if 61_1 61 > 0, then the parabola is
convex-up, and thus, a* = 0 if am ::; � and a* = 1

if am > �; (2) 61-t61 ::; 0, and, either am ::;
a" = 0, or 0 < am ::; 1 and a* = am, or am >
a• = 1.

0 and
1 and

In terms of the model structure, a choice of a• = 1
implies that predictions based on prior information
should be ignored categorically. This conclusion is
consistent with the finding that, if 61_1, 61 > 0, for
i = t - 1, t, the values of di and h; are correlated
more strongly with the outcome Si than are the val­
ues of Si-l and P i-1. The conclusion follows because
prior to observing the outcome for supply at time i,
the probabilities Q[S;Ida, h;J and R [Si lsi-IoPi-d are
distributions for the node S; predicted from current
information, di and hi, and from prior information,
Si-1 and Pi-1· Thus, these probabilities are a measure
of the correlation of the current and the prior informa­
tion with the finding-that is, the observed outcome
Si. Conversely, a choice of a• = 0 implies that predic­
tions based on current information should be categori­
cally ignored. W hen Ot-1 and 61 are of opposite signs,
the appropriate choice of a• may take on a value inter­
mediate between 0 and 1, implying that the prediction
for supply based on maximum-likelihood is a weighted
mix of the two predictions.
Once a has been computed-that is, updated to reflect
new observations-the model can be used to forecast
next month's supply. We scroll CARSALES forward one
time point, and compute the marginalized distribution
Pr[St+11{J in the b elief network using probabilistic in­
ference. For large models, or for models used in high
stakes time-pressured environments, an approximate
algorithm that trades off accuracy of inference for ef­
ficiency of computation is preferred.

6

NUMERICAL EXAMPLE

Let us consider an example using the additive model
for CARSALES. We assume that all nodes are binary­
that is, demand, price, industry health and sales are
all either high (H) or low (L). The conditional prob­
ability distributions for Q[ st = Hld1,h1] and R [st =

45

46

Dagum, Galper, and Horvitz

t

0

1

2

d,
h,
Pt
St

H
H
H

H
H
H
L

H
H
H
L

H
H
H

0.0
0.40

0.0
0.40

a

Pt-!Bt-1
HH
HL
LH
LL

Rlst

=

HIPt-tBt-d
0.90
0.40
0.40
0.10

Figure
3: The conditional probabilities Q[s1 = H ld1, p t] and
R[st = Hlst-1 ,Pt-1] in CARSALES. In the example, the
conditional probability for the car-sales node is given
by the convex combination of the probabilities Q and
R with parameter a.

Pt

H
L

ht
H
L

•
a

St+l

H
H

6
L

H
L

H

H

H

1.0
0.56

0.5
0.73

0.0
0.90

0.0
0.90

8
L

9

L

11
L
L

H
L
H

H

L

10
L
L

L

H

L
L

L
L

0.5
0.48

1.0
0.56

1.0
0.56

0.0
0.10

7

L

5
L

L
L

0.0
0.10

Figure 5: Time-series of data for CARSALES over twelve
periods. Values for a• are maximum-likelihood esti­
mates corresponding to the observed data. For each

P rlPt = H lhtl
0.35
0.80

The conditional probabilities

Pr[d1

are given in Figure 3. The remammg
conditional probabilities for CARSALES are given in

Figure 4.
Figure 5 contains a time-series of observations of the
variables of CARSALES made over twelve consecutive
periods. Initially, the time-series is assumed to be sta­
tionary with data reflecting a healthy U.S. car industry
and high-volume sales in Japan. The model is in equi­
librium with the time-series, where in this example,
•
the equilibrium is reflected in the value of a , which
takes on the value 0 when equilibrium is reached. Ex­
ogenous events that disturb the level of the time-series
occur at t = 3, 6, 9. CARSALES adapts to the exoge­
nous disturbance with a'" increasing and subsequently
decreasing over ensuing periods. The number of peri­
ods over which a'" increases is a function of the lagged
influences in the model-that is, the noncontempora­
neous relations.
=

t

d,
h,
Pt
St

L
H
H

Pr[st+l = Hletl in CARSALES with the o:* computed
at time t and where {1 denotes all observations made
up to and including timet.

Hlst-t.Pt-d

At t

St+l

4

period, we forecast the probability that the supply will
be high in the next period. We denote this forecast by
St+l, and we compute it by evaluating the inference

Prldt = HIPtJ
0.25
0.65

= Hjp1]
and
= Hjh1] of CARSALES. The prior probability
for the industry health is P r [h1 = H] = 0.85.

4:
Pr [p1

Figure

•

L

3
L

3 we observe a sudden drop in the demand

which persists through subsequent time periods. The
persistence of this drop allows us to rule out noise as
the cause, and we can assume that the change in the
demand has been precipitated by an exogenous event.

Concomitant with the low demand there is an increase
in supply, while both industry health and price remain
temporarily unchanged. CARSALES responds to the
•
disturbance by temporarily increasing a until a new
equilibrium is achieved. The forecasted probabilities
for a high supply rise from 0.4 to 0.9 during this period.
At t = 6, we observe a drop in price which once again
disturbs the equilibrium state. The low price contin­
ues through remaining periods, and reflects, to some
extent, the market forces that result form high supply
and low demand which are captured by the supply­
demand model CARSALES. However, the probability
that the price drops in CARSALES when demand is low
and supply and industry health are high, cannot alone
account for the persistence of the low price. We antic­
ipate that the price has been exogenously clamped at
a low value. Although a single drop in price at t = 6
does not affect the value of o:*, the consistently low val­
ues represent an unlikely circumstance. The CARSALES
model responds to this scenario by adjusting a• dur­
ing the subsequent two time periods. The forecasted
probability for supply made in period 7 drops in an·
ticipation of a drop in supply by period 8, but which
is first observed at period 9. At t = 9, subject to de­
clining prices and demand, the health of the industry
deteriorates, and consequently, supply drops as well.
Once again, the disturbance is sensed by CARSALES
*
through the parameter a , and the forecasts for supply
drop even further. In the absence of further changes,
by period 11 the model is again at equilibrium.

Dynamic Network Models for Forecasting

7

RELATED WORK

Most research in temporal reasoning has focused on
the representation of time with logical predicates,
rather than on dynamic modeling of the state of the
world under uncertainty [2, 13, 18]. Several approaches
have been proposed to support temporal reasoning
using probability theory. To date, most of this re­
search has been hindered by problems with captur­
ing dynamic changes in temporal models as new ob­
servations become available. Early attempts to de­
velop probabilistic methods for temporal reasoning
have posed static models of dynamic domains, in which
exogenous influences are captured in fixed conditional­
probability distributions. Such models rely entirely on
prior knowledge of the domain, and offer no method
for refining the probabilistic dependencies of the mod­
els dynamically with new data. DNMs can adapt to
exogenous influences by fine tuning their conditional­
probability distributions. Such dynamic adaptation
can reduce forecasting errors and improve planning
and control.
Cooper , et al. [5] propose methods for encoding un­
certain temporal relationships under several restric­
tive assumptions, to allow the exact computation of
the joint probability of a hypothesis and the accumu­
lated temporal evidence. Dean and Kanazawa [8] de­
velop a probabilistic model for projection based on a
functional (e.g., exponential) decay model of the per­
sistence with time of propositions. Berzuini [3] em­
beds semi-Markov models in a belief-network repre­
sentation and uses approximate probabilistic inference
to compute the degree of belief in past states and in
future states. Tatman shows that a Markov decision
process can be encoded in an influence diagram [19].
Kanazawa and Dean [12] apply approximate decision�
making processes to these influence diagrams to trade
off accuracy of prediction for speed of decision making.
Most of the models developed in research on temporal .
reasoning have a limited ability to adapt to new obser­
vations, and their Markov nature, prevents them from
making forecasts that extend beyond Markov simula�
tions. Recent work by Abramson [1] describes a belief�
network model that predicts future crude-oil prices
given historical evidence. However, he employs classi�
cal time-series methods external to the belief-network
to reest imat e model parameters.

8

CONCLUSION

The temporal dependencies and time-based evolution
of the states of variables in a dynamic domain limit
the applicability of conventional static belief-network
models. DNMs extend classical dynamic modeling,
by providing an expressive language and platform for
ongoing research on probabilistic temporal reasoning.
DNMs are ideally suited for forecasting and control in
domains for which detailed prior knowledge is avail­
able about the dynamic forces and relations at play,

but is sufficiently complex to preclude a complete
specification. These are the domains that we face in
probabilistic-reasoning applications. With the DNM
approach, machinery is provided for compensating for
the exogenous influences in an unbiased fashion. Our
future research on DNMs includes exploring the per­
formance of alternate inference algorithms to solve spe­
cial DNM topologies, validating the predictive behav�
ior of alternative models, and investigating methods
for inducing DNMs from static belief networks by iden�
tifying temporal dependencies from time-series data.

Acknowledgments
This work was supported by the National Science
Foundation under grant IRI�9108385 and Rockwell
Science Center IR&D funds.

References
[1)

Bruce Abramson. ARC01: An application of be­
lief networks to the oil market. In Proceedings
of the Seventh Conference on Uncertainty in Ar­
tificial Intelligence, pages 1-8, Los Angeles, CA,
July 1991. Association for Uncertainty in Artifi­
cial Intelligence.

[2] J. Allen. Towards a general theory of action and
time. Journal of Computer and Systems Sciences,
31(2):288-301, 1985.

[3]

C. Berzuini, R. Bellazzi, and S. Quaglini. Tem­
poral reasoning with probabilities. In Proceedings
of the 1989 Workshop on Uncertainty in Artificial
Intelligence, pages 14-21, Windsor, Ontario, July
1989. Association for Uncertainty in Artificial In­
telligence.

[4]

R. Chavez and G. Cooper. A randomized approx­
imation algorithm for probabilistic inference on
bayesian belief networks. Networks, 20:661-685,
1990.

[5] G.

Cooper, E. Horvitz, and D. Heckerman.
A method for temporal probabilistic reasoning.
Technical Report KSL 88-30, Medical Computer
Science, Stanford University, Stanford, CA, Au­
gust 1988.

[6] P. Dagum and R.M. Chavez.
Approximating
probabilistic inference in bayesian belief networks.
Technical Report KSL-91�46, Knowledge Systems
Laboratory, Stanford University, Stanford, CA,
July 1991.

[7]

An analysis of
P. Dagum and E. Horvitz.
Monte-Carlo algorithms for probabilistic infer­
ence. Technical Report KSL-91-67, Knowledge
Systems Laboratory, Stanford University, Stan­
ford, CA, October 1991.

[8]

T. Dean and K. Kanazawa. P robabilistic causal
reasoning. In Proceedings ofthe Fourth Workshop
on Uncertainty in Artificial Intelligence, pages

47

48

Dagum, Galper, and Horvitz

73-80, Minneapolis, MN, August 1988. American
Association for Artificial Intelligence.
[9]

R. Fung and K.-C. Chang. Weighing and in­
tegrating ev idence for stochastic simulation in
Bayesian networks. In Uncertainty in Artificial
Intelligence 5, pages 209-219. Elsevier, Amster­
dam, The Netherlands, 1990.

[10]

A.C. Harvey. Forecasting, structural time series
models, and the Kalman filter. Cambridge Uni­
versity Press, New York, 1990.

[11]

M. Henrion. Propagating uncertainty in Bayesian
networks by probabilistic logic sampling. In Un­
certainty in Artificial Intelligence 2, pages 149163. North-Holland, Amsterdam, The Nether­
lands, 1988.

[12]

K. Kana.zawa and T. Dean. A model for projec­
tion and action. In Proceedings of the Eleventh
International Joint Conference on Artificial Intel­
ligence, pages 985-990, Detroit, Ml, August 1989.

[13]

P. Ladkin. Time representation: A taxonomy of
interval relations. In Proceedings of the Fifth Na­
tional Conference on Artificial Intelligence, pages
360-366, P hiladelphia, PA, 1986. American Asso­
ciation for Artificial Intelligence.

[14]

J. Pearl. Addendum: Evidential reasoning using
stochastic simulation of causal models. Artificial
Intelligence, 33:131, 1987.

[ 15]

J. Pearl. Evidential reasoning using stochastic
simulation of causal models. Artificial Intelli­
gence, 32:245-257, 1 987.

[16]

R. Shachter and M. Peot. Evidential reasoning
using likelihood weighting. 1989. Unpublished
manuscript.

[17]

R. Shachter and M. Peot. Simulation approaches
to general probabilistic inference on belief net­
works. In Uncertainty in Artificial Intelligence
5, pages 221-231. Elsevier, Amsterdam, The
Netherlands, 1990.

[18]

Y . Shoham and N. Goyal. Temporal reasoning
in artificial intelligence. In Exploring Artificial
Intelligence. Morgan Kaufmann, San Mateo, CA,

1988.
[19] J.

Tatman. Decision processes in influence di­
agrams: Formulation and analysis. PhD thesis,
Engineering-Economic Systems, Stanford Univer­
sity, Stanford, CA,

[20]

1985.

M. West and J. Harrison. Ba y esian forecasting
and dynamic models. Springer Verlag, New York,

1989.

