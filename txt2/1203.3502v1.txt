
the problem is due to a single fault,
different actions address different faults,
costs do not depend on the previous history, and
there are no questions,

then the problem is solvable in O(n · lg n) time where
n is the number of actions. This algorithm is the wellknown ”P-over-C” algorithm by (Kadane and Simon,
1977) which was first brought into a troubleshooting
context by (Kalagnanam and Henrion, 1990). Furthermore, if any of the above assumptions are relaxed
without restrictions, the problem becomes NP-hard
(Vomlelová, 2003). If assumption (a) is replaced with
an assumption about multiple independent faults, an
O(n·lg n) P-over-C-like algorithm also exists (Srinivas,
1995). Troubleshooting without assumption (b) can
also be somewhat simplified due to the dependency
set algorithm of (Koca and Bilgic, 2004).
(Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where
the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1). The idea is that in
order to access an action in a bottom level cluster Ki ,
you need to pay an additional cost Coi and to close the
cluster you have to pay an additional cost Cci . Thereby
it is possible to model e.g. the repair of complex manmade devices where you need to take apart some of the
equipment to perform certain actions. If we can determine whether an action has solved the problem without assembling the cluster first, Langseth and Jensen
said that the cluster has inside information; otherwise the cluster is without inside information. They
furthermore describe heuristics for both problems. In
this paper we present a proof of correctness of their
algorithm for the problem with inside information. We
furthermore extend the model to a tree of clusters and
give an O(n · lg n) time algorithm that is proved optimal. (Warnquist et al., 2008) describe a slightly more
general cost cluster framework, but they do not address the issue of finding an efficient algorithm.

conditional cost Cα (ε) of an action α given evidence
ε is given by Cα + CK(α) if α ∈ CA(ε) and by Cα if
α ∈ FA(ε).

Cluster 0
α1
Co1

Cc1

Cluster 1
α3

α2

α4

Co2

Cc2

Cluster 2
α5

α6

Co3

Cc3

Cluster 3
α7

α8

Figure 1: Example of the flat cost cluster model. To
open a cluster Ki we pay the cost Coi , and to close a
cluster we pay the cost Cci .

2

PRELIMINARIES

In this paper we shall examine troubleshooting problems where the following model parameters are given.
F = {f1 , . . . , fm } is a set of faults describing the
possible causes to the problem. For each fault f ∈
F, we have a probability P(f) describing how likely
it is that f is present when troubleshooting begins.
A = {α1 , . . . , αn } is a set of actions that can potentially solve the problem. Each action α has two
possible outcomes, namely ”α = yes” (the problem
was fixed) and ”α = no” (the action failed to fix the
problem). Each action α has a positive cost Cα describing the resources required to perform the action.
Finally, each action has an associated success probability P(α = yes | f), the probability of solving the
problem by performing the action when f is present.
The set of actions A can be partitioned into ` + 1 clusters K, K1 , . . . , K` where cluster K is the top-level cluster and the remaining are bottom-level clusters. The
cost of opening a cluster Ki is Coi and the cost of closing it again is Cci . We define CKi = Coi +Cci . An action
α belongs to cluster K(α).
During the course of troubleshooting we gather evidence εi meaning that the first i actions failed tosolve
the problem, and we have by assumption P ε0 = 1
x:y
because the device
as
Sy is faulty. We also write ε
shorthand for i=x {αi = no}. FA(ε) is the set of
free actions consisting of all actions (excluding those
already performed) from open clusters given evidence
ε. CA(ε) is the set of confined actions consisting of
all actions from closed clusters. Note that we have
FA(ε) ∪ CA(ε) ⊆ A and FA(ε) ∩ CA(ε) = ∅ for all
evidence ε. By performing an action α from CA(ε) we
pay the cost CK(α) because at this point we are certain
that we must both open and close the cluster. In that
case α is called an opening action (for K(α)), and all
remaining actions of K(α) are released by removing
them from CA(ε) and adding them to FA(ε). The

Throughout this paper we uphold the following simplifying assumptions about the model:
1 (The single fault assumption). Initially the problem
is known to exist and it is due to the presence of a
single fault from F.
2 (The idempotent action assumption). Repeating a
failed action will not fix the problem.
3 (The carefulness assumption). By performing an action or testing the system, we never introduce new
faults.
4 (The independent actions assumption). Different
actions address different faults.
5 (The costless system test assumption). Checking
whether the problem still exists after performing an action can be done at a negligible cost.
6 (The inside information assumption). All clusters
have inside information.
Due to the single-fault assumption we may compute
the repair probabilityPof an action given evidence ε
as P(α = yes | ε) =
f∈F P(α = yes | f) · P(f | ε). In
a few places we shall abbreviate P(α = yes | ε) with
P(α | ε). Due to the independent actions assumption
P(α) /P(β) = P(α | ε) /P(β | ε) for all evidence ε not
involving α or β. We shall therefore abbreviate the
initial repair probability P(α = yes) as Pα .
A troubleshooting sequence is a sequence of actions
s = hα1 , . . . , αn i prescribing the process of repeatedly
performing the next action until the problem is fixed
or the last action has been performed. We shall write
s[k, m] for the subsequence hαk , . . . , αm i and s(k, m)
for the subsequence hαk+1 , . . . , αm−1 i. The index of
an opening action in a troubleshooting sequence s is
called an opening index, and the set of all opening indices for s is denoted Z with Z ⊆ {1, . . . , n}, |Z| = `.
To measure the quality of a given sequence we use the
following definition.
Definition 1. Let s = hα1 , . . . , αn i be a troubleshooting sequence. Then the expected cost of repair (ECR)
of s is given by
ECR (s) =

n
X


P εi−1 · Cαi (εi−1 ) .

i=1

Formally, our optimization problem is to find a troubleshooting sequence with minimal ECR. Without
cost clusters, the problem is easily solved due to the
theorem below.

Theorem 1 (Kadane and Simon (1977)). Let s =
hα1 , . . . , αn i be a troubleshooting sequences in a model
without cost clusters. Then s is optimal if and only if
Pαi
Pαi
≥
Cαi
Cα i

for i ∈ {1, . . . , n − 1} .

If costs are not conditional and actions are independent, the lemma below leads directly to the ”P-over-C”
algorithm.
Lemma 1 (Jensen et al. (2001)). Let s be a troubleshooting sequence and let αx and αx+1 be two adjacent actions in s. If s is optimal then

Cαx (εx−1 ) + 1 − P αx | εx−1 · Cαx+1 (εx ) ≤
Cαx+1 (εx−1 ) +
1 − P αx+1 | εx−1



· Cαx (εx−1 , αa+1 = no) .

With assumption 1, 3, 4, and 5 we may simplify computations and notation somewhat because of the following result.
Proposition 1. Let s = hα1 , . . . , αn i be a troubleshooting sequence. Then the ECR of s may be computed as


i−1
n
X
X
Pαj  ,
Cαi (εi−1 ) · 1 −
ECR (s) =
j=1

i=1

where 1 −

Pi−1

j=1

Pαj


= P εi−1 .

This easy computation of the probabilities can be
dated back to (Kalagnanam and Henrion, 1990) and
(Heckerman et al., 1995).
Thus, due to our assumptions, we may completely
ignore F, P(f), and P(α = yes|f) once the repair probabilities have been computed. Therefore, we mainly
use Pα in the rest of this paper.
Using the set of opening indices Z, we can rewrite the
definition of ECR of a sequence s to


i−1
X
X
ECR (s) =
Cαi · 1 −
Pαj 
i=1

j=1


+

X
z∈Z

CK(αz ) · 1 −

z−1
X


Pαj  (1)

j=1

where we have decomposed the terms into those that
rely on the cost of performing actions and those that
rely on the cost of opening and closing a cluster. We
define the efficiency of an action α given evidence ε
as ef(α | ε) = Pα /Cα (ε), and we write ef(α) for the
unconditional efficiency Pα /Cα . Finally, the cluster
P
efficiency of an opening action is cef(α) = Cα +CαK(α) .

Lemma 2. Let s = hα1 , . . . , αn i be an optimal troubleshooting sequence with opening indices
zi ∈ Z. Then the ` + 1 subsequences s[α1 , αz1 ),
s[αzi , αzi+1 ) ∀i ∈ {1, . . . , ` − 1}, and s[αz` , αn ] are
ordered with respect to descending efficiency.
Proof. Between opening indices the costs are not conditional, and so we must sort by descending ef(·) to be
optimal.
We have now established that given the opening index
for each cluster, it is a simple task of merging ordered
sequences to establish an optimal sequence. The difficult part is to determine the opening indices.

3

THE EXTENDED P-OVER-C
ALGORITHM

The standard ”P-over-C” algorithm works by sorting
the actions based on descending efficiency. The extended algorithm works in a similar manner, but it
also considers the efficiency of a cluster: if a cluster is
more efficient than all remaining actions and clusters,
we should perform some actions from that cluster first.
Definition 2. The efficiency of a cluster K is defined
as
P
α∈M Pα
P
ef(K) = max
M⊆K CK +
α∈M Cα
and the largest set M ⊆ K that maximizes the
ficiency is called the maximizing set of K. The
quence of actions found by sorting the actions of
maximizing set by descending efficiency is called
maximizing sequence of K.

efsethe
the

It turns out that it is quite easy to calculate the efficiency of a cluster. The following result is a slightly
more informative version of the one from (Langseth
and Jensen, 2001):
Lemma 3. Let K be a cluster. Then the maximizing set M can be found by including the most efficient
actions of K until ef(K) starts decreasing. Furthermore, all actions α in the maximizing set M have
ef(α) ≥ ef(K) and all actions β ∈ K \ M have
ef(β) < ef(K).
The algorithm is described in Algorithm 1. If n denotes the total number of actions, we can see that line
2 takes at most O(n · lg n) time. Once the actions have
been sorted, line 3-6 takes at most O(n) time. The
loop in line 7-20 can be implemented to run in at most
O(n · lg(` + 1)) time by using a priority queue for the
most efficient element of A and the most efficient element of each cluster. Thus the algorithm has O(n·lg n)
worst case running time. In the next section we prove
that the algorithm returns an optimal sequence.

Algorithm 1 The extended P-over-C algorithm
(Langseth and Jensen, 2001)
1: function ExtendedPOverC(K, K1 , . . . , K` )
2:
Sort actions of K and all Ki by descending ef(·)
3:
Calculate ef(Ki ) and maximizing sets Mi
4:
for all i ∈ {1, . . . , `}
5:
Let Kclosed = {Ki | i ∈ {1, . . . , `}}
6:
Let A = {α | α ∈ K or α ∈ Ki \ Mi for some i}
7:
Let s = hi
8:
repeat
9:
Let β be the most efficient action in A
10:
or cluster in Kclosed
11:
if β is an action then
12:
Add action β to s
13:
Set A = A \ {β}
14:
else
15:
Add all actions of the maximizing set
16:
of cluster β to s in order of
17:
descending efficiency
18:
Set Kclosed = Kclosed \ {β}
19:
end if
20:
until Kclosed = ∅ and A = ∅
21:
Return s
22: end function

Proof. We shall use the fact that for positive reals we
have
b
a
a+b a
⊗ ⇔ ⊗
c+d
c
d
c
for any weak order ⊗ (e.g. ≥ and ≤). Let M consist
of actions in K such that ef(M) is maximized. Then
ef(M) equals
P
P
α∈M\{β} Pα + Pβ
α∈M Pα
P
P
=
CK + α∈M Cα
CK + α∈M\{β} Cα + Cβ
=

SP + Pβ
P
=
SC + Cβ
C

where β is chosen arbitrarily. Let furthermore γ ∈
K \ M. We shall prove
Pβ
P
Pγ
>
≥
Cβ
C
Cγ
which implies the theorem. We first prove the leftmost inequality. Because ef(M) is maximal we have
SP + Pβ
SP
Pβ
SP
≥
which is equivalent to
≥
SC + Cβ
SC
Cβ
SC
which again is equivalent to

Example 1. We consider a model with three clusters,
where Kα is the root cluster and Kβ and Kγ are the
bottom-level clusters. We have CKβ = 2 and CKγ = 1,
and the following model parameters:

α1
α2
β1
β2
γ1
γ2

P
0.14
0.11
0.20
0.10
0.25
0.20

C
1
1
1
1
1
1

ef(·)
0.14
0.11
0.067
0.033
0.125
0.10

cluster
Kα
Kα
Kβ
Kβ
Kγ
Kγ

ef(K)

0.075
0.15

The maximizing set for Kβ is {β1 , β2 } and for Kγ it
is {γ1 , γ2 }, and from this the cluster efficiencies have
been calculated. Algorithm 1 returns the sequence s =
hγ1 , γ2 , α1 , α2 , , β1 , β2 i which has ECR
ECR (s) = 2+0.75+0.55+0.41+0.30·3+0.10 = 4.71 .
If we followed the simple P-over-C algorithm we would
get the sequence s2 = hα1 , γ1 , α2 , γ2 , β1 , β2 i with ECR

ECR s2 = 1+0.86·2+0.61+0.50+0.30·3+0.10 = 4.83 .

SP + Pβ
Pβ
≥
.
Cβ
SC + Cβ
The second inequality is proved similarly.
When we look at opening indices we get the following
result.
Lemma 4. Let s = h. . . , αx , αx+1 , . . .i be an optimal
troubleshooting sequence, and let Z be the opening indices of s. Then
cef(αx ) ≥ ef(αx+1 ) if x ∈ Z, αx+1 ∈ FA(εx−1 )
ef(αx ) ≥ cef(αx+1 ) if αx ∈ FA(εx−1 ), x + 1 ∈ Z
cef(αx ) ≥ cef(αx+1 ) if x ∈ Z, x + 1 ∈ Z
Proof. Apply Lemma 1 and do some pencil pushing.
For example, case 1: x ∈ Z and αx+1 ∈ FA(εx−1 ). In
this case we have

Cαx + CK(αx ) + 1 − P αx | εx−1 · Cαx+1 ≤


Cαx+1 + 1 − P αx+1 | εx−1 · Cαx + CK(αx )
m
P αx+1 | εx−1




Cαx + CK(αx ) ≤ P αx | εx−1 Cαx+1

m

4

CORRECTNESS OF THE
ALGORITHM

We start with a proof of Lemma 3:

ef(αx+1 ) ≤ cef(αx )
because P(αx ) ≥ P(αx+1 ) ⇔ P(αx | ε) ≥ P(αx+1 | ε)
for independent actions.

Definition 3. Let s[x, y] be a subsequence of a troubleshooting sequence s. Then the efficiency of s[x, y] is
given by
Py
Pαi
ef(s[x, y]) = Py i=x i−1
C
)
i=x αi (ε
Definition 4. Let s = h. . . , αx , . . . , αy , . . .i be a troubleshooting sequence. If all actions of the subsequence
s[x, y] belong to the same cluster, we say that the subsequence is regular. If furthermore s[x, y] is as long as
possible while not breaking regularity, we say that the
subsequence is a maximal regular subsequence.
Remark. Any troubleshooting sequence can be partitioned into a sequence of regular subsequences, and
if all the subsequences are maximal, this partition is
unique.
Lemma 5. Let s be an optimal troubleshooting sequence, and let s[x, x + k] and s[y, y + `] (with y =
x + k + 1) be two adjacent regular subsequences such
that K(αx ) 6= K(αy ) or such that neither x nor y is an
opening index. Then
ef(s[x, x + k]) ≥

ef(s[y, y + `])


So ECR (s) − ECR s2 ≤ 0 is equivalent to


"x+k
# y+`
y+`
x+k
X
X
X
X
Cαi (εi−1 ) ·
Pαj ≤ 
Cαi (εi−1 ) ·
Pαj
i=x

j=y

i=y

j=x

which yields the result.
Lemma 6. There exists an optimal troubleshooting
sequence s where for each opening index x ∈ Z, there
is a maximal regular subsequence s[x, x+j] (j ≥ 0) that
contains the maximizing sequence for cluster K(αx ).
Proof. Let s be an optimal troubleshooting sequence,
and let x be an opening index. Let s[x, x + j] be a
maximal regular subsequence and assume that it does
not contain the maximizing set. Then there exists
αy ∈ K(αx ) with y > x + j + 1 such that
ef(αy ) > ef(s[x, x + j])
Observe that the subsequence s[x, y − 1] can be partitioned into m > 1, say, maximal regular subsequences
s 1 , . . . , s m with s 1 = s[x, x + j]. By Lemma 5 we have
ef(αy ) > ef(s 1 ) ≥ ef(s 2 ) ≥ · · · ≥ ef(s m ) ≥ ef(αy )

Proof. We consider the sequence
s2 = h. . . , αx−1 , αy , . . . , αy+` , αx , . . . , αx+k , . . .i
which is equal to s except that the two regular sequences have been swapped.
Since s is optimal we

have ECR (s) − ECR s2 ≤ 0. Because the subsequences are regular and belong to different clusters or
do not contain opening indices, the costs are the same
in the two sequences in both s and s2 . Therefore,
we

get that the terms of ECR (s) − ECR s2 equal



Cαx (εx−1 ) · P εx−1 − P εx−1 , εy:y+`
..
.



x+k−1
x+k−1
Cαx+k (ε
)· P ε
− P εx+k−1 , εy:y+`



Cαy (εy−1 ) · P εy−1 − P εx−1
..
.



y+`−1
y+`−1
− P εx−1 , εy:y+`−1
Cαy+` (ε
)· P ε
since the remaining terms cancel out. Now observe
that


P εx+i−1 − P εx+i−1 , εy:y+` =


y+`
y+`
x+i−1
x+i−1
X
X
X
X
1−
Pαj − 1 −
Pαj −
Pαj  =
Pαj
j=1

j=1

j=y

j=y

and, similarly,


P εy+i−1 − P εx−1 , εy:y+i−1 =


y+i−1
y+i−1
x−1
x+k
X
X
X
X
1−
Pαj − 1 −
Pαj −
Pαj  = −
Pαj
j=1

j=1

j=y

j=x

where the last inequality follows by the fact that αy is
not an opening action (so we avoid ≥ cef(αy )). This
situation is clearly impossible. Therefore s[x, x + j]
must contain the maximizing set. By Lemma 2, it
must also contain a maximizing sequence.
Remark. In the above proof there is a technicality that
we did not consider: there might be equality between
the efficiency of an action in the maximizing sequence,
the efficiency of the maximizing sequence, and one or
more free actions. This problem can always be solved
by rearranging the actions, and so for all proofs we
shall ignore such details for the sake of clarity.
Finally, we have the following theorem:
Theorem 2. Algorithm 1 returns an optimal troubleshooting sequence.
Proof. By Lemma 5 we know that an optimal sequence
can be partitioned into a sequence of maximal regular
subsequences which is sorted by descending efficiency.
If we consider Lemma 6 too, then we know that we
should open the clusters in order of highest efficiency
and perform at least all actions in their maximizing
sequences as computed by Lemma 3. By Lemma 2
we know that the order of actions in the maximizing
sequences is the optimal one. By Lemma 5 we also
know that all free actions α with ef(α) > ef(K) must
be performed before opening the cluster, and all free
actions with ef(α) < ef(K) must be performed after
opening the cluster and performing all the actions in
its maximizing sequence.

Cluster 0
α1
Co1

α2
Cc1

Co2

Cluster 1
α3

Cc2

Cluster 2

α4
Co3

α5

α6

Cc3

Cluster 3
α7
Co4

α8
Cc4

Cluster 4
α10

α9

Co5

Cc5

Cluster 5
α12

α11

Figure 2: Example of a tree cost cluster model. To
open a cluster Ki when the parent cluster is open we
pay the cost Coi and to close a cluster given that all
children clusters are closed we pay the cost Cci .

5

THE TREE CLUSTER MODEL

In this section we shall investigate an extension of the
flat cluster model where the clusters can be arranged
as a tree. We call such a model for a tree cluster model,
and an example is given in Figure 2. In the tree cluster
model, the ECR does not admit the simple decomposition of Equation 1. The complication is that several
clusters might need to be opened before performing an
action in a deeply nested cluster. We therefore call
troubleshooting sequences in the tree cluster model
for tree troubleshooting sequences. Unfortunately, it is
easy to construct examples that show that Algorithm 1
will not yield optimal tree troubleshooting sequences.
Therefore, we shall present a new algorithm that solves
the tree cluster model in O(n · lg n) time.
First we need some additional definitions. The conditional cost Cα (ε) of α ∈ Ki will now depend on how
many clusters that have been opened on the path from
the root K to Ki . We therefore let AK(Ki | ε) denote
the set of ancestor clusters that needs to be opened on
the path from the root K to Ki given evidence ε. We
then define
X
CK ,
Cα (ε) = Cα + CK(α) (ε)
CKi (ε) =
K∈AK(Ki | ε)

Given this, Definition 1 is still valid for tree troubleshooting sequences.

A single action is called an atomic action. A compound
action consists of opening a cluster K and a sequence
of actions in which each action may be either atomic
or compound. Note that we shall usually not distinguish syntactically between atomic and compound actions. Also note that a compound action corresponds
to a subsequence where the first action is an opening action, and the efficiency of a compound action is
simply defined as the efficiency of the corresponding
subsequence. If T is a tree cluster model and K is an
arbitrary cluster in T , then the subtree model induced
by K, denoted TK , is a new tree cluster model containing exactly the clusters in the subtree rooted at
K, and with K as the open root cluster. If the induced
subtree model is a flat cluster model, we call it a flat
subtree model.
Definition 5. Let TK = {K, K1 , . . . , K` } be a flat subtree model. Then the absorbtion of K1 , . . . , K` into K
is a new cluster K↑ containing
1. for each child cluster Ki , a compound action induced by the maximizing sequence for Ki , and
2. all remaining actions from K,K1 ,. . . ,K` .
Note that in K↑ all the actions in a child cluster Ki that
are not contained in the newly generated compound
action will have a lower efficiency than the compound
action for Ki .
Definition 6. Let T be a tree cluster model, and let K
be any cluster in T . Then TK may be transformed into
a single cluster K↑ by repeated absorbtion into the root
cluster of flat subtree models. The resulting cluster K↑
is called the model induced by absorbtion into K.
Remark. By construction, the compound actions in a
model induced by absorbtion into the root cluster K
will only contain actions from the subtrees rooted at
a child of K.
With these definitions we can now present Algorithm
2. The algorithm works in a bottom-up fashion, basically merging leaf clusters into their parents (absorbtion) until the tree is reduced to a single cluster. Then
an optimal sequence is constructed by unfolding compound actions when they are most efficient.
The algorithm can be made to run in O(n · lg n) time
by the following argument. Sort the actions of all clusters in the tree T —this takes at most O(n · lg n) time.
During absorbtion, it is important to avoid merging
all actions of the child clusters into the parent cluster. Instead, we merge only the compound actions
into the parent cluster (takes O(` · lg n) time overall),
and create a priority queue holding the most efficient
remaining action of each child cluster. When creating a compound action for a parent cluster, we then

Algorithm 2 The bottom-up P-over-C algorithm
function BottomUpPOverC(T )
Input: a cluster tree T with root K
Compute the model K↑ induced by absorbtion
into K (see Definition 6)
Let s = hi
while K↑ 6= ∅ do
Let β be the most efficient action in K↑
if β is an atomic action then
Add action β to s
else
Add all actions of β to s in the order
prescribed by β
end if
Set K↑ = K↑ \ {β}
end while
Return s
end function
use actions from the priority queue as needed, and update the priority queue whenever an action is taken
out. Therefore, creating all the compound actions can
never take more than O(n · lg `) time. As the absorbtion process moves towards the root, we are forced to
merge priority queues from different subtrees. A simple induction argument can establish that it takes at
most O(` · lg `) time to merge all these priority queues.
In the following we shall prove that Algorithm 2 computes an optimal tree troubleshooting sequence. The
first two lemmas are minor generalizations of previous
lemmas, and the proofs are almost identical.
Lemma 7. Lemma 2 generalizes to tree troubleshooting sequences.
Lemma 8. Lemma 5 generalizes to subsequences of
actions that consists of (i) only free actions, or (ii)
actions from the same subtree.
Next we shall investigate the special properties of the
compound actions generated by the absorbtion process.
Definition 7. Let T be a tree cluster model, and let K
be any non-leaf cluster in T . A maximizing compound
action α̂ for K in T is defined as any most efficient
compound action in the model induced by absorbtion
into K.
Lemma 9. Let T be a tree cluster model, and let K be
any non-leaf cluster in T . Let TK be the subtree model
induced by K, and let α̂ be a maximizing compound
action for K in T . Then
ef(α̂) ≥ ef(β)
where β is any possible compound action in TK not
including actions from K.

Proof. We proceed by induction. Basis is a flat cluster model T = {K, K1 , . . . , K` } with compound actions βˆ1 , . . . , βˆ` of K and α̂ = maxi β̂i . Let β be any
compound action including actions from clusters in
T \ {K}, and assume that ef(β) > ef(α̂). We shall
use the fact
Pn
n Pi
Pi
n Pi
≤ max
min
≤ Pni
(2)
i
i Ci
Ci
C
i
i
(which is also known as Cauchy’s third inequality).
Then by Equation 2, β cannot be formed by any combination of the β̂i ’s as this would not increase the efficiency. Therefore β must be formed by either a strict
subset or a strict superset of one of the β̂i ’s. If β is a
subset of any β̂i , then the maximality of β̂i leads to a
contradiction. If β is a superset of any β̂i , then it will
include subsets of actions from a set of clusters with
subscripts I ⊆ {1, . . . , `}. Let us denote the subsets
from each Ki as βi . We then have
P
Pβ̂i
Pβ
Pβ
= ef(α̂)
ef(β) = Pi∈I i ≤ max i ≤ max
i∈I
C
C
C
i∈{1,...,`}
βi
i∈I βi
β̂i
where the first inequality follows by Equation 2, the
second follows by the definition of compound actions
formed during absorbtion, and the last equality is by
definition of a maximizing compound action. Since the
sets βi were chosen arbitrarily, we get a contradiction.
Hence in all cases ef(α̂) ≥ ef(β).
Induction step: we assume the Lemma is true for
all children Ki , . . . , K` of an arbitrary cluster K
where the children have maximizing compound actions
βˆ1 , . . . , βˆ` . A similar argument as above then shows
that the lemma is true for K as well.
Lemma 10. Let T be a tree cluster model with root
cluster K. Then there exists an optimal tree troubleshooting sequence s that contains (as subsequences) all
the compound actions of the model induced by absorbtion into K. Furthermore, the compound actions in s
are ordered by descending efficiency.
Proof. Let s = hα1 , . . . , αx , . . . , αx+k , . . .i be an optimal tree troubleshooting sequence and let αx be an
opening action, and let s[x, x + k], k ≥ x be the sequence of maximal length of actions from the same
subtree. Let furthermore s[x, x + k] be the first subsequence that contradicts the lemma, that is, s[x, x + k]
does not contain the compound action α̂ for the cluster K(αx ). Then there exists an atomic action αy ∈ α̂
(with y > x + k + 1) such that αy 6∈ s[x, x + k]. We
then have
ef(αy ) > ef(α̂) > ef(s[x, x + k])
because all atomic actions in a compound action are
more efficient than the compound action itself, and because α̂ is the most efficient compound action in the

subtree rooted at K(αx ) (Lemma 9). We can then partition the actions between αx+k and αy into m > 1,
say, subsequences (of maximal length) s 1 , . . . , s m . If
one (or more) of these subsequence is more efficient
than αy , we immediately get a contradiction to optimality of s because such a subsequence can be moved
before s[x, x + k] (Lemma 8). So we can assume that
all the m subsequences are less efficient than αy . Then
by successive application of Lemma 8 we can decrease
the ECR by moving αy to position x + k + 1. However, this again contradicts that s was optimal. Hence
s[x, x + k] must contain α̂.
By Lemma 8 it follows that the order of the compound
actions must be by descending efficiency.
Theorem 3. Algorithm 5 returns an optimal troubleshooting sequence.
Proof. By Lemma 10 we only need to establish the
order of the free actions between compound actions.
By Lemma 8 it follows that any compound action is
preceeded by more efficient free actions and followed
by less efficient free actions.

6

CONCLUSION

We have presented an algorithm, which in O(n · lg n)
time (n being the number of actions) provides an optimal troubleshooting sequence for scenarios where the
cost clusters form a tree and have inside information.
This is a useful result on its own, but there is more to
it.
When evaluating algorithms for troubleshooting, you
must distinguish between off-line and on-line activity.
If your task is off-line, the time complexity of your
algorithm may not be particularly important as long
as the result can be stored easily (like for example
an optimal action sequence). However, if the decision
support system is flexible, it must allow the user to interact with the recommendations and have the system
calculate an optimal next action based on alternative
information.
Furthermore, for many scenarios you will request online calculation of an optimal sequence; for example
when the model includes questions and tests. For this
kind of scenario, a direct representation of an optimal strategy may require too much space. Therefore,
a myopic question heuristic usually relies on optimal
sequences of actions calculated on-line.
Finally, our results imply a major improvement for offline methods like AO∗ because the search tree can now
be extensively pruned. This is because all subtrees
that consist entirely of actions can be replaced with a
single sequence of actions.

7

ACKNOWLEDGEMENTS

We would like to thank the three anonymous reviewers
for their excellent feedback. Thanks also go to Sven
Skyum for help with Lemma 3.

References
D. Heckerman, J. S. Breese, and K. Rommelse.
Decision-theoretic troubleshooting. Communications of the ACM, 38(3):49–57, 1995.
F. V. Jensen, U. Kjærulff, B. Kristiansen, C. Skaanning, J. Vomlel, and M. Vomlelová. The SACSO
methodology for troubleshooting complex systems.
Artificial Intelligence for Engineering Design, Analysis and Manufacturing, 15:321–333, 2001.
J. Kadane and H. Simon. Optimal strategies for a class
of constrained sequential problems. The Annals of
Statistics, 5:237–255, 1977.
J. Kalagnanam and M. Henrion. A comparison of decision analysis and expert rules for sequential diagnosis. In UAI ’88: Proceedings of the Fourth
Conference on Uncertainty in Artificial Intelligence,
pages 271–282, Amsterdam, The Netherlands, 1990.
North-Holland Publishing Co. ISBN 0-444-88650-8.
E. Koca and T. Bilgic. A troubleshooting approach
with dependent actions. In R. L. de Mántaras and
L. Saitta, editors, ECAI 2004: 16th European Conference on Artificial Intelligence, pages 1043–1044.
IOS Press, 2004. ISBN 1-58603-452-9.
H. Langseth and F. V. Jensen. Heuristics for two extensions of basic troubleshooting. In Proceedings of
the Seventh Scandinavian Conference on Artificial
Intelligence, pages 80–89. IOS Press, 2001. ISBN
1-58603-161-9.
S. Srinivas. A polynomial algorithm for computing the
optimal repair strategy in a system with independent component failures. In UAI ’95: Proceedings
of the Eleventh Conference on Uncertainty in Artificial Intelligence, pages 515–522. Morgan Kaufmann,
1995.
M. Vomlelová. Complexity of decision-theoretic troubleshooting. Int. J. Intell. Syst., 18(2):267–277,
2003.
H. Warnquist, M. Nyberg, and P. Säby. Troubleshooting when action costs are dependent with application to a truck engine. In Proceeding of the Tenth
Scandinavian Conference on Artificial Intelligence,
pages 68–75, Amsterdam, The Netherlands, 2008.
IOS Press. ISBN 978-1-58603-867-0.

