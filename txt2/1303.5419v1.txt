available also for conventional (quantitative) control
and will be incorporated later into our framework for
discrete probabilistic monitoring.
The conventional q uantitative approach to such a
tracking problem is to use a controller such as a
Kalman Filter (Bar-Shalom and Fortmann, 1988),
which is based on the cycle: predict state, measure

(i.e. sense), update state estimate. Such quantitative
methods are inadequate for handling the gross changes
that are the focus of our work, as they are restricted
to reporting ever larger covariances. Light beam sen­
sors provide coarse, comparatively sparse data about
movement in an environment, which are not suited to a
conventional quantitative treatment. A symbolic rep­
resentation of change is more informative, as we apply
probabilistic reasoning techniques to monitoring gross
changes.
Belief Networks (Pearl, 1988) integrate a mechanism
for inference under uncertainty with a secure Bayesian
foundation. Belief networks have been been used
in various applications, such as medical diagnosis
(Spiegelhalter et al., 1989) and model-based vision
(Levitt et al., 1989), which initially were more static,
i.e. essentially the nodes and links do not change over
time. Such approaches involve determining the struc­
ture of the network; supplying the prior probabilities
for root nodes and conditional probabilities for other
nodes; adding or retracting evidence about nodes; re­
peating the inference algorithm for each change in evi­
dence. There has also been work on the dynamic con­
struction of belief networks (Breese, 1989) (C harniak
and Goldman, 1989), but the desired output is still a
single static network. Only recently have a few re­
searchers used belief networks in dynamic domains,
where the world changes and the focus is reasoning
over time. Such dynamic applications include robot
navigation and map learning based on temporal belief
networks (Dean and Wellman, 1991) and monitoring
diabetes (Andreassen et al., 1991). For such applica­
tions the network grows over time, as the state of each
domain variable at different times is represented by a
series of nodes. These dynamic networks are Marko­
vian, which constrains the state space to some extent,
however it is also crucial to limit the history being
maintained in the network. We have developed such
a dynamic belief network for discrete monitoring us­
ing light beam sensor data (Nicholson, 1992) which we
briefly describe in Section 2.
Sensor data may be noisy or incorrect. In Section 3
we review how conventional quantitative methods val­
idate sensor data and reject incorrect data, then de-

208

Nicholson and Brady

scribe the types of incorrect data which may occur
in the domain. In Section 4 we show how the basic
DBN, which infers only an impossible combination of
evidence, may be modified to handle (and implicitly re­
ject) specific types of incorrect data. We then present
an extension to the DBN in Section 5 which provides
a qualitative explanation of inconsistent data being
caused by a defective sensor, allowing us to model ei­
ther intermittent or persistent faults.

2
2.1

THE DOMAIN
THE DISCRETE SPATIAL AND
TEMPORAL MODEL

The environment (a laboratory in which a robot ve­
hicle roams) is divided into regions by the light beam
sensors. Without significant loss of generality, we re­
strict attention initially to rectangular regions. We
monitor moving objects, which may be robots or peo­
ple. An object's position is given by the region it is
believed to be in. Each light beam sensor provides data
about a light beam sensor crossing (BC): the direction
of the crossing, and the hegin and tend time points for
the time interval over which it occurred. The tempo­
ral representation is a time line divided at irregular
intervals by the tbegin/tend time points. The time in­
tervals between observation data, during which there
is no change in the world state, are labelled T0, T1,
... T;, T;+l, etc. (We also refer to successive intervals
as T and T+l.) The discrete trajectory for an object
is a sequence of region/time interval pairs (R, T). The
heading of an obj ect in a given region indicates from
which direction it entered (i.e. one of N, S, E, W).
We also assume that we have a model of the object's
mobility, the tendency of an object to move. This is
a function over time of the speed of the object, the
spatial layout, the type of object, and so on, and gives
us the probability that it will move at time instant t,
which can be projected onto the time interval T.
2.2

THE DBN MODEL

This discrete spatial and temporal model of the do­
main may be represented by the discrete valued nodes
in the DBN. For now we make the reasonable prac­
tical assumption that the environment is closed and
that the number of objects, N, in the environment,
is known and fixed; the more general case is not sig­
nificantly more complex but involves dynamic mod­
ification of the network structure. The spatial lay­
out of regions and sensors is fixed and known; let us
suppose that we have M regions and P sensors. Ta­
ble 2.1 gives a summary of the types of nodes, their
states, and their function in the network. The world
nodes are those that represent the world state space:
object position (OBJ), heading (HEAD) and mobility
(MOTION}, and region occupancy information (#R).
Nodes are time-stamped with the time interval, T;,
over which they apply and during which the world

Table
Node
UHJ;fl')

HEAD;(T)
MOTION;(T)
#RAT)

1:

DBN Node Types

:States and l''unctton
r1 .r2

rM

• . , .

Position of object i at timeT
u,hN,hs,hE,hw
Heading of object i: u = unknown;

stat, aoye

Mobility of object i;
for stationary

stat short
0, 1, ...

n

Region occupancy - number only:
for i, region j contains i objects

HC-Otl::i;

BC-ACT;

nc,dir1,dir2

crossing data from sensor i:
nc indicates no crossing,
dir1, dir2: the possible directions

nc, dir1 ,dir2,both
Actual crossings of LB i;
both represents objects crossing
in both directions

does not change. Observation nodes are those rep­
resenting the sensor crossings: a node for the crossing
data provided by the sensor (BC-OBS), and a node
representing the actual physical crossing of the whole
sensor which occurred {BC-ACT). We make this dis­
tinction between actual and observed because objects
may cross a sensor in both directions during the ob­
servation data time interval, T BC, however the sensors
only detect a single directional crossing. The proba­
bility distribution (PD) for BC-OBS., is:

P(BC-OBS;=dirl I BC-ACT; = dirl)
P(BC-OBS;=dir2 IBC-ACT; :::: dir2)
P(BC-OBS ;=dir2 IBC-ACT; = both)
P(BC-OBS;=dir1 IBC-ACT; =both)=
P(BC-OBS;=nc IBC-ACT; nc)
1
=

=
=

=

1
1
0.5
0.5

=

During any given time interval T when nothing has
changed, there will be N object position, heading, and
mobility nodes, and M region nodes. If there are P
light beam sensors, a sensor crossing will generate P
actual crossing (BC-ACT) and observed signal (BC­
OBS) nodes.

.

..._,

ITTTl
L::.J.:.L.LJ

Figure 1: (a) General expansion of the network; (b)
Example scenario used throughout this paper.
The dynamic construction of a network combines the
world model (movement of objects between regions)
and the observation model (the light beam sensor data
which is generated) as the network grows over time (see
Figure l(a)). The network expansion and inference

Sensor Validation Using Dynamic Belief Networks

algorithm is:
1.

2.

3.
4.
5.
6.

since they are non-linear.

Make new instiUlces of world nodes
(OBJ, HEAD, MOTION, R) for the T+l interV&l.
Connect old {T) &nd new (T+l) world nodes.
Create new observation nodes (BC-ACT, BC-OBS).
Connect world iUld observation nodes.
Add da.ta. as evidence for obs. nodes (BC-OBS).
Run inference algorithm to update beliefs.

If step 5 is omitted then the predictions made by the
network corresponds to a prediction of the position
of an object dependent only on its previous position
and its mobility. If the sensor crossing data is added 88
evidence, then the inference gives an updated estimate
of the object position at time interval T+1, and may
also change beliefs about any node in the network,
including those before time intervalT.
The DBN is multiply-connected, requiring compli­
cated inference algorithms, such as conditioning or
clustering (Pearl, 1988). The problem of inference for
such networks is NP-hard (Cooper, 1990), however im­
proved algorithms such as (Jensen et al., 1990) have
made inference in carefully structured networks feasi­
ble (Andreassen et al., 1987). The DBN as described
gives us an inference engine which infers alternative
world models (the position of object in regions) with
associated probabilities, from both the model of object
motion (the prior probabilities for the objects' mobil­
ity) and the the sensor crossing data (the observation
model). (Nicholson, 1992) provides more details.
The example scenario, shown in Figure 1(b) used
throughout this paper is a linear arrangement of 4 re­
gions, 3 light beam sensors containing one object. The
methods described in this paper also apply to multiple
objects and other divisions of the environment, includ­
ing a grid of sensors.

A previous paper (Nicholson and Brady, 1992) shows
how the DBN may be extended to maintain a limited
history of the movement of the object. This provides a
solution to the data association problem (DAP), that
of deciding which object has given rise to which ob­
servation. Quantitative solutions to the DAP include
certain techniques for handling observations which do
not fall within the validation regions. One method is
to discard them as "clutter", which is sometime called
a false alarm (Bar-Shalom and Fortmann, 1988). An
alternative is to initiate a new track (and hence filter)
for such an observation and discontinue it after a cer­
tain time if no further data supports this hypothesis
of a new object.
In some quantitative methods track continuation (Bar­
Shalom and Fortmann, 1988p. 255} is done to handle
missing data. If the validation region is empty, the
track is extrapolated. If a predetermined number of
subsequent validation regions in a row are also empty,
the track is dropped.
3.2

Incorrect light beam sensor data may be classified
fol1ows:

3.1

a sensor crossing is signaled but in
fact never took place, a fa]se positive. This corre­
sponds to clutter, noise or general false alarms in
quantitative methods.

2.

Wrong Direction Data: a beam is broken, but the
signaled direction of crossing is incorrect. The
sensor data is inaccurate, rather than completely
wrong; the sensor is certainly malfunctioning.

3.

Missing Data: an object moves from one region
to another but no sensor crossing data is regis­
tered, a false negative. This corresponds directly
to missed detection in quantitative methods.

4.

Wrong Time Data: a sensor crossing does oc­
cur, and the direction is correct, however the time
stamp is incorrect.

INCORRECT DATA
Quantitative Methods

Quantitative approaches to tracking and sensor vali­
dation involve a noise model; random perturbations
which usually have only a small effect. For the usual
case of unbiased estimators, a Gaussian model is ad­
equate and is optimal for white noise. (If the estima­
tors are biased, there are models for "coloured" noise).
These are used for continuous variables. If variables
values are discrete a Poisson distribution is used in­
stead of a Gaussian. To handle gross errors of the sort
that are the focus here, a number of different tech­
niques have been proposed. A threshold called a vali­
dation gate may be applied to the Gaussian (for exam­
ple, 2 standard deviations, corresponding to 97.7%).
Alternatively robust statistics (Huber, 1981; Durrant­
W hyte, 1987) may be used, where, for example, the
error is a linear combination of two Gaussians. Fi­
nally non-parametric statistics have been developed;
but they are more difficult to compute and analyse

as

1. Ghost Data:

,

3

Incorrect Data for the Domain

Suppose we know that the object is in region R1 at
timeT. The observation BC-OBS3 of either direction
of crossing must be ghost data. However if we know
the object is in region Rt and the next data received
is BC-OBS1 = dir2, then this may be either ghost
data or wrong direction data. Obviously we are not
always able to determine immediately that data is in­
correct: this may depend on the combination of data
received. Suppose that we do not know the where­
abouts of the only object in the environment and that
we receive two pieces of data: BC-OBS1 = dirt and
BC-OBS3 = dir2. Received together, the two obser­
vations are not mutually compatible, they are incon­
sistent; one must be a ghost crossing (or they both
might be). If they are observed sequentially, there

209

210

Nicholson and Brady

may have been some missing crossings, or again one
or both are ghost data. We want to represent these
as possible but competing alternatives, and to allow
subsequent data to support a particular alternative.
In this paper we do not deal with the possibility that
both ghost and wrong direction data could be caused
by an object which the system does not know about;
we assume that all initialisation information is correct
and that no new objects appear. The main point to
be noted for both ghost and wrong direction data is
that there is an observation node with evidence in the
DBN which directly represents the incorrect data.
We have based the DBN on the assumption that the
time frames are determined by the sensor data which
corresponds to a change of state, i.e. an object has
moved between regions. Missing data means that an
abject has moved undetected to another region. In
some situations we can model this missing data within
the existing DBN expansion and inference algorithm.
Suppose, for example, there is a missing crossing for
sensor LB1, and an observation is received for another
sensor, LB2. While adding the received observation,
BC-OBS2 = ciir1, we create a negative data node far
the first sensor, BC-OBS1 = DC, which represents the
missing crossing (although with incorrect time stamp).
However if nothing has changed, the network has not
been expanded, and there is not even an incorrect DC
signal recorded. If the object that made the unde­
tected movement generates the next positive observa­
tion, then there will never be a BC-OBS added with
evidence nc that actually represents the wrong read­
ing. If the region the object has moved into undetected
is otherwise unoccupied this may cause a subsequent
detected sensor signal that would be considered ghost
data, or wrong direction data. The higher level rea­
soning and additional expansion of the DBN which is
required to handle this missing data is given in (Nichol­
son, 1992).
If the time stamp is incorrect but the temporal order
of the observation data nodes added to the network
is correct, then wrong time data will only affect the
system's temporal reasoning, for example comparing
against schedules and predictions. If the error in the
time stamp is wrong to the extent the order of the BC
nodes is wrong, this will generate problems of missing
data and ghost crossings. Such incorrect ordering of
data cannot be handled within the network and is not
considered in this paper.

4

HANDLING INCORRECT DATA
WI THIN THE BASIC DBN

The basic DBN does not handle inconsistent data; it
finds the evidence impossible and rejects it. We can
modify the existing DBN to provide a mechanism for
handling certain kinds of inconsistent data.

4.1

MODIFYING THE PD FOR BC-OBS

The first three types of incorrect data which we iden­
tified above involve a discrepancy between the sensor
crossing data received by the DBN controller, and the
crossing which actually took place. We have already
modeled the distinction between the crossing which
took place and the data received by creating the two
types of sensor crossing node, BC-ACT and BC-OBS.
The modification to the existing DBN involves chang­
ing the probability distribution for the BC-OBS node.
Instead of using binary values, we represent the uncer­
tainty in the network itself, as the PD entries for each
BC-OBSr become:
P(BC-OBS=dir1IBC-ACT=dir1)=conft
P(BC-OBS=dir2IBC-ACT=dir1)=(1-con/J)/2
P(BC-OBS=nciBC-ACT=dir1)=(1-conh)/2

ok
wrong
miss.

P(BC-OBS=dir1IBC-ACT=dir2)=(1-conft)/2
P(BC-OBS=dir2IBC-ACT=dir2)=con/J
P(BC-OBS=nciBC-ACT=dir2)=(1-con/t)/2

wrong
ok
miss.

P(BC-OBS=dir1IBC-ACT=nc)=(1-con/2)/2
P(BC-OBS=dir2jBC-ACT=nc)=(l-conh)/2
P(BC-OBS=ncjBC-ACT=nc)=con/2

ghost
ghost
ok

The confidence in the observation is given by some
value based on a model of the sensor's performance
and is empirically obtainable; conft is the confidence
in the positive sensor data, con/2 is the confidence in
the negative sensor data (or, 1-con/2 is the probability
of ghost data). We have modeled positive data being
ghost or wrong direction data as being equiprobable
- this need not be the case and can be replaced by
any alternative plausible values. Likewise for negative
data, although the equiprobable direction of the actual
crossing seems intuitively reasonable.
4.2

RESULTS FOR UNINITIALISED
EXAMPLE

We now show the results from the modified DBN for
the example environment, with the position of the ob­
ject at To unknown. The sensor observations made
are as follows.
Crossing

To
Tt

to
to
T:a to
T3 to

Tt
T2
T3
T4

BC-OBS2
nc

BC-OBSt
dir1
nc

nc

DC

nc

nc

nc

BC-OBS3
nc
dir2
dir1
dir2

Table 2 and Figure 2 shows the beliefs inferred by
the DBN after each new observation is received and
the network expanded. Each row of example diagrams
shows the updated beliefs for the position of the object
at some timeT. The observations are shown between
the appropriate rows. Each column corresponds to the
belief at some timeT for the position of the object over
time, i.e. shows the inferred trajectory. We make the

Sensor Validation Using Dynamic Belief Networks

Table 2: Beliefs inferred by the modified DBN for
inconsistent observations. Initial position unknown.

conf

=

0.99.
0.8827
0.0405
0.0384
0.0384
0.0405
0.8827
0.0384
0.0384

.,.

.,

0.4 81
0.02195
0.0221
0.4779
0.0219
0.4781
0.0220
0.4780
1
0.4779
0.4781
0.0220

.,

3

0.0 66
0.0035
0.0403
0.8796
0.0035
0.0766
0.0401
0.8798
0.0035
0.0764
0.9162
0.0039
0.0035
0.0763
0.0768
0.8434

4
0.0002
0.0436

0.911:110

0.0002
0.0042
0.0433
0.9523
0.0002
0.0039
0.9918
0.0041
0.002
0.0039
0.0041
0.9918
0.0002
0.0039
0.9526
0.0433

.,

BC-OBSt{Tt)
BC-OBSa(T2)
correct
ghost
ghost
correct
wrong direction ghost
ghost
wrong direction
ghost
ghost
The first two alternatives have the same probabilities
and are considered the most likely (i.e. approaching
0.5 probability).

Beliefs during Ta: The additional BC-OBSa(Ta)
crossing (from Ra to �) acts as support for the
BC-OBS3(T2 ) observation being correct; belief(BC­
ACT3(T2 ) = dir2) = 0.8761 and belief(BC­
ACTt(Tl) = nc) = 0.9265, i.e. BC-OBSt(To) was
probably ghost data.
Beliefs during T4 : The additional BC-OBSa(T4)
crossing is further support for the alternative that
the first observation was ghost data and second
correct; belief(BC-ACT1{Tt)=nc) = 0.996 and
beliet(BC-ACTa(T2 )=nc) = 0.9484. The DBN has
inferred that the object is probably initially in Rt;
belief(OBJt(To)=r 4) = 0.9520 .
4.3

RESULTS FOR INITIALISED
EXAMPLE

DATA:N.,.U
... _
DAT'-U•l4

A

�• I I
...

_

•

c

• I

• I

• I I I

I�!! I I�!! I I !!� I

.........
...,.

Figure 2: Object position beliefs for inconsistent ob­
servations from Table 2. The belief that the object is
in a region is indicated by the intensity of shading.

following observations on these results.
Beliefs during T0: 4 alternatives are being main­
tained explicitly, all equally probable.
Beliefs during T1: The DBN is nearly certain that
the OBJ moved R1 to R2. The initial beliefs (i.e. the
Oth instance) have been revised, indicating that the
OBJ was very likely to have been in R1. If the data
was ghost data (considered unlikely), there is a small
chance that the object started in R 2, Ra or�- There
is also the alternative that the crossing occurred but in
the opposite direction. Hence the belief for R2 (ghost
plus wrong direction alternatives) is larger than R3
and R4 (ghost only).
Beliefs during T 2: The system now maintains the
alternatives:

J)J

Figure

,01

3:

.01

.....

0

0

I

0

0

-

·

0

'

Object position beliefs with successive BC­

INV nodes unconnected.

Figure 3 shows the beliefs inferred with the object
initially in R1, with no observations added (column
1) , then for the 3 alternative observations shown. We
make the following observations on these results.
No observations: The object may stay in R1 or move
into Rz. Sensors LB 2 and LB3 should generate a no­
crossing signal, because there are no object in the re­
gions they separate, however the DBN infers a small
probability of a ghost crossing signal. The beliefs in­
ferred for the signal BC-OBSt are a combination of the
possible nc or dir2, plus possible incorrect data from
the sensor, hence the predicted observation probabili­
ties differ from the actual crossings predicted.
Observation A: For the BC-OBS1 = dir1 crossing
data, the DBN correctly infers that this might be cor­
rect data (i.e. BC-ACTt = dirt) or ghost data (i.e.
BC-ACT1 = nc).

211

212

Nicholson and Brady
Because there was no object in R2 at
To, the BC-ACT1 = dir2 crossing must be i�corr�ct
data; it may be either ghost data, or wrong duectlon
data.

Observation B:

BC-ACT(f)

BC-INV(T)

The DBN infers that BC-ACTa must
be nc, implicitly rejecting the observation as incorrect
data.

Observation C:

4.4

Our model includes observations as specific evidence
for a variable, the BC-OBS node. One possible al­
ternative would be to model the uncertainty in the
accuracy of the observation by using virtual evidence
{Pearl, 1988), which is given as a likelihood ratio of
the states of the BC-OBS node. If the data was
for a dir1 crossing of sensor LB.,, then the spe­
cific evidence using the existing scheme would be
..t-evidenc:e(BC-OBS., = dir1). The corresponding
virtual evidence for takes the form dir1 :DIR2: IC, i.e.
conf: (1-con/)/2: {1-con/)/2. This use of virtual
evidence provides the same results as modifying the
PD for BC-OBS. Since the BC-OBS evidence is the
physical output of a sensor, we prefer to enter it as
specific evidence and model the difference between � he
observation from the sensor and the actual crossmg
within the DBN itself.
5

EXPLAINING BAD DATA AS A
DEFECTIVE SENSOR

The modification to the DBN described in the pre­
vious section provides a mechanism for handling (by
implicitly rejecting) certain inconsistent data. It rep­
resents adequately the underlying assumptions about
the data uncertainty, which are that the observed sen­
sor crossing might not match the actual sensor crossing
that took place. However it does not provide an ex­
planation of why the observed sensor data might not
reflect the actual crossing. We want to represent the
most usual source of incorrect data, namely a defective
sensor.
5.1

BC-OBS(T)

Using Virtual Evidence

THE INVALIDATING NODE

We adapt an idea that has been used in other re­
search areas, that of a moderating or invalidating con­
dition. In the social sciences and psychology, the term
"moderator" is used for an alternative variable that
"messes up" or "moderates" the relationship between
other variables (Zedeck, 1971; Wermuth, 1987; Wer­
muth, 1989). A similar idea has been used in expert
system research; in (Andersen et al., 1989) such nodes
are called "invalidators". Of course, this idea is also fa­
miliar to the AI community; Winston (Winston, 1977)
described the notion of a censor, which acts as an "un­
less" condition: if a BC-ACT occurs, then BC-OBS
will be generated unless the sensor is defective.

Figure 4: Adding the invalidating node,
the DBN

BC-INV,

to

We add a node, BC-INV, the invalidating node, which
has two states, [work • det] short for "working" and
"defective". It is connected as a predecessor of BC­
OBS (see Figure 4). The PD for BC-OBS for ghost
data, wrong direction data, and missing data is given
by:
,

P(BC-OBS=dir1 IBC-ACT=dir1 BC-INV=vort) = 1
P(BC-OBS=dir2l BC-ACT=dir2 BC-INV=vort) 1
P(BC-OBS=nc I BC-ACT =nc BC-INV=vort) = 1
=

P(BC-OBS=dir2 I BC-ACT=dirl BC-INV=def) = 0.5
P(BC-OBS=nc I BC-ACT=dir1 BC-INV=def) = 0.5
P(BC-OBS=dir1 I BC-ACT=dir2 BC-INV=def) = 0.5
P(BC-OBS=nc I BC-ACT=dir2 BC-INV=def) = 0.5
P(BC-OBS=dirl I BC-ACT=nc BC-INV=def) = 0.5
P(BC-OBS=dir2 I BC-ACT=nc BC-INV=def) = 0.5

The question then arises: what are the prior probabil­
ities for BC-INV? We explicitly represent how likely
it is that the sensor is working correctly by the prior
probabilities for BC-INV, which can be obtained from
empirical data; con/ is now explicitly the confidence
that the sensor is working.
P(BC-INV=vort I ) = conf
P(BC-INV=def I) = 1-conf
5.2

RESULTS FOR SENSOR STATUS

The inference algorithm was run for the same set of al­
ternative observations (A, B and C ) on the DBN with
the BC-INV nodes added; again the object is initially
in R1 and con/ = 0.99. The additional beliefs inferr�d
for the BC-INV nodes having state def are shown m
Figure 3 under the appropriate sensor {in row labelled
P(def)). For cases A and B, the DBN infers that all
nc observations for sensors LB2 and LBa are correct
(i.e. BC-INV =wort) because there were no objects in
adjacent regions to move across these sensors. In case
C the DBN infers correctly that sensor LBa must be
d�fective (i.e. BC-INVa = def); there is a small pos­
sibility that the nc observation for sensor LBt may be
incorrect, if there is missing data.
5.3

MODELING SENSOR STATU S OVER
TIME

Sensor Validation Using Dynamic Belief Networks

P(BC-OBS:::::dir1 IBC-ACT=dir1 BC-INV=def)=x
P(BC-OBS=dir2IBC-ACT=dir2 BC-INV=de:f)=x
P(BC-OBS=nciBC-ACT=nc BC-INV�def)=x > 0

BC.OOS(T+I)

Figure

5:

Modeling sensor status over time.

The invalidating node provides the explicit representa­
tion of the cause of incorrect data - a defective sensor.
However, there is no connection between successive
BC-INV nodes, which means no correlation between
the working status of a sensor at different times. If
the DBN infers that a sensor is defective at some time
T because the dat a received has been wrong, it should
also effect the interpretation put on subsequent (and
possibly earlier) data from that sensor. To provide
such a model of the sensor, we assume that at the ini­
tial time T0 all BC-I NV ;(T0 ) nodes have some prior
such as described above. At each time step, a copy
is made of all the BC-INV nodes (whether or not any
data is received for that sensor), and each is connected
to its success or (see Figure 5). The PO for each BC­
INV(T+l) is then given by:

A persistent fault may be modeled by X equals 0, but
without the need to change the probability distribu­
tion for BC-OBS. An example of a persistent fault is
the incorrect wiring of the sensor so that the crossing
direction is wrong each signal. In practice, a controller
will request confirmation of the status of the sensor,
or receive information that it has been repaired. In
this case, BC-INV(time-of-report) will h av e no prede­
cessors and the prior will reflect the confidence in the
status report. Results from the DBN with the BC­
INV{T) to BC-INV (T+l) connection for the same set
of observations are shown in Figure 6, conf = 0.99, d
= 0.01, X = 0. Since X = 0, once sensors LB1 (case
B) and LB3 (case C) has been identified as definitely
defective, the DBN infers that the probability it was
defective initially (BC-INV3(To) = def) is 0.5025.

.....

... _
..

�

..

·-

�iI1 I
I0 I •lffl-1
I I •(JI
.0031
1
0
.0011 0
0

0

d

where d is a degradation factor and X is related to the
consistency of the fault.
The degradation factor dis the probability that a sen­
sor which has been working during the previous time
interval has begun to respond defectively. It is based
on a model of the expected degradation of the sensor
and is a function of the time between sensor readings.

5.4

.Ot99 .0199 ..,191

0

I � i: 1 I I ;; f ! I I ! f-+ I
.916)

Tt•�+�l I
l'(do!)

P(BC-INV(T+I)==vork IBC-INV(T)::::: vork)::::: IP(BC-INV(T+I)==def I BC-INV(T)= vork)::::: d
P(BC-INV(T+l)==def I BC-INV{T} = def) = 1-X
P(BC-INV(T+l)==vork IBC-INV(T)::::: def)=X

> 0
> 0

PERSISTENT AND INTERMITTENT
FAULTS

There are two general models for a defective sensor: an
intermittent fault, which means that not every signal
from the sensor is incorrect; a persistent fault, that
manifests itself for each observation.
One method for modeling an intermittent fault is to
make the variable X strictly positive. However if the
DBN infers from the data that (i) BC-INV(T;) = def,
and (ii) BC-INV(Ti+I) =work then the fault detected
during T; cannot be passed on to T;+2· An alterna­
tive is to have X = 0 all the time (i.e. once a sensor is
known to be defective it remains defective) and change
the PD for BC-OBS so that if a defective sensor can
still produce correct data:

Figure 6: Object position beliefs inferred by DBN with
successive invalidating nodes connected.
5.5

MODELING DIFFERENT DEFECTS

The current BC -INV node, with only two states,
does not allow the explanation to distinguish between
types of defects. We can increase the BC-INV states
to [work, def-ghost, def-dir, def-miaa], for ghost
data, wrong direction data and missing data respec­
Details of and results for these additional
tively.
states, as well as results for various combinations of
con f , d and X may be found in (Nicholson, 1992).

6

CONCLUSIONS

The basic DBN provides discrete tracking of objects
based on light beam sensor data, in a method which
is analogous to quantitative filter techniques. In this
paper we have described a solution to the problem of
incorrect or noisy data. By changing the PD for the
BC-OBS node to contain values other than 1 or 0,
the DBN is able to handle inconsistent data, rather
than simply inferring a contradiction in the evidence.
The addition of a node which models the status of
the sensor as working or defective, as another parent
of the BC-OBS node, provides an explanation of the
incorrect data as being caused by a defective sensor.

213

214

Nicholson and Brady

The connection of the successi ve instances of the inval­
idating node models the status of a sensor over time,
allowing the DBN to handle both persistent and in­
termittent faults. We have shown that a combination
of AI techniques - discrete representation and reason­
ing with uncertainty - can provide a solution to a real
world problem, i.e incorrect sensor data. Moreover,
the solution is in some ways more intuitive than equiv­
alent conventional quantitative methods.
Acknowledgements

References
Andersen, L. R., Krebs, J. H., and Andersen, J. D.
(1989). Steno: an expert system for medical diagno­
sis. Journal of Applied Statistics, 18(1): 139-153.
Andreassen, S., Benn, J., Hovorks, R., Olesen, K. G.,
and Carson, R. E. (1991). A probabilistic approach
to glucose prediction and insulin dose adjustment:
Description of metabolic model and pilot evaluation
study. Unpublished draft.
Andreassen, S., Woldbye, M., Falck, B., and Andersen,
S. (1987). MUNIN - A causal probabilistic network
for interpretation of electromyographic findings. In

Proceedings of the Tenth International Joint Confer­
ence on Artificial Intelligence, pages 366-372.
Bar-Shalom, K. and Fortmann, T. E. (1988). Tracking
and data association. Mathematics in Science and
Engineering Series. Academic Press.
Breese, J. ( 1989). Construction of belief and decision
networks. Technical Memorandum 30, Rockwell Palo
Alto Laborator y, 444 High Street, Palo Alto, Califor­
nia 94301.
Charniak, E. and Goldman, R. (1989). Plan recog­
nition in stories and in life. In Proc. of the Fifth

Workshop on Uncertainty in Artificial Intelligence,

54-60.

Cooper, G. (1990). The computational complexity of
probabilistic inference using bayesian belief networks.

Artificial Intelligence, 42:393-405.
Dean, T. and Wellman, M. P. (1991). Planning and
control. Morgan Kaufman Publishers, San Mateo,
Ca.
Durrant-Whyte, H.

F. (1987). Integration, Coordina­
tion, and Control of Multi-Sensor Robots Systems.

Kluwer Academic Press, Boston, MA.
Huber, P.

(1981). Robust Statistics.

John Wiley.

Jensen, F., Lauritzen, S., and Olesen, K. (1990).
Bayesian updating in causal probabilistic networks
by local computations.
Computational Statistics

Quarterly, 4:269-282.

of the Fifth Workshop on Uncertainty in Artificial
Intelligence, pages 233-244.
Nicholson, A. E.

(1992). Monitoring Discrete Environ·
ments using Dynamic Belief Networks. PhD thesis,

Dept. of Engineering Sciences, Oxford University.

Nicholson, A. E. and Brady, J. M. (1992). The data
association problem when monitoring robot vehicles
using dynamic belief networks. In Proc. of the 10th

European Conf. on Artificial Intelligence {ECAI-92).

We wish to thank Hugh Durrant-Whyte, Finn Jensen,
Uffe Kjaerulff, Steffen Lauritzen, Stuart Russell and
David Spiegelhalter for valuable discussions during the
development of this research; the Rhodes Trust.

pages

Levitt, T., Mullin, J., and Binford, T. (1989). Model­
based influence diagrams for machine vision. In Proc.

Pearl, J.

{1988). Probabilistic Reasoning in Intelligent
Systems. Morgan Kaufmann, San Mateo, Ca.

Spiegelhalter, D., Franklin, R., and Bull, K. (1989).
Assessment criticism and improvement of imprecise
subject probabilities for a medical expert system. In

Proc. of the Fifth Workshop on Uncertainty in Arti­
ficial Intelligence, pages 335-342.
Wermuth, N. (1987). Parametric collapsibility and the
lack of moderating effects in contigency tables with a
dichotomous response variable. J. Roy. Statist. Soc.

B, 49:353-364.
Wermuth, N. (1989). Moderating effects in multivari­
ate normal distributions. Methodika, III:74-93.

Artificial Intelligence.
W inston, P. H. (1977).
Addison-Wesley Publishing Co., Massachusetts.
Zedeck, S. {1971). Problems with the use of moderator
variables. Psychological Bulletin, 76:295-310.

