
grows. The class of first-order, open-universe probabilistic languages, including BLOG (Milch et al.,
2005a) and Church (Goodman et al., 2008), handles cases in which the number of objects (in BUGS,
the index set) is unknown and perhaps unbounded,
and object identity is uncertain. It is still possible
to write a complete inference algorithm for BLOG,
based on MCMC over partial worlds; each such world
is constructed from the minimal self-supporting set
of variables relevant to the evidence and query variables. Generality has a price, however: BLOGâ€™s
default Metropolisâ€“Hastings inference engine samples
each variable conditioned only on its parents (Milch &
Russell, 2006). This approach leads to unacceptably
slow mixing rates for many standard models, in which
evidence from child variables is highly informative.
Our goal is to remedy this situation, primarily by extending the range of situations in which Gibbs sampling from the full, conditional posterior can be used
within BLOG. Section 2 of this paper introduces the
terminology of contingent Bayesian networks (CBNs),
which we will use as the propositional â€œabstract machineâ€ for open-universe stochastic languages. Section 3 surveys previous work related to general purpose sampling of CBNs and describes its limitations.
Section 4 then describes our novel Gibbs sampling algorithm for CBNs which addresses these limitations;
its implementation for BLOG is described in Section 5. Finally, we present experimental results on
various models in Section 6, demonstrating substantial speedups over existing methods.

2

Contingent Bayesian Networks

This section repeats, and in some cases generalizes,
definitions proposed by Milch et al. (2005b). A contingent Bayesian network (CBN) consists of a set of
random variables V, and for each variable X âˆˆ V, a domain dom(X) and decision tree TX . The decision tree
is a directed binary tree, where each node is a predi-

switching parents of X in Ïƒ. Intuitively, changes in
the values of switching parents can switch the distribution of X, as well as its set of parents. A switching
variable in Ïƒ is a switching parent for one or more
variables in Ïƒ. For the CBN of Example 1, the instantiation [ WingType=Helicopter, RotorLength=6,
BladeFlash=true ] makes WingType a switching parent of both RotorLength and BladeFlash.

WingType

RotorLength

An instantiation Ïƒ is self-supporting if it supports all
variables in Ïƒ. Assuming that the CBN is well-defined
(Milch et al., 2005b), we can define the probability of
a self-supporting instantiation as follows:

WingType=Helicopter
BladeFlash

p(Ïƒ) =
Figure 1: The CBN of Example 1, in which the BladeFlash sensor model differs for helicopters and planes.
cate on some subset of V. Each leaf of TX encodes a
probability distribution parameterized by a subset of
V, and defined on dom(X).
Example 1. An aircraft of unknown WingType â€“ Helicopter or FixedWingPlane â€“ is detected on a radar.
Helicopters have an unknown RotorLength, and depending on this length they might produce a characteristic pattern called a BladeFlash (Tait, 2009) in the
returned radar signal. A FixedWingPlane might also
produce a BladeFlash. As summarized in Figure 1,
TWingType = F1

F2
if WingType = Helicopter
TRotorLength =
null otherwise

F3 (RL) if WingType = Helicopter
TBladeFlash =
F4
otherwise
where RL is an abbreviation for RotorLength.
An instantiation Ïƒ is an assignment of values to a subset of V. We write vars(Ïƒ) for the set of variables to
which Ïƒ assigns values, and ÏƒX for the value that Ïƒ
assigns to a variable X. Ïƒ X=a is a modified instantiation which agrees with Ïƒ except for setting X to a.
An instantiation Ïƒ is said to be finite if vars(Ïƒ) is finite. An instantiation Ïƒ supports X if all the variables
needed to evaluate TX are present in Ïƒ. In Example 1, [WingType=FixedWing] supports BladeFlash,
but [WingType=Helicopter] does not.
We write ÏƒTX for the minimal subset of Ïƒ needed to
evaluate TX , and pX (Â· | ÏƒTX ) for the resulting distribution of X. The parents of X in Ïƒ are vars(ÏƒTX ),
while the children of X in Ïƒ are
Î›(Ïƒ, X) = {Y | Y âˆˆ vars(Ïƒ), X âˆˆ vars(ÏƒTY )}.

(1)

The subset of vars(ÏƒTX ) which were used to evaluate
internal nodes of TX (rather than the leaf) are the

Y

pX (ÏƒX | ÏƒTX )

(2)

X âˆˆ vars(Ïƒ)

An instantiation Ïƒ is feasible if p(Ïƒ) > 0.

3

Related Work

Milch and Russell (2006) have previously shown
that the state space for Markov chain Monte Carlo
(MCMC) inference in CBNs may consist of minimal partial instantiations that support the evidence,
E, and query variables, Q. This idea has been exploited to build the current, default inference engine
for BLOG. Standard sampling algorithms for nonparametric, Dirichlet process mixture models use a related
representation: they instantiate parameters for those
mixture components which support the evidence, as
well as a few auxiliary components (Neal, 2000). Our
new algorithm builds on both of these methods.
3.1

Parent-Conditional Sampling

In the absence of a model-specific, user supplied
proposal distribution, BLOGâ€™s existing inference engine relies on a parent-conditional proposal. This
algorithm picks a variable, X, at random from all
non-evidence variables in the current instantiation Ïƒ,
V (Ïƒ) = vars(Ïƒ) âˆ’ E, and proposes a new instantiation
Ïƒ 0 with the value of X drawn from pX (Â· | ÏƒTX ). If X
was a switching variable in Ïƒ, we may then need to instantiate new variables, and uninstantiate unneeded
ones, to make Ïƒ 0 minimal and self-supporting over
Q âˆª E. All new variables are instantiated with values drawn from their parent-conditional distribution.
We say that any Ïƒ 0 constructed by this procedure is
X
reachable from Ïƒ via X, or Ïƒ
Ïƒ 0 . The following
properties are easily seen to be true of reachability.
Proposition 1. A minimal self-supporting feasible instantiation Ïƒ 0 is reachable from an instantiation Ïƒ via
X if and only if X âˆˆ vars(Ïƒ) âˆ© vars(Ïƒ 0 ), and Ïƒ and Ïƒ 0
agree on all other variables in vars(Ïƒ) âˆ© vars(Ïƒ 0 ).

Proposition 2. If Ïƒ
Ïƒ 0 , then there does not exist
Y
Y âˆˆ V (Ïƒ), Y 6= X, such that Ïƒ
Ïƒ0 .

1. Create an initial, minimal, self-supporting feasible
instantiation Ïƒ consistent with the evidence E,
and including the query variables Q.

The nature of this proposal distribution q(Ïƒ â†’ Ïƒ 0 )
makes it quite simple to compute the acceptance ratio
for the Metropolisâ€“Hastings (MH) method (Andrieu
et al., 2003), which takes the following form:

2. Initialize statistics of the query variables to zero.

X



Î±(Ïƒ â†’ Ïƒ 0 ) = min 1,

p(Ïƒ 0 )q(Ïƒ 0 â†’ Ïƒ)
p(Ïƒ)q(Ïƒ â†’ Ïƒ 0 )

(3)

0
pX (ÏƒX

| ÏƒTX )
|V (Ïƒ)|

Y

Y

pY (Ïƒ 0 Y | ÏƒT0 Y )

(4)

âˆˆvars(Ïƒ 0 )âˆ’vars(Ïƒ)

From Equations (2) and (4), the terms corresponding to vars(Ïƒ 0 ) âˆ’ vars(Ïƒ) cancel in p(Ïƒ 0 )/q(Ïƒ â†’ Ïƒ 0 ).
Similarly, terms in vars(Ïƒ) âˆ’ vars(Ïƒ 0 ) cancel in
q(Ïƒ 0 â†’ Ïƒ)/p(Ïƒ). Further, it is easy to see that for
variables Y âˆˆ vars(Ïƒ) âˆ© vars(Ïƒ 0 ) âˆ’ Î›(Ïƒ, X) âˆ© Î›(Ïƒ 0 , X),
ÏƒTY = ÏƒT0 Y . Hence, pY (Â· | ÏƒTY ) = pY (Â· | ÏƒT0 Y ) and the
terms for all such variables Y , including X, cancel out.
Finally, the acceptance ratio Î±(Ïƒ â†’ Ïƒ 0 ) reduces to:

ï£³

1,

|V (Ïƒ)|
|V (Ïƒ 0 )|

(b) Randomly propose Ïƒ 0 such that Ïƒ
Ïƒ 0 using
the distribution of Equation (4).
(c) Compute the acceptance ratio, Î±(Ïƒ â†’ Ïƒ 0 ),
via Equation (5).
(d) With probability Î±(Ïƒ â†’ Ïƒ 0 ), set Ïƒ â† Ïƒ 0 .
Otherwise, leave Ïƒ unchanged.
(e) Update query statistics using Ïƒ.
4. Report query statistics.

q(Ïƒ â†’ Ïƒ 0 ) =

min

(a) Choose X âˆˆ V (Ïƒ) uniformly at random.
X



For any Ïƒ 0 reachable from Ïƒ via X, the unique way
of proposing this transition is to select X from V (Ïƒ),
0
propose the value ÏƒX
for it, and finally propose corresponding values for all new variables in Ïƒ 0 . Thus,

ï£±
ï£²

3. Repeat for the desired number of iterations:

Y
Y âˆˆÎ›(Ïƒ,X)âˆ©Î›(Ïƒ 0 ,X)

ï£¼
)ï£½

pY (ÏƒY0 | ÏƒT0 Y
(5)
pY (ÏƒY | ÏƒTY ) ï£¾

Note the dependence on those variables which are children of X in both Ïƒ and Ïƒ 0 . The overall algorithm is
summarized in Figure 2.

Figure 2: General purpose inference in CBNs using
parent-conditional Metropolisâ€“Hastings proposals, as
in (Milch & Russell, 2006).
Smith (1990). For discrete variables X, the Gibbs sampler computes a weight w(a) for each a âˆˆ dom(X):
Y
w(a) = pX (a | ÏƒTX )
pY (ÏƒY | ÏƒTX=a
) (6)
Y
Y âˆˆ Î›(Ïƒ,X)
0
ÏƒX

A new value
is then sampled from a normalized distribution with mass proportional to these non-negative
weights. Viewed as a Metropolis-Hastings proposal,
the acceptance probability for the Gibbs sampler always equals one; Gibbs moves are never rejected.

Equation (5) summarizes the main problem with
parent-conditional sampling: if the proposed value for
the sampled variable X does not assign high probability to the children of X, the move will be rejected. To
avoid undue assumptions, hierarchical Bayesian statistical models often use dispersed or â€œvagueâ€ priors, so
that such parent-conditional proposals have extremely
low acceptance probabilities.

The Gibbs sampler can be consistently applied to variables with finite, countable, or even uncountable domains, so long as the full conditional posterior can be
tractably normalized and sampled from. For models
specified via languages like BUGS, Gibbs sampling has
proven quite successful. However, most existing applications and analysis of the Gibbs sampler implicitly
assume a closed universe model, and instantiate the
full, finite set of variables at all iterations. If this algorithm were naively applied to a CBN, then for some
switching variables X and configurations a âˆˆ dom(X),
Ïƒ X=a might not support some children of X. For such
inconsistent model configurations, the normal Gibbs
weight w(a) cannot be evaluated.

The Gibbs sampler addresses this issue by directly
sampling X from its full conditional distribution,
pX (Â· | ÏƒVâˆ’X ), rather than its parent-conditional prior
pX (Â· | ÏƒTX ). This method was originally proposed
by Geman and Geman (1984) for inference in undirected Markov random fields, and later popularized as
a general Bayesian inference method by Gelfand and

One possible solution, proposed in the context of
Dirichlet process (DP) mixture models by Neal (2000),
augments Ïƒ with auxiliary variables chosen so that
Ïƒ X=a is self-supporting for all a âˆˆ dom(X). This augmented Ïƒ, which is now no longer minimal, is used to
construct the Gibbs weights; following the move any
remaining non-supported variables are discarded.

3.2

Gibbs Sampling

dom(X) = {0, 1, 2}
X âˆ¼ Categorical(.1, .6, .3)

X=0

X=1

X=2

dom(Yi ) = {0, 1} for all i âˆˆ N

1
Bernoulli( 1+X
)
if (X + i) mod 2 â‰¡ 0
Yi âˆ¼
1
Bernoulli( 1+X+Y
)
otherwise
i+1
Evidence: Y1 = true. Query: X.

Y2 = 1

Y2 = 0

Figure 3: A CBN which requires infinitely many auxiliary variables for standard Gibbs sampling approaches.
Such auxiliary variables are always sampled conditioned on Ïƒ, given the current value of X. For example, if ÏƒX = a and if Ïƒ was augmented with a variable
Z needed to support Ïƒ X=b for some b âˆˆ dom(X) âˆ’ a,
then we would sample Z from pZ (Â· | ÏƒTX=a
). This can
Z
lead to poor mixing rates, or an inconsistent sampler
if pZ (Â· | ÏƒTX=a
) and pZ (Â· | ÏƒTX=b
) have non-overlapping
Z
Z
support. Note that this issue doesnâ€™t arise with the
DP mixture sampler, since TZ had no dependence on
X, and pZ (Â· | ÏƒTX=a
) = pZ (Â· | ÏƒTX=b
) for any a, b.
Z
Z
To further illustrate this issue, consider the model of
Example 1 and a minimal instantiation, Ïƒ = [ WingType = FixedWingPlane, BladeFlash = True ]. If we
were to apply a typical auxiliary variable method to
do MCMC sampling in this model, we would first instantiate RotorLength given WingType = FixedWingPlane, and then construct Gibbs weights for WingType = FixedWingPlane and Helicopter. However,
the only value of RotorLength that can be sampled
given WingType = FixedWingPlane is null, and this
value has probability 0 with WingType = Helicopter.
The resulting chain will not mix to the true posterior.
In fact, there are cases when the auxiliary variable
method is not well defined, because we may need an
unbounded number of auxiliary variables. Consider
the rather artificial but instructive CBN in Figure 3,
and an instantiation Ïƒ = [X = 0, Y1 = 1, Y2 = 1]. To
augment Ïƒ such that it is self-supporting for all values
of X, we certainly need to add Y3 , since Y2 depends on
Y3 when X = 1. But Y3 depends on Y4 when X = 0,
and so we need to add Y4 , and so on. Ultimately, we
would need to instantiate Yi for all i â‰¥ 1.

4

Gibbs Sampling in Contingent
Bayesian Networks

We now develop a general-purpose extension of standard Gibbs samplers, which is applicable to arbitrary
switching variables with finite domains. The proposal for a switching variable, X, will proceed in
three steps. First, the instantiation, Ïƒ, is reduced
to a subset of variables, core(Ïƒ, X), that is guaran-

Y1 = 1

Y1 = 1

Y1 = 1

Ïƒ0

Ïƒ1

Ïƒ2

Figure 4: The three partial instantiations considered
for Gibbs sampling of X given Y1 as evidence. Here, Ïƒ0
is the current instantiation, and Ïƒ1 , Ïƒ2 are candidate
new configurations.
teed to exist in a minimal, self-supporting instantiation constructed from Ïƒ X=a , for any a âˆˆ dom(X). Second, we construct minimal self-supporting instantiations Ïƒi , i = 1, . . . , | dom(X)| âˆ’ 1, for each value in
dom(X) âˆ’ {ÏƒX }. These instantiations agree with Ïƒ on
core(Ïƒ, X), but assign different values to X. Any remaining variables in these Ïƒi configurations are sampled from their parent-conditional priors. For notational simplicity, we define Ïƒ0 = Ïƒ. Finally, we assign
weights to these Ïƒi , i = 0, . . . , | dom(X)|âˆ’1, and make
a transition proportional to these weights.
It may seem counter-intuitive to first reduce the instantiation, and then extend it. After all, the pair of
algorithms described in Section 3, parent-conditional
sampling and auxiliary variable Gibbs sampling, first
extended the current instantiation before reducing it.
The motivation for our approach is simple: variables
whose existence depends on the value of X should be
sampled in a world with the appropriate value of X.
Consider again, for example, the model in Figure 3,
and three partial instantiations illustrated in Figure 4.
Now, starting from Ïƒ0 (in which X = 0), we could have
fixed the value of Y2 when constructing Ïƒ2 (in which
X = 2). However, the distribution of Y2 given X = 2
is quite different from that given X = 0, and fixing
the value of Y2 could lead to low probability instantiations. The resampling of non-core variables like Y2
also simplifies the detailed balance equations discussed
later. In particular, our algorithm is designed so that
the distribution of Ïƒ2 does not depend on whether we
start from Ïƒ0 or Ïƒ1 . Thus, when demonstrating detailed balance between pairs of instantiations, we need

not reason about other instantiations which might be
involved in the transition. This last observation relies
on the fact that core(Ïƒ0 , X) = core(Ïƒ1 , X). We will
first prove this in general.
Definition 1. For an instantiation Ïƒ and variables
X, Y, Z âˆˆ vars(Ïƒ), if TZ refers to X and Y , and the
first reference to X precedes the first reference to Y ,
the edge linking Y to Z is said to be contingent on X.
Definition 2. Let core(Ïƒ, X) denote the subset of
variables in vars(Ïƒ) âˆ’ {X} which have a path (possibly of length zero) consisting of parent-child edges,
excluding edges contingent on X, to some variable in
Q âˆª E.
Note that we have left X out of core(Ïƒ, X) mainly for
simplifying the subsequent text. However, it is not
hard to see that there is a path from X to Q âˆª E not
contingent upon X. For example, consider the shortest
path from X to Q âˆª E and let this path start with the
X â†’ Y edge. Now, the edge X â†’ Y is not contingent
upon X (by definition) and if some other edge, W â†’
Z, along this path is contingent upon X then we can
find a shorter path starting with X â†’ Z. It should
be further noted that all the ancestors of X have a
path to X not contingent upon X (otherwise, a cyclic
instantiation would make the CBN not well-formed).
Hence all the ancestors of X are in core(Ïƒ, X).
Definition 3. For an instantiation Ïƒ and variable
4
X âˆˆ vars(Ïƒ), let Î¥(Ïƒ, X) = Î›(Ïƒ, X) âˆ© core(Ïƒ, X) denote the children of X also contained in core(Ïƒ, X).
Proposition 3. For any
supporting instantiations, Ïƒ
common to them, if Ïƒ and Ïƒ 0
core(Ïƒ, X) = core(Ïƒ 0 , X) and

pair of minimal selfand Ïƒ 0 , and variable X
agree on core(Ïƒ, X) then
Î¥(Ïƒ, X) = Î¥(Ïƒ 0 , X).

Proof. Let Y âˆˆ core(Ïƒ, X), then either Y âˆˆ Q âˆª E or
there exists a path of edges not contingent on X from
Y to QâˆªE. Clearly, if Y âˆˆ QâˆªE then Y âˆˆ core(Ïƒ 0 , X).
Otherwise, let Z be the first child in such a path. Since
X is not referenced before Y in TZ , X is also not referenced before any W referenced before Y in TZ . Such a
variable W must also be in core(Ïƒ, X) since W has the
same path to Q âˆª E via Z as Y . But Ïƒ and Ïƒ 0 agree on
core(Ïƒ, X) and hence on W . Since Ïƒ and Ïƒ 0 agree on
all the variables referred before Y in TZ it follows that
the evaluation of TZ up to Y is identical in Ïƒ and Ïƒ 0 .
Hence, the Y to Z edge is not contingent on X in Ïƒ 0 .
By induction, the path from Y to Q âˆª E in Ïƒ 0 is not
contingent on X, which implies that Y âˆˆ core(Ïƒ 0 , X).
Now, suppose core(Ïƒ, X) âŠ‚ core(Ïƒ 0 , X). For any element in core(Ïƒ 0 , X) âˆ’ core(Ïƒ, X) there must be a path
of edges not contingent upon X in Ïƒ 0 to Q âˆª E via
some variables in core(Ïƒ, X) âˆª {X} (trivially, since
Q âˆª E âŠ† core(Ïƒ, X) âˆª {X}). Let Y and Z be one such
parent-child pair in Ïƒ 0 s.t. Y âˆˆ core(Ïƒ 0 , X)âˆ’core(Ïƒ, X)

and Z âˆˆ core(Ïƒ, X) âˆª {X}. Now, all the variables referred in TZ up to the first reference of X (if any)
would also be in core(Ïƒ, X) since they have an edge to
Z which is not contingent on X. Since Ïƒ and Ïƒ 0 agree
on core(Ïƒ, X), the evaluation of TZ would follow an
identical path in Ïƒ and Ïƒ 0 up to the first reference of
X. Therefore, since Y is not referred to after X while
evaluating TZ in Ïƒ 0 , it follows that Y âˆˆ core(Ïƒ, X).
Let Y âˆˆ Î¥(Ïƒ, X), i.e. Y is a child of X in Ïƒ and
Y âˆˆ core(Ïƒ, X). From the above result Y âˆˆ core(Ïƒ 0 , X)
and we will next show that Y is a child of X in Ïƒ 0 . Consider the evaluation path of TY in Ïƒ. All the variables
that are referred before X are also in core(Ïƒ, X) by definition. Since these variables will have the same value
in Ïƒ 0 , it follows that the evaluation of TY in Ïƒ 0 will lead
to X being referred. In other words, X is a parent of
Y in Ïƒ 0 which implies that Î¥(Ïƒ, X) âŠ† Î¥(Ïƒ 0 , X). By
symmetry, Î¥(Ïƒ 0 , X) âŠ† Î¥(Ïƒ, X)
Proposition 4. For any two minimal self-supporting
instantiations, Ïƒ and Ïƒ 0 , there is at most one variable X common to them such that Ïƒ and Ïƒ 0 agree on
core(Ïƒ, X), but differ on X.
Proof. Assume to the contrary that there exist two
such variables X and Y . Now, since Ïƒ and Ïƒ 0 agree
on core(Ïƒ, X) but differ on Y , it follows that Y 6âˆˆ
core(Ïƒ, X). Hence Y cannot be in Q âˆª E. But since
Ïƒ is a minimal instantiation, Y must have a path to
Q âˆª E. Now consider the shortest path of Y to Q âˆª E.
Some edge, W â†’ Z, in this path must be contingent
on X. Hence we can construct a path from X to QâˆªE
via Z which canâ€™t be contingent on Y (otherwise, Y
would have a shorter path to Q âˆª E). This implies
that X âˆˆ core(Ïƒ, Y ), but then Ïƒ and Ïƒ 0 agree on X, a
contradiction.
For each value in dom(X), the corresponding partial
instantiation Ïƒi is assigned the following weight:
w(Ïƒi ) =

pX (ÏƒiX | ÏƒiTX )
|V (Ïƒi )|

Y

pY (ÏƒiY | ÏƒiTY )

Y âˆˆ Î¥(Ïƒ,X)

(7)
Up to a multiplicative constant, this expression reduces to Equation 6 if X is not a switching variable. The complete pseudo-code is given in Figure 5. Note that if X is not a switching variable then
core(Ïƒ, X) = vars(Ïƒ) âˆ’ X and the algorithm reduces
to regular Gibbs sampling.
It only remains to show that detailed balance holds
between any two minimal instantiations Ïƒ0 and Ïƒ1 .
It follows from Propositions 3 and 4 that there is
at most one shared variable X such that a transition is possible between Ïƒ0 and Ïƒ1 by sampling X.
Thus, the only way for this transition to occur from

1. Create an initial, minimal, self-supporting feasible
instantiation Ïƒ consistent with the evidence E,
and including the query variables Q.

Substituting for w(Ïƒ1 ) and w(Ïƒ0 ):
q(Ïƒ0 â†’ Ïƒ1 )
=
q(Ïƒ1 â†’ Ïƒ0 )

2. Initialize statistics of the query variables to zero.

X=v

i
Ïƒi
ii. Construct Ïƒi : core(Ïƒ, X) âˆª {X}
for i = 1, . . . , n âˆ’ 1.
iii. Compute w(Ïƒi ) from Equation (7) for i =
0, . . . , n âˆ’ 1.
iv. Normalize w(Â·) and sample an index j
from this distribution. Set Ïƒ â† Ïƒj .
Else
X
i. Randomly propose Ïƒ 0 such that Ïƒ
Ïƒ0
using the distribution of Equation (4).
ii. Compute the acceptance ratio, Î±(Ïƒ â†’
Ïƒ 0 ), via Equation (5).
iii. With probability Î±(Ïƒ â†’ Ïƒ 0 ), set Ïƒ â† Ïƒ 0 .
Otherwise, leave Ïƒ unchanged.
(c) Update query statistics using Ïƒ.

4. Report query statistics.
Figure 5: General purpose Gibbs sampling in CBNs

Ïƒ0 is to first select X for sampling with probability
1
|V (Ïƒ0 )| . Next, the new variables in Ïƒ1 , Ïˆ(Ïƒ0 , X, Ïƒ1 ) =
vars(Ïƒ1 ) âˆ’ core(Ïƒ
Q 0 , X) âˆ’ {X}, must be sampled with
probability Y âˆˆ Ïˆ(Ïƒ0 ,X,Ïƒ1 ) pY (Ïƒ1Y |Ïƒ1TY ). Finally, we
must select Ïƒ1 out of all the other random instantiw(Ïƒ1 )
ations, with probability w(Ïƒ0 )+...+w(Ïƒ
. Now, the
nâˆ’1 )
instantiations Ïƒ2 , . . . , Ïƒnâˆ’1 are random variables and
hence the overall transition probability, q(Ïƒ0 â†’ Ïƒ1 ),
depends on the expected value of this last probability
under the distribution of these random variables:
"
#
Y
1
w(Ïƒ1 )
pY (Ïƒ1Y | Ïƒ1TY )E Pnâˆ’1
|V (Ïƒ0 )|
i=0 w(Ïƒi )
Y âˆˆÏˆ(Ïƒ0 ,X,Ïƒ1 )

We can construct a similar expression for the reverse
move probability, and note that the numerator in the
expectation is a constant, and the rest of the expectation doesnâ€™t depend on which of Ïƒ0 or Ïƒ1 we start out
q(Ïƒ0 â†’Ïƒ1 )
with. Thus, q(Ïƒ
is:
1 â†’Ïƒ0 )
Q
|V (Ïƒ1 )| w(Ïƒ1 ) Y
Q
|V (Ïƒ0 )| w(Ïƒ0 ) Y

âˆˆ Ïˆ(Ïƒ0 ,X,Ïƒ1 )

pY (Ïƒ1Y | Ïƒ1TY )

âˆˆ Ïˆ(Ïƒ1 ,X,Ïƒ0 ) pY (Ïƒ0Y | Ïƒ0TY )

Y âˆˆ Î¥(Ïƒ,X)

Q
pX (Ïƒ1X | Ïƒ1TX )
Y
Â·Q
pX (Ïƒ0X | Ïƒ0TX )
Y

3. Repeat for the desired number of iterations:
(a) Choose X âˆˆ V (Ïƒ) uniformly at random.
(b) If X has finite domain (say, dom(X) =
{v0 , . . . , vnâˆ’1 } and ÏƒX = v0 ).
i. Compute core(Ïƒ, X).

Y

pY (Ïƒ1Y | Ïƒ1TY )
pY (Ïƒ0Y | Ïƒ0TY )

âˆˆ Ïˆ(Ïƒ0 ,X,Ïƒ1 )

pY (Ïƒ1Y | Ïƒ1TY )

âˆˆ Ïˆ(Ïƒ1 ,X,Ïƒ0 ) pY (Ïƒ0Y | Ïƒ0TY )

1)
Observe that the only terms missing from p(Ïƒ
p(Ïƒ0 ) above
are those for variables in core(Ïƒ, X) âˆ’ Î¥(Ïƒ, X). However, if Y âˆˆ core(Ïƒ, X) then ÏƒY = ÏƒY0 and further if
Y 6âˆˆ Î›(Ïƒ, X) all the parents of Y are also in core(Ïƒ, X)
and hence have the same values in Ïƒ and Ïƒ 0 . Thus
these variables have identical values and distributions
in Ïƒ0 and Ïƒ1 and their terms cancel out. Finally,

p(Ïƒ1 )
q(Ïƒ0 â†’ Ïƒ1 )
=
q(Ïƒ1 â†’ Ïƒ0 )
p(Ïƒ0 )

5

BLOG Compiler

We have implemented our algorithm in a new implementation of the BLOG language, which we will refer
to as blogc1 . The broad outline of our implementation is similar to Milchâ€™s public-domain MetropolisHastings version, except in two significant aspects.
First, for variables with (possibly unknown) finite domain, we always use Gibbs sampling. By statically
analyzing the structure of the model we can determine which variables are switching variables, which
ones need to be resampled for each transition, etc.
Based on the analysis, appropriate code is generated
that does the actual sampling and reporting.
Consider, as an example, the BLOG model in Figure 6.
This model describes the prior distribution of two
types of aircraft â€“ fixed-wing planes and helicopters.
These planes may produce an arbitrary number of
blips on the radar (the fact that plane a produces a
blip b is represented by setting Source(b) = a). Further, helicopters due to the interaction of their rotor
with the radar beam can produce blade-flashes in the
radar blip. In this model, the variable RotorLength(a)
for all aircraft a can easily be Gibbs sampled. If
WingType(a) =Helicopter then RotorLength(a) can
be either Short or Long, otherwise it can only be null
(as per BLOG semantics for a missing else clause).
While compiling the model we can detect that the
children variables of WingType(a) in any instantiation are all the BladeFlash(b) variables such that
Source(b) = a. In order to speed up the computation of the Gibbs weights at runtime, we maintain a
list, for each object a of type Aircraft, of all objects b
of type Blip such that Source(b) = a.
1
blogc
is
available
for
http://code.google.com/p/blogc/

download

from:

The variable WingType(a) is more interesting. It
can only take two possible values, but since it is a
switching variable, care has to be taken when sampling it. In particular, the variable RotorLength(a)
has to be uninstantiated. This is because all the children edges from RotorLength(a) are contingent on the
value of WingType(a). Note that Source(b) for all objects b of type Blip is also a switching variable. However, in this case the decision to uninstantiate a variable WingType(a) such that Source(b) = a depends
on whether there exists another object b0 such that
Source(b0 ) = a.
The second major difference in our implementation is
the handling of number variables. Instead of directly
sampling the number variables, our implementation
proposes birth and death moves. In the radar example,
for each object w of type WingType, we generate an
Aircraft object that has no blips assigned to it. The
death move kills off such objects with no blips. In
order to get faster mixing, we allow some extra flexibility in the birth and death move during an â€œinitializationâ€ phase. During this phase, birth and death
moves ignore the probability of child variables. To understand the motivation, assume for a moment that
the expected number of blips for a given aircraft was
one million. Now, a birth move which proposes an aircraft with 0 blips would be almost certainly rejected.
By allowing such birth moves during initialization, we
give the inference engine an opportunity to later attach blips to the aircraft.

6

Experimental Results

We have compared the convergence speed and accuracy of blogc against the existing generic MetropolisHastings inference engine provided with BLOG, which
we will refer to as BLOG-MH. Since a Gibbs and a
MH sampler perform different amount of work in each
sample we felt that it was more appropriate to compare the two inference engines with respect to time.
In order to control for the compiler optimizations in
blogc we have implemented a version of BLOG-MH
in blogc which we will refer to as blogc-MH. For some
of the other experiments we have also implemented a
version of Gibbs sampling that doesnâ€™t uninstantiate
and resample variables not in the core, which we shall
refer to as blogc-noblock.
In the following three models each inference engine is
run for a varying number of samples, where a sample
is as defined by that inference engine. For each number of samples, inference is repeated 20 times with a
different random seed and the mean and variance of a
query variable is plotted against the average elapsed
time (in seconds).

type
type
type
type

AircraftType;
Length;
Aircraft;
Blip;

origin
random
origin
random

AircraftType WingType(Aircraft);
Length RotorLength(Aircraft);
Aircraft Source(Blip);
Boolean BladeFlash(Blip);

guaranteed AircraftType Helicopter, FixedWingPlane;
guaranteed Length Short, Long;
#Aircraft(WingType = w)
if w = Helicopter then
~Poisson [1.0]
else
~Poisson [4.0];
#Blip ~Poisson[2.0];
#Blip(Source = a) ~ Poisson[1.0];
RotorLength(a) {
if WingType(a) = Helicopter then
~TabularCPD [[0.4, 0.6]]
};
BladeFlash(b) {
if Source(b) = null then
~Bernoulli [.01]
elseif WingType(Source(b)) = Helicopter then
~TabularCPD[[.9,.1],[.6,.4]]
(RotorLength(Source(b)))
else
~Bernoulli [.1]
};
obs {Blip b} = {b1, b2, b3, b4, b5, b6};
obs
obs
obs
obs
obs
obs

BladeFlash(b1)
BladeFlash(b2)
BladeFlash(b3)
BladeFlash(b4)
BladeFlash(b5)
BladeFlash(b6)

query
query
query
query
query
query

=
=
=
=
=
=

true;
false;
false;
false;
false;
false;

WingType(Source(b1));
WingType(Source(b2));
WingType(Source(b3));
WingType(Source(b4));
WingType(Source(b5));
WingType(Source(b6));

Figure 6: Example of helicopters and fixed-wing planes
being detected by a radar

0.96

blogc
BLOG-MH
blogc-MH

0.95
Average

0.94
0.93
0.92
0.91
0.90
0.89

0

10

20

30

40

50

Variance

10âˆ’2

type Ball;
type Draw;

10âˆ’3

random Real TrueWeight(Ball);
random Ball BallDrawn(Draw);
random Real ObsWeight(Draw);

10âˆ’4

10âˆ’5

0

10

20

Time (s)

30

40

50

guaranteed Draw Draw[10];
#Ball ~ Poisson[6.0];

Figure 7: Results on the Alarm Bayes Net
TrueWeight(b) ~ UniformReal [0.0, 100.0];

First, we evaluate on the Alarm network of (Beinlich
et al., 1989) available from the Bayes Network Repository2 (Friedman et al., 1997). This is a Bayes Net
with 37 discrete random variables of which we observe
9. The results are summarized in Figure 7. The important thing to note is that the variance achieved by
blogc in less than 2 seconds is much better than that
achieved by blogc-MH in 15 seconds and by BLOGMH in 40 seconds. The compiler optimizations are
clearly giving a big boost but the Gibbs sampling is
helping considerably as well.
Next, we consider the model in Figure 8 which is the
urns-and-balls example of (Milch et al., 2005a) with a
slight twist. Balls have a weight instead of a discrete
color. Figure 9 shows that blogc converges significantly
faster than BLOG-MH. However, all the improvement
here is being driven by the compiler optimizations as
evidenced by the fact that blogc-MH is keeping pace
with blogc. This similarity is likely due to the fact
that our current blogc implementation does not resample the TrueWeight variables from their full posterior.
This shortcoming arises because blogc does not yet
support Gibbs updates for continuous variables, and
is not a limitation of the proposed Gibbs sampler for
switching variables. Nevertheless, the example demonstrates the soundness of the blogc-MH implementation
in addition to the compiler optimizations.
Our final result is on the radar example of Figure 6.
For this model we experimented running blogc without the logic which detects that RotorLen(a) must
be uninstantiated when sampling W ingT ype(a). This
mode is labeled as blogc-noblock in Figure 10. In
this experiment we are querying the probability that
2

http://www.cs.huji.ac.il/site/labs/compbio/Repository/

BallDrawn(d) ~ UniformChoice({Ball b});
ObsWeight(d) {
if BallDrawn(d) != null then
~UnivarGaussian[1](TrueWeight(BallDrawn(d)))
};
obs
obs
obs
obs
obs
obs
obs
obs
obs
obs

ObsWeight(Draw1) = 61.8;
ObsWeight(Draw2) = 64.4;
ObsWeight(Draw3) = 17.7;
ObsWeight(Draw4) = 81.8;
ObsWeight(Draw5) = 40.9;
ObsWeight(Draw6) = 81.9;
ObsWeight(Draw7) = 82.3;
ObsWeight(Draw8) = 82.9;
ObsWeight(Draw9) = 82.6;
ObsWeight(Draw10) = 60.8;

query
query
query
query
query
query
query
query
query
query

TrueWeight(BallDrawn(Draw1));
TrueWeight(BallDrawn(Draw2));
TrueWeight(BallDrawn(Draw3));
TrueWeight(BallDrawn(Draw4));
TrueWeight(BallDrawn(Draw5));
TrueWeight(BallDrawn(Draw6));
TrueWeight(BallDrawn(Draw7));
TrueWeight(BallDrawn(Draw8));
TrueWeight(BallDrawn(Draw9));
TrueWeight(BallDrawn(Draw10));

Figure 8: Example of selecting balls with replacement
from an urn and measuring their weight

performance comparable to model-specific inference
code for a number of widely used statistical models.

82.5

Average

82.0

7

81.5

blogc
BLOG-MH
blogc-MH

81.0
80.5

Variance

80.0
100
10âˆ’2
10âˆ’4
10âˆ’6
10âˆ’8
10âˆ’10
10âˆ’12
10âˆ’14
10âˆ’16
10âˆ’18
10âˆ’20
10âˆ’22
10âˆ’24
10âˆ’26
10âˆ’28

0

5

10

15

20

25

30

Conclusions

We have demonstrated a significant improvement in inference performance for models written in the BLOG
language. Our Gibbs sampling algorithm for CBNs
and our compiler techniques for generating efficient
inference code are generally applicable to all openuniverse stochastic languages.
Acknowledgements

0

5

10

15
Time (s)

20

25

30

Figure 9: Balls with unknown weights

0.7

This work wouldnâ€™t have been possible without the
considerable assistance provided by Brian Milch to
make the models presented here work in BLOG-MH.
Matthew Can provided a translation of the Alarm
Bayes Net to BLOG. Finally, the first author wishes
to thank his family for their boundless patience and
support during this work.

Average

0.6
0.5

blogc
BLOG-MH
blogc-noblock

0.4
0.3

References

0.2
0.1

0

5

10

15

20

25

30

35

10âˆ’1

Andrieu, C., de Freitas, N., Doucet, A., & Jordan,
M. I. (2003). An introduction to MCMC for machine
learning. Machine Learning, 50, 5â€“43.

Variance

10âˆ’2
10âˆ’3
10âˆ’4
10âˆ’5
10âˆ’6
10âˆ’7

0

5

10

15

Time (s)

20

25

30

35

Figure 10: Results on the radar model
W ingT ype(Source(b1)) = Helicoper. Given that
BladeF lash(b1) = true we expect this probability to
be quite high. blogc converges to the true probability
in less than a second. However, neither BLOG-MH
nor blogc-noblock are able to come close to the true
probability even after 30 seconds. This is explained by
the fact that these two samplers are unable to directly
sample the W ingT ype(a) variables. The fact that they
are able to make any progress at all is due to the birth
move which creates new aircraft for each WingType
and samples their RotorLen variable. Later, the move
which resamples Source(b) for each blip has the opportunity to select this new aircraft. These two moves
thus compensate for the fact that the move which attempts to sample W ingT ype(a) is always rejected.
In follow-on work, we plan to demonstrate inference

Beinlich, I., Suermondt, G., Chavez, R., & Cooper,
G. (1989). The alarm monitoring system: A case
study with two probabilistic inference techniques for
belief networks. Proc. 2â€™nd European Conf. on AI
and Medicine. Springer-Verlag, Berlin.
Friedman, N., Goldszmidt, M., Heckerman, D., & Russell, S. (1997). Challenge: Where is the impact of
Bayesian networks in learning? IJCAI.
Gelfand, A. E., & Smith, A. F. M. (1990). Samplingbased approaches to calculating marginal densities.
JASA, 85, 398â€“409.
Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Trans. on Pattern Analysis
and Machine Intelligence, 6, 721â€“741.
Goodman, N., Mansinghka, V., Roy, D., Bonawitz,
K., & Tenenbaum, J. (2008). Church: a language
for generative models. UAI.
Milch, B., Marthi, B., Russell, S. J., Sontag, D., Ong,
D. L., & Kolobov, A. (2005a). BLOG: Probabilistic
models with unknown objects. IJCAI (pp. 1352â€“
1359).

Milch, B., Marthi, B., Sontag, D., Russell, S., Ong,
D. L., & Kolobov, A. (2005b). Approximate inference for infinite contingent Bayesian networks. In
Proc. 10th AISTATS (pp. 238â€“245).
Milch, B., & Russell, S. (2006). General-purpose
MCMC inference over relational structures. Proceedings of the Proceedings of the Twenty-Second Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-06) (pp. 349â€“358). Arlington,
Virginia: AUAI Press.
Neal, R. M. (2000). Markov chain sampling methods for dirichlet process mixture models. Journal of
Computational and Graphical Statistics, 9, 249â€“265.
Spiegelhalter, D., Thomas, A., Best, N., & Gilks, W.
(1996). BUGS: Bayesian inference using gibbs sampling, version 0.50 (Technical Report).
Tait, P. (2009). Introduction to radar target recognition. The Institution of Engineering and Technology,
United Kingdom.

