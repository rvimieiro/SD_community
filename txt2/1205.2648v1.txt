learning and reasoning in such systems. Other approximate
inference methods such as loopy belief propagation are also
hard to implement because of the key role that context sensitive independencies play in the model. Sampling-based
algorithms are one applicable method for reasoning in such
systems. Parametric estimation in Snijders (2005) and Snijders et al. (2007) was implemented using a forward sampling method. However, this method can only handle data
that completely specifies all variables at discrete time instants. The samples generated by their forward sampling
algorithm are not entirely consistent with the observations
and the information provided by the observations is only
partially used during the learning procedure.
Parametric estimation for the network-attribute coevolution model requires observations of the network as it
evolves (at least three snapshots at different times). Usually, direct observation of a social network is very expensive. The scarceness of the data could result in inaccurate
estimation of the model. Alternatively, other observations
such as communication events among people (emails and
instant messages), can reflect people’s relationship indirectly. More importantly, they are easier to collect. Utilization of these data can greatly help us to study the dynamics
of social networks.
Continuous time Bayesian networks (CTBNs) (Nodelman
et al., 2002) model asynchronous stochastic systems’ independencies among discrete-valued processes. In this paper,
we first show the relation between the CTBN model and the
social network dynamics model of Snijders et al. (2007).
We then demonstrate a parameter estimation method based
on the CTBN importance sampling of Fan and Shelton
(2008). This method is a full sampling-based inference
method and can handle any type of observation data including asynchronous, partial, and duration observations.
We then present a hidden social network dynamics model
in which indirect observations such as emails events among
people can be utilized. We develop a Markov chain Monte
Carlo (MCMC) sampling algorithm for the model and apply it to parameter estimation. Our methods not only im-

162

FAN & SHELTON

prove upon previous parameter estimation methods for social network dynamics, they also extend their range to deal
with more flexible data sources.
1.1 Previous Work
The idea of using a continuous-time model for social networks is not new. The reciprocity model in Wasserman
(1979) considers the evolution of the links between any two
actors in a network as a continuous-time Markov process
with four states. The transition rate of the state is time homogeneous and assumed to be independent of all the other
links in the network. The popularity model in Wasserman
(1980) assumes that the transition rate of a link depends on
the number of incoming links of the actor that the transition
link points to. Thus, the transition rate is time-variant and
the state of popular actors who have more incoming links
may change faster. These two models are computationally
efficient but have limited ability to represent some common
properties of social networks, such as transitivity.
The actor-oriented model, proposed in Snijders (2005), is
an extension of the reciprocity model. It allows the probability that a link changes to depend on the entire network
structure. The model can be simulated using forward sampling and the method of moments (Bowman & Shenton,
1985) is used to estimate the parameters. Steglich et al.
(2006) shows an application of this model. An alternative Bayesian-based parameter estimation method is implemented in Koskinen and Snijders (2007).

2 Background
We briefly review the network-attribute co-evolution model
(Snijders et al., 2007), the continuous time Bayesian network model (Nodelman et al., 2002), and the importance
sampling algorithm for CTBNs (Fan & Shelton, 2008).
2.1 Continuous-Time Social Network Model
The evolution of a social network depends not only on the
network structure, but also on the characteristics of the actors. At the same time, the values of the actors’ attributes
are also influenced by the structure of the network. In the
network-attribute co-evolution model, actors change their
connections and attributes to maximize a utility function.
Continuous-Time Markov Process Let X be a
continuous-time, finite-state, homogeneous Markov process with n states {x1 , . . . , xn }. The behavior of X is
0
and the intensity
described by the initial distribution PX
matrix


−qx1 qx1 x2 · · · qx1 xn
 qx2 x1 −qx2 · · · qx2 xn 


QX = 
 ,
..
..
..
..


.
.
.
.
qxn x1

qxn x2

···

−qxn

UAI 2009

with which X transitions from
where qxi xj is the intensity
P
xi to xj and qxi = j6=i qxi xj . The intensity matrix QX
is time-invariant. Given QX , the amount of time X stays at
xi follows an exponential distribution with parameter qxi .
That is, the probability density of X remaining at xi for
duration t is qxi exp(−qxi t). The probability that X transitions from xi to xj is θxi xj = qxi xj /qxi .
Network-attribute Co-evolution Model There are two
types of variables in the network-attribute co-evolution
model: the evolving pair-wise relationships among the N
actors and the H ≥ 1 discrete-valued attributes1 for each
actor. The number of actors is fixed during the entire process. At any time t, the relation links can be described
as a directed graph, which is represented by an N × N
adjacency matrix Y (t), where Yij (t) represents the relation directed from actor i to actor j (i, j = 1, . . . , N ).
Yij (t) = 1 if there is a tie from actor i to j and Yij (t) = 0
otherwise. Self relations are not considered in the network. The actors’ attributes at t can be represented by
H integer vectors Zh (t) of size N , where Zhi (t) denotes
the value of actor i on attribute h. Therefore, the networkattribute co-evolution is modeled using the stochastic process X(t) = (Y (t), Z1 (t), . . . , ZH (t)).
The network-attribute co-evolution model assumes that the
process X(t) is a continuous-time Markov process. The
evolution of the network is modeled as actors making decisions to maximize their satisfaction with the network: an
actor may choose to add or remove an outgoing tie, or
change the value of one attribute in order to (approximately
and locally) maximize a utility function. At any time t,
given the current state X(t), the decisions made by the actors are conditionally independent. It is further assumed
that when making a decision, the actor can only change
one outgoing tie or change one attribute value. Because
of the continuous-time nature, no two events may occur at
exactly the same time. Thus, at any time, only one actor
can add or remove an outgoing tie or increase or decrease
one value unit of an attribute. For each actor i, the times
between two network changes and between two attribute
decisions are exponentially distributed with parameters λni
and λai , called rate functions. Usually, they are assumed to
be constant values.
At a transition point, the actor chooses to add or remove a tie to maximize the value of the network utility function fin (β n , yhi, ji, z) + ǫn , or to change the
value of an attribute to maximize the attribute utility function fia (β a , y, z h hi, δi) + ǫa , where fin (β n , yhi, ji, z) and
fia (β a , y, z h hi, δi) are the objective functions for network
and attribute decisions respectively. y and z are the current states of the network and attributes. yhi, ji denotes
the state of the network after the tie from i to j changes.
1

Snijders et al. (2007) call the attributes of the actors “behaviors.” We call them “attributes” to avoid confusion with the
dynamic behavior of the model.

UAI 2009

FAN & SHELTON

z h hi, δi denotes the state of the attribute after actor i
changes the attribute z h by δ, where δ ∈ {−1, +1}. Both
objective functions are modeled as a weighted sum of effects (features) that depend on the topology of the network
and the attribute values. The functions have the form
fi (β, y, z) =

L
X

βk sik (y, z)

k=1

where sik (y, z) is an effect that expresses a property of the
network structure and the attribute values from the view of
actor i, and L is the number of effects the actor considers.
For example, we can choose sik (y, z) to be the “density
effect” defined as the number of out-going ties from i, or
the “attribute tendency” of actor i, which is the current attribute value of i.
ǫn and ǫa are random noise. Following Snijders et al.
(2007), we set them to be Gumbel distributions with mean
0 and scale parameter 1. Then the transition probability of
actor i changing the tie to j and actor i changing the value
of zh by δ are
P (yhi, ji|y, z) = P

exp(fin (β n , yhi, ji, z))
n n
k6=i exp(fi (β , yhi, ki, z))

(1)

exp(fia (β a , y, z h hi, δi))
P (z h hi, δi|y, z) = P
. (2)
a a
δ exp(fi (β , y, z h hi, δi))

Given the rate functions and the transition probabilities, the
intensity matrix of the continuous Markov process X(t)
can be written as

λn P (yhi, ji|y, z) if x̂ = (yhi, ji, z)


 ai
λi P (z h hi, δi|y, z) if x̂ = (y, z h hi, δi)
qx,x̂ =
(3)
n
−(λ
+ λai )
if x̂ = x


0 i
otherwise.

Parameter Estimation Snijders et al. (2007) assume
that observations are only available at discrete time points
t1 < t2 < · · · < tM , where M ≥ 3. The parameters α = (λn , λa , β n , β a ) are estimated based on M network observations y(t1 ), . . . , y(tM ) and attribute observations z(t1 ), . . . , z(tM ). Parameters are estimated using the
method of moments (MoM) (Bowman & Shenton, 1985).
MoM estimates the parameters such that the expected values of some statistics D(y, z) under the estimated parameter are equal to the observed values. The statistics used by
Snijders et al. (2007) for each parameter are as follows.
Parameter
λn
λa
βkn
βka

D(y, z)
P
|y
(t
ij
m−1 ) − yij (tm )|
P i,j
|z
(t
hi
m−1 ) − zhi (tm )|
h,i
P
n
s
(y(t
m ), z(tm−1 ))
Pi ik
a
s
(y(t
m−1 ), z(tm ))
i ik

Their estimation algorithm uses the Newton-Raphson
method starting with random parameters. In each iteration,
the expectation of the statistic values are calculated using
forward sampling between two time points tm and tm+1 .

163

2.2 Continuous Time Bayesian Networks
Continuous time Bayesian networks (CTBNs) (Nodelman
et al., 2002) are factored representations of general Markov
processes. We review them here and then relate the
network-attribute co-evolution model to them in Section 3.
Continuous time Bayesian networks factorize a homogeneous continuous Markov process into local variables. The
intensities for each variable X are described using a conditional intensity matrix (CIM) QX|U , which is defined as
a set of intensity matrices QX|u , one for each instantiation u of the variable set U. The evolution of X depends
instantaneously on the values of the variables in U. A
continuous time Bayesian network N over X consists of
0
two components: an initial distribution PX
, specified as a
Bayesian network B over X, and a continuous transition
model, specified using a directed (possibly cyclic) graph G
whose nodes are X ∈ X. Each variable X ∈ X is associated with a conditional intensity matrix, QX|UX , where
UX denotes the parents of X in G,
Forward sampling semantics for a CTBN The dynamics of a CTBN can be described using a forward sampling
algorithm. For each variable X ∈ X, it maintains x(t) —
the state of X at time t — and Time(X) — the next potential transition time for X, which is sampled from an exponential distribution. The algorithm adds transitions one at
a time, advancing t to the next earliest variable transition.
The next state is sampled from a multinomial distribution.
When a variable X (or one of its parents) undergoes a transition, Time(X) is resampled.
Likelihood and Sufficient Statistics A CTBN defines a
probability density over trajectories σ of a set of variables
X. It is a member of the exponential family, so one way
to describe the distribution is to use the sufficient statistics
of σ (Nodelman et al., 2003). Let T [x|u] be the amount
of time X = x while UX = u, and M [x, x′ |u] be the
number of transitions
from x to x′ while UX = u. If we
P
let M [x|u] = x′ M [x, x′ |u], the probability density of
trajectory σ (omitting the starting distribution) is
Y
PN (σ) =
LX (T [X|U], M [X|U])
(4)
X∈X

where LX (T [X|U], M [X|U])


YY
Y
′
M[x,x |u] 
q M[x|u] exp(−qx|u T [x|u])
=
θxx′ |u
x|u
u

x

x′ 6=x

is the local likelihood for variable X.
Importance Sampling Inference for CTBNs is the task
of estimating the distribution over trajectories given some
evidence (a trajectory with some missing values or transitions for some variables during some time intervals). Since

164

FAN & SHELTON

exact inference is intractable for large networks, approximate inference is often used.
We previously presented an importance sampling algorithm
for CTBNs (Fan & Shelton, 2008). Instead of sampling
from the target distribution PN defined by the CTBN, it
samples from a proposal distribution P ′ , which guarantees
that all sampled trajectories will conform to the evidence
e. Each sample σ is weighted as w(σ) = PPN′(σ,e)
(σ) . If we
draw a set of samples D = {σ[1], . . . , σ[M ]} i.i.d. from the
proposal distribution, the estimated conditional expectation
of a function f given evidence e is
ÊN [f | e] =
where W =

PM

m=1

M
1 X
f (σ[m])w(σ[m])
W m=1

(5)

w(σ[m]).

The proposal distribution is based on forward sampling. At
each sample step, the importance sampler adds a new transition to the sampled trajectory and advances time from the
current time t to t + ∆t. To ensure variables are consistent
with the evidence, it occasionally departs from the regular
forward sampling algorithm and “forces” the behavior of
one or more variables. The weight contribution for each
variable in each step is calculated accordingly.
In each time step from t to t + ∆t, the importance sampling algorithm chooses the proposal distribution for each
variable based on the following three cases:
• If there is no upcoming evidence for the variable, or
the current state of the variable is the same as the upcoming evidence, the next transition time is sampled
from an exponential distribution. The weight contribution for that variable is 1.
• If the behavior of the variable is given according to
the evidence, the trajectory of the variable is set to be
the same as the evidence in that time interval. The
weight contribution is the likelihood of the variable
in the interval [t, t + ∆t). This case corresponds to
standard likelihood weighting.
• If the current state of the variable does not agree
with the upcoming start of evidence at te , the next
transition time is sampled from a truncated exponenq exp(−q∆t)
, where q is the cortial distribution 1−exp(−q(t
e −t))
responding intensity for the variable. If the variable
is involved in the next transition, the weight contribution is 1 − exp(−q(te − t)). Otherwise, it is
1−exp(−q(te −t))
1−exp(−q(te −t−∆t)) .
The weight of the sampled trajectory is the product of the
weight contributions of all the variables in each time step.

3 Sampling for Learning Social Networks
The method of moments (MoM) parameter estimation
method in Snijders et al. (2007) only uses some sufficient

UAI 2009

statistics of the observation data. Samples generated during
the estimation procedure do not fully agree with the observations, which may affect the estimation accuracy. Additionally, calculating the true statistics, D(y, z), requires
that, at each observation point, all the network and attribute
values are fully observed. Thus, it is hard for MoM estimation to handle observation data with missing values or
evidence about durations, common in real applications.
The network-attribute co-evolution model assumes that the
entire state X(t) of the social network is a continuoustime Markov process. We can easily convert the model
to a CTBN and apply the importance sampling algorithm
to the converted model. The samples generated by importance sampling algorithm are consistent with the observations and we apply maximum likelihood estimation.
3.1 Importance Sampling for Network-attribute
Co-evolution Model
It is natural to decompose the model into variables Yij (t)
(i, j = 1, . . . , N, i 6= j) and Zhi (t) (h = 1, . . . , M, i =
1, . . . , N ) where Yij (t) is a binary variable representing
the link status from actor i to actor j and Zhi (t) denotes
the state of attribute variable of actor i. Given the current
instantiation (y, z) of the whole system, the conditional intensity matrix Qnij|y,z for link variable yij (t) can be extracted from Equation 3:


0
0
−λni Pi,j
λni Pi,j
n
Qij|y,z =
.
(6)
1
1
λni Pi,j
−λni Pi,j
k
where Pi,j
= P (yhi, ji|yij = k, y, z) for k = 0, 1. The
conditional intensity matrix Qai|y,z for attribute variable
Zhi (t) can be extracted similarly.

The transition probabilities depend on the utility functions,
whose values depend on the current instantiation of the entire system. Independencies among variables only hold for
particular assignments to certain other variables (analogous
to context sensitive independence for Bayesian networks).
For example, if the network utility function’s features includes the attribute similarity to connected actors, then the
dynamics of link Yij can potentially depend on all Zk , but
at any given instant, only depend on those Zk for which
Yik = 1. If any one of these links Yik changes, the independencies between Yij and {Zk } will change. However, the independencies are fixed between any two consecutive transitions. This dynamic CTBN structure prevents efficient use of other approximate CTBN inference
algorithms like expectation propagation (Saria et al., 2007).
We could apply the Gibbs sampling algorithm of El-Hay
et al. (2008), but it must calculate the true posterior density between every two consecutive transitions which can
be arbitrarily complex. Sampling from the posterior density involves binary search, which we have found to be too
computational costly.
Using the converted CTBN model, we can apply the impor-

UAI 2009

FAN & SHELTON

tance sampling algorithm for the model. This also allows
for general evidence patterns beyond complete snapshots.
3.2 Maximum Likelihood Estimation
The importance sampling algorithm can generate weighted
samples that fully agree with the observations. The loglikelihood of the samples can be calculated using Equation 4 and Equation 5. Therefore, we can use maximum likelihood estimation to learn the parameters α =
(λn , λa , β n , β a ). Since the data are partially observed,
we employ the Monte Carlo expectation maximization
(MCEM) algorithm (Wei & Tanner, 1990). For this application of EM, the steps are as follows.
Expectation Step: Using the current parameters, apply
the importance sampling algorithm to generate m weighted
samples. Calculate the sufficient statistics and the loglikelihood of the samples.
Maximization Step: Using the sufficient statistics and
log-likelihood as if they came from the complete data, update parameters. Rate parameters λni and λai are set to
be M n [i]/T and M a [i]/T respectively, where M n [i] and
M a [i] are the number of link changes and attribute changes
for actor i. The weight parameters β n and β a can not be
solved analytically from the log-likelihood function. We
use conjugate gradient ascent to estimate β.
Notice that the rate parameters and the weight parameters
can be updated separately. To increase the accuracy, we
divide the EM iterations into two loops so that the two sets
of parameters are estimated alternatingly.
The rate parameters are calculated using the expected number of transitions of the model. Since the time intervals
between transitions are sampled from the exponential distribution with the current intensity rate q, it is difficult to
sample a trajectory with a slower rate. (The algorithm tends
to add additional transitions to get the trajectory to agree
with the evidence.) Therefore, if the initial rate parameter
is larger than the true value, it is unlikely that the EM algorithm will converge to the true rate with a reasonable number of samples. Therefore, instead of sampling transitions
using the current intensity q, we sample transitions from
the exponential and truncated exponential distribution with
intensity q/2. We adjust the sample weight accordingly.

4 Hidden Social Network Dynamics Model
The network-attribute co-evolution model assumes that the
adjacency matrix Y (t) can be observed M ≥ 3 times. Even
obtaining one complete observation of the network is very
expensive. However, communication events among people, such as emails, instant messages, and phone calls, are
easier to collect. We can fully observe these events continuously with lower cost. The occurrence of these events
depends on the connection status between people. Thus, al-

165

though they may not be as accurate, these events indirectly
reflect the relationships among people. In such model, the
network itself is unobserved (hidden) all the time. We call
this model the hidden social network dynamics model.
4.1 Model Definition
Let Y (t) be the network of N actors, which evolves in continuous time in the same way as in the network-attribute
co-evolution model. (We do not consider the attribute variables. Adding them to the model is straight-forward). Let
O(t) be the observations (such as emails or phone calls)
among the N actors. Oij (t) ∈ O(t) (i, j = 1, . . . , N, i 6=
j) is the observation directed from i to actor j. We assume that the dynamics of Oij (t) depends only on Yij (t)
and Yji (t) and it is fully observed as Y (t) evolves. Usually, O(t) is just a set of instantaneous events. There is no
“state” for this kind of variable. We use “toggle variables”
to model such variables as a continuous-time Markov process. That is, each variable Oij (t) is a binary variable containing two indistinguishable states. The intensities with
which the variable transitions in both states are required to
be the same. The instantaneous event is represented as the
variable flipping between states. We assume that all the
event variables share the same set of parameters. That is,
the intensity matrix for Oij (t) is


obs
obs
qkl
−qkl
=
Qobs
obs
obs
ij|Yij =k,Yji =l
−qkl
qkl
where k, l ∈ {0, 1}.
Therefore, the hidden social network dynamic model contains two sets of variables: the network variables Y (t) and
the observations O(t). The evolution of the network variables is the same as in the network-attribute co-evolution
model. It depends on the network rate λn and the utility
function f n . The dynamics of each observation variable
Oij (t) depend only on the state of link variables Yij (t) and
Yji (t). According to the Markov properties of CTBNs,
Oij (t) is independent of all the other variables given the
entire trajectory of Yij (t) and Yji (t).
4.2 Metropolis-Hasting Sampling Algorithm
Due to the large number of variables in the hidden social network dynamic model, exact inference is intractable.
Since the model can be naturally converted to a CTBN, we
can apply the importance sampling algorithm in Fan and
Shelton (2008). However, because only Y (t)’s children are
observed, the trajectory of Y (t) is sampled blindly with no
guidance from the evidence when applying the importance
algorithm. Any incorrectly sampled variable can make the
entire trajectory be highly unlikely. Given the large sample space for Y (t), the importance sampler generates many
trajectories with very small weights.
An alternative method is to use MCMC to guide the sampling toward more likely trajectories. Here we develop

166

FAN & SHELTON

a Metropolis-Hasting algorithm (Hastings, 1970) which
reuses the importance sampling algorithm. The procedure
starts with an arbitrary trajectory that is consistent with the
evidence. Then in each iteration, it randomly picks a variable Yij (t) and replaces the entire trajectory of Yij (t) using the importance sampling algorithm, fixing the rest of
the trajectory as evidence. If the acceptance ratio of the
new sampled trajectory is larger than a random number u
which is sampled from a [0, 1] uniform distribution, the
new trajectory is accepted. Otherwise, the old trajectory
is kept. Let σ be the trajectory from the previous iteration,
and σ ′ be the sampled trajectory in the current iteration.
Let P be the target distribution given by the model and P ′
be the proposal distribution used by the importance sampling algorithm. The acceptance ratio of the sampled trajectory σ ′ in the Metropolis-Hasting algorithm is defined to
′
)P ′ (σ|σ′ )
be r(σ, σ ′ ) = PP(σ
(σ)P ′ (σ′ |σ) .
We define σY to be the trajectory of Y (t) in σ, σYij to be
the trajectory of Yij (t) in σ and σ/Yij to be the trajectory
of Y (t) except Yij (t). We define σO and σOij similarly.
According to the Markov properties of CTBNs, we have

×

=

i

P (σYi j |σ/Yi j )
P ′ (σYi j |σ/Yi j )

′
)
L(σ/Y
ij

w(σY′ ij )

L(σ/Yij ) L(σOij , σOij |σYij , σYji ) w(σYij )

(7)

where L(·) is the partial likelihood function and w(·) is
the weight contribution of the variable in the importance
sampling algorithm.
If the proposal distribution is as described in Section 2.2,
w(σY′ ij ) and w(σY′ ij ) in Equation 7 are 1 since there is no
evidence on Yij (t). If another proposal distribution is used,
the weight contribution should be adjusted accordingly.
4.3 Parameter Estimation
To estimate the parameters, we can use the Monte Carlo
EM algorithm described in Section 3.2. In the expectation
step, we use the Metropolis-Hasting algorithm to generate
equally weighted samples. In the maximization step, we
update the parameters alternatingly. Calculating λn and β n
obs
is the same as described in Section 3.2. qkl
in the conditional intensity matrix of Oij can be estimated as
obs
qkl

P

i6=j
= P

M [Oij |Yij = k, Yj,i = l]

i6=j

T [Oij |Yij = k, Yji = l]

.

We evaluate the learning algorithm using importance sampling on both synthetic data and real sociological data. We
compare the result to the method of moments (MoM) learning algorithm. We also evaluate our learning algorithm using MCMC for the hidden social network dynamics model
on a real dataset of emails.
5.1 Network-attribute Co-evolution Model
We first built a synthetic social network with 10 people and
one time-variant attribute for each person. We assume the
rates are homogeneous across people. We consider three
effects on the network change rule (features): the density
effect (number of outgoing links), the reciprocity effect
(number of reciprocity links) and the attribute-related similarity. The attribute utility function considers two effects:
tendency and similarity. The utility functions are
X
fin (β n , y, z) =
(β1n yij + β2n yij yji + β3n yij simij )
j
X
fia (β a , y, z) = β1a zi + β2a
yij simij
(8)
where simij = 1 − |zi − zj |/Range(z) is the attribute
similarity between actors i and j. These are the same
effects or features as in Snijders et al. (2007). We set
(β1n , β2n , β3n ) = (−1, 1.5, 1) and (β1a , β2a ) = (0.1, 1) to
generate the synthetic data. Rate parameters for the network and attributes were both set to be 0.5.

P (σYi j |σ/Yi j )
P (σY′ i j |σ/Yi j )

L(σOij , σOij |σY′ ij , σYji )

5 Experimental Results

j

P (σY′ )P (σO |σY′ ) P ′ (σY |σY′ , σO )
P (σY )P (σO |σY ) P ′ (σY′ |σY , σO )
′
P (σY′ ) P (σOij , σOji |σYij , σYji )
=
P (σY ) P (σOij , σOji |σYij , σYji )

r(σ,σ ′ ) =

′
P (σY
|σ/Yi j )
ij
′
′
P (σY
j |σ/Yi j )

UAI 2009

We also implemented the MoM learning algorithm in Snijders et al. (2007) and compared it to our method. Note
that their algorithm can only deal with evenly-spaced, fully
observed point evidence. Therefore, for a comparison, the
observation dataset was generated by sampling a full trajectory but only recording the values at regular intervals of
∆t. We randomly sampled another 100 full trajectories as
testing data. Learning accuracy was tested by calculating
the log-likelihood of the testing trajectories under the estimated models. Figure 1 shows the results for different
amounts of data and different values of ∆t. We used 400
samples and averaged across 4 runs (although the values
were very stable across runs).
Our algorithm outperforms MoM almost all the time. Its
accuracy is much higher than MoM when the number of
observation is small. Since samples generated by our algorithm fully agree with the observations, they provide more
accurate information about the system, which is valuable
when observation data are limited. When the time interval
is relatively small and there are enough observation data,
our algorithm can accurately estimate the model. As ∆t increases, the estimation accuracy drops. The expected time
between transitions for any given variable is 2 time units.
Therefore, when ∆t = 8, it is difficult to estimate the number of changes in the network between observations, thus
explaining the poor performance of both algorithms.

UAI 2009

FAN & SHELTON
λn
β1n
β2n
β3n
β4n

−2800
Log−likelihood

167

−3050
−3250

−3500

1

Rate/Actor
0.031
Density
−2.362
Reciprocity
1.210
Activity
0.115
Popularity
0.119

k, l
0, 0
0, 1
1, 0
1, 1

obs
qkl
0.002
0.023
0.296
0.604

Figure 3: Estimated parameters for Enron dataset

2

10
10
Number of Observations

∆t = 1
−2800
Log−likelihood

Log−likelihood

−2500

−3350

−4150

−5000

1

2

to build reciprocated connections and they are unlikely to
build a connection with someone arbitrary. These parameters seem reasonable and roughly match the rates found by
Snijders et al. (2007).

EM
MoM
True LLH

−2900

−3000

−3100

10
10
Number of Observations

1

2

∆t = 4

∆t = 8

Figure 1: Log-likelihood of testing data as a function of the
number of training data intervals.
λn
β1n
β2n
β3n

Network Parameter
Rate/Actor
0.019
Density
−2.39
Reciprocity
2.15
Similarity
0.53

5.2 Hidden Social Network Dynamics Model

10
10
Number of Observations

λa
β1a
β2a

Attribute Parameter
Rate/Actor
0.004
Tendency
0.14
Similarity
1.17

Figure 2: Estimated parameters for the 50 girls dataset.
Real Social Data Example: We then applied our algorithm to the “50 girls data” from the Teenage Friends and
Lifestyle Study (Michell & Amos, 1997). The dataset measures the changes in a network of 50 school girls, along
with time-variant attributes such as smoking habits and alcohol consumption. The data contains three observations
spaced one year apart. In this paper, we concentrate on
exploring the effect between the network and the level of
alcohol consumption. Alcohol consumption was measured
by self-reported questions on a scale ranging from 1 (never)
to 5 (more than once a week). We consider the same effects
(features) as in the previous experiment. That is, the utility functions have the same format as Equation 8. The true
parameters are obviously unknown.
Since this model describes the dynamics of all the links
between any two actors in the network and the alcohol attribute for every actor, the model contains 2500 variables;
50 have 5 values and the remainder are binary. No existing exact inference algorithm can handle a system with so
many variables. We ran the EM algorithm on this model
using 400 samples. The estimated parameters are shown
in Figure 2. The time unit was one day. From this result,
we can see that, on average, a student changes a friendship
every one to two months, and a student’s alcohol consumption level remains unchanged for approximately 8 months.
Parameters β a indicate that students tend to change their
attributes so that they will be similar to their friends. The
network parameters β n show that people strongly prefer

To evaluate the hidden social network dynamic model, we
used the Enron email dataset (Shetty & Adibi, 2004). The
dataset contains emails from 151 employees between 1998
and 2002. We preprocessed the data: We only chose emails
sent in 2001 since most of the emails were sent in that year.
We removed emails whose sender and recipient were the
same. Emails that were sent to many recipients were usually general notices such as a reminder of a presentation at
certain time and not indicative of a working relationship. If
the number of recipients in an email is larger than a threshold tr , we filtered out that email. In our experiment, we set
tr be 5. For the rest of the emails which were sent to multiple recipients, we treated them as multiple single-recipient
e-mails and randomly jittered the sent times. We took the
intersection of people who sent at least 100 emails in 2001
and people who received at least 100 emails in 2001 as the
set of the actors in our model. Emails among these actors
were used as our observation. After the process, we obtained a dataset containing 6738 emails for 31 people. We
set the time unit to be one day in this experiment.
We considered four effects on the network utility function:
the density effect, the reciprocity effect, the activity effect
and the popularity effect. Therefore, the utility function is
X
(β1n yij + β2n yij yji
f n (β n , y) =
j

+ β3n yij

X
k

yjk + β4n yij

X

ykj ) .

k

We ran Monte Carlo EM using the Metropolis-Hasting
sampler with 400 samples for each iteration. We took one
sample for every 1000 trajectories. Before starting the EM
iterations, we sampled 10000 samples as the “burn-in” iterations. In each EM iteration, we used the last trajectory in
previous iteration as our initial sample and used 1000 samples as the “burn-in” iterations. We randomly picked the
initial parameters for the model and ran the EM algorithm
5 times. All the 5 runs had very similar results. We took
the average for each parameter as our learned parameters.
The learned parameters are listed in Figure 3.
We can see that, on average, a person would consider

168

FAN & SHELTON

UAI 2009

Acknowledgment This research was sponsored by
AFOSR YIP award FA9550-07-1-0076 and DARPA award
HR0011-09-1-0030.

References
(a) Apr. 11

(b) Jul. 20

(c) Oct. 28

Figure 4: Enron adjacency matrix at different times.
changing a working relationship about every month. When
choosing the connection to change, the person is very unlikely to build a random connection (β1n = −2.1) and
prefers to build reciprocated connections (β2n = 1.5).
These results are very similar to what we learned from the
“50 girls dataset.” The number of popularity and activity
of an actor has a positive effect (β3n and β4n are multiplied
by the number of connections to or from an actor, so they
can be smaller than β2n and still have similar impact). On
average, a person A will send an email to another person B
about every 3 days if there is a connection from A to B. If
there is a reciprocated connection, A will send an email to
B at least every 2 days. If there is no connection between
them, it is unlikely that A will send an email to B.
We used the learned parameters as the true parameters of
the model. Starting with a random trajectory, we ran our
MCMC algorithm for 1,000,000 “burn in” iterations. Then
we drew a sample every 1000 iterations. We repeated this
until we sampled 1000 trajectories. Using the 1000 trajectories, we calculated the probability P (Yij (t) = 1),
for i, j = 1, . . . , 31, i 6= j. Figure 4 shows the network
structures as matrices at three different times throughout
the year. Darker spots represents higher connection probability. Since the Enron dataset represents working groups
changing over one year, we can see that the three matrices are different, showing that the links among people are
dynamic processes, but there are some stable connections.

6 Conclusion
We provide a sampling-based learning algorithm for
continuous-time social network models and provide results
for a model with 2500 variables. We also provide a hidden
social network dynamics model in which indirect observation of the network can be used and develop an MCMC
sampling algorithm for it. Our method is simple and easy
to implement. The idea of the algorithm is general and can
be easily extended to other continuous-time systems. For
social networks, we provide a learning method that is better
than the previous method of moments estimation, particularly when data is scarce (a common occurrence in sociology studies). Furthermore, we present a new model that
can deal with other type of datasets which previous social
network estimation methods cannot. This greatly extends
the types of social dynamic data that can be analyzed.

Bowman, K., & Shenton, L. (1985). Method of moments.
Encyclopedia of Statistical Sciences, 5, 467–473.
El-Hay, T., Friedman, N., & Kupferman, R. (2008). Gibbs
sampling in factorized continuous-time Markov processes. UAI08.
Fan, Y., & Shelton, C. R. (2008). Sampling for approximate inference in continuous time Bayesian networks.
ISAIM08.
Hastings, W. K. (1970). Monte Carlo sampling methods
using Markov chains and their applications. Biometrika,
57, 97–109.
Koskinen, J. H., & Snijders, T. A. (2007). Bayesian inference for dynamic social network data. Journal of Statistical Planning and Inference, 137, 3930–3938.
Michell, L., & Amos, A. (1997).
Teenage friends
and lifestyle study dataset. http://www.stats.ox.ac.uk/
∼snijders/siena/siena datasets.htm.
Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time Bayesian networks. UAI02.
Nodelman, U., Shelton, C. R., & Koller, D. (2003). Learning continuous time Bayesian networks. UAI03.
Saria, S., Nodelman, U., & Koller, D. (2007). Reasoning at
the right time granularity. UAI07.
Shetty, J., & Adibi, J. (2004). The Enron email dataset
database schema and brief statistical report. http://www.
isi.edu/∼adibi/Enron/Enron.htm.
Snijders, T. A. (2005). Models for longitudinal network
data, chapter 11. New York: Cambridge Univ. Press.
Snijders, T. A., Steglich, C. E., & Schweinberger, M.
(2007). Modeling the co-evolution of networks and behavior. In Longitudinal models in the behavioral and
related sciences, chapter 4. Lawrence Erlbaum.
Steglich, C., Snijders, T. A. B., & West, P. (2006). Applying SIENA: An illustrative analysis of the co-evolution
of adolescents’ friendship networks, taste in music, and
alcohol consumption. Methodology, 2, 48–56.
Wasserman, S. (1979). A stochastic model for directed
graphs with transition rates determined by reciprocity.
In K. Schuessler (Ed.), Sociological methodology, 392–
412. Jossy-Bass.
Wasserman, S. (1980). Analyzing social networks as
stochastic processes. J. Am. Stat. Assn., 75, 280–294.
Wei, G. C. G., & Tanner, M. A. (1990). A Monte Carlo
implementation of the EM algorithm and the poor man’s
data augmentation algorithms. J. Am. Stat. Assn., 85,
699–704.

