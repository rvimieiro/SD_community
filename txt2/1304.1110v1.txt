Kim L. Pob

Medical Informatics, Stanford University

ABSTRACT
In recent years, there have been intense research efforts to develop efficient methods for probabilistic
inference in probabilistic influence diagrams or belief networks. Many people have concluded that the best
methods are those based on undirected graph structures, and that those methods are inherently superior to
those based on node reduction operations on the influence diagram.

We show here that these two

approaches are essentially the same, since they are explicitly or implicity building and operating on the
same underlying graphical structures. In this paper we examine those graphical structures and show how

this insight can lead to an improved class of directed reduction methods.
1. Introduction

main results in this paper are based on the connections
Chyu has established between such diagrams and the

In recent years, there have been intense research efforts

undirected graph methods, allowing similar efficient

to develop efficient methods for probabilistic inference

computations using directed reduction operations [Chyu,

in probabilistic influence diagrams or belief networks.

1990a; Chyu,

As these networks become increasingly popular

connections and specialized reduction operations which

1990b].

By

recognizing

these

representations for capturing uncertainty in expert

exploit evidence nodes in the probabilistic influence

systems, the performance of inference procedures is

diagram [Shachter, 1989], we can obtain complexity of

essential for normative reasoning in real time. To date,

the same order with both undirected and directed

the best exact techniques for general probabilistic

reduction methods.

influence diagrams appear to those based on analogous
undirected graphical structures [Andersen et al., 1989;

In Sections 2 and 3 we introduce the notation and

Jensen et al., 1990a; Jensen et al., 1990b; Lauritzen and

framework of the directed probabilistic influence

Spiegelhalter, 1988; Shafer and Shenoy, 1990]. Some

diagram and undirected moral graph, respectively.

people have also concluded that those methods are

Section 4 explains the use of the arc reversal operation

inherently superior to those based on node reduction

to transform influence diagrams and Section 5 presents

operations on the influence diagram [Shachter, 1986;

the corresponding operations to incorporate evidence

We show here that these two

into the diagram. These pieces are integrated into a new

approaches are essentially the same, since they are

directed reduction method in Section 6, and some

Shachter, 1988].

explicitly or implicity building and operating on the

conclus�ons and extensions are presented in Section 7.

same underlying graphical structures. In this paper we

I
I
I
I

examine those graphical structures and show how this
insight can lead to an improved class of directed

2

•

Probabilistic Influence Diagrams

reduction methods.
A probabilistic influence diagram is a network built on
The key to this connection is the decomposable

a directed acyclic graph.

probabilistic influence diagram [Smith, 1989].

correspond to uncertain quantities, which can be

The

The nodes in the diagram

238

observed, while the arcs indicate the conditioning

A PID will be called a

I

decomposable PID O£liD if

relationships among those quantities. A decomposable

there is an arc between every two nodes with a common

probabilistic influence diagram is a special type of

child. It will be called decomposable with respect to

influence diagram whose properties will be explored

.D2dstj if

throughout this paper.

decomposable.

It can be shown that if a PID is

decomposable,

then

A probabilistic influence diagram

<fiiD is

a network

the subgraph induced by j's ancestral set is
every

subgraph

of

it

is

decomposable as well [Chyu, 1990b].

structure built on a directed acyclic graph (Howard and

A list of the nodes N in a directed graph is said to be

Matheson, 1984]. Each node j in the set N= { 1, ... .n }
corresponds to a random variable X j. Each variable Xj

ordered if none of the parents of a node follow it in the
list. Such a list exists if and only if there is no directed

has a set of possible outcomes and a conditional
probability distribution 7tj over those outcomes. The
conditioning variables for 7tj have indices in the set of

cycle among

parents or conditional predecessors CG) c N, and are
indicated in the graph by arcs into node j from the nodes
in C(j). Each variable Xj is initially unobserved, but at

the nodes.

Whenever a PID

is

decomposable with respect to a node j, there is a unique
ordered list for the ancestral set of j (Chyu, 1990b].
One graph will be said to be consistent with another if

both have the same nodes but the former has a subset of

some time its value Xj might become known. At that
point it becomes an evidence variable, its index is

conditions is said to be minimal if there is no other

included in the set of evidence variables E, and this is

graph consistent with it that satisfies those conditions.

the arcs of the latter.

A graph satisfying certain

represented in the diagram by drawing its node with
shading.

3.

Moral Graphs and Chordal Graphs

As a convention, lower case letters represent single
nodes in the graph and exact observations while upper
case letters represent sets of nodes and random variables.

If J is a set of nodes, J � N, then

XJ

Moral and chordal graphs are undirected graph structures

which correspond closely to PID's. The nodes have the

denotes the vector

same meanings, but there are many directed graphs

For example, the
of variables indexed by J.
conditioning variables for Xj are denoted by Xc(j) and

corresponding to any undirected one. To appreciate the
qualities of DPID's we need to explore the relationships

might take on values XC(j)·

between PID's and their undirected analogs.

In addition to the parents, we can defme the children or
(direct) successors of a node j. It is also convenient to

Given a PID, its corresponding moral mgh is obtained

keep track of the ancestors or indirect predecessors of

by adding undirected arcs between any nodes with a
common child and dropping the directions from all of

node j which are defined to include the parents of j.

the arcs.

Likewise, the ancestral set of node j is the ancestors of

example of incest in genetics [Jensen et al., 1990b] is

For example, a PID corresponding to an

node j, plus j itself. Finally, the nondescendants ND(j)

shown in Figure la and its corresponding moral graph

of node j are those nodes which are neither direct nor

is shown in Figure lb. The undirected arcs which were

indirect successors of node j. ND(j) does not include

added between nodes with common children are drawn

node j itself.

with dashed lines. Although the moral graph of a PID

Because there might be some observed evidence nodes in

same moral graph.

the diagram, some care must be taken to interpret the
meaning of the distribution 7t j within node j. When

A moral graph is called a chordal fmWh if every cycle of

there is no evidence then 7tj is simply the probability
for Xj given its conditioning variables, P (Xj I Xqj)l·

two nodes in the cycle which is not itself in the cycle.

is unique, there can be many PID's corresponding to the

four nodes or more possesses a £.h.Qa1, an

arc

between

However, in generalnj is defmed as conditional on its

(Chordal graphs are also called triana;ulated [Berge,

nondescendant evidence nodes,
P{ Xj I Xc(j)• XEnND(j) = XEriNI)(j)

of the nodes in an undirected graph is said to be

1973; Golumbic, 1980] and

}.

decomposable.)

A listing

�

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I

239

if, for every node j in the list, there are arcs between all

There is a strong relationship between DPID's and

of the nodes which are adjacent to j and precede it in the

chordal graphs, stated in following theorem.

list. A moral graph is chordal if and only if it has a
perfect list [Golumbic, 1980]. For example, the graph
shown in Figure l d is a minimal chordal graph
corresponding to the moral graph shown in Figure lb.
It is clearly chordal since ( B A C D F G H E I J
perfect list.

) is a

It is minimal because it would not be

Theorem 1
A PID is decomposable if and only if its ordered list
is perfect on its moral graph.

frQQt

Given a DPID, its moral graph can be obtained

I

chordal without both of the added arcs, drawn with

without adding any new arcs.

dashed lines. It is not unique, however, since there

decomposable its ordered list will be perfect for that

be many minimal chordal graphs corresponding to the

moral graph.

I

same moral graph. A perfect ordering can always be

Given a perfect list on a moral graph, directions

found, if one exists, by using maximum

be added to the undirected arcs from earlier nodes in

I

� [Tarjan and Yannakakis, 1984].

can

cardinality

Because it is

can

the list to later ones. This will be an ordered list for
the PID and the PID wiH be decomposable because
the list was perfect.

•)

We

can

always obtain a DPID from a chordal graph by

I

using one of its perfect lists as an ordered list. Such a

I

were added or modified from the original PID shown in

DPID is shown in Figure l c using the perfect list ( B A

C D F G H E I J ) . The dashed arcs are the ones that

Figure Ia.

that corresponding chordal graph, and any ordered list for

I

the DPID will be perfect for the chordal graph. There is
only one other result needed to characterize their
relationship, defining the minimal DPID in tenns of an

I
I

original PID and a desired or� ordered list.

Theorem 2.
Given a target ordered list and a moral graph, there

c)

corresponds a unique minimal DPID.

ftQQf:

I

Starting with the last node in the list, add undirected
arcs to the moral graph until the ordered list is

perfect, so it is an ordered list for the corresponding

I

DPID. There was no choice which arcs to add, and
the list would not be perfect if any of the new arcs
were not added, so the DPID is both unique and
minimal.

I

I
I

#

Although there is no unique minimal chordal graph in
general corresponding to a given moral graph, there is

I
I

Similarly, the moral graph for a DPID is

only one for which a target ordered list is perfect. As a
result, we can summarize the relationships between a
PID and its associated DPID's, moral graphs, and
Figure 1. Different graphical representations
for the incest example.

chordal graphs.

Given a PID there is a unique moral

graph. Given that moral graph and a target ordered list,

240

there is a unique minimal DPID. Finally, the moral
graph for the DPID is the minimal chordal graph
corresponding to the original PID for which the target
ordering is perfect

reverse in the target order. This algorithm creates the
minimal number of additional arcs. Its correctness is
given by the following theorem.
Theorem 3, Transforming toTarget DPID

4.

Influence Diagram Transformations

The arc reversal operation transforms one PID into
another with a different ordered list. In the process,
extra arcs often must be added to the PID. However,in
transforming to and from DPID's, we can guarantee
limits on the addition of those extra arcs.
The arc reversal operation transforms a PID by changing
the direction of one of the arcs [Olmsted, 1983;
Shachter, 1986]. Afterwards, each of the two nodes
inherits their common parents. The operation can be
interpreted as momentarily merging the two nodes and
then splitting them apart. The arc (i, j) is reversible if
it is the only directed path from i to j. Otherwise, a
directed cycle would be created by reversing the arc. The
general case for arc reversal is shown in Figure 2, in
which the arc (i,j) is reversed. Afterwards,A,B, and C
are parents for both i and j.

Figure 2. General Arc Reversal Operation.

Given a target ordered list and any PID, we can
transform the PID into another PID consistent with the
minimal DPID, using only arc reversal operations
[Chyu, 1990b; Shachter, 1990]. The algorithm
involves visiting each node j in the reverse target order:
reverse all arcs to j's successors which come before it in
the target order. Arcs must be reversed in the order they
appear in the current PID. but when there is a choice,

Given a PID and a target ordered list, a new PID
consistent with the corresponding minimal DPID can
be obtained through a sequence of arc reversals.

frQQt

The proof is by induction as we visit each node k in
the reverse target order. We have two induction
hypotheses: the current PID contains no arcs outside
of the target DPID and the target list after k is an
ordered list for the current PID.
To prove the theorem we must show that all of the
arcs reversed are reversible, and that the induction
hypotheses are maintained.

First, we show that the target list starting with k will
be ordered for the current PID. This follows,because
we reverse any arcs from k to successors which
precede it in the ordered list, and all of the other nodes
which follow k are already in the target order.
Second, we show that any arc (k, j) to be reversed is
indeed reversible. If this were not true, then there
must be some node i, k � i � j. If i belongs before
k then (k, i) would have been reversed before (k, j).
Therefore i must belong after k, but it is not properly
ordered since it precedes j. Thus we contradict the
induction hypotheses and it must be true that arc (k,
j) is reversible.
Finally,we must show that no arcs are created outside
of the target DPID. A new arc is created when we
reverse arc (k,j) only if there is some node i..%: which
is a parent of k or j and not of the other. Since all
nodes following k are in their target order, k must
follow both i and j in the target order. Now all
current arcs are by induction in the target chordal
graph, so this new arc is required for the target
#
ordering to be perfect
As a special case of this result, we can transform
between any two DPID's which have the same moral
graph,and hence correspond to the same chordal graph
[Chyu, 1990b; Smith, 1989].
Corollary I.
We can transform one DPID to another DPID
corresponding to the same chordal graph through a

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I

241

I
I

sequence of arc reversals.
By similar reasoning, it can be shown that any arc
reversal

operations

on

a

DPID

will

keep

it

decomposable [Chyu, 1990b]. However, the resulting

conditional distribution 1tk, P{ Xk I Xqk)• Xj = Xj },
no longer depends on X j- For example, if C were
observed in the DPID shown in Figure 1c, then after
evidence absorption we obtain the DPID shown in
Figure 3.

I

PID will not in general be a minimal DPID for the
starting PID and the target order.

The operation of evidence absorption does not destroy

I

Theorem 4.
1f a sequence of

the observed node to its children are absorbed.

I
I
I
I

the decomposability of a PID, since all of the arcs from
arc reversal operations are perfonned

Proposition I.

on a DPID, it will continue to be decomposable.

If evidence absorption is performed on a DPID, it
remains decomposable.

S.

Evidence Transformations
When evidence is absorbed at a node the distributions of

New observations are incorporated into a PID in two

its ancestors are affected indirectly. To propagate these

steps. First, the evidence is absorbed into the network

effects throughout the network, we must reorder the PID

and then it is propagated throughout the network using

so that the evidence node has no ancestors.

the evidence reversal operation, a variant of arc reversal.

reordering process consists of a sequence of specialized

In the process, new arcs are added until the PID

reversal operations. Evidence reversal of the arc (i, j) is

eventually becomes a DPID.

At all times, the PID

This

closely related to arc reversal, except that because the

successor node is observed there is no need for it to have

represents the posterior joint distribution.

a child afterward [Shachter, 1989]. The general case is
shown in Figure 4. It can be thought of as arc reversal

I

followed by evidence absorption, but it is more efficient
to recognize the

special properties of evidence reversal.

I
I

'

I
I
I
I
I
I
I

Figure 3. DPID after evidence absorption of C.

The operation of evi dence absor:ption maintains the
posterior joint distribution while recognizing the
observation of an exact value for a variable in the PID
[Lauritzen and Spiegelhalter, 1988; Shachter, 1989].
There is no longer any need to maintain distributions
with the other possible outcomes for the variable in its
node or in the nodes of its children. Therefore, when Xj
is observed at value Xjo the conditional distribution 1t j

,

becomes a likelihood function, P( X j = Xj I Xcu) } and
the arc to each child k of j is absorbed, since the

Figure 4. General Evidence Reversal Operation.

When evidence reversal is performed on arc (i,

j),

evidence node j moves one step closer to the start of an
ordered list for the PID.

In order for it to have no

ancestors, the operation will have to be performed on
each ancestor in reverse order.

This sequence of

evidence reversal operations is called e vidence
propuatio n [Lauritzen and Spiegelhalter, 1988;

I

242

Shachter, 1989]. Afterwards, node j will have neither

generality, suppose the arc from I to the evidence

parents nor children. For example, consider the part of

node is reversed before the arc from m. Afterwards m

the incest PID shown in Figure Sa.

will be a parent of I.

We have some

#

evidence about C, but it is not an exact observation of
C, so we create a variable K whose exact observation

By this same logic, if the ancestral set is already

describes the evidence for C. (Node K is created and

decomposable then no new arcs will be created by

absorbed at the same time, so it has no children and its

evidence propagation. Also, since the ancestral set will

distribution is simply a likelihood function for C.

be decomposable, and the ancestral set of the sink nodes

Because K has no children and only one parent, a DPID

(nodes without children) is the entire PID, evidence at

would remain decomposable after it was added.)

all of the sink nodes will result in a DPID.

Evidence propagation consists of evidence reversals with
C, A, and B in tum until node K is disconnected as
shown in Figure 5b, 5c, and 5d. There was a choice

Corollary 2.

When evidence propagation is performed on a DPID,
no new arcs are created.

whether to reverse A before B since they were not
ordered beforehand in the PID.

Notice that they are

ordered afterward and the PID has become a DPID in the
process, as will be proven in general below. Finally,

�Corollary
3.
Once evidence propagation has been perfomed from

the evidence could have originally related to multiple

all

sink

nodes

nodes as in shown in Figure 5e. This works best when

decomposable.

in

a

PID,

the

PID

will be

the nodes are a subset of a� [Golumbic, 1980].
Each node and its parents are contained in some clique.

Evidence propagation can be performed efficiently even
when evidence has been absorbed at multiple nodes in

b)

a)

the PID. Each unobserved node in the network has to
be visited once, in reverse graph order:

if it has no

evidence children, there is nothing to do; if it has
exactly one, then perform evidence reversal; otherwise it
must have multiple evidence children, and they can be

d)

c)

combined into one evidence child by multiplying their
likelihood functions so that a single evidence reversal
can be performed.

(If some of the multiple evidence

children have multiple parents, then the resulting
product has all of their parents.)

•>

In summary, the operations of evidence absorption and
evidence propagation eventually result in a DPID. If
the PID is already decomposable and evidence is only

Figure 5. Application of evidence propagation
on part of the incest example.

S.
* Theorem
Once evidence propagation has been performed from
node j in a PID, the PID will be decomposable with
respect to node j.
Proof:
Consider any node i with multiple parents in the
ancestral set for j, and let I and m be any two of those
parents.

Both I and m are parents of the evidence

node after the arc from i is reversed. Without loss of

within cliques, then those operations will never add new
arcs.

6.

I
I
I
I
I
I
I
I
I
I
I
I
I

Putting it All Together

In this section, we assemble the

I

results from

throughout the paper to develop a directed reduction
algorithm to compute the posterior joint distribution.
Because the choice of chordal graph is arbitrary, we can
obtain precisely the same chordal graph as in the best
undirected methods [Andersen et al., 1989; Jensen et al.,

I
I
I
I

I
I
I
I
I
I
I
I
I

243

1990a;

Jensen

et al., 1990b; Lauritzen and
1988; Shafer and Shenoy 1990) with
similar complexity using directed reduction operations.

absorbed and propagated while maintaining a PID

The first step in this process is to determine a target

observations, then evidence propagation should be

ordered list for the DPID. The list can either be selected

performed in reverse order thro ughout the PID to avoid

directly or, if a chordal graph is chosen instead, one of

duplicate operations.

Spiegelhalter

,

,

absorption and propagation. If the evidence is about
nodes in the same clique, then that evidence can be
consistent with the target DPID. If there are multiple

its perfec t lists should be used. One way to generate the
perfect list is to perform maximum cardinality search on

In this method, we maintain an updated posterior joint

the chordal graph, using an ordered list for the original

distribution for the PID given the evidence. If we desire

PID to break ties [Chyu, 1 990b; Tarjan and
Yannalcakis, 1984).

obtained through reduction operations [Shachter, 1988].

any general conditional distributions, they can be
If we want posterior marginal distributions for the

Using this list and the algorithm described in Section 4,

variables in the PID, they can be obtained by a

we can pre-reverse arcs to obtain a PID consistent with
a perfect list for

probability propagation process [Lauritzen and
S piegelh alter, 1988; Shachter, 1989] operati ng on the
cliques. By comparing the bask operations performed

the chordal graph is shown in Figure ld. We can pre­

by the different methods, we can verify that they have

reverse arcs from the original PID shown in F igure la

the same order of complexity. This is because at each

PID shown in Fig ure 6. The shaded,
dashed arcs would not appear in this PID, but we can

graphical structure and operating on data structures of

the unique minimal DPID. For example, given target
ordered list ( B A CD F G HE I 1

)

,

to obtain the

infer them from the target ordering.

If they were

present, we would have the DPID shown in Figure lc.

I

step they are performing similar tasks on the same
the same max i ma l dimensions. There can, of course, be
significant differences in the actual computation times.

Proposition 2.

The directed reduction method and the undirected

methods of HUGIN and Lauritzen-Spiegelhalter are of

I

the same order of complexity.

I

7.

We have shown that a directed red uction algorithm can

I
I
I
I
I
I
I

Conclusions and Extensions

perform operations on the same graph and of the same
order of complexity as the best undirected methods for
probabilistic inference. This result can be interpreted in
two ways. First, pre-reversals allow us to use the best
possible choice of chordal graph so we can Jearn from

Figure 6. riDfor evidence propagation afterpre­
reversals.

the undirected methods a superior straten for reduction.
Second, we can plainly see how the chordal graph

structure represents the w ors t case" for posterior ioim
"

We can n ow perform evidence absorption and

dependence. No matter what evidence (within cliques) is

propagation on the PID. In the process, the shaded,

observed, no additional arcs will be necessary to

dashed arcs in Figure 6 might have to be added. In the

represent the posterior PH>.

worst case, they will all appear and we will obtain the
If the evidence absorption is exact

Some natural extensions to the directed algorithm are to

evidence about nodes in the network, then those nodes
and their incident arcs will be absorbed through evidence

exploit efficiencies which have been developed in either

target DPID.

the directed or undirected representations.

244

In the directed representation, an important property is
that of a deterministic function, a variable whose
outcome is known with certainty given its parents'
outcomes. This introduces additional conditional
independence into the diagram which can be exploited
during evidence propagation. At the same, when the
PID is only being used to obtain posterior marginal
distributions for a subset of variables or with limited
observations, then the PID can be preprocessed to
eliminate variables that are irrelevant for the desired
results [Geiger et al., 1989; Shachter, 1988; Shachter,
1990]. This elimination can be performed on the
working PID or, if possible, before the target DPID is
determined.
Another promising hybrid might exploit the impressive
speed and simplicity of the HUG IN undirected method
[Andersen et al., 1989; Jensen et al., 1990a; Jensen et
al., 1990b] by maintaining joint distributions for a node
and its parents instead of conditional distributions. This
simplifies the operation of arc reversal, but does require
maintaining the full DPID instead of simply a PID
consistent with it. There are a couple of advantages to
using this method on undirected graphs which appear
applicable to directed methods as well. These
advantages are symmetric operations for evidence and
probability propagation and the recognition of zeros in
the sparse joint distribution matrices.

8.

Acknowledgements

We are grateful for the comments and suggestions of
Richard Barlow, Stephen Chyu, and Robert Fung.

9.

References

Andersen, S. K., Olesen, K. G., Jensen, F. V., and
Jensen, F. (1989). HUGIN--a shell for building belief
universes for expert systems. 11th International Joint
Conference on Artificial Intelligence, Detroit.
Berge, C. (1973). Graphs and Hyper graph s .
Amsterdam: North-Holland.
Chyu, C. C. (1990a). Computing Probabilities for
Probabilistic Influence Diagrams. Ph.D. Thesis,
IEOR Dept., University of California, Berkeley.
Chyu, C. C. (1990b). Decomposable Probabilistic

Influence Diagrams (ESRC 90-2). Engineering Science
Research Center,University of California, Berkeley.
Geiger, D., Verma, T., and Pearl, J. (1989). d­
separation: from theorems to algorithms. Fifth
Workshop on Uncertainty in Artificial Intelligence,
University of Windsor,Ontario, 118-125.
Golumbic, M. C. (1980). Algorithmic Graph Theory
and PerfectGraphs . London: Academic Press.

I
I
I
I

Howard, R. A. and Matheson, J. E. (1984). Influence
Diagrams. In R. A. Howard and J. E. Matheson (Ed.),
The Principles and Applications of Decision Analysis

I

Menlo Park, CA: Strategic Decisions Group.
Jensen, F. V., Lauritzen, S. L., and Olesen, K. G.
(1990a). Bayesian updating in recursive graphical
models by local computations. Computational
Statistics Ouanerly, to appear.

I

Jensen, F. V., Olesen, K. G., and Andersen, S. K.
(1990b). An algebra of Bayesian belief universes for
knowledge based systems. Networks, to appear.
Lauritzen, S. L. and Spiegelhalter, D. J. (1988). Local
computations with probabilities on graphical structures
and their application to expert systems. J. Royal
Statist. Soc, B, �(2), 157-224.
Olmsted, S. M. (1983). On r�resenting and solving
decision problems. Ph.D. Thesis, Engineering­
Economic Systems Department, Stanford University.
Shachter, R. D. (1986). Evaluating Influence Diagrams.
Operations Research, �(November-December), 871882.
Shachter, R. D. (1988). Probabilistic Inference and
Influence Diagrams. Operations Research, Jn(July­
August), 589-605.
Shachter, R. D. (1989). Evidence Absoprtion and
Propagation through Evidence Reversals. Fifth
Workshop on Uncertainty in Artificial Intelligence,
University of Windsor, Ontario, 303-310.
Shachter, R. D. (1990). An Ordered Examination of
Influence Diagrams. Networks, to appear.
Shafer, G. and Shenoy, P. P. (1990). Probability
propagation. Annals of Mathematics and Artificial
Intelligence, to appear.
Smith, J. Q. (1989). Influence Diagrams for Statistical
Modeling. Annals of Statistics,ll, 654-672.
Tarjan, R. E. and Yannakakis, M. (1984). Simple
linear-time algorithms to test chordality of graphs,test
acyclicity of hypergraphs, and selectively reduce acyclic
hypergraphs. SIAM Journal of Computing,l3., 566579.

I
I
I
I
I
I
I
I
I
I
I
I
I

