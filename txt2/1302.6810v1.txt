tion; the plan ner is assumed to be able to specify alter­
na te outcomes for a gi ven ac tion ( sensing is treated as
an action), but not to have any information about the
relative likelihood of these outcomes. CNLP [Peot and
Smith, 1992], PLINTH [G oldman and Boddy, 1994a,
Goldman and Boddy, 1 994b] and Cassandra [Pryor
an d Collins, 1993] are disjunctive pl anners of this type.
The SENSp planner extends this approach by distin­
guis hin g between sensation actions and actions which
alter the world, essentially i mpos in g a qualitative cost
measure over conditional plans [ Etz ion i et a/., 1992].
The second approach, which has not often been im-

MN 65-2200

3660 Technology Drive
Minneapolis, MN 55418
boddy@src.honeywell.com
plemented for complicated domains, is fully decision­
theoretic planning. This requires a model which spec­
ifies alternative outcome sets, a probability measure,
and a utility function over world states. Plans gener­
ated should maximi z e the expected utility.
a third technique, which we call epsilon­
safe (c-safe) planning, positioned between these two
extremes. The intention is as follows: the planning
system will make use of conditional planning tech­
niques, using information about the likelihoods of the
various different outcomes of the conditional acts to
guide the planning process and to support the ef­
fective construction of incomplete conditional plans.
The planner will attempt to provide a plan which will
achieve the goal with a probability at least 1 - t, where
f is a parameter to be supplied by the user .1
We propose

While probabilistic reasoning adds complexity to the
representations used in conditional planning, it is our
thesis that in practice this complexity will result in a
simplification of the actual planning process. The use
of probabilities allows us to i mp ose the c cutoff, allow­
ing us to ignore low-probability portions of the search
space. Probabilities also provide us with an effective
heuristic (an optimistic estimate of the probability of
plan success) for searching the space.
While we agree that decision-theoretic planning is, in
an ideal sense, the Right Thing, we feel that much
wor k remains to be done before decision theoretic
techniques may be combined with planners. Well­
man and Doyle [1992] and more recently Haddawy and
Hanks [1993] have shown that goals as used by AI plan­
ners cannot be straightforwardly (i . e ., without human
in te rventio n ) translated into utility functions.
Our approach is inspired by techniques used in en­
gineering risk y systems where it is regarded as either
infeasible or undesirable to specify a u tility modeL Un­
der such circumstances, one typically specifies that one
1 K ushmerick, Hanks and Weld [1993) have indepen­
dently developed an approach similar to epsilon-safe plan­
ning, though the resulting plans are not conditional.
Draper, et. al. [1993] are extending this framework to con­
ditional plans.

254

Goldman and Boddy

operators between distinguished start and finish nodes.
Any ordering of the actions which represents a topo­
logical sort of the DAG will achieve the goal (mod­
ulo the standard classical planning assumptions). The
edges of the graph are either causal links or order­
ing links. For every precondition of an action' there
will be a causal link from the operator which estab­
lishes that precondition to the action which has it as
a precondition. Ordering links are employed to elimi­
nate potential clobberers (steps which delete protected
propositions).

Home

Figure 1: The Skiier's micro-world.
wants a system which has a failure bound
over some period of use.

of

epsilon

In this paper, we present two simple f-safe planners
constructed as extensions to two conditional planners:
PLINTH (Goldman a n d Boddy, 1994a] and CNLP [Peat
and Smith, 1992]. These conditional planners generate
plans in the presence of actions with uncertain out­
comes. We show that an epsilon-safe planner may be
constructed atop them in a straightforward way, gi v en
that one assumes that the outcomes of conditional ac­
tions are chosen independently. We then show how
this independence assumption m ay be relaxed. To do
so, we combine techniques of conditional planning with
knowledge-based construction of probabilistic models.
2

CNLP

Recently, Peot and Smith [1992] have introduced
CNLP, a conditional planner based on McAilester and
Rosenblitt's SNLP [McAIIester and Rosenblitt., 1991].
CNLP extends SNLP by adding conditional actions.
Conditional actions provide a simple disjunctive rep­
resentation of uncertainty. Each conditional action has
a number of possible outcomes, one of which will oc­
cur if the action is executed.2 Given a goal, an initial
state and a set of actions (some of which may be condi­
tional) the CNLP algorithm will generate a conditional
plan to achieve the goal. The conditional plan is akin
to a conventional non-linear plan, but it branches at
every conditional action. Below each branch point will
be a partial conditional plan which will carry the agent
from the given outcome to the goal. For example, Fig­
ure 2(a), taken from Peot and Smith's paper, gives a
conditional plan for going skiing in the situation de­
picted in Figure 1.

CNLP generalizes the graph representing a (partial)
nonlinear plan by imposing on it a notion of context.
When a conditional action is introduced into the plan
graph, it splits the plan into multiple contexts: one
for each outcome of the conditional action. For exam­
ple, the action (observe (road b s)) has two possible
outcomes: (clear b s) and (not (clear b s)). For
each context, CNLP introduces a unique label. As in
F igure 2(a), let us call the label for (clear b s) ol1
and that for (not (clear b s)), ob. Labels are used
to mark the various actions of the plan to indicate
the conditions under which they should be performed.
This label is propagated to every proposition and ac­
tion which depend on the conditional outcome. To
each context introduced, there corresponds a separate
goal node. This has the effect of creating a separate
plan for every context. In the skiing example, when
the conditional action (observe (road b s)) is intro­
duced into the plan, a second goal node is introduced.
The original goal node is now labeled to indicate that
it corresponds to the case where the road is seen to
be clear and a second goal node is introduced for the
problem of planning a solution to the problem which
will work when the road is known not to be clear.

The CNLP algorithm involves only limited extensions
to SNLP CNLP only needs to worry about threats
within compatible contexts. CNLP may resolve threats
not only by ordering them before or after matching
preconditions, but also by forcing them into different
contexts.
.

,

CNLP is an elaboration of SNLP. SNLP constructs a
non-linear plan by building a directed acyclic graph of
2We provide a detailed analysis of conditional actions
[Goldman and Boddy, 1994b].

elsewhere

3

Plinth

work reported elsewhere, we have developed
[Goldman and Boddy, 1994a], a linear con­
ditional planner loosely based on McDermott's regres­
sion planner PEDESTAL [McDermott, 1991]. We have
shown that this planner is sound and complete with
respect to its action representation.
In

PLINTH

Given the current prevalence and popularity of non­
linear planning, our decision to construct a linear con­
ditional planner may require some explanation. In
conventional, "classical" planning applications, non­
linear planning is usually an improvement over linear
planning because fewer commitments yields a smaller
search space, at a small added cost to explore each el­
ement of that search space [Minton et a/., 199 1]. How-

Epsilon-Safe Planning

(hav &kia)

(clear c �

255

(nc;:,Jctoar c p)l

(road\))

o2,)v/o2,2
(obs

(no� �·� b s)) _J;Jo b c)

(dear b s) _

�0 1�

0 1,

(obs

(•rd
� /'b)
�

ob

b s))

(not(ath

(gotskis)

omeb)

g

(at h001o)

oal-1
g

(a)
F igure 2: Condi tional plans to go to a
Multiple possible outcomes of an action
plan.

ski-resort.

(a)

A CNLP

7�

l

a e)
goal-2

(b)
plan.

T

goal-3

Causal links are shown as solid lines.
are ordering links. (b) A PLINTH

are marked as ol, o2. Broken lines

ever, it is not clear that this tradeoff operates in the
same way for conditional planners. When plans have
multiple br anche s , the savings from considering fewer
ordering s is likely to be mu ch less and may not repay
the cost in the added complexity of indivi dua l plan
expansion actions. In particular , the domain in which
we have applied PLINTH is one i n which subgoal inter­
actions are m inor, and t hu s in which a linear planner
can be effectively employed. Conditional linear plan­
ning is simpler in conception as well as in implemen­
tation. In particu lar , our conditional linear planner
can be shown to be s o u nd and complete; we do not
yet know of a sound and complete conditional non­
linear planner. Finally, the op e r ati o n which is needed
to properly construct branching non-linear plans resol v in g clobberers through conditioning apart - is
a very difficult operation to direct. In addition to the
arguments on behalf of a c o n d i tional linear planner in
and of itself, imposing a probability structure over a
conditional linear plan is easier than imposing it over

a conditional nonlinear plan.

New goals may be introduced when steps are intro­
duced, either to satisfy preconditions or to plan for
co nti n genc ies introduced by conditional actions. In
essence, this algo r i thm is the same as that of a con­
ventional linear planner. The crucial difference is in
the effect of adding a conditional action to the plan.

When adding a conditional action, A, there will be
some outcome, 0, such that A- 0 will establish the
goal literal (otherwise A would not have been chosen
for insertion). This outcome will establish what one
can think of as the "main line" of the plan. However,
there wi ll also be some set of alternative outcomes,
{ 0;}. In ord er to derive a plan which is guaranteed
to achieve the goal, one must find a set of actions
which can be added to the plan such that the goals
are achieved after A - Oi. for all i. This is done by
adding new goa l nodes to the tree for these alternative
contingenc i es . The addition of these goal nodes ren­
ders the plan tree-shaped, rather than linear. PLINTH

will plan for all of the goal nodes in the plan. The
early portions of the plan will be shared among the
different contingencies .

PLINTH's cond i ti on al linear planning algorithm is non­
deterministic and regressive. The planner operates by
selecting an unrealized goal and nondeterministically
choosing a way to resolve that goal while respec ti ng
existing p ro te c tions . To resolve a goal PLINTH will

A PLINTH plan for the earlier
shown in in Figure 2(b).

either

4

1. find that goal to be true in the initial state;
2. find an e xisting step in the plan which establishes
the goal or

3. add to the plan a new step which establishes the

goal.

Ski World example is

E-safe planning with simple model

A preliminary approach to probabilistic planning may
be developed by imposing a simple probability mea­
sure over partial plans. We start by associating with
each conditional operator a probability distribution
over its outcomes. The plan tree will provide a proba-

256

Goldman and Boddy

bility measure of the chance of be ing at a given point in
the plan. We use this measure in two way s : first , by
computing the probability mass associated with the
set of goal nodes in the plan graph, we can deter­
mine an estimated probability of success of our plan;
second, when choosing a next node to expand in our
search, we will choose to expand one whose label has
the most probability mass and thus can contribute the
most probability mass to the successful p l an . We may
construct this measure in a straightfor ward way if we
assume that the outcomes of the conditional actions
are indep endent .
The two conditional plann er s admit of a simple
epsilon-safe adaptation if one makes two assumptions:

1. Actions will only be done when their precondi­
tions are known to be true;

2. The probability distribution over the outcomes of
an action depends only on the state of the wo rl d
encapsulated in the preconditions for t h at action.
The first is a commo n l y -ma d e planning assumption.
The second is a M ar ko v assumption, one of the c-onse­

quences of which is that conditional action outcomes
are conditiona l l y independent , given the preconditions
encoded in each operator. In our construction of more
complicated prob a bility m odels ( Sec t io n 5), b o t h of
these assumptions are re l axed somewhat.
To build such an adaptation, one must be able to as­
sign a probability measure over a conditional plan. We
start by associating with each conditional action a dis­
tribution over its outcomes. Given these d ist ri butions
and the assumptions above, we can impose a probabil­
ity measure on PLINTH plans. Recall that a PLINTH
plan tree contains multiple goal nodes, each of which
corresponds to a context - a single set of outcomes
of conditional actions. Since the contexts are mutu­
ally exclusive and exhaustive, we can add together the
probability of success for each com pl e t e d goal node to
determine the overall probability of success . Since the
outcome of each conditional action is independent, we
can associate with each label the cor r espondi n g out­
come probability and determine the probability of suc ­
cess by multipl ying tog ethe r the probabilities associ­
ated with each outcome label in each p a th to a goal
node. An analogous method suffices to put a p ro ba­
bility measure on CNLP plans.
An i m portant feature of the probability measure is
that even before the plan is completed, it ca n be used
to bound the proba bi lity of success. In particular ,
we can choose which goal nod e (context) to work on
based on how promising it is. We beli e v e that this
heuristic information will substantially improve plan­
ning search.
We may work around ou r Markov assumption to some
extent, at the expense of some effort in encoding the
operators and world state. Consider a case where the
independence assumption taken at its face value is

clear to be violated. In Peot and Smith's SkiWorld
example, the probability of observing the roads to be
open could be radically changed by the occurrence of
a blizzard, in a way which induces a dependency be­
tween these outcomes. We can capture this interaction
by au gmenting the representation of the world state,
and splitting the existing operators into multiple op­
erators with more complex preconditions.
We can capture the dependency within the limits of
the simple model by adding to the world state repre­
sentation the proposition blizzard. Since the prob­
ability of success following a road is influenced by
whether or not there is a blizzard, we repl ace our ob­
s e rve ( clear(X,Y)) operator schema by two operator
schemas, one for the case where there is a blizzard, and
one for the case where there is not a blizzard. The
BURIDAN plann er [Kushmerick et al., 1993] handles
context-dependency by the use of triggers, an equiva­
lent me chan ism .
Representational tricks of this kind will only be suffi­
cient to cover over limited departures from the essen­
tial model. If there are too many dependencies, the
not.ation will become too unwieldy. Furthermore, this
trick wi ll not work in the event that there are unob­
servable propos i tions which induce dependencies.
5

Building more complex models

We believe that the simple probabilistic model de­
scribed above will prove to be useful for domains with
a simple action model. However, the simple model
breaks down when applied to domains where there are
significant dependencies among action outcomes, par­
ticul arly if these dependencies are the result of events
that are not directly observable.
Consider an elaboration of Peot and Smith's "Ski
world" exa m ple . Let us suppose that points B and
C are within, say, 100 miles of each other. Then in
severe snowstorm conditions, there will be a substan­
tial correlation between the states of the road from B
to Snowbird and the road from C to Park City. If we
have the additional option of going to Switzerland to
go skiing , 3 this depend e n cy may be quite important.
Upon o bserv i ng the closure of the road to Snowbird,
it may be better for us to just fly to Switzerland, since
we know that it is likely that the road to Park City
will also be blocked. Alternatively, it may be a good
idea for us to make a plan in which we first listen to
the radio to determine whether or not there is a bliz­
z ard. In the event of a blizzard, we fly to Switzerland,
otherwise we should try to find an acceptable route to
one of the two resorts .
In this section we outline linear and nonlinear ver­
sions of the t-safe planner that allow for dependen­
cies. These planners build probabili ty models in par3 Let us assume we are also quite wealthy and do not
have to be at work on Monday.

257

Epsilon-Safe Planning

allel with the construction of their plans. The p rob ­
ability model employs techniques of Knowledge-based
model construction [We l l man et al., 1992], which we
will discuss further below. We begin by outlining our
simplifying assumptions; we discuss the formal repre­
sentation of the planning problem; we briefly review
knowledge-based model construction and we conclude
with a presentation of the t-safe pl anning algorithms.

blizzard( {true, false}) P(blizzard)
0.1
clear(X,Y, {true, false})- blizzard({true, false})
P(clear(X,Y)) I blizzard)
0.1
P(clear(X,Y)) I not blizzard 0.999
=

=

=

Figure 3: Conditional outcome statements
the Ski World.

Knowledge-based model construction
(KBMC )

5.2
5.1

Assumptions

1.

The initial state of the world is

completely known,
modulo uncertainty. For every pr op osition Q, the
in iti al state contains either Q, not(Q) or a prior
distribution, P(Q). We allow the prior distribu­
tion to be factored as a d ir ec ted graph (belief net­
wo rk) . E.g., if there are three propositions A, B
and C whos e truth value we do not know, we may
wish to represent P(A), P(B) and P(C) in terms,
say , of P(A), P(BIA ) and P(CIA).

2.

The outcomes of every action are observe d by the
agent. Outcomes cannot be predicted, but will be
obser ved when th ey occur.

3. We assume that all observation actions are infal­
lible. For the purposes of this pr elimi nar y study,
this simplifies things considerably.
4. In order for an action to be performed, all of its
p recond iti ons must be known to hold .

Ass um pt i ons 2 and 4 are simplifications that make the
algorithm m u ch cleaner. That these simplifi c ations are
reasonable for applications sucl1 as plan n ing organiza­
tional behavior .4 If one is, say, pla nni ng the operations
of a truck ing company, it is reasonable to assume that
one will know whether or not the truck arrives at the
warehous e and whether or not it is out of fuel. These
as sum ptions are probably not reasonable for ap pl ica­
tions such as plann ing a series of motions or manipu­
lations by a robot with sensors that yield o n ly a pprox­
imate i n for m at i on . Uncertain obser vations (vi olations
of ass umption 3) may be modeled as certain observa­
t ions of variables which are related probabi l is t ic a ll y to
real st ates of the world (for our domains, this seems
preferable intuitively, as well).

We extend
influences.

the plan representation by adding causal
Rather than encodi ng the es tablis her

and consumer of a given proposition causal influences

record a situation where the truth of the giv�n p rop o­
sition may ch ange the outcome distribution for a con­
ditional action. Causal influences will be represented
differently in the plans of the two c:-safe planners: im­
plicitly in the linear version, explicitly in the n on l ine ar.

4

Or generating high-level

by methods like
Bresina [1990]

those

plans for "robustification"

described

by

Drummond

and

for use in

There exis t a number of techniques for graphically rep­
resenting probabi lity and decision models ( see [Pearl,
1988, Shafer and Pearl, 1990]). W hile these represen­
tations make possible efficient inference and knowledge
acquisition, they are inherently propositional and are
l i m ited in t h eir abilities to represent particular prob­
lem inst ances . The KBMC approach is to encode gen­
eral k nowl edg e in an expressive language, then con­
struct a decision mo del for each particular situation
or problem instance. The interested reader can find
more details on KBMC in the review by W ellman , et.
al . [1992]. For the purposes of our c:-safe planner, we
record kn owledge about patterns of causal interaction
in a knowledge-base. When attacking any particula r
p l an ning probl em , releva nt piec e s of this knowledge
will be drawn from the knowledge base and assembled
into a probability model to evaluate the conditional
outcom es.
Breese's ALTERID system [Breese, 1992] prov ides a
comple t e and sound method for KBMC. In ALTERID,
r andom variables are named by condition al outcome
statements. C onditional probab ilitie s of various out­
comes are described using a notation
clauses. As in Horn clauses, there is
case

similar to Horn
a.

head, in this

n a m ing the influenced

variable. The body of the
cla use is a list of conditional outcome statements which
influence the head var iable. If the body of the clause
is empty an u ncondi tional distribution must be pro­
vided. For example, we might encode our ( very lim­
ited) knowledge of meteorology in the Ski domain us­
ing the ALTERID clauses gi ven in F i gure 3.
In £-safe planners , plans have a bipartite representa­
tion. In a dd ition to the plan graph, there is also a
p robabil is t i c model. This is a belief network, whose
star t state is c ons truct ed from the initial conditions,
and which will be augment ed to reflect the current
partial p lan.
5.3

Linear Planning

As in

PLINTH, plans will be r ep r esented as trees. In
PLINTH, the nodes in the plan graph are plan steps,
each of which is a particular instance of some opera­
tor. There are also two kinds of dummy steps, start,
which roots the tree , and goal. G oal nodes have as
pr econdit ions t he goal propositions; every leaf of the
p lan tree will be a goal node.
The t- s afe linear planning algorithm

is an extension

258

Goldman and Boddy

to the PLINTH algorithm. As before, goals will be
introduced and discharged in one of three ways. The
difference is that the algorithm will now maintain a set
of causal influences to be resolved as well as a set of
goals. Causal influences need to be handled specially
because they may be known to be true, known to be
false, or unknown, at the time the conditional action is
performed. This distinguishe s them from conventional
preconditions, which must be known to be true.5

There are three ways to discharge an open causal in­
fluence:

1.

Try to get to know the outcome of the event.
Choose some observation action which can estab­
lish the value of the event. In the SkiWorld ex­
ample, one might listen to the radio to determine
whether or not there is a b lizzard in the moun ­
tains.

2.

Cause the event to have a particular outcome. A
somewhat farfetched example would be to seed
the clouds to en sure the presence of a blizzard.
Etz ioni , et. al. [1992] discuss the issues encoun­
tered when planning in domains where proposi­
t io ns may be either observed or established.

In fact, the STRIPS - sty le representation we use is
not sufficiently ex pressive to capture the distinc­
tion between observation and establishment, so
these two cases col l a pse into one from the stan d­
point of the plann ing al gori thm .

3.

Choose to act in ign or ance of the outcome. To
preserve correctness, the agent's ignorance must
be protected. This is done to avoid paradoxical
situ ations where the agent wi l l observe a propo­
sition, not like the outcome, so "pretend" that i t
hasn't made the observation and look repeatedly
until the outcome is more to its liking.

Our planning algorithm, so far, is a straightforward
extension of PLINTH. However , on ly half of our job is
done. In order fo r this method to be useful, we need
some way of ca l culating the probability of s uccess of
various plan branches. We use the belief net model we
construct, in conjunction with the plan , to do so.
The interface between the pl an- and model-building
aspects of the plann er will be mediated by the add ition
of c onditi onal and observation actions to the pl an . In
doing so, we will construct a probability distribution
over t he contexts of the plan.

On invocation of the planner, we will use the AL­
TERID algorithm and the initial state description to

construct a belief network capt uring the pr i or distri­
bution over the propositions whose truth values are
unknown.6 Each outcome of a conditional outc om e
..,Even

AoL's secondary preconditions must
known value at the time an action is performed.

have

a

6In the implementation, we will construct the belief net­
work on a lazy, as-needed basis.

statement will have a unique label. Labels in the be­
lief network will correspond to labels in the plan.
When conditional steps are added to the plan, paralle l
nodes will be added to the belief network. T he out­
come space of this no de is the set of possible outcomes
of the conditional step. For every open influence on
the conditional action, we draw an arc from the corre­
sponding conditional outcome statement in the belief
network to the conditional action node. I.e., the arcs
in the belief network represent those causal influences
w hich must be encapsulated in a p robabil ity distribu­

tion.

No nodes need be added to the belief network t o paral­
lel the addition of observation steps to the plan. How­
ever, the labels of the observation outcomes must be
the labels of the outcomes of the observed variable in
the belief network.
As causal influences are resolved these causal links
will be cut.
Now, in order to find the prob ability
of a context, one finds the joint pro bability of a set
of labels (w hich are outcomes of variables in the net­
work ) . Since the goal nodes are labeled with contexts,
one may use this c omp utation to determine an up per
bound on the probability of success of a plan branch.
To find the probability of a particular outcome in a
plan br anch , find the probability of the outcome con­
ditional on t he probability of the context in which the
action is executed.
Let us return to the Ski World example, 1 co mplicated
by the dependencies given in Figure 3 and consider one
way the algorithm might proceed. Initially, the plan­
ner attempts to reach Snowbird, reaching the st ate
shown in Figure 4(a). This is done by first discharging
the goals to reach Snowbird, then the subgoal of the
road from B to Snowbird being clear. When this lat­
ter goal is discharged by adding the observe(B,S)

step, the clear(B,S) node is added to the mod el ,
and we add the influence of blizzard. In this ex­
ample, the planner has decided not to try to de­
termine whether or not there is a blizzard ( or per­
haps is unable to do so). A protection of the form
unk(blizzard,start,observe(B,S)) must be added
to the plan. The planner may evaluate the model to
estimate ( u pper- boun d ) the probability of success in
reaching Endl, which is .9091.

Let us assume now that the planner successfully com­
pletes the full plan up to Endl (given the earlier
probability estimate, this is surely a sensible strategy ) .
Now it begins to try to reach End2 by getting to Park
City. Discharging the goal of being at Park City, it
adds the step of go( C, Park City), which introduces
the new goals of being at C and having the road from
C to Park City be clear. The planner discharges the
latter goal by introducing the step of observing the
road from C to Park City. In turn, this introduces the
7In

the

interest

of simplicity,

have (skis ) subgoal in t his example.

we

will

ignore

the

Epsilon-Safe Planning

Start

blizzard
Start

clear(B,S)
obs(B,S)

259

�-

2

obs(B,S)

1

blizzard

clear(B,S

go( home, B)

-­

�--

--

----

go(B,S)

----

2

I

go(B,S)

trA):) clear(C,P)

.J<

/

/

_,-"

/

/

/

/

obs(C,P)
go(C,P)

End1 (1)

End1 (1)

End2 (2)

Figure

4:

End3

(2,2)

Example of Epsilon-planning with PLINTH.

influence of blizzard on clear(C, Park City). Af­
ter connecting those variables in the model, we reach
the situation shown in Figure 4(b). At. th is point, we
may consult the model to bound the chance of success
pursuing End2 (which is the joint probability of find­
ing the road from B to S closed but that from C to
P open). The incremental improvement pursuing this
plan is less than 1 %, so if the planner is sufficiently fa­
natic in its devotion to skiing, perhaps it should begin
considering that trip to Switzerland.
5.4

End2
(2,1)

Nonlinear Planning

As in CNLP, plans will be represented as directed
acyclic graphs. In CNLP, the nodes in the plan graph
are plan steps, each of which is a particular instance
of some operator. There are also two dummy steps,
start, which establishes the initial conditions, and fin­
ish, which has as preconditions the goal propositions.
There will also be four kinds of link in the plan:
1. causal links: a triple (e, P, c) (sometimes written
e __!:__.c), where e is a step which establishes (has
as postcondition) the proposition P, which is con­
sumed by (appears as precondition of) the step c.
2. conditioning links: a triple {C, 0', B}, where Cis
a conditional action , one of whose outcomes is 0'
and B is an action (of any type), which cannot be
performed unless the outcome of C is 0'.
3. ordering constraints: A pair (51, 52) (commonly
written 51 < 52) which indicates that step 5,
must be performed before 52.
4. influence links: A triple [i, P, c] , where i is a step
and P is in a proposition family which influences
the conditional step c.
The first three types of links are as per
latter is new to the <-safe planner.

CNLP.

The

In order to reflect the fact that the planner's uncer­
tainty about the world is encoded in the initial condi­
tions, we treat ignorance preconditions specially. We

have a special kind of link: any step, s which has as
its precondition that some the outcome of some condi­
tional outcome statement, P, be unknown, may have
that precondition satisfied only by a link of the form
(start, P, s. This is a consequence of the fact that ig­
norance is never added to an <-safe planning problem
(a consequence of our simplifying assumptions).
The <-safe planning algorithm is given in Appendix
A. Note that most of the algorithm is identical to the
CNLP algorithm. We have simply added a new step,
necessary to properly handle causal influences on con­
ditional actions. Causal influences need to be han­
dle d specially because they may be known to be true,
known to be false, or unknown, at the time the con­
ditional action is performed. This distinguishes them
f ro m conventional preconditions, which must be known
to be true.8
This added complication is handled in step 4 of the
Find-completion procedure. One way to handle an
open causal influence is to try to get to know the out­
co m e of the event. Step 4a handles collecting informa­
tion about the outcome.
The somewhat unusual aspect is provided by step 4b,
The purpose of this step is to allow us to ha ndle the
case where the planner intends to perform a condi­
tional action in ignorance of the outcome of some
causal influences. To preserve correctness, the agent's
ignorance must be protected. This is done to avoid
paradoxical situ atio ns where the agent will observe a
proposition , not like the outcome, so "pretend" that it
hasn't made the observation. For example, let us as­
sume the status of a road from B to Snowbird depends
on whether there has been a blizzard and the agent
plans to listen to a weather report and drive down the
road if no blizzard is reported. It does not make sense
for the agent to plan to listen to another weather re­
port, hoping for no blizzard, if it hears an unfavorable
report initially. The "ignorance link" constructed in
8Even AoL's secondary preconditions must have
known value at the time an action is performed.

a.

260

Goldman and Boddy

select some conditional step a which IS
possibly before both v and s .
1 1 . L et C a be the context of a .
iii. Select two of the outcome labels of a, a;
and a; (i f. j), such that Ca U a; is con­
sistent with the context of v and Ca U aj
is consistent with the context of s .
I V . return
Complete(Plan U {a, a; , v} U
{a, a1 , s} ) ;
1.

step 4b prevents this from happening.
The interface between the model- and plan-construc­
tion operations will be handled in the same way as i n
the linear t-safe planner.
6

Summary

We have presented an approach to high-level planning
under uncertainty that we call £-safe planning . This
approach ducks the complexities of decision-theoretic
planning by specifying a level of acceptable risk, L
The planner is committed to meet some specified goal
with a probability of success of at least 1 - t. We have
presented two meas u res of probability fo r <-safe plan­
ning: a straightforward extension to conditional plan­
ning for which computing the necessary probabilities
is simple but which makes a drastic independence as­
sumption and a second approach which relaxes this in­
dependence assumption . The latter ap p ro ach involves
the incremental construction of a probability depen­
dence model in conj unction with the construction of
the plan graph . We have shown how these probability
models may be integrated i n t o PLINTH and CNL P . We
are currently working on the implementation of these
techniques as part of a project on plan n i n g i mage pro­
cessing actions for N ASA's Earth Observing System
in collaboration with Nick Short, J r . an d J acqueline
LeMoigne-Stewart of N ASA G odd ard [Boddy e t al. ,
1994).
A

3 . I f there i s some step

w in t h e Plan which has some
open precondition P. Do one of the following:
8 be some step consistent w ith w which
establishes P .
return Complete(Plan U (s, P, w))
(b) Select an operator o ; from the set of operators
which add P. Create a new step s which is
of type o; .
return Complete(Plan U 8 U (s, P, w))

( a)

4 . If there is an open i nfluence P on a conditional
step s, non-deterministically choose to do one of
the followi ng:
(a) Observe the state of the conditional
outcome statement, P : This may be
done either using a pre-existing step of the
plan , or by inserting a new step. Non­
deterministically choose one of:
1 . Let s be some step consistent with w
which establ ishes/observes some outcome
P; in the family of P .
return Comp1ete ( Plan U (s, P, , w ))
1 1 . Select an operator o; from the set of oper­
ators which establish/observe P; , for some
P; in the family of P . Create a new step
s which is of type Oi .
return Complete ( Plan U s U (s, P; , w))
(b) Record ignorance of the state of the
conditional outcome statement, P: If
the outcome of P is unknown in the initial
state,

t::- safe planning algorithm for CNLP

Plan (Initia1Conds , Goal)

1. model := belief-net(Initia!Conds) ;
This step of the planning algorithm establishes a
model which will satisfy the constraints on the
i n i t i al conditions ( Assumption 1 ) .
2. i n i t i al- p l an : = make- i n i t- plan (Goal ) ;
We i n i t i al ize the c o n d i tional plan grap h .
3 . Complete(ini tial-plan , model);
Recursive function w h i ch finds and returns the
plan (or signals failure) .
Complete(Plan, Model)
1. Check for success/failure
2. If there is a link I = (s, P, w) U [s , P, w] and there
is a compatible threat v9 to I such t h at the Plan
does not contai n either v > w or s > v resolve the
clobberer by doing one of the following:
( a) return Complete( Plan U v > w)
{b) return Comp lete( Plan U v < s)
(c) Conditioning:
9 Note that if P is of t h e form U n know n ( X ) , then P will
be threatened by any X; in the family of X .

Let

return

Complete( Plan U [start, Unknown(?), w ] )
5.

Collect additional information: For some
conditional step, s, for some influence P on s
such that P i s unknown at the time s will be
done, choose some operator o, (one of) whose out­
come(s) is P' which is not independent of P. Cre­
ate step s1, instance of o,
return Complete(Plan U s' U (s' , P', s))

6 . If there is a post condition with a context cnew

which is not compatible with the context of any
existing goal , create a new goal step g whose con­
text is cnew .
return Complete(Plan U 9)

Epsilon-Safe Planning

Acknowledgements
Thanks to M ark Peot , and D avi d Smith for d iscussions
w h i c h helped clarify these ideas, and to the anonymous
reviews for helpful comments.

and Rosenbli t t , 1991 ] McAllester, David
and Rosenblitt, David 1 99 1 . Systematic nonlinear

[Boddy

et al., 1 99 4] Boddy,
Mark S . ;
Goldman,
Robert P. ; and White, J ames 1994. Planning for
image analysis. In Proce e dings of the 1994 Goddard
AI Conference. to appear.
1992 ] Breese, J oh n S. 1992. Construction of

belief and decision networks.
ligence 8 ( 4) :624-64 7 .

Comp u t a ti o n a l Intel­

[ Drap er

et al., 1 99 3] Draper, Denise; Hanks, Steve;
and Wel d , Daniel 199 3 .
P robabilistic plan n i ng
w i t h i n formation gathering and contingent execu­
tion. Technical Report 93- 12-04, Department of
Computer Science and Engi neering, U niversity of

Washington , Seattle, WA.
and Bresina, 1990 ] Drummond ,
Mark and Bresina, John 1 990 . Anytime synthetic
projection : M aximizing the probabil ity of goal satis­
faction . In Proceedings of the E ig h t h Na tional Con­
fe rence o n A rtificial In tellig ence , Cambridge, M A .
M IT Press. 1 38- 1 44 .

[ Etzioni

et al. , 1992] Etzioni , O t·en ; Hanks, Steve;
Weld , Daniel S. ; Draper , Denise; Les h , Neal; and
Williamso n , Mike 1992 . An approach to p l an n i n g
w i t h incomplete information . In Nebel, Bernhard ;
Rich , Charles; and Swartout , William, editors 1992 ,
Principles of Knowledge RepTesentatwn and Rea­

s oning:Proceedings of the Third Int e rn at i o n al Con­
fe rence, Los A l tos, C A . Morgan Kaufmann Publ ish­

ers, Inc. 1 1 5- 1 25 .

[M cDermott,

1 991] McDermott, Drew 1991. Regres­

sion planning. International Journal of Intelligent
Systems 6(4 ) :357-41 6 .
e t al. , 1991] Minton,
Steven ;
B res i na ,
John L . ; and Dru mm o n d , Mark 1 99 1 . Commitment
strategies in planning: A comparative analysis. In
Proceedings of the 1 2th International Joint Confer­
e n ce on A rtificial Intelligence. Morgan Kaufmann
P u blishers, Inc.

[ M in ton

[Pearl , 1988]

Pear l , J udea 198 8 . Probabilistic Reason­
Networks of Plausible
Morgan Kaufmann Publishers, Inc. , Los

Infe re n c e .
A l tos , CA.

[ Peot

and Smith, 1992] Peat, Mark A. and Smith,
David E. 1 992. Conditional nonlinear planning. In
Hendler , J ames, editor 1992, Artificial Intelligence
Planning Systems: Proceedings of the First Inter­
national Co nfe re n c e, Los Altos, CA. Morgan Kauf­
m ann Publishers, Inc. 189- 197.
and Collins, 1 9 9 3] Pryor, Louise and Collins,
G regg 1993. Cassandra: Planning for contingencies.
Technical Report 41, The Institute for the Learning
Sciences, Northwestern University.

[ Pryor

[Raiffa,

1968] Raiffa, Howard 1968. Decision Analy­
sis: Introdu ctory Lectures o n Choices under Uncer­

tain ty. Behavioral Science:

[Goldman and Boddy, 1 994a] Goldman, Robert P.
and Boddy, M ark S . 1994a. Conditional linear plan­
ning. In Hammon d , K ristian J . , editor 1994a, A r­
t ifi ci a l In t e llig e n ce Pla n n z ng Sys t e ms: Proceedings
of the Se cond Interna tional Conference, Los A ltos ,
�A . Morgan Kaufmann Publ ishers , I n c . forthcom­
mg.
and Boddy,

planning. In Proceedings of the Ninth National Con­
Camb ridge , MA.

fe re n ce on A rtificial Intelligence,
MIT Press. 634-639 .

ing in In t e llig e n t Systems:

[ D rum m on d

[Go ld man

[ K us h me ri ck et al. , 1993] Kushmerick,
Nicholas;
Hanks, Steve; and Weld, Daniel 1 993. An algorithm
for probabilistic planning. Technical Report 93-060 3 , Department of Computer Science and Engineer­
ing, University of Washington, Seattle, WA.

[ M cA l l ester

References

[ Breese,

261

1994 b]

Goldman,

Robert

P.

and Boddy, M ark S . 1994b. Representing uncer­
tainty i n simple p lann e rs . In Doyle, J . ; Sandewal l ,
E . ; a n d Torasso , P . , ed i to r s 1 994b , Principles of
Kn o w ledg e Rep re se nt a t i o n and Reasoning: Proceed­

ings of th e Fou rth In tern a ti o n a l Conference (KR94),
San M ateo, C A . Morgan Kaufmann Publishers, I n c .

To appear.

[H addawy

and Hanks , 1993] Haddawy,
Peter and H anks, Steve 1993 . Utility models for

goal-directed decision-theoretic p l anners. Technical
Re po r t 93-06-04 , Department of Computer Science
a nd Engi n eering, U n iversity of Washington , Seattle,
WA .

Q uan t i t ati ve Methods.

Random House, New Yor k .

[Shafer

and Pearl , 1990] Shafer , Glenn and Pearl,
J u dea, editors 1990. Readings in Uncertain Reason­
ing. Morgan Kaufmann Publishers, Inc., Los A l tos,
CA.

[Wel lman

and Doyle, 1992 ] Wellman, M ichael P . and
Doyle, J on 1992 . Modular u t ility representation for
decision- theoretic pl an n ing . In Hendler, James, ed­

i tor 1992, A rtificial Intelligence Planning Systems:
Proceedings of the First International Conference,
Los A l tos, CA. Morgan Kaufmann Pu blishers, Inc.
236-242.

[Well man

et al., 1 992] Wellman , M i chael P.; Breese,
J ohn S . ; and Goldman , Robert P. 1992. From knowl­
edge bases to decisi on models. Knowledge Engineer­
ing Review 7( 1 ) : 35-53.

