
Intuitively, EDML can be thought of as relying on two
key concepts. The first concept is that of estimating
the parameters of a single random variable given soft
observations, i.e., observations that provide soft evidence on the values of a random variable. The second
key concept behind EDML is that of interpreting the
examples of an incomplete data set as providing soft
observations on the random variables of a Bayesian
network. As to the first concept, we also show that
MAP and ML parameter estimates are unique in this
case, therefore, generalizing the fundamental result
which says that these estimates are unique for hard
observations. This result is interesting and fundamental enough that we treat it separately in Section 4 before we move on and discuss the origin of EDML in
Section 5.
We discuss some theoretical properties of EDML in
Section 6, where we identify situations in which it is
guaranteed to converge immediately to optimal estimates. We present some preliminary empirical results
in Section 7 that corroborate some of the convergence
behaviors predicted. In Section 8, we close with some
concluding remarks on related and future work. We
note that while we focus on binary variables here, our
approach generalizes to multivalued variables as well.
We will comment later on this and the reason we restricted our focus here.

2

TECHNICAL PRELIMINARIES

We use upper case letters (X) to denote variables and
lower case letters (x) to denote their values. Variable

sets are denoted by bold-face upper case letters (X)
and their instantiations by bold-face lower case letters
(x). Since our focus is on binary variables, we use
x (positive) and x̄ (negative) to denote the two values of binary variable X. Generally, we will use X to
denote a variable in a Bayesian network and U to denote its parents. A network parameter will therefore
have the general form θx|u , representing the probability Pr (X = x|U = u).
Note that variable X can be thought of as inducing a
number of conditional random variables, denoted Xu ,
where the values of variable Xu are drawn based on
the conditional distribution Pr (X|u). In fact, parameter estimation in Bayesian networks can be thought
of as a process of estimating the distributions of these
conditional random variables. Since we assume binary
variables, each of these distributions can be characterized by the single parameter θx|u , since θx̄|u = 1−θx|u .
We will use θ to denote the set of all network parameters. Given a network structure G in which all variables are binary, our goal is to learn its parameters
from an incomplete dataset, such as:
example
1
2
3

X
x
?
x̄

Y
ȳ
ȳ
?

Z
?
?
z

We use D to denote a dataset, and di to denote an
example. The dataset above has three examples, with
d3 being the instantiation X = x̄, Z = z.
A commonly used measure for the quality of parameter
estimates θ is their likelihood, defined as:
QN
L(θ|D) = i=1 Pr θ (di ),
where Pr θ is the distribution induced by network
structure G and parameters θ. In the case of complete
data (each example fixes the value of each variable),
the ML parameters are unique. Learning ML parameters is harder when the data is incomplete, where EM
is typically employed. EM starts with some initial parameters θ0 , called a seed, and successively improves
on them via iteration. EM uses the update equation:
PN
P rθk (xu|di )
k+1
θx|u = Pi=1
,
N
i=1 P rθ k (u|di )
which requires inference on a Bayesian network parameterized by θk , in order to compute P rθk (xu|di ) and
P rθk (u|di ). In fact, one run of the jointree algorithm
on each distinct example is sufficient to implement an
iteration of EM, which is guaranteed to never decrease
the likelihood of its estimates across iterations. EM
also converges to every local maxima, given that it
starts with an appropriate seed. It is common to run

EM with multiple seeds, keeping the best local maxima it finds. See (Darwiche, 2009; Koller & Friedman,
2009) for recent treatments on parameter learning in
Bayesian networks via EM and related methods.
EM can also be used to find MAP parameters, assuming one has some priors on network parameters.
The Beta distribution is commonly used as a prior on
the probability of a binary random variable. In particular, the Beta for random variable Xu is specified
by two exponents, αXu and βXu , leading to a density
∝ [θx|u ]αXu −1 [1 − θx|u ]βXu −1 . It is common to assume
that exponents are > 1 (the density is then unimodal).
For MAP parameters, EM uses the update equation
(see, e.g., (Darwiche, 2009)):
PN
αXu − 1 + i=1 Pr θk (xu|di )
k+1
.
θx|u
=
PN
αXu + βXu − 2 + i=1 Pr θk (u|di )
When αXu = βXu = 1 (uninformative prior), the
equation reduces to the one for computing ML parameters. When computing ML parameters, using
αXu = βXu = 2 leads to what is usually known as
Laplace smoothing. This is a common technique to
deal with the problem of insufficient counts (i.e., instantiations that never appear in the dataset, leading
to zero probabilities and division by zero). We will
indeed use Laplace smoothing in our experiments.
Our method for learning MAP and ML parameters
makes heavy use of two notions: (1) the odds of an
event, which is the probability of the event over the
probability of its negation, and (2) the Bayes factor (Good, 1950), which is the relative change in
the odds of one event, say, X = x, due to observing some other event, say, η. In this case, we have
the odds O(x) and O(x|η), where the Bayes factor is
κ = O(x|η)/O(x), which is viewed as quantifying the
strength of soft evidence η on X = x. It is known that
κ = Pr (η|x)/Pr (η|x̄) and κ ∈ [0, ∞]. When κ = 0,
the soft evidence reduces to hard evidence asserting
X = x̄. When κ = ∞, the soft evidence reduces to
hard evidence asserting X = x. When κ = 1, the soft
evidence is neutral and bears no information on X = x.
A detailed discussion on the use of Bayes factors for
soft evidence is given in (Chan & Darwiche, 2005).

3

AN OVERVIEW OF EDML

Consider Algorithm 1, which provides pseudocode for
EM. EM typically starts with some initial parameters
estimates, called a seed, and then iterates to monotonically improve on these estimates. Each iteration
consists of two steps. The first step, Line 3, computes
marginals over the families of a Bayesian network that
is parameterized by the current estimates. The second step, Line 4, uses the computed probabilities to

Algorithm 1 EM

Algorithm 2 EDML

input:
G:
A Bayesian network structure
D:
An incomplete dataset d1 , . . . , dN
θ:
An initial parameterization of structure G
αXu , βXu : Beta prior for each random variable Xu
1: while not converged do
2:
Pr ← distribution induced by θ and G
3:
Compute probabilities:

input:
G:
A Bayesian network structure
D:
An incomplete dataset d1 , . . . , dN
θ:
An initial parameterization of structure G
αXu , βXu : Beta prior for each random variable Xu
1: while not converged do
2:
Pr ← distribution induced by θ and G
3:
Compute Bayes factors:

Pr (xu|di )

4:

and

for each family instantiation xu and example di
Update parameters:
θx|u ←

αXu − 1 +
αXu + βXu

κix|u ←

Pr (u|di )

Pr (xu|di )/Pr (x|u) − Pr (u|di ) + 1
Pr (x̄u|di )/Pr (x̄|u) − Pr (u|di ) + 1

for each family instantiation xu and example di
Update parameters:

4:

PN

Pr (xu|di )
PN
− 2 + i=1 Pr (u|di )
i=1

5: return parameterization θ

(1)

θx|u ← argmax [p]αXu −1 [1 − p]βXu −1
p

N
Y

[κix|u · p − p + 1]

i=1

(2)
5: return parameterization θ

update the network parameters. The process continues until some convergence criterion is met. The main
point here is that the computation on Line 3 can be
implemented by a single run of the jointree algorithm,
while the update on Line 4 is immediate.

random variable X are unique in this case and characterized by θx = Nx /N . If one further assumes a Beta
prior with exponents α and β that are ≥ 1, it is also
known that the MAP parameter estimates are unique
x +α−1
and characterized by θx = NN+α+β−2
.

Consider now Algorithm 2, which provides pseudocode
for EDML, to be contrasted with the one for EM. The
two algorithms clearly have the same overall structure.
That is, EDML also starts with some initial parameters estimates, called a seed, and then iterates to update these estimates. Each iteration consists of two
steps. The first step, Line 3, computes Bayes factors
using a Bayesian network that is parameterized by the
current estimates. The second step, Line 4, uses the
computed Bayes factors to update network parameters. The process continues until some convergence
criterion is met. Much like EM, the computation on
Line 3 can be implemented by a single run of the jointree algorithm. Unlike EM, however, the update on
Line 4 is not immediate as it involves solving an optimization problem, albeit a simple one. Aside from
this optimization task, EM and EDML have the same
computational complexity.

Consider now a more general problem in which the
observations are soft in that they only provide soft
evidence on the values of random variable X. That
is, each soft observation ηi is associated with a Bayes
factor κix = O(x|ηi )/O(x) which quantifies the evidence that ηi provides on having observed the value
x of variable X. We will show later that the ML estimates remain unique in this more general case, if at
least one of the soft observations is not trivial (i.e.,
with Bayes factor κix 6= 1). Moreover, we will show
that the MAP estimates are also unique assuming a
Beta prior with exponents ≥ 1. In particular, we will
show that the unique MAP estimates are characterized by Equation 2 of Algorithm 2. Further, we will
show that the unique ML estimates are characterized
by the same equation while using a Beta prior with
exponents = 1. This is the first key concept that underlies our proposed algorithm for estimating ML and
MAP parameters in a binary Bayesian network.

We next explain the two concepts underlying EDML
and how they lead to the equations of Algorithm 2.

3.2
3.1

ESTIMATION FROM SOFT
OBSERVATIONS

Consider a random variable X with values x and x̄, and
suppose that we have N > 0 independent observations
of X, with Nx as the number of positive observations.
It is well known that the ML parameter estimates for

EXAMPLES AS SOFT
OBSERVATIONS

The second key concept underlying EDML is to interpret each example di in a dataset as providing a soft
observation on each random variable Xu . As mentioned earlier, soft observations are specified by Bayes
factors and, hence, one needs to specify the Bayes factor κix|u that example di induces on random variable

x
X1

X2

…

XN

Figure 1: Estimation given independent observations.

Xu . EDML uses Equation 1 for this purpose, which
will be derived in Section 5. We next consider a few
special cases of this equation to highlight its behavior.
Consider first the case in which example di implies
parent instantiation u (i.e., the parents U of variable
X are instantiated to u in example di ). In this case,
i)
Equation 1 reduces to κix|u = O(x|u,d
O(x|u) , which is the
relative change in the odds of x given u due to conditioning on example di . Note that for root variables X,
which have no parents U, Equation 1 further reduces
i)
to κix = O(x|d
O(x) .
The second case we consider is when example di is
inconsistent with parent instantiation u. In this case,
Equation 1 reduces to κix|u = 1, which amounts to
neutral evidence. Hence, example di is irrelevant to
estimating the distribution of variable Xu in this case,
and will be ignored by EDML.
The last special case of Equation 1 we shall consider
is when the example di is complete; that is, it fixes
the value of each variable. In this case, one can verify
that κix|u ∈ {0, 1, ∞} and, hence, the example can be
viewed as providing either neutral or hard evidence
on each random variable Xu . Thus, an example will
provide soft observations on variables only when it is
incomplete (i.e., missing some values). Otherwise, it
is either irrelevant to, or provides a hard observation
on, each variable Xu .
In the next section, we prove Equation 2 of Algorithm 2. In Section 5, we discuss the origin of EDML,
where we go on and derive Equation 1 of Algorithm 2.

4

ESTIMATION FROM SOFT
OBSERVATIONS

Consider a binary variable X. Figure 1 depicts a network where θx is a parameter representing Pr (X = x)
and X 1 , . . . , X N are independent observations of X.
Suppose further that we have a Beta prior on parameter θx with exponents α ≥ 1 and β ≥ 1. A standard
estimation problem is to assume that we know the values of these observations and then estimate the parameter θx . We now consider a variant on this problem, in
which we only have soft evidence ηi about each obser-

vation, whose strength is quantified by a Bayes factor
κix = O(x|ηi )/O(x). Here, κix represents the change
in odds that the i-th observation is positive due to evidence ηi . We will refer to ηi as a soft observation on
variable X, and our goal in this section is to compute
(and optimize) the posterior density on parameter θx
given these soft observations η1 , . . . , ηN .
We first consider the likelihood:
QN
Pr (η1 , . . . , ηN |θx ) = i=1 Pr (ηi |θx )
QN
= i=1 [Pr (ηi |x, θx )Pr (x|θx ) + Pr (ηi |x̄, θx )Pr (x̄|θx )]
QN
= i=1 [Pr (ηi |x)θx + Pr (ηi |x̄)(1 − θx )]
QN
∝ i=1 [κix · θx − θx + 1].
The last step follows because κix = O(x|ηi )/O(x) =
Pr (ηi |x)/Pr (ηi |x̄). The posterior density is then:
ρ(θx |η1 , . . . , ηN ) ∝ ρ(θx )Pr (η1 , . . . , ηN |θx )
QN
∝ [θx ]α−1 [1 − θx ]β−1 i=1 [κix · θx − θx + 1].
This is exactly Equation 2 of Algorithm 2 assuming
we replace the random variable X with the conditional
random variable Xu .2
The second derivative of the log posterior is
X  (κi − 1) 2
β−1
α−1
x
−
−
−
i − 1)θ + 1
[θx ]2
[1 − θx ]2
(κ
x
x
i
which is strictly negative when κix 6= 1 for at least one
i. This remains true when α = β = 1. Hence, both
the likelihood function and the posterior density are
strictly log-concave and therefore have unique modes.
This means that both ML and MAP parameter estimates are unique in the case of soft, independent observations, which generalizes the uniqueness result for
hard, independent observations on a variable X.

5

THE ORIGIN OF EDML

This section reveals the technical origin of EDML,
showing how Equation 1 of Algorithm 2 is derived, and
providing the basis for the overall structure of EDML
as spelled out in Algorithm 2.
EDML originated from an approximation algorithm
for computing MAP parameters in a meta network.
Figure 2 depicts an example meta network in which
2
The case of κix = ∞ needs to be handled carefully
in Equation 2. First note that κix = ∞ iff Pr (ηi |x̄) = 0
in the derivation of this equation. In this case, the term
Pr (ηi |x)θx +Pr (ηi |x̄)(1−θx ) equals c·θx for some constant
c ∈ (0, 1]. Since the value of Equation 2 does not depend
on constant c, we will assume c = 1. Hence, when κix = ∞,
the term [κix · θx − θx + 1] evaluates to θx by convention.

h
H1

S1

H2

E1

s|h

S2

H3

E2

s|h

e|h

S3

E3

e|h

Figure 2: A meta network induced from a base network
S←−H−→E. The CPTs here are based on standard
semantics; see, e.g., (Darwiche, 2009, Ch. 18).

parameters are represented explicitly as nodes (Darwiche, 2009). In particular, for each conditional random variable Xu in the original Bayesian network,
called the base network, we have a node θx|u in the
meta network which represents a parameter that characterizes the distribution of this random variable.
Moreover, the meta network includes enough instances
of the base network to allow the assertion of each example di as evidence on one of these instances. Assuming that θ is an instantiation of all parameter variables,
and D is a dataset, MAP estimates are then:
θ? = argmax ρ(θ|D),
θ

where ρ is the density induced by the meta network.
Computing MAP estimates exactly is usually prohibitive due to the structure of the meta network. We
therefore use the technique of edge deletion (Choi &
Darwiche, 2006), which formulates approximate inference as exact inference on a simplified network that is
obtained by deleting edges from the original network.
The technique compensates for these deletions by introducing auxiliary parameters whose values must be
chosen carefully (and usually iteratively) in order to
improve the quality of approximations obtained from
the simplified network. EDML is the result of making
a few specific choices for deleting edges and for choosing values for the auxiliary parameters introduced,
which we explain next.
5.1

INTRODUCING GENERATORS

Let X i denote the instance of variable X in the base
network corresponding to example di . The first choice

3

H3

H3

E3

E3

3

3

Eh:

3

Eh:

3

3

Eh

Eh

Eh

Eh

e|h

e|h

e|h

e|h

(a) Adding generators

(b) Deleting copy edges

Figure 3: Introducing generators into a meta network
and then deleting copy edges from the resulting meta
network, which leads to introducing clones.

of EDML is that for each edge θx|u −→X i in the meta
network, we introduce a generator variable Xui , leading
to the pair of edges θx|u −→Xui −→X i . Figure 3(a)
depicts a fragment of the meta network in Figure 2, in
which we introduced two generator variables for edges
θe|h −→E 3 and θe|h̄ −→E 3 , leading to θe|h −→Eh3 −→E 3
and θe|h̄ −→Eh̄3 −→E 3 .
Variable Xui is meant to generate values of variable X i
according to the distribution specified by parameter
θx|u . Hence, the conditional distribution of a generator
Xui is such that Pr (xiu |θx|u ) = θx|u . Moreover, the
CPT of variable X i is set to ensure that variable X i
copies the value of generator Xui if and only if the
parents of X i take on the value u. That is, the CPT of
variable X i acts as a selector that chooses a particular
generator Xui to copy from, depending on the values
of its parents U. For example, in Figure 3(a), when
parent H 3 takes on its positive value h, variable E 3
copies the value of generator Eh3 . When parent H 3
takes on its negative value h̄, variable E 3 copies the
value of generator Eh̄3 .
Adding generator variables does not change the meta
network as it continues to have the same density over
the original variables. Yet, generators are essential
to the derivation of EDML as they will be used for
interpreting data examples as soft observations.
5.2

DELETING COPY EDGES

The second choice made by EDML is that we only
delete edges of the form Xui −→X i from the augmented
meta network, which we shall call copy edges. Figure 3(b) depicts an example in which we have deleted

h

the root and generators Xui as children. When soft
evidence is asserted on these generators, we get the
estimation problem we treated in Section 4.

H2:
H1
S1

H3

H2
E1

S3

S2

E2

S2h:

E2h:

E3

EDML can now be fully described by specifying (1)
the soft evidence on each generator Xui in a paramei
ter island, and (2) the CPT of each clone Xu:
in an
example island. These specifications are given next.
5.4

S1h

S2h

s|h

S3h

S2h:

s|h

e|h

E2h:

e|h

Figure 4: An edge-deleted network obtained from the
meta network in Figure 2 found by: (1) adding generator variables, (2) deleting copy edges, and (3) adding
cloned generators. The figure highlights the island for
example d2 , and the island for parameter θs|h .

the two copy edges from Figure 3(a).
Note here the addition of another auxiliary variable
i
Xu:
, called a clone, for each generator Xui . The addition of clones is mandated by the edge deletion framei
is chosen
work. Moreover, if the CPT of clone Xu:
carefully, it can compensate for the parent-to-child information lost when deleting edge Xui −→X i . We will
later see how EDML sets these CPTs. The other aspect of compensating for a deleted edge is to specify
soft evidence on each generator Xui . This is also mandated by the edge deletion framework, and is meant
to compensate for the child-to-parent information lost
when deleting edge Xui −→X i . We will later see how
EDML sets this soft evidence as well, which effectively
completes the specification of the algorithm. We prelude this specification, however, by making some further observations about the structure of the meta network after edge deletion.
5.3

PARAMETER & EXAMPLE ISLANDS

Consider the network in Figure 4, which is obtained
from the meta network in Figure 2 according to the
edge-deletion process indicated earlier.
The edge-deleted network contains a set of disconnected structures, called islands. Each island belongs
to one of two classes: a parameter island for each network parameter θx|u and an example island for each
example di in the dataset. Figure 4 provides the full
details for one example island and one parameter island. Note that each parameter island corresponds
to a Naive Bayes structure, with parameter θx|u as

CHILD-TO-PARENT
COMPENSATION

The edge deletion approach suggests the following soft
evidence on generators Xui , specified as Bayes factors:
κix|u =

O(xiu: |di )
P ri (di |xiu: )
=
,
O(xiu: )
P ri (di |x̄iu: )

(3)

where P ri is the distribution induced by the island
of example di . We will now show that this equation
simplifies to Equation 1 of Algorithm 2.
i
from the
Suppose that we marginalize all clones Xu:
island of example di , leading to a network that induces
a distribution Pr . The new network has the following
properties. First, it has the same structure as the base
network. Second, Pr (x|u) = P ri (xiu: ), which means
that the CPTs of clones in example islands correspond
to parameters in the base network. Finally, if we use
u to denote the disjunction of all parent instantiations
excluding u, we get:

κix|u

=
=
=

P ri (di |xiu: )
P ri (di |x̄iu: )
Pr (di |xu)Pr (u) + Pr (di |u)Pr (u)
Pr (di |x̄u)Pr (u) + Pr (di |u)Pr (u)
Pr (xu|di )/Pr (x|u) − Pr (u|di ) + 1
.
Pr (x̄u|di )/Pr (x̄|u) − Pr (u|di ) + 1

This is exactly Equation 1 of Algorithm 2. Hence, we
can evaluate Equation 3 by evaluating Equation 1 on
the base network, as long as we seed the base network
with parameters that correspond to the CPTs of clones
in an example island.
5.5

PARENT-TO-CHILD
COMPENSATION

We now complete the derivation of EDML by showing
how it specifies the CPTs of clones in example islands,
which are needed for computing soft evidence as in the
previous section.
In a nutshell, EDML assumes an initial value of these
CPTs, typically chosen randomly. Given these CPTs,
example islands will be fully specified and EDML will
compute soft evidence as given by Equation 3. The

h
H1

S1

H2

E1

s|h

S2

s|h

H3

E2

e|h

S3

E3

e|h

Figure 5: A pruning of the meta network in Figure 2
given H 1 = h̄, H 2 = h and H 3 = h̄.

computed soft evidence is then injected on the generators of parameter islands, leading to a full specification
of these islands. EDML will then estimate parameters
by solving an exact optimization problem on each parameter island as shown in Section 4. The estimated
parameters are then used as the new values of CPTs
for clones in example islands. This process repeats
until convergence.
We have shown in the previous section that the CPTs
of clones are in one-to-one correspondence with the parameters of the base network. We have also shown that
soft evidence, as given by Equation 3, can be computed
by evaluating Equation 1 of Algorithm 2 (with parameters θ corresponding to the CPTs of clones in an
example island). EDML takes advantage of this correspondence, leading to the simplified statement spelled
out in Algorithm 2.

6

SOME PROPERTIES OF EDML

Being an approximate inference method, one can
sometimes identify good behaviors of EDML by identifying situations under which the underlying inference
algorithm will produce high quality approximations.
We provide a result in this section that illustrates this
point in the extreme, where EDML is guaranteed to return optimal estimates and in only one iteration. Our
result relies on the following observation about parameter estimation via inference on a meta network.
When the parents U of a variable X are observed to
u in an example di , all edges θx|u? −→X i in the meta
network become superfluous and can be pruned, except for the one edge that satisfies u? = u. Moreover,

edges outgoing from observed nodes can also be pruned
from a meta network. Suppose now that the parents of
each variable are observed in a dataset. After pruning
edges as indicated earlier, each parameter variable θx|u
will end up being the root of an isolated naive Bayes
structure that has some variables X i as its children
(those whose parents are instantiated to u in example
di ). Figure 5 depicts the result of such pruning in the
meta network of Figure 2, given a dataset with H 1 = h̄,
H 2 = h and H 3 = h̄.
The above observation implies that when the parents
of each variable are observed in a dataset, parameters
can be estimated independently. This leads to the following well known result.
Proposition 1 When the dataset is complete, the ML
estimate for parameter θx|u is unique and given by
D#(xu)/D#(u), where D#(xu) is the number of examples containing xu and D#(u) is the number of examples containing u.
It is well known that EM returns such estimates and
in only one iteration (i.e., independently of its seed).
The following more general result is also implied by
our earlier observation.
Proposition 2 When only leaf variables have missing values in a dataset, the ML estimate for each parameter θx|u is unique and given by D#(xu)/D+ #(u).
Here, D+ #(u) is the number of examples containing
u and in which X is observed.
We can now prove the following property of EDML,
which is not satisfied by EM, as we show next.
Theorem 1 When only leaf variables have missing
values in a dataset, EDML returns the unique ML estimates given by Proposition 2 and in only one iteration.
Proof Consider an example di that fixes the values
of parents U for variable X and consider Equation 1.
First, κix|u = 1 iff example di is inconsistent with u
or does not set the value of X. Next, κix|u = 0 iff example di contains x̄u. Finally, κix|u = ∞ iff example
di contains xu. Moreover, these values are independent of the EDML seed so the algorithm converges in
one iteration. Given these values of the Bayes factors,
Equation 2 leads to the estimate of Proposition 2. 
We have a number of observations about this result.
First, since Proposition 1 is implied by Proposition 2,
EDML returns the unique ML estimates in only one
iteration when the dataset is complete (just like EM).
Next, when only the values of leaf variables are missing
in a dataset, Proposition 2 says that there is a unique
ML estimate for each network parameter. Moreover,

Theorem 1 says that EDML returns these unique estimates and in only one iteration. Finally, Theorem 1
does not hold for EM. In particular, one can show that
under the conditions of this theorem, an EM iteration
will update its current parameter estimates θ and return the following estimates for θx|u :
−

D#(xu) + D #(u)Pr (x|u)
.
D#(u)
Here, D− #(u) is the number of examples that contain
u and in which the value of X is missing. This next
estimate clearly depends on the current parameter estimates. As a result, the behavior of EM will depend
on its initial seed, unlike EDML.
When only the values of leaf variables are missing,
there is a unique optimal solution as shown by Proposition 2. Since EM is known to converge to a local optimum, it will eventually return the optimal estimates
as well, but possibly after some number of iterations.
In this case, the difference between EM and EDML is
simply in the speed of convergence.
Theorem 1 clearly suggests better convergence behavior of EDML over EM in some situations. We next
present initial experiments supporting this suggestion.

7

MORE ON CONVERGENCE

We highlight now a few empirical properties of EDML.
In particular, we show how EDML can sometimes find
higher quality estimates than EM, in fewer iterations
and also in less time.
We highlight different types of relative convergence behavior in Figure 6, which depicts example runs on a
selection of networks: spect, win95pts, emdec6g, and
tcc4e. Network spect is a naive Bayes network induced from a dataset in the UCI ML repository, with
1 class variable and 22 attributes. Network win95pts
(76 variables) is an expert system for printer troubleshooting in Windows 95. Networks emdec6g (168
variables) and tcc4e (98 variables) are noisy-or networks for diagnosis (courtesy of HRL Laboratories).
We simulated datasets of size 2k , using the original
CPT parameters of the respective networks, and then
used EDML and EM to learn new parameters for a
network with the same structure. We assumed that
certain variables were hidden (latent); in Figure 6, we
randomly chose 14 of the variables to be hidden. Hidden nodes are of particular interest to EM, because it
has been observed that local extrema and convergence
rates can be problematic for EM here; see, for example
(Elidan & Friedman, 2005; Salakhutdinov, Roweis, &
Ghahramani, 2003).

0EDML
1
2
3
4
5
6 1EM
10
1e2
0.0EDML

spect

102

iteration

103

spect
EDML

0
1
2
3
4
5
62
4
10 10

win95pts

0.0

EM 3
10
1e2

0.2

0.2

0.4

0.4

0.6

0.6

0.8 EM
101
1e2
0.0EDML
0.2
0.4
0.6
0.8
1.0
1.2
1.4 EM
1.6 1
10
1e2
0.0EDML
0.5
1.0
1.5
2.0
2.5
3.0
3.5 EM
4.0 1
10

102

iteration

103

104

0.8
103

104

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6 3
10

104

tcc4e

102

iteration

103

emdec6g

102

iteration

103

EDML

EM

time

104

105

win95pts

104

105

106

105

106

emdec6g
1e2
EDML
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
EM
4.0 3
104
105
10

106

EDML

time

tcc4e

EM
104

time

time

Figure 6: Quality of parameter estimates over iterations (left column) and time (right column). Going
right on the x-axis, we have increasing iterations and
time. Going up on the y-axis, we have increasing quality of parameter estimates. EDML is depicted with a
solid red line, and EM with a dashed black line.
In Figure 6, each plot represents a simulated data set
of size 210 , where EDML and EM have been initialized with the same random parameter seeds. Both
algorithms were run for a fixed number of iterations,
1024 in this case, and we observed the quality of the
parameter estimates found, with respect to the log posterior probability (which has been normalized so that
the maximum log probability observed is 0.0). We assumed a Beta prior with exponents 2. EDML damped
its parameter updates by a factor of 21 , which is typical
for (loopy) belief propagation algorithms.3
3
The simple bisection method suffices for the optimization sub-problem in EDML for binary Bayesian networks.
In our current implementation, we used the conjugate gradient method, with a convergence threshold of 10−8 .

In the left column of Figure 6, we evaluated the quality of estimates over iterations of EDML and EM. In
these examples, EDML (represented by a solid red
line) tended to have better quality estimates from iteration to iteration (curves that are higher are better), and further managed to find them in fewer iterations (curves to the left are faster).4 This is most
dramatic in network spect, where EDML appears to
have converged almost immediately, whereas EM spent
a significant number of iterations to reach estimates of
comparable quality. As most nodes hidden in network
spect were leaf nodes, this may be expected due to
the considerations from the previous section.
In the right column of Figure 6, we evaluated the
quality of estimates, now in terms of time. We remark again that procedurally, EDML and EM are very
similar, and each algorithm needs only one evaluation
of the jointree algorithm per distinct example in the
data set (per iteration). EDML solves an optimization problem per distinct example, whereas EM has a
closed-form update equation in the corresponding step
(Line 4 in Algorithms 1 and 2). Although this optimization problem is a simple one, EDML does require
more time per iteration than EM. The right column
of Figure 6 suggests that EDML can still find better
estimates faster, especially in the cases where EDML
has converged in significantly fewer iterations. In network emdec6g, we find that although EDML appeared
to converge in fewer iterations, EM was able to find
better estimates in less time. We anticipate in larger
networks with higher treewidth, the time spent in the
simple optimization sub-problem will be dominated by
the time to perform jointree propagation.
We also performed experiments on networks learned
from binary haplotype data (Elidan & Gould, 2008),
which are networks with bounded treewidth. Here, we
simulated data sets of size 210 , where we again randomly selected 41 of the variables to be hidden. We
further ran EDML and EM for a fixed number of iterations (512, here). For each of the 74 networks available, we ran EDML and EM with 3 random seeds, for
a total of 222 cases. In Figure 7, we highlight a selection of the runs we performed, to illustrate examples of
relative convergence behaviors. Again, in the first row,
we see a case where EDML identifies better estimates
in fewer iterations and less time. In the next two rows,
we highlight two cases where EDML appears to converge to a superior fixed point than the one that EM
appears to converge to. In the last row, we highlight
an instance where EM instead converges to a superior
estimate. In Figure 8, we compare the estimates of
4

We omit the results of the first 10 iterations as initial
parameter estimates are relatively poor, which make the
plots difficult to read.

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

greedy.15.1
EDML
EM

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

bounded.u.20.5
EDML

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

bounded.u.25.5
EDML

1e2

greedy.1.1
EM
EDML

0

1

102

iteration

greedy.15.1

103

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10

bounded.u.20.5

103

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10

bounded.u.25.5

103

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10
1e2

greedy.1.1
EM
EDML

EM

102

iteration

EM

102

iteration

0

1

2

2

3

3

4
101

102

iteration

4
103 103

EDML
EM

105

106

time

EDML
EM

105

106

time

EDML
EM

105

time

104

time

105

106

106

Figure 7: Quality of parameter estimates over iterations (left column) and time (right column). Going
right on the x-axis, we have increasing iterations and
time. Going up the y-axis, we have increasing quality of parameter estimates. EDML is depicted with a
solid red line, and EM with a dashed black line.
EDML and EM at each iteration, computing the percentage of the 74 × 3 = 222 cases considered, where
EDML had estimates no worse than those found by
EM. In this set of experiments, the estimates identified by EDML are clearly superior (or at least, no
worse in most cases), when compared to EM.
We remark however, that when both algorithms are
given enough iterations to converge, we have observed
that the quality of the estimates found by both algorithms are often comparable. This is evident in Figure 6, for example. The analysis from the previous
section indicates however that there are (very specialized) situations where EDML would be clearly preferred over EM. One subject of future study is the identification of situations and applications where EDML

100 % of 222 cases, EDML favored
80
60
40
20
0
101

iteration

102

Figure 8: Quality of EDML estimates over 74 networks (3 cases each) induced from binary haplotype
data. Going right on the x-axis, we have increasing
iterations. Going up the y-axis, we have an increasing
percentage of instances where EDML’s estimates were
no worse than those given by EM.

izes to multivalued variables since edge deletion does
not require a restriction to binary variables and the
key result of Section 4 also generalizes to multivalued
variables. The resulting formulation is less transparent
though when compared to the binary case since Bayes
factors no longer apply directly and one must appeal to
a more complex method for quantifying soft evidence;
see (Chan & Darwiche, 2005). We expect our future
work to focus on a more comprehensive empirical evaluation of EDML, in the context of an implementation
that uses multivalued variables. Moreover, we seek to
identify additional properties of EDML that go beyond
convergence.
References
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent
Dirichlet allocation. JMLR, 3, 993–1022.
Chan, H., & Darwiche, A. (2005). On the revision of probabilistic beliefs using uncertain evidence. Artificial Intelligence, 163, 67–90.
Choi, A., & Darwiche, A. (2006). An edge deletion semantics for belief propagation and its practical impact on
approximation quality. In AAAI, pp. 1107–1114.

would be preferred in practice as well.

Darwiche, A. (2009). Modeling and Reasoning with Bayesian Networks. Cambridge University Press.

8

Dempster, A., Laird, N., & Rubin, D. (1977). Maximum
likelihood from incomplete data via the EM algorithm.
Journal of the Royal Statistical Society B, 39, 1–38.

FUTURE AND RELATED WORK

EM has played a critical role in learning probabilistic graphical models and Bayesian networks (Dempster et al., 1977; Lauritzen, 1995; Heckerman, 1998).
However learning (and Bayesian learning in particular)
remains challenging in a variety of situations, particularly when there are hidden (latent) variables; see, e.g.,
(Elidan, Ninio, Friedman, & Shuurmans, 2002; Elidan
& Friedman, 2005). Slow convergence of EM has also
been recognized, particularly in the presence of hidden
variables. A variety of techniques, some incorporating more traditional approaches to optimization, have
been proposed in the literature; see, e.g., (Thiesson,
Meek, & Heckerman, 2001).
Variational approaches are an increasingly popular formalism for learning tasks as well, and for topic models
in particular, where variational alternatives to EM are
used to maximize a lower bound on the log likelihood
(Blei, Ng, & Jordan, 2003). Expectation Propagation also provides variations of EM (Minka & Lafferty,
2002) and is closely related to (loopy) belief propagation (Minka, 2001).
Our empirical results have been restricted to a preliminary investigation of the convergence of EDML, in
contrast to EM. A more comprehensive evaluation is
called for in relation to both EM and other approaches
based on Bayesian inference. We have also focused this
paper on binary variables. EDML, however, general-

Elidan, G., & Friedman, N. (2005). Learning hidden
variable networks: The information bottleneck approach.
JMLR, 6, 81–127.
Elidan, G., & Gould, S. (2008). Learning bounded treewidth Bayesian networks. JMLR, 9, 2699–2731.
Elidan, G., Ninio, M., Friedman, N., & Shuurmans, D.
(2002). Data perturbation for escaping local maxima in
learning. In AAAI/IAAI, pp. 132–139.
Good, I. J. (1950). Probability and the Weighing of Evidence. Charles Griffin, London.
Heckerman, D. (1998). A tutorial on learning with Bayesian networks. In Jordan, M. I. (Ed.), Learning in Graphical
Models, pp. 301–354. MIT Press.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical
Models: Principles and Techniques. MIT Press.
Lauritzen, S. (1995). The EM algorithm for graphical association models with missing data. Computational Statistics
and Data Analysis, 19, 191–201.
Minka, T. P. (2001). Expectation propagation for approximate Bayesian inference. In UAI, pp. 362–369.
Minka, T. P., & Lafferty, J. D. (2002). Expectationpropogation for the generative aspect model. In UAI, pp.
352–359.
Salakhutdinov, R., Roweis, S. T., & Ghahramani, Z.
(2003). Optimization with EM and expectation-conjugategradient. In ICML, pp. 672–679.
Thiesson, B., Meek, C., & Heckerman, D. (2001). Accelerating EM for large databases. Machine Learning, 45 (3),
279–299.

