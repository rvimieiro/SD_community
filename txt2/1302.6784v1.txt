where A, the counterfactual antecedent, specifies an
event that is contrary to one's real-world observations,
and C, the counterfactual consequent, specifies a re­
sult that is expected to hold in the alternative world
where the antecedent is true. A typical instance is "If
Oswald were not to have shot Kennedy, then Kennedy
would still be alive" which presumes the factual knowl­
edge of Oswald's shooting Kennedy, contrary to the
antecedent of the sentence.
Because of the tight connection between counterfactu­
als and causal influences, any algorithm for computing
solutions to counterfactual queries must rely heavily on
causal knowledge of the domain. This leads naturally
to the use of probabilistic causal networks, since these

networks combine causal and probabilistic knowledge
and permit reasoning from causes to effects as well as,
conversely, from effects to causes.
To emphasize the causal character of counterfactuals,
we adopt the interpretation in [Pearl, 1993b], accord­
ing to which a counterfactual sentence "If it were A,
then B would have been" states that B would prevail
if A were forced to be true by some unspecified action
that is exogenous to the other relationships considered
in the analysis.
Causal theories specified in functional form (as in
[Pearl and Verma, 1991, Druzdzel and Simon, 1993,
Poole, 1993]) are sufficient for evaluating counterfac­
tual queries, whereas the causal information embed­
ded in Bayesian networks is not sufficient for the task.
Every Bayes network can be represented by several
functional specifications, each yielding different eval­
uations of a counterfactual. The problem is that, de­
ciding what factual information deserves undoing (by
the antecedent of the query) requires a model of tem­
poral persistence, and, as noted in [Pearl, 1993c], such
a model is not part of static Bayesian networks. Func­
tional specifications, however, implicitly contain the
needed temporal persistence information.
Consider an example with two variables A and B, rep­
resenting Ann and Bob's attendance, respectively, at
a party (A = a1 when Ann is at the party, A = ao
otherwise; B = b1 when Bob is at the party, B = bo
otherwise), and it is believed that Ann's attendance
has a causal influence on Bob's attendance, sho wn by
the arrow A -+ B). Assume that previous behavior
shows P(b1lai) = 0.9 and P(bolao) = 0.9. We observe
that Bob and Ann are absent from the party and we
wonder whether Bob would be there if Ann were there.
The answer depends on the mechanism that accounts
for the 10% exception in Bob's behavior. If the rea­
son Bob occasionally misses parties (when Ann goes)
is that he is unable to attend (e.g., being sick or hav­
ing to finish a paper for U AI), then the answer to our
query would be 90%. However, if the only reason for
Bob's occasional absence (when Ann goes) is that he
becomes angry with Ann (in which case he does ex­
actly the opposite of what she does), then the answer
to our query is 100%, because Ann and Bob's current
absence from the party proves that Bob is not angry.

Counterfactual Probabilities

Thus, we see that the information contained in the con­
ditional probabilities on the observed variables is insuf­
ficient for answering counterfactual queries uniquely;
some information about the mechanisms responsible
for these probabilities is needed as well. Still, when
only a probabilistic model is given, informative bounds
on the counterfactual probabilities can often be de­
rived, and this paper provides a general framework for
evaluating these bounds.
The next section will introduce concise notation for ex­
pressing counterfactual queries. Section 3.2 will derive
a general expression for counterfactual probabilities in
terms of a functional specification. Section 3.3 will
present a general procedure for evaluating bounds on
counterfactual probabilities when only a probabilistic
specification is supplied. Section 4 will apply this pro­
cedure for evaluating bounds on treatment effects in
partial compliance studies, while Section 5 will demon­
strate the use of this procedure in product liability
litigation.
2

NOTATION

3.1

47

FUNCTIONAL MODELS

For the previously described party example, a func­
tional specification models the influence of Ann's at­
tendance (A) on Bob's attendance (B) by a determin­
istic function

b= Fb(a, t:b)
where t:b stands for all unknown factors that may in­
fluence Band the prior probability distribution P(t:b)
quantifies the likelihood of such factors. For example,
whether Bob has been grounded by his parents and
whether Bob is angry at Ann could make up two pos­
sible components of t:b. Given a specific value for t:b,
B becomes a deterministic function of A; hence, each
value in t:0 's domain specifies a response function that
maps each value of A to some value in B's domain. In
general, the domain for fb could contain many compo­
nents, but it can always be replaced by an equivalent
variable that is minimal, by partitioning the domain
into equivalence regions, each corresponding to a sin­
gle response function [Pearl, 1993a]. Formally, these
equivalence classes can be characterized as a function
rb : dom(Eb ) --+ N, as follows:

0 if Fb(ao, q) = 0
1 if Fb(ao, t:b) = 0
2 if Fb(ao, fb) = 1
3 if Fb(ao, t:b) = 1

&
&
&
&

Let the set of variables describing the world be desig­
nated by X= {X1,X2, . . . ,Xn}· As part of the com­
plete specification of a counterfactual query, there are
real-world observations that make up the background
context. These observed values will be represented in
the standard form Xt, x2, ... , Xn. In addition, we must
represent the value of the variables in the counterfac­
tual world. To distinguish between Xi and the value
of Xi in the counterfactual world, we will denote the
latter with an asterisk; thus, the value of xi in the
counterfactual world will be represented by x;. We
will also need a notation to distinguish between events
that might be true in the counterfactual world and
those referenced explicitly in the counterfactual an­
tecedent. The latter are interpreted as being forced to
the counterfactual value by an external action, which
will be denoted by a hat (e.g., x).

Obviously, rb can be regarded as a random variable
that takes on as many values as there are functions
between A and B. We will refer to this domain­
minimal variable as a response-function variable. rb
is closely related to the potential response variables in
Rubin's model of counterfactuals [Rubin, 1974], which
was introduced to facilitate causal inference in statis­
tical analysis [Balke and Pearl, 1993].

Thus, a typical counterfactual query will have the form
"What is P(c•W, a, b)?" to be read as "Given that we
have observed A = a and B = b in the real world, if
A were a•, then what is the probability that C would
have been c* ?"

hb,r0(a) are given by

3

BOUNDS ON

{

For this example, the response-function variable for
B has a four-valued domain rb E {0, 1, 2, 3} with the
following functional specification:

b

(1)

where the mappings defined by each response function

hb,o(a) = bo

hb,I(a) =

hb,a(a)

hb, 2 (a) =

=

b1

COUNTERFACTUA LS
In [Balke and Pearl, 1994], an algorithm was presented
for evaluating the unique quantitative solutions to
counterfactual queries when a functional model is
given. In this section we briefly describe the form of
the functional model using response-function variables
and how the solution is evaluated uniquely. Then we
deal with probabilistic specifications and show how
bounds can be obtained by optimizing the solution
above over all functional models consistent with the
probabilistic specification.

Fb(at, t:b) = 0
Fb(a1, t:b) = 1
Fb(at, t:b ) = 0
F0(ai, q) = 1

{
{

bo
bl

if a= ao
if a= a1

bl
bo

if a= ao
if a= a1

The response-function variable for A has a two-valued
domain ra E {0, 1} with the functional specification:

!a(ra) = ha,r. ()

a
where

ha,o()

=

ao

The prior probability on the response functions P(rb)
and P(ra) in conjunction with fb(a, r b) and fa(ra) fully
parameterizes the model.

48

Balke and Pearl

For each observable variable X;, there will be a func­
tion that maps the value of X; 's observable causal in­
fluences pa(X;) and X; 's response-function variable r.,,
to the value of X;
x;

fx;(pa(x;),r.,.)

=

If the model is complete (such as the functional model
described in [Pearl and Verma, 1991]), all response
functions will be mutually independent, and each will
be characterized by a prior probability P(rx.). How­
ever, when some variables are left out of the analy­
sis, the response functions of the remaining variables
(x1, ... , xn) may be dependent and, in principle, a
joint probability P(r.,1,
, r.,n) would be required. In
practice, only local dependencies will be needed.
.

•

.

If one assumes that two variables A and B are de­
pendent via some exogenous common cause, then we
create an edge between ra and rb and specify the joint
distribution P(ra,rb)· This treatment of latent vari­
ables will be utilized in the applications discussed in
Sections 4 and 5.
3.2

If a set of variables A C X in the model are externally
forced to the value a, then according to the action­
based semantics of [Pearl, 1993a], the recursive func­
tion becomes
x;

=

{

of the underlying functional model.

The connection between the factual and counterfactual
worlds is discussed in [Balke and Pearl, 1994] where it
is argued that the response-function variables should
assume the same values in both worlds. For the party
example, this invariance allows the response function
variables ra and rb to be shared between the networks
corresponding to the two worlds (see Figure 1).

;
if X; E A
i
f.,,(r.,.) if X; t$. A and pa(X;) = 0
fx,(/�1 (r), fi2 ( r) , .. . , f�. (r), rx.) otherwise

The counterfactual probability P(c* Ia*, o) may be
rewritten
P(c*, ola*)
P(c*la*, o) =
P(ola*)
Since an action can only affect its descendants in the
graph [Pearl, 1994] we have P(ola) = P(o) which is
readily computed from the probabilistic specification.
P(c*, olD.*) may be evaluated in terms of the functional
model by summing the probabilities of the response­
function configurations which are consistent with the
arguments (c*, a*, o). Formally,

FUNCTIONAL EXPRESSION

We now derive an expression for P(c*la*, o) in terms

J:,(r)

P(c*, olD.*)
where
R

=

{rl'v'o:,Eo[x;

=

fx,(r)] and 'v'xjEe•[xj

=

J:;(r)]}

Hence, the counterfactual probability may be written
in terms of the structure {pa(x;)} and parameters P(r)
of the functional model:
P(r)
(2)
P(c* Iii*, o) = ErER
P( o)
In the next section this expression will be optimized
under the constraints imposed by the probabilistic
specification.
3.3

CONSTRAINTS AND OPTIMIZATION

The probabilistic specification P(x; I pa(x;)) for a com­
plete model imposes a set of constraints on P(rx,) of
the form
Figure 1: Factual (A, B) and counterfactual (A*, B*)
worlds for the functional analysis of the structure A­

B. The response-function variables ra and rb (summa­
rizing all exogenous influences on A and B) attain the
same value in the real and counterfactual worlds.
Let r = (r.,1,r.,2, ,r.,..) represent the set of
response-function variables for all the variables in the
model. Given the value of r, all variables X; E X
are functionally determined according to the recursive
function:
•

x;

=
=

•

•

j.,,(r)
/x,(fu1(r),/u2(r), ... , /u. (r),r.,J

where pa(X;) = {U1.U2, . . . ,Uk}
influences of X; in the model.

C

X are the causal

LP(rx.)t(rx,;x;,pa(x;)) (3)
where the characteristic function t indicates which val­
ues of rx, map the particular value of X; 's causal in­
fluences (pa(x;)) to the specific value of X; (x;), i.e.
t( r.,,;x;,pa( x;))

{

1 if X;= fx, (pa(x;),rx,)
otherwise

0

For an incomplete model, if X; and Xj are assumed to
have an exogenous common cause, then the common
constraint for these two variables will be given instead
by
(4)
P(x;, xilpa (x;)- {xi},pa(xj)- {x;}) =
L P(r:c, r.,J t (rx , ; Xi, pa(x i ))t (rx; ; Xj, pa(Xj))

Counterfactual Probabilities

Note that the constraints
P(rx,, rxJ·

m

Eq. (4) are linear in

For example, in the party story (which is complete
with two binary variables A and B) the constraints
are given by
P(btlao)
P(bJial)
P(at)

P(rb=2) + P(rb=3)
P(rb=l) + P(rF3)
P(ra=l)

Additional subjective constraints may also be imposed
on the underlying functional model. For example, we
may subjectively believe that Bob is never spiteful
against Ann, which can be simply written P(rb=2) = 0
and added to the existing set of constraints.
Given the entire set of linear constraints and the objec­
tive function from Eq. (2) , the bounds may be evalu­
ated using techniques for optimizing non-linear objec­
tive functions under linear constraints (Scales, 1 985)
In general, the optimization procedure may converge
to a local minima/maxima which would produce false
bounds. If the objective is to prove that the counter­
factual probability falls within a certain range, care
must be taken to ensure that global optima are found.
.

If the objective function given by Eq. (2) is linear, the
minimum/maximum may be determined using linear
programming techniques. In this case, when the prob­
lem size is small enough, we may also derive symbolic
bounds to the counterfactual probability in terms of
the probabilistic specification. This is accomplished
by tracking the conditions that lead to the various de­
cisions in the Simplex Tableau algorithm. This pro­
cedure generates a decision tree where each leaf node
contains a symbolic solution [Balke and Pearl, 1993].
4

APPLICATION TO CLINICAL
TRIA LS WITH IMPERFECT
COMPLIANCE

Consider an experimental study where random as­
signment has taken place but compliance is not per­
fect (i.e., the treatment received differs from that as­
signed). It is well known that under such conditions
a bias may be introduced, in the sense that the true
causal effect of the treatment may deviate su bstan­
tially from the causal effect computed by simply com­
paring subjects receiving the treatment with those not
receiving the treatment. Because the subjects who did
not comply with the assignment may be precisely those
who would have responded adversely (positively) to
the treatment, the actual effect of the treatment, when
applied uniformly to the population, might be substan­
tially less (more) effective than the study reveals.
In an attempt to avert this bias, economists have de­
vised correctional formulas based on an "instrumen­
tal variables" model ([Bowden and Turkington, 19841)
which, in general, do not hold outside the lin­
ear regression model.
A recent analysis by
[Efron and Feldman, 1991] departs from the linear

49

regression model, but still makes restrictive com­
mitments to a particular mode of interaction be­
tween compliance and response.
[Robins, 1989]
and [Manski, 1990] derived nonparametric bounds on
treatment effects using different techniques; how­
ever their bounds are not tight. [Holland, 1988] has
given a general formulation of the problem (which
he called "encouragement design") in terms of Ru­
bin's model of causal effect and has outlined its rela­
tion to path analysis and structural equations models.
[Angrist et al., 1993], also invoking Rubin's model,
have identified a set of assumptions under which the
"Instrumental Variable" formula is valid for certain
subpopulations. These subpopulations cannot be iden­
tified from empirical observation alone, and the need
remains to devise alternative, assumption-free formu­
las for assessing the effect of treatment over the pop­
ulation as a whole. In this section, we derive bounds
on the average treatment effect that rely solely on ob­
served quantities and are universal, that is, valid no
matter what model actually governs the interactions
between compliance and response.
The canonical partial-compliance setting can be graph­
ically modeled as shown in Figure 2.

Observed
Response
Figure 2: Graphical representation of causal dependen­
cies in a randomized clinical trial with partial compli­
ance.
We assume that Z, D, andY are observed binary vari­
ables where Z represents the (randomized) treatment
assignment, D is the treatment actually received, and
Y is the observed response. U represents all factors,
both observed and unobserved, that may influence the
outcome Y and the treatment D. To facilitate the
notation, we let z, d, and y represent, respectively,
the values taken by the variables Z, D, and Y, with
the following interpretation: z E { zo, zt } , zr asserts
that treatment has been assigned (zo, its negation);
dE {do, dt}, d1 asserts that treatment has been ad­
ministered (do, its negation); and yE {yo, yt}, Yl as­
serts a positive observed response (y0, its negation).
The domain of U remains unspecified and may, in gen­
eral, combine the spaces of several random variables,
both discrete and continuous.
The graphical model reflects two assumptions of inde­
pendence:
1. The treatment assignment does not influence Y
directly, but only through the actual treatment
D, that is,
z _II Y I {D,U}
(5)
In practice, any direct effect Z might have on

50

Balke and Pearl

2.

Y would be adjusted for through the use of a
placebo.
Z and U are marginally independent, that is,
Z II U.
This independence is partly ensured
through the randomization of Z, which rules out
a common cause for both Z and U. The absence
of a direct path from Z to U represents the as­
sumption that a person's disposition to comply
with or deviate from a given assignment is not in
itself affected by the assignment; any such effect
can be viewed as part of the disposition.

and Y), we define the corresponding response-function
variables (rz, rd, and ry, respectively).
Figure 3 shows the graphical representation of the re­
sulting functional model. Because D and Y are as­
sumed to be influenced by an unobservable common
cause, the response-function variables rd and ry are
connected by an edge.
The states of the variables rd and ry have the following
interpretations:

These assumptions impose on the joint distribution1
the decomposition
P{y, d, z, u)

=

P (yld, u) P(dlz, u) P(z) P(u)

(6)

which, of course, cannot be observed directly because
U is a latent variable. However, the marginal distribu­
tion P(y, d, z) and, in particular, the conditional dis­
tributions P(y, dlz), z E {zo, zt}, are observed, and the
challenge is to assess the causal effect of D on Y from
these distributions. 2
In addition to the independence assumption above, the
causal model of Figure 2 reflects claims about the be­
havior of the population under external interventions.
In particular, it reflects the assumption that P(yld, u)
is a stable quantity: the probability that an individ­
ual with characteristics U = u given treatment D = d
will respond with Y = y remains the same, regardless
of how the treatment was selected - be it by choice
or by policy. Therefore, if we wish to predict the dis­
tribution of Y under a condition where the treatment
D is applied uniformly to the population, we should
calculate

L P(yld, u)P(u)

P(y* id*)

u

(7)

Likewise, if we are interested in estimating the average
change in Y due to treatment, we define the average
causal effect, ACE(D-+ Y) ([Holland, 1988]), as
ACE(D-+ Y)

(8)

The task of causal inference is then to estimate or
bound the expression in Eq. (8), given the observed
probabilities P(y, dlzo) and P(y, dlzr). This may be
accomplished by following the procedure detailed in
Section 3.3 where the objective function to be opti­
mized is the difference between the two counterfactual
probabilities on the right-hand side of Eq. (8).

First, the functional model corresponding to the prob­
abilistic model of Figure 2 must be specified. For
each of the observable variables in the model (Z, D,
1 We take the liberty of denoting the prior distribution
of U by
even though U may consist of continuous
variables.
2
In practice, of course, only a finite sample of

P(u),

P(y, dlz)

will be observed, but since our task is one of identification,

not estimation, we make the large-sample assumption and
consider

P(y,dlz)

as

given.

structure equivalent to that of Figure 1 but
employing response-function variables rz, rd and ry.

Figure 3: A
D
rd

is a deterministic function of the variable Z and
E {0, 1, 2, 3}:
d = fd(z, rd) = hd,rd(z)

where
hd,o(z)

=do

hd,3(z) = dt

hd,t(z)

=

hd,2(z) =

{
{

do

if z

= zo

dl

if Z = Z1

dt
do

if z = zo
if Z = Zt

Similarly, Y is a deterministic function of D and ry E
{0, 1, 2, 3}:
fy(d, ry) = hy,r.(d)
y
(9)
where
if d =do
hy ,t (d) = Yot if d = dt
hy,o(d) =Yo
Y
hy,3(d) =Yt

hy,2(d)

=

{
{

Yt
Yo

if d =do
if d = dt

The correspondence between the states of variables
rd and ry and the potential response vectors in the
Rubin's model [Rosenbaum and Rubin, 1983] is rather
transparent: each state corresponds to a counterfac­
tual statement specifying how a unit in the population
(e.g., a person) would have reacted to any given in­
put. For example, rd = 1 represents units with perfect
compliance, while rd = 2 represents units with per­
fect defiance. Similarly, ry = 1 represents units with
perfect response to treatment, while ry = 0 represents
units with no response (y = y0) regardless of treat­
ment. The counterfactual variables Y1 and Yo usually
invoked in Rubin's model can be obtained from ry as
follows:
.
1 if ry =1 or ry =3
Yt = {Y 1f D = d 1 }
0
otherwise
_

-

{

Counterfactual Probabilities

{Y

Yo =

if

= do }

D

=

{6

if r11 = 2 or r11 = 3
otherwise

In general, treatment response and compliance atti­
tudes may not be independent, hence the arrow rd ----+
r
in Figure 3. The joint distribution over rd x r11 re­
11
quires 15 independent parameters, and these parame­
ters are sufficient for specifying the model of Figure 3,
P(y, d, z, rd , r11) = P(yid, r11)P(d[rd, z)P(z)P(rd,r11),
because Y and D stand in functional relation to their
parents

Eq. (12) can now be rewritten as a linear combination
of the Q parameters:
ACE(D- Y) =

(10)

P(r11=2) + P(ry=3)

(11)

4.1

Poo 1 =
Pou =
Pt a . I =
Pllt =

L

n=OO

L

=1

n=OO

P(yo,do[zt)
P(yo,dtlzt)
P(yt, do[zt)
P(yt,d tlzt)

k E {0, 1, 2, 3}.

Pn.! =

1

the

=

+

q12 + q13

qzr

qro + q12 + q3o + q32
qo2 + qo3 + qn + q23
qll + q13 + q31 + q33

1

qu + qzt

+qat - qo2 - q12 - q22- q32

Subject to:

Pq

>

(15)
Oforj,k E {0,1,2,3}

PlLO

max

implies that q specifies a point in 15-dimensional space.
This space will be referred to as Q.

+

P

Pn.l- P11.0-Pto.o- Pou-P10.1

-Pou -Pto.t
P oL o - Pr o.o

-

Pao.t- Pou - Pto.t -PoLo- Poo.o
Poo.o-PoLo- Pto.o-

population un­

1

+

(16)

oo . o- 1
POO.l - 1
Pu.o- P11.1- Pto.r- Po r .o - Pto.o
P11.1

Pou -Poo . r

Similarly, the upper bound is given by
ACE(D ___, Y) ::;

The probabilistic constraint

j=O 1:::::0

+ qor + q2o +

Minimize: qat +

(13)

P(ra=j, r11=k)

3 3
L:l:qjk

qoo

ACE( D - Y) ?::

der study. These parameters will be notated as

where j,

Poo.t

qo3

Given a poi n t p in P space, the strict lower bound
on ACE(D----+ Y ) can be determined by solving the
following linear programming problem:

The joint probability over rd x r11, P(rd , r11 ) , has 16 pa­

q;k =

+

However, for problems of this size, the procedure may
be used for deriving symbolic expressions as well, lead­
ing to the following lower bound on the treatment ef­
fect

further imply tha t p = (Poo.o, . . . , Ptu ) can be spec­
ified by a point in six-dimensional space. This space
will be referred to as P.
rameters and completely specifies

q21 + q23 + q31 + q33

qjk

11

Pno

qoz

P11.0

which will be written in matrix form, p= Pi[.

The probabilistic constraints
11

Pta o

Pw

The conditional distribution P(y, d[z) over the observ­
able variables is fully specified by eight parameters,
which will be notated as follows:
da[zo)
PoLo= P( yo , dt[zo)
Pta o = P (yl, do[zo)
PlLO = P(yt,dtlzo)

qll

qzo + q22 + q3o + q32

Ptu

In this section we will explicate the relationship be­
tween the parameters of the observed distribution
P(y, d[z) and the parameters of the joint distribution
P(rd,ry) of the response functions. This will lead di­
rectly to the linear constraints needed for minimiz­
ing/maximizing ACE(D----+ Y) given the observation
P(y, d[z).

(

+ qro +

PoLo

Pou

(12)

LINEAR PROGRAMMING
FORMULATION

Poo.o= P yo,

qao + qo r

Poa.o

and
ACE(D----+ Y) = P(r11=1)- P(r11=2)

( 4) we can write the constraints

which reflect the direct linear transformation from a
point q in Q space to the corresponding point pin the
observation space P:

in the graph. The causal effect of the treat­

P(r11=1) + P(ry=3)

(14)

Applying Eqs. (3) and

ment can now be obtained directly from Eqs. (7) and
(9) according to Eq. (2), giving

P(y�[dr)
P(y; [d�)

51

mm

1 - POLl - PlO.O
1 -PoLo- Pto.t
-pot.o + Pou + Poo.r + Pu.o + Poo.o
-pou + Ptu + Poo.t + Pot.o + Poo.o
Pru + Poo.1
+
-Pro . o +

-Pto.l

P11.0

+ Poo o

P11.1 + Poo.l
Pu o

+

Poo.o

+ Pll o+
+ P 11 . 1 +

Pto.o
P10.1

52

Balke and Pearl

We may also derive bounds on the treatment responses
under the condition where treatment is uniformly ap­
plied to the population by optimizing Eqs. (10) and
(11) individually (under the same linear constraints).
The resulting bounds are:
Pta

o + PtLo- Poo

.

l

-

P111 }

PlO.l
PlO.O

max{

PoLo+ P1o.o-

Poo.1 - Pou

.

PoLo+ Pto.o + P10.1 + P11.1

1- Poo 1

min

1- Poo o

Pto.o + PtLo + Pou

P(Ytidt)

}

+ Pta. I

}
P11.1
P11.1

:::; P(y�idi):::;

.{

mm

� = ���:�

Poo.o + Pu.o + Pto 1

+ P11.1
Pla.o + Pl1.0 + PoO.l + P11.1

}

These bounds improve upon the results of
[Manski, 1990]. In addition, one can prove that these
are the tightest possible assumption-free bounds.
Examples and additional results regarding bounds on
treatment effects in partial compliance studies are pre­
sented in [Balke and Pearl, 1993].
5

APP LICATIONS TO LIABILITY
JUDGMENT

Evaluation of counterfactual probabilities could be en­
lightening in some legal cases in which a plaintiff claims
that a defendant's actions were responsible for the
plaintiff's misfortune. Improper rulings can easily be
issued without an adequate treatment of counterfactu­
als. Consider the following hypothetical and fictitious
case study, especially crafted to accentuate the dispar­
ity between different methods of analysis.
The marketer of PeptAid (antacid medication) ran­
domly mailed out product samples to 10% of the
households in the city of Stress, California. In a follow­
up study, researchers determined for each individual
whether they received the PeptAid sample, whether
they consumed PeptAid, and whether they developed
peptic ulcers in the following month.
The causal structure which describes the influences
in this scenario is identical to the partial-compliance
model given by Figure 2, where z1 asserts that
PeptAid was received from the marketer; d1 asserts
that PeptAid was consumed; and y1 asserts that pep­
tic ulceration occurred. The data showed the following
distribution:

P(z!)

=

0. 1

0.32
0.32

=

0.04

=

0.32

P(yo, dolzt)
P(yo,dtlzt)
P(yt,dolzt)
P(yt. dt l zt )

=

0. 50

P(ytjdo)

=

0.02

=

0.17

=

0. 67

=

0.14

=

0.26

In addition, the intent-to-treat analysis showed that
those individuals who received the PeptAid samples
had a 45% greater chance of developing peptic ulcers

P(ytlzo)

and
Pn.o
P11.1
-poo.o- Pot o + Poo.1 +
-PoLo-P1o.o + P10.1 +

=
=

This data indicates a high-correlation between those
individuals who consumed PeptAid and those who de­
veloped peptic ulcers in the following month

:::; P(yi id�) :::;

{

P(yo, dolzo)
P(yo, dtlzo)
P(y,,dolzo)
P(y,, dtlzo)

=

0.36

The plaintiff (Mr. Smith), having heard of the study,
litigated against both the marketing firm and the
PeptAid producer. The plaintiff's attorney argued
against the producer, claiming that the consumption
of PeptAid triggered his client's ulcer and resulting
medical expenses. Likewise, the plaintiff's attorney
argued against the marketer, claiming that his client
would not have developed an ulcer, if the marketer had
not distributed the product samples.
The defense attorney, representing both the manufac­
turer and marketer of PeptAid, though, rebutted this
argument, stating that the high correlation between
PeptAid consumption and ulcers was attributable to a
common factor, namely, pre-ulcer discomfort. Individ­
uals with gastrointestinal discomfort would be much
more likely to both use PeptAid and develop stomach
ulcers. To bolster his clients' claims, the defense at­
torney introduced expert analysis of the data showing
that, on the average, consumption of PeptAid actually
decreases an individual's chances of developing ulcers
by at least 15%.
Indeed, the application of Eqs. 16 and 17 results m
the following bounds on the average causal effect of
PeptAid consumption on peptic ulceration
-0.23 :S ACE(D- Y):::; -0.15
and proves that PeptAid is beneficial to the population
as a whole.
The plaintiff's attorney, though, stressed the distinc­
tion between the average treatment effects for the
entire population and the sub-population consisting
of those individuals who, like his client, received the
PeptAid sample, consumed it and then developed ul­
cers. Analysis of the population data indicated that
had PeptAid not been distributed, Mr. Smith would
have had at most a 7% chance of developing ulcers re­
gardless of any confounding factors such as pre-ulcer
pain. Likewise, if Mr. Smith had not consumed
PeptAid, he would have had at most a 7% chance of
developing ulcers.
The damaging statistics against the marketer are ob­
tained by evaluating the bounds on the probability
that the plaintiff would have developed a peptic ulcer

Counterfactual Probabilities

if he had not received the PeptAid sample, given that
he in fact received the sample PeptAid, consumed the
PeptAid, and developed peptic ulcers. This probabil­
ity may be written in terms of the functional model
parameters:

P(rz==l )[q13 + Q31 + Qaa]
P (yt, d1, z!)
But, since Z is a root node in the probabilistic speci­
fication, P(rz==l) == P(zt); therefore,
Ql3 + Q31 + Q33
Q13 + Q31 + Q33

=

counterfactual probabilities in Eqs. (10) and (11) on
the features of the plaintiff.
ACE(D-> Y/zt,dt,Yt) =

P(yi jd;:, Zt,dt, Yt)- P(yi jd�, Z1, dt,Y1)
Counterfactual probabilities have the property that if
the counterfactual antecedent is implied by the real­
world observation, then the probability of the coun­
terfactual consequent is the same as in the real-world
given the observations:

P(c* /a•, o)

P(yt, ddzt)

and
0.93 � ACE(D-> Y/z1,d1,yt) � 1.00
0.93 � ACE(Z- Y/zt,dt ,YI) � 1.00

{

Ptl.l

�

Poo.o

}

P11 0- POO.l - PtO.l

P11.1

Pto.o

- Po1.1 - P10.1

� P(y�/z�,zt,dt,YI)

{

1- min

Ptl.t

Pta.

�

�� �11.0

1 - Poo.o- P10.1

}

Similarly, the damaging evidence against PeptAid's
producer is obtained by evaluating the bounds on
the counterfactual probability P(yi ld�, Yt. d1, zt). In
terms of the Q parameters the counterfactual proba­
bility is written:
Qll + Q13 + Q31 + Q33
Q13

=

+

Q33

P11.1

If we minimize/maxirniee the numerator given the lin­
ear constraints, we arrive at the following bounds:

1
Ptt.t

-- max

P(c = c* /a)

Ptu

P(y,dlz):

1

=

Therefore,

This expression is linear with respect to the Q pa­
rameters; therefore, we may use linear optimization
to derive symbolic bounds on the counterfactual prob­
ability with respect to the probabilistic specification

--max

53

{

�

Pll.l- Po .o- Pn.o
Pto.o- POl.l - PtO.l

{

}

� P(yi jd�. Zt, dt, yt) �
1

-- min

Ptu

P1 1.1

Pto.o + Pu.o
1 - Poo o- Plo.t

}

Substituting the observed distribution P(y, d/z) into
these formulas, the following bounds were obtained
d1,

Yt) � o.o7
0.00 � P(y�jd�,Zt,dt,Yd �0.07

o.oo � P(y� /z0,

z1,

We can write the average causal effects for the sub­
population resembling the plaintiff by conditioning the

At least 93% of the people in the plaintiff's subpopu­
lation would not have developed ulcers had they not
been encouraged to take PeptAid (zo), or similarly,
had they not taken PeptAid ( do ) . This lends very
strong support for the plaintiff's claim that he was ad­
versely affected by the marketer and producer's actions
and product.
The judge ruled in favor of the plaintiff. PeptAid
withdrew the product from the market, and initiated
a research effort to identify observable characteris­
tics of those individuals who are adversely effected by
PeptAid.
6

CONCLUSION

This paper has developed a procedure for evaluat­
ing bounds on counterfactual probabilities. At first
thought, one may believe that assumption-free bounds
would be very weak bounds, but this paper has demon­
strated that in certain circumstances, the results of
such analysis could provide compelling evidence for
legal decisions and development of treatment policies.
The corner-stone of counterfactual analysis is the
use of functional models with response-function vari­
ables, for which the counterfactual probability may be
uniquely written. The task of determining bounds in­
volves the optimization of this expression under the
constraints imposed by the known probabilistic spec­
ification. In general, the task is reduced to the op­
timization of a polynomial function subject to linear
constraints, which introduces the problem of local min­
ima/maxima.
If the counterfactual probability is linear with respect
to the functional specification, then the bounds are
easily found via linear programming. In addition, in
some cases we may be able to derive symbolic bounds
on counterfactual probabilities in terms of the prob­
abilistic specification. Such bounds were derived in

54

Balke and Pearl

applications involving: ( 1) the determination of treat­
ment efficacy from studies where subjects do not com­
ply perfectly with treatment assi gnment, and (2) the
determination of liability in product-safety litigation.
Acknowledgements

T he research was partially supported by Air Force
grant #AFOSR 90 0136, NSF grant #IRI-9200918,
Northrop Micro grant #92-123, and Rockwell Micro
grant #92-122. Alexander Balke was supported by
the Fannie and John Hertz Foundation.

References
[Angrist et a/., 1993] J.D. Angrist, G.W. Imbens, and
D.B. Rubin. Identification of causal effects using in­
strumental variables. Technical Report No. 136, De­
partment of Economics, Harvard University, Cam­
bridge, MA, June 1993.
[Balke and Pearl, 1993] Alexander Balke and Judea
Pearl. Nonparametric bounds on causal effects from
partial compliance data. Technical Report R-199,
Cognitive Systems Laboratory, Computer Science
Department, UCLA, September 1993. Submitted to
the Journal of the American Statistical Association
(JASA).
[Balke and Pearl, 1994] Alexander Balke and Judea
Pearl. Probabilistic evaluation of counterfactual
queries. Technical Report R-213, Cognitive Systems
Laboratory, Computer Science Department, UCLA,
1994. To appear in AAAI-94.
[Bowden and Turkington, 1984] Roger J. Bowden and
Darrell A. Turkington. Instrumental Variables.
Cambridge University Press, Cambridge, MA, 1984.
[Druzdzel and Simon, 1993] Marek J. Druzdzel and
Herbert A. Simon. Causality in bayesian belief net­
works. In Proceedings of the 9th Annual Conference
on Uncertainty in Artificial Intelligence (UAI-93},
pages 3-11, 1993.
[Efron and Feldman, 1991] B. Efron and D. Feldman.
Compliance as an explanatory variable in clinical
trials. Journal of the American Statistical Associa­
tion, 86(413):9-26, March 1991.
[Holland, 1988] Paul W. Holland. Causal inference,
path analysis, and recursive structural equations
models. In C. Clagg, editor, Sociological Method­
ology, pages 449-484. American Sociological Associ­
ation, Washington, DC, 1988.
[Manski, 1990] Charles F. Manski. Nonparametric
bounds on treatment effects. American Economic
Review, Papers and Proceedings, 80:319-323, May
1990.
[Pearl and Verma, 1991] Judea Pearl and Thomas
Verma. A theory of inferred causation. In James
Allen, Richard Fikes, and Erik Sandewall, edi­
tors, Principles of Knowledge Representation and
Reasoning: Proceedings of the Second Intern a­
tional Conference, pages 441-452. Morgan Kauf­
mann Publishers, San Mateo, CA, 1991.

[Pearl, 1993a] Judea Pearl. Aspects of graphical mod­
els connected with causality. In Proceedings ofthe
49th Session of the International Statistical Insti­
tute, pages 391-401, Florence, Italy, August 1993.
Short version in Statistical Science.
[Pearl, 1993b] Judea Pearl. From Adams' condition­
als to default expressions, causal conditionals, and
counterfactuals. Technical Report R-193, UCLA
Cognitive Systems Laboratory, February 1993. To
appear in Festschrift for Ernest Adams, Cambridge
University Press, 1994.
[Pearl, 1993c] Judea Pearl. From conditional oughts
to qualitative decision theory. In David Beckerman
and Abe Mamdani, editors, Uncertainty in Artificial
Intelligence, Proceedings of the Ninth Conference,

pages 12-20. Morgan Kaufmann, 1993.
[Pearl, 1994} Judea Pearl. A probabilistic calculus of
actions. Technical Report R-212, UCLA Cognitive
Systems Laboratory, 1994. This volume (UAI-94).
[Poole, 1993] David Poole. Probabilistic Horn abduc­
tion and Bayesian networks. Artificial Intelligence,
64(1 ):81-130, 1993.
[Robins, 1989] J.M. Robins. The analysis of random­
ized and non-randomized AIDS treatment trials us­
ing a new approach to causal inference in longitudi­
nal studies. In L. Sechrest, H. Freeman, and A. Mul­
ley, editors, Health Service Research Methodology: A
Focus on AIDS, pages 113-159. NCHSR, U.S. Pub­
lic Health Service, 1989.
[Rosenbaum and Rubin, 1983] P. Rosenbaum and
D. Rubin. The central role of propensity score in
observational studies for causal effects. Biometrika,
70:41-55, 1983.
[Rubin, 1974] Donald B. Rubin. Estimating causal ef­
fects of treatments in randomized and nonrandom­
ized studies. Journal of Educational Psychology,
66(5):688-701, 1974.
[Scales, 1985] L.E. Scales. Introduction to Non-Linear
Optimization. Springer-Verlag, New York, 1985.

