
solve this problem by introducing more so­

tion.

For instance, the posterior distribution, which

is the solution to the Bayesian learning problem, is
obtained by computing the normalising integral. Sim­
ilarly, in statistical mechanics, the Gibbs distribution
is obtained by computing the partition function (the
large normalising sum). The most popular integration
methods for calculating these important target distri­
butions are the Laplace method, variational approxi­
mation and MCMC simulation.

phisticated MCMC algorithms. One of these

The Laplace method is an approximate integration

algorithms is a mixture of two MCMC ker­

method based on truncated Taylor expansions of the

nels: a random walk Metropolis kernel and a

integrand.

block Metropolis-Hastings (MH) kernel with

with a tractable function, it becomes possible to evalu­

That is, by approximating the integrand

a variational approximation as proposal dis­

ate the integral analytically. Unfortunately, in high di­

tribution. The MH kernel allows one to lo­

mensions, this will require the expensive computation

cate regions of high probability efficiently.

of many cross-derivative terms. Moreover, it will pro­

The Metropolis kernel allows us to explore

vide poor approximation results unless the integrand

the vicinity of these regions. This algorithm

is approximately log-quadratic.

outperforms variational approximations be­
cause it yields slightly better estimates of the
mean and considerably better estimates of
higher moments, such as covariances. It also
outperforms standard MCMC algorithms be­
cause it locates the regions of high proba­
bility quickly, thus speeding up convergence.
We also present an adaptive MCMC algo­
rithm that iterates between improving the
variational approximation and improving the

MCMC approximation. We demonstrate the

algorithms on the problem of Bayesian pa­
rameter estimation for logistic (sigmoid) be­
lief networks.

Variational approximation also relies on approximat­
ing the integrand. Yet, it approximates the integrand
by a lower bound that makes the integral tractable
and that results in a lower bound on the integral. The
approximation error is then minimized by maximising
the lower bound. In other words, we replace the in­
tegration problem by an easier optimization problem.
Variational methods have been shown to provide fast
and reasonable approximate estimates in many scenar­
ios (Jaakkola and Jordan 1999, Jordan, Ghahramani,

Jaakkola and Saul1999). However, variational approx�
imations often result in algorithms that yield poor es­
timates of high order moments, such a covariances and
kurtosis.

MCMC simulation is a powerful and accurate inte­

1

INTRODUCTION

gration method (Gilks, Richardson and Spiegelhalter
1996, Robert and Casella 1999). Here, one draws a set

Many problems arising in machine learning and de­

of samples from the target distribution. This distribu­

cision theory can be interpreted as high-dimensional

tion is then approximated by an empirical distribution,

integration tasks.

whose support is the set of samples and whose range

Bayesian computation would be

DE FREITAS ET AL.

UAI2001

121

is the number of times each sample appears. Hence,

tant connections with research carried out in the area

the complex integrals are replaced by simple discrete

of neural computation.

sums. The big disadvantage of these methods is that

it is often impossi ble to draw samples from the target
distribution directly.

This problem is circumvented

by drawing samples from a proposal distribution, and
then using Markov chain weighing mechanisms to en­
sure that these samples correspond to samples from
the target distribution. The main difficulty with this
approach is that the design of the proposal distribu­
tions is far from trivial. It varies with application do­
main and, if not done properly, the algorithms can take
very long to converge

(i.e.,

mix poorly).

2

VARIATIONAL METHOD

The aim of variational methods is to convert a complex
problem into a simpler, more tractable problem; see for
example (Jordan et al. 1999). The simpler problem is
generally characterized by a decoupling of the degrees
of freedom in the original problem. This decoupling is
achieved by introducing an extra set of parameters, the
so-called variational parameters. The variational pa­
rameters are then optimized so that the solution to the

To attack the problems inherent to variational and

simpler problem resembles the solution to the complex

MCMC approximation simultaneously, we introduce

problem.

a new class of MCMC algorithms that use variational

in the variational paradigm.

approximations as proposal distributions.

models with hidden variables, the likelihood

We show

that naive algorithms exploiting this property can mix
poorly, but address this problem by introducing more

Convexity bounds play an important role

of the observed data

0

xv

For example, in many

p(xv IO)

given the model parameters

cannot be easily evaluated because it requires the

sophisticated MCMC kernels based on block sampling

integration of the hidden variables xh. However, if we

and mixtures of MCMC kernels. In particular, we use

know a lower bound on the likelihood, we can max­

mixtures with variational kernels that allow the algo­

imize this bound to obtain an approximate solution.

rithm to detect the regions of high probability quickly
and Metropolis kernels that enable it to explore the
neighborhood of these regions.

Lower bounds on the likelihood can be easily obtained

using Jensen's inequality

The resulting algo­

rithm converges quickly to the regions of high proba­
bility and also yields reasonable approximations to the
entire distribution of interest. Our approach makes it
possible to combine variational and MCMC algorithms
within a rigorous probabilistic setting so as to exploit
the benefits of both approaches.

We also introduce

where

q(xh)

is an arbitrary density over the hid­

den states with respect to the Lebesgue or counting

an adaptive variational MCMC scheme, whereby the

measure.

MCMC simulation is used to improve the variational

back Leibler divergence between q and p (that is,

approximation, which in turn is used as proposal dis­
tribution.

That is, each algorithm assists the other

adaptively.

using a variational approximation for mixtures of fac­
tor analyzers as the proposal for an importance sam­
pler could lead to an improvement in the accuracy of
the results. The approach we take here is more general

and surmounts many of the problems encountered in
the importance sampling approach.
We demonstrate the approach on the task of Bayesian
parameter estimation of logistic (sigmoidal) belief net­
works with latent variables. This problem is of interest
for several reasons. F irst, it exhibits nonlinearity and
non-Gaussianity. Second, it includes the problems of
logistic regression and classification with missing ob­

servations as a sub-case. Thir d , the noise is very unin­

formative and consequently one has to be very careful
when applying model testing techniques such as cross­
validation.

-KL(qiiP))

Fourth, the model with hidden nodes is

unidentifiable. Lastly, this type of network has impor-

while the the last term is known as the
-lEq(xh) logq(xh) , of the distri­

entropy, H (q(xh) ) �
bution q.

Recently, Ghahramani and Beal (2000) showed that

The right hand side is the negative Kul l­

[

]

It is clear, therefore, that maximising the

lower bound is equivalent to minimising the Kullback
Leibler divergence.
We choose a parametric form,

ij(xhiA),

of

q(xh)

that

makes the right hand side of equation (1) easy to eval­
uate. The variational parameters

A

can then be opti­

mized to get a bound that is as tight as possible.
It may be impossible, in general, to choose a specific

ij(xhiA) that makes the evaluation
Eq(xh/A) [logp(xiO)J tractable. However, additional
flexibility can be introduced by lower bounding p(xiO)
with a well-chosen function p( x iO, e), where e denotes
functional form of
of

an additional set of variational parameters. To sum­
marize, the variational approach involves the following
two steps:

1. Introduce the variational parameters

e

to make

the conditional joint distribution of the hidden
and visible variables,

p(xiO),

tractable.

1 22

DE FREITAS ET AL.

2.

O,

UAI2001

E �""<il, where

Introduce the variational distribution q with pa­

by

rameters >. to make the conditional marginal

on which

tractable.

cardinality of

distribution

of the

visible variables,

p(x11j0),

x;

n,(i) is the number of variables

depends; that is the number of parent

nodes in the case of a belief network. In general, the

0

is n6 £.

2:; n,.(i).

We restrict the pa­

rameterization of the conditional probability distribu­
Following these steps, we can easily obtain unnor­

tions to the following Bernoulli family with a logistic

malized lower bounds on the likelihood distribu­

mapping

(iJ(x11jO,>.,�) � p(x11j0)), posterior distribution
(p(d0lx11, >.,�) � p(d0lx11)) and marginal likelihood
(j)(x11IA,�) � p(x11)). The parameters 0, �and>. can

tion

be computed by maximising the lower bound on the

marginal likelihood. This computation can be carried
out using an EM algorithm.
2.1

where rp;,t £. Xi,t (a + O�x,.(i),t), x; E { -1, IV and
a is assumed to be fixed. (Note that we only make

Logistic Belief Networks

For demonstration purposes, consider the logistic be­
lief network shown in Figure

L This network repre­

sents the factorized distribution

xl:n.

£.

{x1,x2, ... ,xn.}

could always introduce an extra node fixed to 1 and
treat a as an extra parameter.) To complete the spec­
ification of the Bayesian model, we assume a Gaussian

n.
p(xl:n.IO) = llp(x;lx,.(;),Oi),
i=l

where

the latter assumption for presentation purposes. One

prior

N(f..L0, :Eo)

0;
fLp(dO;).

on the parameters

pendence, that is p(d8)

==

and prior inde­

Note that the analysis applies to logistic BNs of arbi­

represents a stacked

trary sizes and topologies. However, this problem of­

set of nodes, x; denotes the variable associated with

ten decouples into smaller sub-problems. When deal­

node

0;

i, x,.(i)

denotes the parent nodes of node

i,

and

are some unknown parameters associated with node

i. We partition the countable set of random variables

ing with fully observed BNs, the Markov blanket of
each

0

only depends on the data (see Figure 1) and,

hence, we only need to solve several input-output logis­
tic problems. This stops being the case when we have
hidden variables. As shown in the example of Figure 1,

ifx; is unobserved, nodes O i and OJ become dependent.

Yet, typically, one can still benefit from the structure
in the network. The main difficulty arises when a node
has many parents. In this paper, we focus on solving
this problem.
The goal of the analysis will be to compute the poste­

rior distribution p(d8lx11). From this distribution, one

can easily derive other quantities of interest, such as
predictive distributions and marginal distributions.

(A)

Following the variational procedure described at the

(B)

beginning of this section, we place a tractable Gaus­
sian lower bound on the likelihood (Jaakkola and Jor­

F igure 1: (A) Instance of a fully observed belief net­

dan

2000).

This results on a Gaussian lower bound

(8

N(p, 'E)).

work. (B) Instance of a belief network with one hidden

on the posterior

node {right).

the hidden variables are decoupled and generated by a

The parameters

0

are treated as hid­

den units in the Bayesian framework. The dashed box
represents the Markov blanket for node

0;,

while the

continuous boxes are templates indicating the number
of copies of the variables inside them.

X;

E X into

?

part, x

a

visible part,

E Xh, such that

X

xt E X11, and a hidden
{ xv U Xh }. We assume

=

that we have T sets of measurements for the observed
variables·� that is

x11 £. x11•
•
l.noc"tJ ,l.T

E

(X11)n"" xT.

The

distribution of the random variable x; is parameterized

.....

Bernoulli distribution

We also assume that

(xhi>.,...., Be(>.)).

The EM equa­

tions that maximize the lower bound on the marginal

,i.. (..c�. )
likelihood , with 'I'

£. tanh(€;12)
are
4€ ;
'

]

2¢(�i,t-l)Eq(x? I .Xi) X.,.(i),tX�(i),t
x t
, - 2¢(€i,t-l)a: X,(i),t
J.L;,t= "E;,t Eq(x?I.X;)

"E�t1= 'Ei}-1

(

+

+

[( �

E�Llf-Li,t-1)

[

)

]

�:,t =a2
+ tr

>..

Dj
3

=

+

2aJ.L;,t1Eq{x?l>.i) [x,.(i),t]

( (}Ji,t

+

exp (Dj)

_

1-

1 + exp

In this case, the acceptance probability of the MH algo­

IJ.i,tiJ.�,t ) lEq(x�l>.;) [x,.(i),tX�(i),t])

(Dj)

[ XjJ.LJX7r(j) -�i ] ·

{)
a>.i !Eqcx.-cn I>.; l

known to perform poorly in high dimensions unless the

1
=

N

)

L J8(i) (dO)'
i=l

IN (f), as follows

I (f). The main disadvantage of simple Monte Carlo
methods is that often it is not possible to draw sam­
directly. This problem can, however,

be circumvented by the introduction of MCMC algo­
rithms. Assuming that we can draw samples from a
proposal distribution

rr(dO),

the key idea of MCMC

simulation is to design Markov chain mechanisms that
cause the proposed samples to migrate so that their

empirical distribution approximates p(dB).
The most popular example of this class of algorithms
is the Metropolis-Hastings

1999).

(MH )

algorithm

(Robert

A Metropolis-Hastings step of

invariant distribution, say
1r

( dB*I 0),

p (dB),

and proposal dis­

involves sampling a can­

B* given the current value 8 accord­
ing to rr (dO* I B).
The Markov chain then moves
towards 8* with acceptance probability A(O, 0*) =
1
min { I, (p(dO)rr(dO*I0)]- p(dB*)7r(dBIO*)}, otherwise
it remains at 9. It is well known that the success or
failure of the algorithm often hinges on the choice of
proposal distribution ( Gilks et al. 1996, Robert and
didate value

Casella

Mengersen and Tweedie

1996).

1999).

The most obvious and immediate way of proceeding
would be to sample new candidates according to the
variational distribution. That is,

the target distribution. Unfortunately, this is one of

3.1

denotes the delta-Dirac mass located

I N (f) is unbiased and by the strong

tribution, say

( Geweke 1989,

In particular, they work poorly when the proposal dis­

cated algorithms in the following subsections.

law of large numbers, it will almost surely converge to

and Casella

bution

To address this problem, we introduce more sophisti­

N

2_"'
f ( O ( i) ) �I (f)= { f(O)p(dO).
N�=
N�
Je
i=l

p(d8)

Both the impor­
algorithm are well

proposal distribution is very close to the target distri­

N

ples from

MH

the characteristics of the variational approximation.

grals, I (f), by discrete sums,

The estimate

(Geweke 1989).

tance sampler and independent

Consequently, one can approximate the inte­

IN (f)=

V:5(:[ }• where

in Bayesian analysis to obtain the

PN (dO)

oCil.

1,

tribution underestimates the higher order moments of

following empirical distribution

(dO)

{

{O(i); i = 1, 2, . . . , N}
p(dO) ( it could be the

draw an i.i.d. set of samples

where 68c•l

min

denotes the importance weights. This

portance sampler

2

from the target distribution

p(dOix),

w(·) £ p(·)fp(-)

=

algorithm and it is closely related to the standard im­

VARIATIONAL MCMC

posterior,

A(O, 0*)

rithm simplifies to

type of algorithm is known as the independent MH

The idea of Monte Carlo integration methods is to

in

123

DE FREITAS ET AL.

UA12001

Block MCMC

To obtain a sampler that mixes faster, we can exploit
the nature of the variational approximation and pro­
pose to update the parameters in blocks.

Each pro­

posal distribution corresponds to a Gaussian distri­
bution whose mean is a subset of the elements of the
mean of the original variational distribution and whose
covariance is the corresponding block-diagonal compo­
nent of the original covariance. The transition kernel,
at iteration

(i + 1 ) ,

for this algorithm is given by

nh

K(oCil,A)

=II KMH-j(oi:l_1+1:b,,o����l+l=b,J;Aj)

where

denotes the size of the j-th block,

bj

denotes

j=l

the

number

of

block s,

(J(i+l)
-[b;+l:bHt]

(i+ll 0ci+l)
(Hll
{Bl:bl ' h+l:b2, ... , obj-2+l:bj-1,B(i)
b;+l:b;+l, ...
9i�b-1+l:b,..) and KMH-j(-;d·) denotes the

MH algorithm in the cycle.

)

nb

�

j-th

( The Gibbs sampler
) Since this kernel

is a special case of this scheme.

allows one to v isit all sets of positive measure, while
being aperiodic,

simple convergence holds true as

the number of samples becomes large.

Obviously,

choosing the size of the blocks poses some trade-offs.
If one samples the components of a multi-dimensional

vector one at a time, the chain may take a very

long time to explore the target distribution.

This

problem gets worse as the correlation between the
components increases.

Alternatively, if one samples

all the components together, then the probability of
accepting this large move tends to be very low.
3.2

Mixtures of MCMC Kernels

A very powerful property of MCMC is that it is pos­
sible to combine several samplers into mixtures and

DE FREITAS ET AL.

124

cycles of the individual samplers (Robert and Casella
1999). This way we can have global proposals to ex­
plore large regions of the parameter space and local
proposals to discover finer details of the target distri­
bution (Andrieu and Doucet 1999, Andrieu, de Freitas
and Doucet 2000). If the transition kernels K1 and
K2 have invariant distribution p(·) each, then the cy­
cle hybrid kernel K1K2 and the mixture hybrid kernel
vK1 + (1- v)K2, for 0 :=; v :=; 1, are also transition ker­
nels with invariant distribution p(·). In this paper, we
adopt a mixture where, with probability v, we sample
(J using the variational block MCMC algorithm and,
with probability 1 - v, we carry out a random walk
Metropolis step (also in blocks). The variational pro­
posal locks into a region of high probability while the
random walk allows one to explore the space around
this region. This allows us to accomplish both rapid
mixing and reasonable exploration of the target distri­
bution.
3.3

4

in Figure 2. To illustrate this, we generated data 4
times using the same model with the parameter set
to 1. Each realization of the data gave us a different
likelihood (and posterior). Hence, if we were to have
a model that represents the posterior well, it is not
guaranteed to predict well. The noise model is too un­
informative and, therefore, poorly suited to predictive
testing techniques such as cross-validation. The prob­
lem is exacerbated as the dimension of the parameter
space increases. We also performed experiments on
multimodal distributions that show the performance
of the algorithm not only in terms of approximating
the mean, but in terms of approximating more com­
plex aspects of the posterior distribution.
0.08

0.08

0.08

0.06

0.04

0.04

O.O<l

0.02

Adaptive Variational MCMC

The goal of adaptation is to update the proposal
distribution based on the behaviour of the Markov
chain. That is, we start an MCMC simulation with
an initial variational approximation, and then use the
MCMC samples to update the variational approxima­
tion. This results on a better variational approxima­
tion and faster mixing. However, one should not al­
low adaptation to take place infinitely often as this
can disturb the stationary distribution and the consis­
tency results. This problem arises because by using
the past information infinitely often, we violate the
Markov property of the transition kernel. That is,
Pr(O(i)IO(oJ,o(ll, ... ,oCi-1)) does no longer simplify
to Pr(O(i) [O(i-1}). We can avoid this problem by per­
forming adaptation only when the chain visits a par­
ticular atomic set. At this atomic set, the chain regen­
erates and, hence, the next tour becomes independent
of the past tour. We adopt an algorithm based on this
principle which was proposed by Gilks, Roberts and
Sahu (1998).
SIMULATIONS

We performed experiments on fully and partially ob­
served logistic BNs. When all the nodes are observed,
the posterior is unimodal. This allows us to compare
the algorithms in high dimensions by evaluating the
distance between their estimates of the mean and the
optimal mean. The likelihood, using a flat prior so
that it is close to the posterior, will be higher for es­
timates close to the optimal posterior mean. We used
this performance test because the optimal mean can
be very different from the generating mean as shown

UAI 2001

0.6

0.8

...

0

O.OB

0.08

0.08

0.08

0.0<1

0.04

0.02

0.02

0

0.8

0.8

1.4

0.6

0.8

0.8

0.8

1.4

1.2

1.4

Figure 2: Likelihood of the data {1000 observations)
when generated by a Bernoulli logistic node with a sin­
gle parameter set to 1. Clearly, 1000 observations are
not enough to recover the true value of the parameter.
We are dealing with a very uninformative noise model.

4.1

Unimodal Models

We used logistic models consisting of one child and a
varying number of parents, ranging from 1 to 50. We
generated sets of 1000 data samples from these mod­
els. We computed posterior approximations using the
variational EM algorithm, the block M-H sampler with
the variational proposal distribution (VarMCMC), the
random walk Metropolis (RW), and the MCMC mix­
ture with a variational kernel and a Metropolis ker­
nel (VarMixMCMC). We repeated this experiment 10
times to obtain estimates of the performance in terms
of means and error bars. We set the random walk vari­
ance to 0.01, the bias parameter to 0.5, the Bernoulli
mean to 0.5 and the generating parameters to uni­
formly random values on (0, 1]. We chose a fairly flat
prior N(O, 1001). The results for 500 and 5000 samples

1 25

DE FREITAS ET AL.

UAI 2001

forms the VarMCMC algorithm, which in turn outper­
forms the standard variational algorithm. The perfor­
mance of the RW depends on the initialization and
data set realization. That is, it might or might not
perform well depending on whether it is initialized in
regions of high probability or not. Of course, as the
number of samples goes to infinity, the RW algorithm
will approximate the mean according to the central
limit theorem. Yet, in practical scenarios we often
need reliable and faster options. The computational
time for the EM and MCMC algorithms is shown in
Table 1.

are shown in Figures 3 and 4 respectively.
OOOO rr____
_ V,.
_, a
-rl
,-;;
o tion-a
.,
1 -m o
o -o --,
- ' VarMCMC mean
- .. VlilrMixMCMC mean

·

7000

3000

Dimension
----'___..
2 0 oooL---,
....
o-- 20-30___."":------<---:: -. ----oo-'

Dimension of e

Figure 3: This figure shows the relative log-likelihood
of the three variational methods with respect to the
log-likelihood of the random walk metropolis (500 sam­
ples). Since all the curves are positive, the three meth­
ods outperform the metropolis algorithm. In addition,
the MCMC mixture with variational and Metropolis
kernels provides better estimates of the mean for dif­
ferent numbers of parents.
'

..
...�
1 '. .
""
'·
1

- VarlaUonal mean

'-·VarMCMCm••n

- .. VarMixMCMC m.an

,,
,

,

'

,

,
,

,·
.

I
_i

",
...

"'"

""

...

-,
·,_

.,.

1
5

10
20
50

500 samples
EM
MCMC
0.01
1.00
9.73
0.43
31.25
3.18
52.16
204.54
477.34 1351.90

5000 samples
EM
MCMC
0.01
10.03
0.40
97.49
313.17
3.36
23.49
1237.87
478.59 13081.37

Table 1: Computational time in Mega-flops for the EM
(Variational) and MCMC algorithms.
In this experiment, we have discussed the performance
of the methods only in terms of approximating the
mean of the posterior. However, we often want to com­
pute other characteristics of the distribution. In the
following section, we show that the VarMixMCMC al­
gorithm is well suited to this more difficult problem.

......

'·

......

'

4.2

'
'

,_

'

,_
,_
,_

't

'
-,
-,_

-2 00

-0oL-----::,�o---2=o---=30--�<0-:-�-:--�oo­
Dimension of 9

Figure 4: The MCMC mixture with variational and
Metropolis kernels provides better estimates of the
mean for 5000 samples. Note that although the per­
formance of the Metropolis algorithm has improved
it does not perform better than VarMixMCMC. Re­
call that VarMixMCMC has a random walk compo­
nent and hence, at worst, will perform similarly to the
standard Metropolis.
It is clear that the VarMixMCMC algorithm outper-

Multimodal Models

In this experiment, we considered a network with two
parents (one hidden and one observed). The posterior
for (} is, therefore, bivariate and can have two modes.
(Note that the two modes appear because of unidenti­
fiability. Either of these modes provides a statistically
valid solution.) For demonstration, we set the gener­
ating parameters for the hidden and observed nodes
to 2 and -1 and the respective Bernoulli means of the
hidden variables to 0.6 and 0.5. We set the bias pa­
rameter to 2, the number of data 50 and the prior to
N(3, 10!). The posterior in this case can be evaluated
numerically on a two-dimensional grid. We show its
contour curves in Figure 5. This figure also shows the
contour plot of the RW MCMC histogram after 5000
iterations and the variational approximation. We no­
tice that the variational approximation fits closely to
one of the modes. We also notice that if the random
walk starts in a region of low probability, it can take
long to locate one of the modes. Its performance will,
therefore, be poor when dealing with posteriors with
elongated contours. Figure 6 illustrates the point that
the naive variational MCMC algorithm locates one of

DE FREITAS ET AL.

126

Fig ure 5:

Approximation with the random walk

Metropolis algorithm after 5000 iterations for a bivari­

UA12001

Figure 7: Approximation with the mixture MCMC

algorithm after 5000 iterations for a bivariate model.

ate model. The contour plot of the 2D histogram of

The variational component allows us to locate a region

can spend a considerable time in regions of low prob­

explore the neighborhood of this region.

the MCMC samples, indicates that the random walk
ability.

of high probability and the random walk allows us to

end up with a variational approximation that does
not underestimate the variance.

Note, however, this

method is appropriate only for problems with lim-

0.06.------,
0.06
0.04
0.02

oL---&�we�
���
1.4
O.B

0.8

1

1.2

1 00 iterations

oL-�•
0.6

0.8

1

1.2

500 iterations

1.4

0
e,

Figure 6: Approximation with the variational MCMC

algorithm after 5000 iterations for a bivariate model.

The variational approximation allows us to locate a

region of high

the modes but fails to explore the support of the pos­

terior. The mixture MCMC algorithm, shown in Fig­
ure

7 solves this problem and provides the best solution

out of all the methods.
4.3

1.4

probability.

Adaptive MCMC Experiment

We tested our adaptive MCMC sampler through re­
generation on the unimodal scenario. We found, as

shown in Figure 8, that the algorithm works well; we

Figure 8: Adaptive MCMC. The variational approx­
imation

[-·] underestimates the variance of
[--J. It also exhibits a slightly

posterior

mean.

the true
different

Using the samples generated by the Markov

chain we update the variational proposal. After only
100 iterations, the new variational approximation (-]

already provides a better estimate of the mean. Even­

tually, the variational approximation becomes much

closer to the target distribution and the MCMC algo­
rithm converges well.

UAI2001

DE FREITAS ET AL.

127

ited fan-in-we found that the acceptance rate decays

Lastly, a more detailed technical report is available at

rapidly to zero beyond a fan-in of seven.

http:/ jwww.cs. berkeley.edu/ ,.._.jfgfjpublications.html.

5

CONCLUSIONS AND FURTHER
WORK

combine variational and MCMC methods. Variational
methods allow us to map the problem under consider­
ation to a subset of simpler problems. By solving these
subproblems we obtain suboptimal distributions, that
can in turn be used as proposals for more complex sam­

pling schemes. We pointed out that naive algorithms

based on this principle can perform poorly because

the variational approximation tends to underestimate
the variance of the posterior distribution. We there­
fore proposed more sophisticated MCMC algorithms
that are clearly able to benefit from the variational ap­
proximation and outperform standard Metropolis al­
gorithms.

Jaakkola and Kevin Murphy.

References
Andrieu, C. and Doucet, A. (1999). Joint Bayesian detec­
tion and estimation of noisy sinusoids via reversible
jump MCMC, IEEE Transactions on Signal Process­
ing 47(10): 2667-2676.

Andrieu, C., de Freitas, J. F. G. and Doucet, A. (2000). Ro­
bust full Bayesian learning for radial basis networks,
to appear in Neural Computation.
Geweke, J. (1989).
Bayesian inference in econometric
models using Monte Carlo integration, Econometrica
24: 1317-1399.
Ghahramani, Z. and Beal, M. J. (2000).

In the multimodal scenario we focused on the problem
of approximating only one of the modes.

For many

models, multimodality arises as the result of label per­
mutation (unidentifiability) and hence any mode is a
correct statistical solution. This is the case of mixture
models. We do recognize that in more complex situa­
tions, where there are more sources of multimodality,
we will need to extend our algorithms.

One simple

strategy is to compute several variational approxima­
tions using different initial conditions. These approxi­
mations can then be used either in parallel or in a mul­
tiple MCMC mixture to visit several modes quickly.
The tempering method described in (Neal

1996)

will

also serve the purpose of jumping modes.
We feel that it is essential to carry out more research in
the direction of adaptive MCMC. Ultimately we would
like to represent high dimensional distributions with
a mixture of adapted (better) variational approxima­
In very large dimensional mixtures for docu­

ment retrieval, one may require up to

We would like to thank Christophe Andrieu, Mathew
Beal, Arnaud Doucet, Zoubin Ghahramani, Tommi

This paper demonstrates that it is advantageous to

tions.

Acknow Iedgements

100

megabytes

to store a single sample (Hofmann and Puzicha

1998).

The storage requirements would decrease considerably
if we were able to only store the sufficient statistics.
Needless to say, better proposal distri bu tions

will also

lead to faster convergence and improved results.

There are a few more interesting research directions.
First, we need to consider algorithms that exploit both
lower and upper variational bounds. These, we believe,
will allow us to locate modes and jump between them
efficiently. Second, we only need to use the variational
approximation to approximate one of the marginals.
It is, therefore, possible to apply this idea when im­
plementin g complex hierarchical Bayesian schemes.

Variational in­

ference for Bayesian mixtures of factor analysers, in
S. Solla, T. Leen and K.-R. Muller (eds), Advances
in Neural Informatio n Processing Systems 12, MIT
Press, pp. 449-455.

Gilks, W. R., Richardson, S. and Spiegelhalter, D. J. (eds)
(1 996). Markov Chain Monte Carlo in Practice, Chap­
man and Hall, Suffolk.
Gilks, W. R., Roberts, G. 0. and Sahu, S. K. (1998).
Adaptive Markov chain Monte Carlo through regener­
ation, Journal of the American Statistical Association

93: 763-769.

Hofmann, T. and Puzicha, J. (1998). Unsupervised learn­
ing from dyadic data, Technical Report TR-98-042,
International Computer Science Institute.
Jaakkola, T. and Jordan, M. I. (1999). Variational meth­
ods and the QMR-DT database, Journal of Artificial
Intelligence 10: 291-322.
Jaakkola, T. and Jordan, M. I. (2000). Bayesian parame­
ter estimation via variational methods, Statistics and
Computing 10: 25-37.
Jordan, M. I., Ghahramani, Z., Jaakkola, T. S. and Saul,
L. K. (1999). An introduction to variational methods
for graphical models, Machine Learning 37: 183-233.
Mengersen, K. L. and Tweedie, R. L. (1996). Rates of con­
vergence of the Hastings and Metropolis algorithms,
The Annals of Statistics 24: 101-121.

Neal, R. M. (1996). Sampling from multimodal distribu­
tions using tempered transitions, Statistics and Com­
puting 6: 353-366.
Robert, C. P. and Casella, G. (1999). Monte Carlo Statis­
tical Methods, Springer-Verlag, New York.

