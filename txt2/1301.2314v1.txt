tions yielded, to identify the parameters that upon
variation are expected to have a large effect on
a probability of interest. We further propose to
build upon the concept of

admissible deviation,

which captures the extent to which a parameter
can be varied without inducing a change in the
most likely outcome.

We illustrate these con­

cepts by means of a sensitivity analysis of a real­
life probabilistic network in the field of oncology.

ations from the original assessment for every single param­
thousands of propagations.

Recently, however, efficient

algorithms for sensitivity analysis have become available,
rendering analysis of real-life probabilistic networks feasi­
ble [2, 3]. These algorithms build upon the observation that
the sensitivity of a probability of interest to parameter vari­
ation complies with a simple mathematical function; this

sensitivity function

basically expresses the probability of

interest in terms of the parameter under study. Computing
the constants for these sensitivity functions requires just a
limited number of propagations.
Sensitivity analysis of a real-life probabilistic network
tends to result in a huge amount of data. For example, for a
real-life network in the field of oncology, comprising some
lOOO parameters, we found that a single analysis yielded
close to 5000 sensitivity functions with two or three con­
stants each. Because the sensitivities exhibited by a prob­

1

abilistic network typically change with evidence, such

Introduction

The numerical parameters for a probabilistic network are
generally estimated from statistical data or assessed by hu­
man experts in the domain of application. As a result of
incompleteness of data and partial knowledge of the do­
main, the assessments obtained inevitably are inaccurate.
Since the outcome of a probabilistic network is built upon
these assessments, it may be sensitive to the inaccuracies
involved and, as a result, may even be unreliable.
The reliability of the outcome of a probabilistic network
can be evaluated by subjecting the network to a

analysis.

an

analysis has to be performed a number of times. For our

sensitivity

In general, sensitivity analysis of a mathematical

model amounts to investigating the effects of inaccuracies
in the model's parameters by systematically varying the
values of these parameters [1]. For a probabilistic network,
sensitivity analysis amounts to varying the assessments for
one or more of its numerical parameters and investigating
the effects on, for example, a probability of interest [2].

network, for example, we conducted over 150 analyses in­
volving data from real patients. For extracting relevant in­
formation from the data thus generated, effective methods
are called for that allow for (automatically) identifying pa­
rameters that are quite influential upon variation.

These

parameters should be selected for further investigation as

the inaccuracies in their assessments are likely to affect the
network's outcome.
In her work on sensitivity analysis of probabilistic net­
works, K. Blackmond Laskey introduced the concept of

sensitivity value [4]. The concept builds upon the (par­
derivative of the sensitivity function that expresses the

tial)

network's probability of interest in terms of a parameter

under study: the sensitivity value is the absolute value of
this derivative at the original assessment for the parame­
ter. As currently available algorithms for sensitivity anal­
ysis of probabilistic networks yield the probability of in-

UAI 2001

VAN DER GAAG & RENOOIJ

terest explicitly as a fimction of the parameter under study,
the derivative and its associated sensitivity value are read­
ily determined. In this paper, we study the derivatives of
sensitivity functions and show how sensitivity values can
be used for selecting parameters for further investigation.
In many real-life applications of probabilistic networks, the
outcome of interest is not a probability, but rather the most
likely value of a variable of interest. In a medical applica­
tion, for example, the outcome of interest may be the most
likely diagnosis given a patient's symptoms and signs. For
this type of outcome, the derivative of a sensitivity fimction
and its associated sensitivity value are no longer appropri­
ate for establishing the effect of parameter variation: a pa­
rameter with a large sensitivity value may upon variation
not induce a change in the most likely outcome, while a
parameter with a small sensitivity value may induce such a
change for just a small deviation from its original assess­
ment. To describe the sensitivities of this type of outcome,
we introduce the concept of admissible deviation. This
concept captures the extent to which a parameter can be
varied without inducing a change in the most likely value
for the variable of interest. We show how the concept of
admissible deviation can be used for selecting parameters.
The various concepts introduced in this paper will be illus­
trated by means of a sensitivity analysis of a moderately­
sized real-life probabilistic network in the field of oncol­
ogy. We would like to note that this network exhibits con­
siderable sensitivity to parameter variation. This observa­
tion contradicts earlier suggestions that probabilistic net­
works are highly insensitive to inaccuracies in the assess­
ments for their parameters I 5, 6]. Our results now seem
to indicate that the sensitivities exhibited by probabilistic
networks may vary from application to application.
The paper is organised as follows. In Section 2, we provide
some preliminaries on sensitivity analysis of probabilistic
networks. In Section 3, we briefly discuss the oesophagus
network with which we will illustrate the concepts intro­
duced in the subsequent sections. In Section 4, we study
the derivative of a sensitivity function and its associated
sensitivity value. In Section 5, we introduce the concept
of admissible deviation and discuss its use for extracting
relevant information from sensitivity data. The paper ends
with our conclusions and directions for further research in
Section 6.
2

Preliminaries

Sensitivity analysis of a probabilistic network amounts to
establishing, for each of the network's numerical parame­
ters, the sensitivityfunction that expresses the probability of
interest in terms of the parameter under study. In the sequel,
we denote the probability of interest by Pr( A a I e ) , or
Pr(a I e) for short, where a is a specific value of the vari­
able A of interest and e denotes the available evidence. The
=

531

network's parameters are denoted by x = p(bi I 1r), where
bi is a value of a variable B and 1r is a combination of val­
ues for the parents of B. We write !Pr(ale)(x) to denote the
sensitivity function that expresses the probability Pr(a I e )
in terms of the parameter x; for ease of exposition, we will

often omit or abbreviate the subscript for the fimction sym­
bol f, as long as ambiguity cannot occur.

Upon varying a single parameter x p(bi I 1r) in a prob­
abilistic network, the other parameters p(bi I 1r), j =f:. i,
specified for the variable B need to be co-varied. Each pa­
rameter p(bi I 1r) can thus be seen as a function gj(x) of
the parameter x under study. In the sequel, we assume that
the parameters p(bj I 1r) are co-varied in such a way that
their mutual proportional relationship is kept constant, that
is, a parameter p(bi I 1r ) is co-varied according to
=

if j

=

i

otherwise
for p(bi I 1r) < 1.
Under the assumption of co-variation described above, a
sensitivity function f(x) is a quotient of two functions that
are linear in the parameter x under study [2, 7]; more for­
mally, the function takes the form

f(x)

x+ b
c·x+ d

=a ·

where the constants a, b, c, and d are built from the assess­
ments for the numerical parameters that are not being var­
ied. From this property we have that a sensitivity function
is characterised by at most three constants. These constants
can be feasibly determined from the network, for example
by computing the probability of interest for a small num­
ber of values for the parameter under study and solving the
resulting system of equations [2]. An even more efficient
algorithm that is closely related to junction-tree propaga­
tion, is available from [3].
3

The oesophagus network

The oesophagus network that will be used to illustrate con­
cepts throughout this paper, is a real-life probabilistic net­
work for the staging of oesophageal cancer. The network
was constructed and refined with the help of two experts
in gastrointestinal oncology from the Netherlands Cancer
Institute, Antoni van Leeuwenhoekhuis, and is destined for
use in clinical practice [8].
As a consequence of a lesion of the oesophageal wall, a
tumour may develop in a patient's oesophagus. The char­
acteristics of the tumour, such as its location in the oe­
sophagus and its macroscopic shape, influence the tumour's
prospective growth. The tu±nour typically invades the oe­
sophageal wall and upon further growth may affect neigh-

VAN DER GMG & RENOOIJ

532

UAI 2001

\..Gutro-eirrami

�--��--.��F��

""""""""'

-:'

I
...
.
--

CT.­

': "

Figure 1: The oesophagus network.
bouring organs. In time, the tumour may give rise to lym­
phatic and haematogenous metastases. The characteristics,
depth of invasion, and extent of metastasis of the cancer
largely influence a patient's life expectancy and are indica­
tive of the effects and complications to be expected from
the various therapeutic alternatives. The three factors are
summarised in the stage of the cancer, which can be ei­
ther I, IIA, liB, III, IVA or !VB, in the order of progressive
disease. To establish the stage of a patient's cancer, typi­
cally a number of diagnostic tests are performed, ranging
from biopsies of the primary tumour to gastroscopic and
endosonographic examinations of the oesophagus.
The oesophagus network is depicted in Figure 1. It cur­
rently includes4 2 variables. The number of values per vari­
able ranges between two and six, with an average of 3.4.
The number of incoming arcs per variable ranges between
zero and three with an average of 1.7; the average number
of outgoing arcs is 2.5, with a minimum of zero and a maxi­
mum of 11. For the network, a total of932 probabilities are
specified. The variable with the largest number of proba­
bilities, 144 , models the stage of the cancer; this variable is
deterministic. The largest number of probabilities specified
for a non-deterministic variable is 80.
Building upon the concepts outlined in Section 2, we per­
formed a sensitivity analysis of the oesophagus network.
We took the probability of a specific stage for the proba­
bility of interest. As six different stages are defined, we
performed six separate analyses, each time focusing on an-

other stage. Of the prior network, that is, the network with­
out any evidence entered, we found 206 of the 932 param­
eters to be influential upon variation. For these parameters,
the analyses yielded a total of 1236 sensitivity functions
with two or three constants each. Because a network's
sensitivities typically change with evidence, we repeated
the analysis with data entered from 156 patients diagnosed
with oesophageal cancer. The number of data entered per
patient ranged between 6 and 21, with an average of 14 .8.
The parameters that we found to be influential upon vari­
ation differed between patients. The number of influential
parameters also differed considerably and was found to be
as high as 826.
4

The derivative and its sensitivity value

For extracting relevant information from the huge amount
of sensitivity data that is typically generated from a proba­
bilistic network, effective methods are needed. In this sec­
tion, we discuss a method for this purpose that is based
on the derivative of a sensitivity function and its associated
sensitivity value. This method provides for selecting pa­
rameters that upon variation have a large effect on a proba­
bility of interest. In the next section, we introduce another
method, based on the concept of admissible deviation, that
focuses on the most likely value of a variable of interest.
In Section 2, we argued that the sensitivity of a probability
of interest to variation of a parameter x can be expressed as

VAN DER GMG & RENOOIJ

UAI 2001

a function f ( x) of the form
f(x)

effect may break down rapidly, as noted before by Laskey
[4]. For some parameters, it may be that the sensitivity val­

a· x + b
=
c·x+d

ues for slightly smaller assessments are very large and the
sensitivity values for slightly larger assessments are quite

The first derivative r ( X) of this function is

especially the sensitivity values become quite large. Find­

The probability of interest is sensitive to deviations from
the original assessment x0 of the parameter under study, if

lf'(xo)l

is greater than zero.

As an example, Figure 2 depicts a sensitivity function that
we found for the oesophagus network. The function shows

p(Sono-cervix = yes I
probability Pr(Stage = III I

the effect of varying the parameter
=

no) on the

specific patient. The assessment for the pa­
=

0.07. For this assessment, we
find a sensitivity value of 0.53, which indicates that devia­
rameter under study is x0

tions from the original assessment would not greatly affect
the probability of interest. If the assessment would have
been 0.02 rather than 0.07, however, a much larger sensitiv­
ity value, of

4.74, would have been found, which indicates

that even minor deviations would have had a considerable
effect. For the value
value of just

0.07

ample, this property holds: the sensitivity value of the orig­

ing a relatively small sensitivity value for a parameter's as­

·

Metas-cervix
case 6) for a

small. For the parameter under study in Figure 2, for ex­
inal assessment is rather small, but for smaller assessments

a·d-b·c
f'(x) =
(c x + d)2

the sensitivity value

533

0.20,

on the other hand, a sensitivity

is found. If the assessment for the pa­

rameter would have been 0.20, therefore, deviations would
have had hardly any effect on the probability of interest.
Based upon the concept of sensitivity value, we might con­
clude that the parameters for whose assessments the sensi­
tivity values are the largest, are the most likely to be quite
influential upon variation and therefore should be selected
for further investigation. Sensitivity values, however, pro­
vide insight in the effect of small deviations only from a
parameter's assessment. When larger deviations are con­
sidered, the quality of the value

as

an approximation of the

sessment is therefore no guarantee that the probability of
interest is hardly affected by variation of this parameter.
From our discussion of the sensitivity function shown in
Figure 2, we have that the quality of a sensitivity value
for indicating the effect of parameter variation decreases
as the parameter's original assessment lies closer to the x­
coordinate of the function's

Therefore, to de­

"shoulder".

cide whether or not the probability of interest is likely to
be affected by inaccuracies in the assessment for a specific
parameter, we should consider not just the associated sen­
sitivity value but also the distance of the assessment to the
x-coordinate of the shoulder of the sensitivity function. We
define the concept of shoulder more formally.
A sensitivity function is either a linear function or a hyper­
bola. For

c = 0,

for example, the sensitivity function is

linear, as we then have that

f(x) =a·x + b = a·x + b
c·x+d

d

=

�.
d

x

+

�
d

If the sensitivity function is not linear, it takes the form of
a hyperbola:
f(x)

1"

x

=-

-s

+ t,

with

c2

1" = --:::­

s =

d
--,
c

and t

=

a
-

c

For ease of reference, Figure 3 depicts the general shape of
a hyperbola. The hyperbola has two asymptotes, parallel
to the x- andy-axes, in x
�
"'

.."

=

sand f(x)

= t, respectively.

The hyperbola further is symmetrical in the line that has

0.8

an absolute gradient of 1 and goes through the intersection

d
<>

point (s, t) of the hyperbola's asymptotes. The point

§" 0.6
II

is termed the

.."'
§.d 0.4

center

(s, t)

of the hyperbola. The point at which

the hyperbola intersects with the line in which it is symmet­
rical, is called the vertex of the hyperbola; this vertex is the

0::

point referred to before as the function's shoulder. As the

0.2

symmetry line has a gradient with an absolute value of

1,

the gradient of the hyperbola at the vertex also has an abso­
OL_�___L______L-----�------�----�
0
0.2
0.4
0.6
0.8
xo

p(Sono-�eTuiz = yes!Meta.:'I-CeTvix =no)

Figure

2:

Pr(Stage = III I case 6) in terms of the pa­
= p(Sono-cervix =yes I Metas-cervix = no).

probability
rameter x

The sensitivity function J(x) expressing the

lute value ofl. Using this property we can easily determine
the x-coordinate x of the vertex:

'
lf (x)l

=

I (x =rs)2 1

=

1 ¢::::::> x = s ±

vfrT

We now return to a sensitivity function f(x) expressing a

534

VAN DER GAAG & RENOOIJ

j(x)

,,

,,

,'/
t

--

�

,

,
-'

)

_

,,

,

,
,,

UAI 2001

tivity value can be used for selecting parameters that upon

,

variation have a large effect on a specific probability of in­
terest. Often, however, we are interested not in the effect of
parameter variation on a probability of interest, but in the
effect on the most likely value for a variable of interest. In
a medical application, for example, the most likely diagno­

vertex

sis given a patient's symptoms and signs may be the out­
come of interest. For this type of outcome, the derivative

45°

________________________________ _

center

of a sensitivity function and its associated sensitivity value
are no longer appropriate for establishing a parameter's ef­
fect upon variation. For some parameters, deviation from
their original assessment may have a considerable effect on

X

s

the probability of a specific outcome and yet not induce a
Figure3: Ahyperbolaf(x).

change in the most likely one; for other parameters, varia­

network's probability of interest in terms of a parameter x

nonetheless result in a change in the most likely outcome.

under study. As noted above, if this function is not linear, it

We would like to note that the idea of focusing on the most

takes the form of a hyperbola. The center of the hyperbola

likely value of a specific variable conforms to the practice

tion may have little effect on the probabilities involved and

is

(- �, �).

Because a sensitivity function is defined on

of sensitivity analysis of decision-theoretic models where

[9].

the entire probability interval [0, 1] and moreover is non­

the most preferred decision is the outcome of interest

negative, we have that -4
< 0 and .!!.
> 0. For the xc
c -

To provide for studying the effects of parameter variation

coordinate x of the vertex of the hyperbola, we find

,

x=

in view of a most likely outcome, we enhance the basic
method of sensitivity analysis for probabilistic networks

-d
± Jia d-b · c l
-___!_...!..._
...:

with the computation of an interval within which a param­

·

-

___

c

eter can be varied without inducing a change in the most

For the sensitivity function shown in Figure 2, for example,

the x-coordinate of the vertex of the hyperbola is x
We observe that the original assessment x0

=

=

0.05.

0.07 for the

likely value of a variable of interest. Now, let A be the

variable of interest. Let x be the parameter under study and
let xo be its assessment. The admissible

( r, s)

parameter under study lies quite close to this coordinate.

is a pair of real numbers

We recall that the sensitivity value for x0 is just 0.53. Be­

between the bounds max(xo

cause the assessment lies close to x, however, the sensitiv­
ity value cannot be considered a good approximation of the

effect of the parameter's variation: small deviations from
the assessment, especially to smaller values, have a con­
siderable effect on the probability of interest. We conclude
that this parameter should be selected for further investiga­

deviation

for x0

such that x0 can be varied

- r,

0) and min ( xo +

s,

1)

without inducing a change in the most likely value for the

variable A;

r

and s, moreover, are the largest numbers for

which this property holds. Note that the interval within
which a parameter can be freely varied can be bounded
for two reasons: either the most likely outcome changes

if the parameter is varied beyond the specified boundary,

tion, regardless of its small sensitivity value.
From the above observations, we have that for extracting

from the sensitivity data the parameters that deserve fur­
ther attention, parameters whose assessment has a sensi­
tivity value larger than 1 should be identified. In addition,
parameters whose original assessment lies close to the

x­

coordinate of the vertex of the associated sensitivity func­
tion should be selected.
To conclude our discussion of sensitivity values, we would
like to note that in the analysis of the oesophagus network
we found rather strong sensitivities. An example is shown

0.2

in Figure 4: for the parameter under study, a sensitivity
value of6.97 was found.

5

Admissible deviation

In the previous section, we focused on the derivative of a
sensitivity function and showed how its associated sensi-

Q UL------�

0.02

Figure

p(X-lung�

=

1/MIMetas-lungs

T he sensitivity function

4:

f(x)

=

110)

expressing the

Pr(Stage = IVB I case 1) in terms of the pa­
p(X-lungs yes I Metas-lungs = no).
rameter x
probability

=

=

VAN DER GAAG & RENOOIJ

UAI2001

or the boundary of the probability interval

[0, 1]

has been

535

Metas-lungs = no)

on the probabilities of the various

reached. To express that a parameter can be varied as far as

different values of the variable

the boundary of the probability interval, we use the symbol

tient. From the figure, it is readily seen that the param­

oo

eter's assessment has associated a small sensitivity value

in the admissible deviation associated with its assess­

Stage

for a specific pa­

ment.

from each of the sensitivity functions. The sensitivity func­

The admissible deviation for a parameter's assessment can

tion f1v8(x), for example, that expresses the probability
Pr(Stage = IVB I case 138) in terms of the parameter

be computed from the sensitivity functions
are yielded for the various values

a,

!Pr(a;le)

that

of the variable A.

under study, is

f

More specifically, the admissible deviation is established

xo
ai is the most likely value for

(

!VB X

by studying the points at which two or more of these func­

)

tions intersect. Suppose that for the original assessment

of the parameter x, the value

lf:vs(0.05)I = 0.71145

tion, that neither of the bounds of the admissible deviation

(r, s) ,

oo.

The admissible deviation for x0 now is the pair

where the leftmost deviation

number for which x0

-r

r

is the smallest real

is the x-coordinate of a point at

!Pr(a;le)(x) intersects with
fPr(a11e)(x) with j "1- i; the

which the sensitivity function
another sensitivity function
rightmost deviation

s

We further observe that the assessment

x0

=

0.05 for the

parameter lies relatively far from the x-coordinate i; of the
function's vertex:

i;

is defined analogously.

=

-1.17403+yi0.09208·l.l7403-1 '17403·11
1

-0.14

We present various examples to illustrate the difference be­
tween using sensitivity values and admissible deviations for

0.09208 ·X + 1.17403
X+ 1.17403

from which we find a sensitivity value of

the variable of interest. Also suppose, for ease of exposi­
equals

_

-

Based on the concept of sensitivity value as discussed in the

studying the effects of parameter variation. The examples

previous section, we conclude that the parameter does not

are taken from patient-specific analyses of the oesophagus

deserve additional attention. Inspection of Figure 5 now

network. The figures used display the sensitivity functions

further reveals that the admissible deviation for the param­

yielded for all the values of the variable

eter's assessment equals

Stage

that models

the stage of a patient's cancer. As we are now considering

( oo, oo) ,

which indicates that the

parameter can be varied over the entire probability interval

a variable of interest rather than a probability of interest,

[0, 1]

using the concept of sensitivity value for selecting interest­

Based on the concept of admissible deviation, therefore,

ing parameters amounts to examining the sensitivity values

the parameter should also be further disregarded.

from all functions for the parameter under study.

without inducing a change in the most likely stage.

For our next example, we consider a parameter that induces

Our first example addresses a parameter that induces small

large sensitivity values, but upon variation is not expected

sensitivity values and upon variation does not result in a

to result in a change in the most likely outcome. The sensi­

change in the most likely outcome. The sensitivity func­

tivity functions for the parameter are depicted in Figure

tions for the parameter are depicted in Figure 5: the fig­

the figure shows the effects of varying

ure shows the effects of varying

x = p( CT-lungs = yes I

yes I Metas-loco = no)

x

=

p( CT-loco

6:
=

on the probabilities of the dif-

0.6 ,-------,
IIA
"'
""
•
.,

�

8

"'
�

0.4

•

�
Q:

0.05

p(CT-Iung• = ye•IMetas-lungs =no)

5: The sensitivity functions expressing the prob­
Pr(Stage I case 138) in terms of the parameter
p(CT-lungs =yes I Metas-lungs =no).
Figure

abilities

p(CT-Ioco

=

li""IMetas-loco =no)

6: The sensitivity functions expressing the prob­
Pr(Stage I case 82) in terms of the parameter
p(CT-loco =yes I Metas-loco =no).
Figure

abilities

536

VAN DER GMG & RENOOIJ

Stage. For the parameter's
0.02, large sensitivity values

ferent values of the variable

original assessment x 0

=

are found from some of the six functions.

UAI 2001

computed to be

(0.10, oo).

As the leftmost deviation is

quite small compared to the assessment

0.20,

we find that

For example,

the parameter deserves further investigation. We would like

from the sensitivity function that expresses the probability

to note that, if the original assessment had been in the inter­

Pr(Stage

=

IIA

sitivity value of

I case 82) in terms of the parameter, a sen­

2.07 is found.

W hen studying the effects of

variation on the probabilities of interest, therefore, the pa­
rameter should be selected for further investigation. Now
consider the effects of variation on the most likely value
of the variable

Stage.

For the parameter's assessment xo,

we find that stage III is the most likely stage for the patient
under study. The sensitivity function for this stage inter­
sects with the sensitivity function for stage IIA at x

= 0.17.

Further inspection of the figure reveals that the admissible
deviation for the parameter's assessment is

(oo, 0.15).

We

observe that the rightmost deviation is relatively large com­
pared to the original assessment.

We therefore conclude

that inaccuracies in the assessment are not reasonably ex­
pected to affect the most likely outcome, and the parameter
should not be selected for further investigation.

values but upon variation affects the most likely outcome.
Figure 7 depicts the sensitivity functions for the parameter

x

= p(Wall-inv = T2 I Shape = polypoid, 5 :::; Length <
lOcm). For the original assessment x0 = 0.2 of the pa­

rameter, the largest sensitivity values are found from the

lf{IA(Q.2)1
lf{u(0.2)[

=

=

III:

then the sensitivity values would not have

extremely small for both directions of variation.
Our final example pertains to a parameter that induces large
sensitivity values and upon variation is expected to result
in a change in the most likely outcome.

The sensitivity

8: the
p( CT-organs =

functions for the parameter are displayed in Figure
figure shows the effects of varying x

medias! llnv-organs

=

none).

=

From two of the sensitivity

functions, we find relatively large sensitivity values:

lf{1A(0.05) I
lf{n (0.05) I

1.34333
0.99446

In addition, the original assessment x0

= 0.05

for the pa­

xm of the vertices of the two functions:

XnA
:i:m

= 0.0597
0.0499

Based upon the concept of sensitivity value, therefore, the
parameter should be selected for further investigation. We
now consider the effects of variation on the most likely out­
come. We observe that for the original assessment the most

0.32151
0.34832

likely stage is IIA. The admissible deviation for the assess­
ment is computed to be

As the sensitivity functions are linear in the parameter
under study, the computed sensitivity values describe the
effects of variation exactly.

[0.04, 0.10],

changed, but the admissible deviation would have become

rameter lies very close indeed to the x-coordinates :i:nA and

We now address a parameter that induces small sensitivity

functions for the stages IIA and

val

Based upon the concept of

sensitivity value, we therefore conclude that the parame­
ter should not be selected for further investigation. Now,
the admissible deviation for the parameter's assessment is

(0.002, oo).

We observe that the

leftmost deviation is extremely small, indicating that an in­
accuracy by just

0.002 in the original assessment will lead
Stage and

to a different most likely value for the variable

may in fact result in a different treatment decision for the
patient under consideration.
The above examples illustrate that admissible deviations

0.6 ,-------,---,

IIA

0.6

��-�-------j iiA
-------.__.j ill
0.2

0.2

p(Wall·inv

= T2ISI>ape =polypoid, 5::;

0.05

Length< 10)

Figure 7: The sensitivity functions expressing the prob­

Pr(Stage I case 120) in terms of the parameter
p(Wall-inv = T2[Shape =polypoid, 5:::; Length< 10cm).
abilities

p(CT-organl! = m.edia.!tllnv-organ.s =none)

8: The sensitivity functions expressing the prob­
Pr(Stage I case 63) in terms of the parameter
p(CT-organs =medias! [Inv-organs =none).
Figure

abilities

UAI 2001

VAN DER GAAG & RENOOIJ

provide additional insight into the sensitivity of a proba­
bilistic network's outcome to inaccuracies in its parame­
ters. We would like to note that the use of admissible de­
viations is especially of interest when decisions are to be
based on the most likely value of a variable of interest [10].

537

Acknowledgements. This research has been (partly) supported
by the Netherlands Computer Science Research Foundation with
financial support from the Netherlands Organisation for Scien­
tific Research (NWO). We are most grateful to Babs Taal and
Berthe Aleman from the Netherlands Cancer Institute, Antoni van
Leeuwenhoekhuis, who spent much time and effort in the con­

struction of the oesophagus network.

6

Conclusions

References
[1] M.G. Morgan, M. Henrion (1990).

Uncertainty. a
Guide to Dealing with Uncertainty in Quantita­
tive Risk and Policy Analysis, Cambridge University

Sensitivity analysis of a probabilistic network serves to
yield insight in the effects of inaccuracies in its numerical

Press, Cambridge.

parameters. As for real-life networks a sensitivity analysis
tends to result in a huge amount of data, effective methods

[2] V.M.H. Coupe, L.C. van der Gaag (2001). Properties

for selecting relevant parameters from the generated data

of sensitivity analysis of Bayesian belief networks.

are called for. In this paper, we introduced two such meth­

Annals of Mathematics and Artificial Intelligence, to

ods.

appear.

One of our methods for extracting relevant information

[3] U. Kjcerulff, L.C. van der Gaag (2000). Making sensi­
tivity analysis computationally efficient. In:

cally, a parameter x is selected for further investigation if

Proceed­
ings of the Sixteenth Conference on Uncertainty in
Artificial Intelligence, Morgan Kaufmann, pp. 317-

the sensitivity function that expresses the network's proba­

325.

from sensitivity data builds upon the derivative of a sen­
sitivity function and its associated sensitivity value. Basi­

bility of interest in terms of x, has a large sensitivity value,
that is, a large absolute gradient at the original assessment

[4] K.B. Laskey (1995). Sensitivity analysis for probabil­
ity assessments in Bayesian networks. IEEE Transac­
tions on Systems, Man, and Cybernetics, voL 25(6),

x0 for the parameter. We argued that the sensitivity value
of a parameter's assessment does not constitute a sufficient
criterion for its selection: if the assessment lies close to
the x-coordinate of the vertex of the associated sensitivity

pp. 901-909.
[5] M. Henrion, M. Pradhan, B. Del Favero, K. Huang,
G. Provan, P. O'Rorke (1996). W hy is diagnosis using

function, then small deviations may have a large effect on

belief networks insensitive to imprecision in probabil­

the probability of interest, regardless of the assessment's

ities ? In:

Proceedings of the Twelfth Conference on
Uncertainty in Artificial Intelligence, Morgan Kauf­

sensitivity value. To identify parameters that are likely to
have a large effect on the probability of interest, therefore,
not only the sensitivity value of its assessment need to be
considered, but also the distance of the assessment to the

mann, pp. 307- 314.
[6] M. Pradhan, M. Henrion, G. Provan, B. Del Favero,

x-coordinate of the sensitivity function's vertex.

K. Huang ( 1996). The sensitivity of belief networks

The derivative and its associated sensitivity value are suit­

tion.

able for identifying parameters that have the largest influ­
ence on a network's probability of interest. We argued,
however, that if the network's outcome is not a single prob­
ability, but rather the most likely value for a variable of
interest, then the sensitivity value is no longer appropriate

to imprecise probabilities: an experimental investiga­
[7]

E.

Artificial Intelligence, vol. 85, pp. 363-397.

Castillo, J.M. Gutierrez, A.S. Hadi (1997). Sen­

sitivity analysis in discrete Bayesian networks.

IEEE
Transactions on Systems, Man, and Cybernetics, voL

27, pp. 412-423.

for this purpose. We introduced the concept of admissible

[8] L.C. van der Gaag, S. Renooij, C.L.M. Witteman,

deviation to provide for studying the effects of parameter

B.M.P. Aleman, B.G. Taal (1999). How to elicit many

variation on this type of outcome: the admissible devia­
tion (r, s) for a parameter's assessment indicates the largest

probabilities. In: Proceedings of the Fifteenth Confer­
ence on Uncertainty in Artificial Intelligence, Morgan

interval within which the assessment can be varied freely

Kaufmann, pp. 647-654.

without inducing a change in the most likely outcome.
We illustrated the various concepts introduced in this paper
by means of a sensitivity analysis of the oesophagus net­

[9] J. Berger (1985).

Bayesian Analysis,

Statistical Decision Theory and
Springer- Verlag, Berlin.

[10] L.C. van der Gaag, V.M.H. Coupe (2000). Sensitivity

work, a moderately-sized real-life network in the field of

analysis for threshold decision making with Bayesian

oncology. The analysis of this network resulted in a huge

E. Lamm a, P. Mello (editors).
AI*IA 99: Advances in Artificial Intelligence, Lec­

amount of data in which considerable sensitivities were

belief networks. In:

hidden. Our methods proved quite useful for extracting the

ture Notes in Artificial Intelligence, Springer-Verlag,

relevant information from these data.

Berlin, pp. 37- 48.

