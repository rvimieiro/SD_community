archically related evidences, and it was shown in both
[ Shafer and Logan, 87] and [Wilson, 87] that the hi­
erarchical case could be dealt with exactly in a com­
putationally efficient manner. The Shafer-Logan al­
gorithm was generalised to propagation of belief func­
tions in Markov Trees [ Shafer and Shenoy, 88] but,

although this is a very important contribution, it still
requires that the product space associated with the
largest clique is small, a condition which will by no
means always be satisfied. The hierarchical evidence
algorithm in [ Wilson, 87] was generalised to arbitrary
evidence sets [Wilson, 89] and, because it calculates
belief directly without first calculating the masses, it
leads to very substantial increases in efficiency (see sec­
tion 4). However this algorithm appears to have com­
plexity worse than polynomial, which is not surprising
since Dempster's Rule is #?-complete [Orponen, 90],
[ P rovan, 90].
This paper describes the Monte-Carlo algorithm given
in [Wilson, 89] which also calculates belief directly (or,
more accurately, it approximates belief up to arbi­
trary accuracy). This calculation has very low com­
plexity, showing that the general pessimism about
the complexity of Dempster-Shafer Theory is mis­
guided. The use of Monte-Carlo algorithms for calcu­
lating Dempster-Shafer belief has also been suggested
in [P earl, 88], [ Kampke, 88] and [ Kreinovich and Bar­
rett, 90].
2

THE MONTE-CARLO
ALGORITHM

Let Belt, . .., Belm be belief functions on a finite frame
8, and let Bel= Belt Etl· ·EtlBelm be their combination
using Dempster's Rule. Using the model of [ Dempster,
67] Bel; is represented by a probability function P; (on
a finite set rl;) and a compatibility function f; : rl; >-->
2° where the meaning of f; is 'for r E rl;, if r is true
then so is f;( r)'.
·

The mass function m; is given by:
m;(f;(c;))= P;(ci), and, for b S::: 8,
Bel;(b)= P;(f;(c;) s;; b), that is,

for c; E rl;,

I:

P;(c;).

,,,r,(,,)�b

Let n = nl X . X Slm and for c = (c), ... ,c,)
define f (c) = n::1 f;(c; ). Define the 'independent
.

.

nte C arlo Algorithm for Dempster-Shafer Belief

A Mo

probability function' P' on f! by P'((c:1, . . ,c:m))
.

n::1 P;(c:;).

Using [ Dempster, 67] it can be seen that
Bel(b)= P'(r(c:) <;; blf(c:) =1 0),
where e.g. P'(r(c:) # 0) just means L<:r(<);>!0 P'(c:).
r(c:) can be viewed as a random set [Nguyen, 78].
The Monte-Carlo algorithm just simulates the last
equation.
A large number, N, of trials are performed. For each
trial:
Randomly pick c: such that f(c:) # 0:
a. For i = 1,... , m
randomly pick an element of f!;, i.e.
pick c; with probability P;(c;)
Let c = (c:1, . . ,em )
b. If r(c:) = 0 then restart trial;
2. If f(c:) <;; b then trial succeeds, letT= 1
else trial fails, let T = 0

1.

.

The proportion of trials that succeed converges to
Bel( b):
E[T] = P'(r(c:) <;; bll'(c:) # 0) = Bel(b).
Var[T] = E[T2]-(E[T])2 = E[T]-(E[T])2 = Bel(b)(1Bel(b)) :S: t·
Let f be the average value ofT over the N trials, i.e.,
the proportion of trials that succeed.
N �T)

= Bel(b)
NVar[TJ < ...!.._
- 4N
N2

E[f]

=

and Var[t]

_

Therefore the variance (an<!_ so also the standard de­
viation) for the estimate, T, of Bel(b) can be made
arbitrarily small independently of 181 and m.
Let us say that the estimate t_ of Bel(b) 'has accuracy
k' if 3 standard deviations ofT is less than or equal to
k. Then f has accuracy k if N 2: -,&,-.
Testing separately if r(c:) = 0 and if f( c:) <;; b wastes
time; these tests can be combined within the same
algorithm (where Xj denotes the jth element of 8):
For each trial:
repeat

pick c: with probability P'(c:)
: 1; T := 1
T0 =
for j = 1 to 181
if

f(c:)

3 Xj then

T0 =
:

if Xj

0;

tf_ b

(since f(c:) # 0)
:= 0; exit trial;

then T

-

end if
end if
next j
until T0 = 0

3

(since r(c:) �b)

COMPUTATION TIME

Picking c; involves m random numbers so takes less
than Am where A is constant, approximately the time
it takes to generate a random number (with efficient
storing of the P;s). Testing if r(c:) 3 Xj takes less than
Bm for constant B. For a given trial there is a prob­
ability K = P'(r(c:) = 0) that the repeat-until loop
will be entered a second time. The expected number
of repeat-until loops per trial is 1��; K is a measure
of the conflict of the evidences [Shafer, 76, p65].
Thus the expected time the algorithm takes is less than
1�� m(A+ Bl81), and so the expected time to achieve
accuracy k is less than 4(1 9�)pm(A + Bl81).
At least for the case where the Bel;s are simple sup­
port functions, the condition f(c) 3 Xj can be tested
more efficiently; under weak conditions this leads to
expected time of less than 4(1 9�)k2 (Am+ Cl81) for
constant C [Wilson, 89].
4

EXPERIMENTAL RESULTS

The algorithm for the case where the Bel;s are simple
support functions has been implemented and tested
using the language Modula-2 on a SUN 3/60 worksta­
tion. The results showed that the value of A is much
bigger than the value of C in this implementation, A
being roughly 40�0 seconds and C roughly 50 �00 sec­
time taken to ge�erate a
onds. A is essentially the
1
random number, and 4000 seconds seems rather slow
for that. This suggests that very substantial speed­
ups (of perhaps an order of magnitude or two) could
be achieved by careful choice and use of the random
number generator and the use of antithetic runs (so
that the random number generator is only used once
for several different data items).
The results indicate that, unless the evidences are ex­
tremely conflicting, the Monte-Carlo algorithm is prac­
tical for problems with large m and 8. For example,
with K = 0.5, m = 181 = 40, and with 1000 tri­
als, the calculation of the approximate value of Bel(b)
would be expected to take 20.6 seconds. The 1000
trials mean that the standard deviation is less than
0.016, and so the confidence interval for the correct
value of belief corresponding to 3 standard deviations
would be roughly [ b- 0.05, b+ 0.05] . If instead we did
10,000 trials this would take a little over 3 minutes,
and give a standard deviation of 0.005. Extrapolating
the figures (which seems unlikely to cause problems in

415

416

Wilson

this case) gives an approximate time of 1 minute for
m = 101 = 120, with 1000 trials, and 5 minutes for
m = 101 = 600.
Also in [Wilson, 89] an exact algorithm for calcu­
lating belief is described (related to those described
in [P rovan, 90]) which involves expressing the event
f(E) s;; b as a boolean expression and then calculat­
ing the probability of this using the laws of boolean
algebra. Again this avoids explicit calculation of the
masses. The complexity for the simple support func­
tion case appears to be approximately of the form

l0llogm.

The usual approaches for calculating belief are mass­
based: they calculate the combined mass function and
use this to calculate the appropriate belief (a good one
of these is the fast Mobius transform in [Kennes and
Smets, 90]). For large m and 0 this is of necessity very
computationally expensive, since if q = min(m, 101),
there can be as many as 2q masses. For simplicity it is
assumed that the calculation of belief then just does 2q
REAL multiplications. The speed of REAL multipli­
cation was tested on the same workstation and within
the same language that the Exact and Monte-Carlo al­
gorithms were tested and implemented on and it was
found that it did just over 104 REAL multiplications
per second. This gives the following results:
m,n
15 X
20 X
25 X
30 X
35 X
50 X

15
20
25
30
35
50

MC
7 sees
11 sees
13 sees
15 sees
17 sees
25 sees

Mass-based 2:
3 sees
1 min
1 hour
1 day
1 month
3000 years

Exact
9 sees
13 sees
46 sees
3 mins
8 mins
2 hours

The values for the Monte-Carlo algorithm were based
on doing 1000 trials and the contradiction being 0.5.
The figure of 2 hours for the Exact in the 50 case is a
very rough upper bound derived from insufficient data.
Details of the experiments and the full results and
analysis are given in [Wilson, 90b].

5

THE GENERALISED

(or f((El, . . . , Em)) = the set {f;(E;)
the logic doesn't have conjunction).

:

i

=

1, ... , m} if

For each trial:
1. Randomly pick E such that
f(E) is not contradictory:
a. For i = 1, . . . , m
randomly pick an element of ll;, i.e.
pick E; with probability P;(t:;)
Let E = (<!, . . . ,Em)

b. If f(c:) is contradictory then restart trial;
2. If b can be deduced from r(c:)
then trial succeeds, let T = 1
else trial fails, let T = 0

Undecidability and semi-decidability would clearly
cause problems, in which case trials which went on
for too long would have to be cut short; if T for these
trials was given the value 0 then this would lead to a
lower bound for Bel(b). This technique of prematurely
halting trials that take too long could be used to in­
crease the efficiency for other cases as well, at the cost
of only finding lower and upper bounds for Bel(b).
The time this algorithm takes is then approximately
���(Am + R) where R is the average time it takes to

see if f(c:) is contradictory, and if f(c:) allows b to be
deduced. Given that the weight of conflict of the ev­
idences is bounded this means that the complexity is
proportional to that of proof in the logic; it is hard to
see how any sensible uncertainty calculus could do bet­
ter than this (although the complexity for this Monte­
Carlo algorithm has a very large constant term if high
accuracy is required).
As Shafer points out [Shafer, 90] 101 can be a large
product space, making the first algorithm impractical.
The generalised algorithm can also be used to greatly
improve the complexity of the algorithms for calcu­
lating Belief in Markov trees [Shafer and Shenoy, 88].
For each trial, propositions (i.e. belief functions with
a single focal element) must be propagated through
the Markov tree. The complexity is then proportional
to that of propagating propositions, rather than the
whole belief functions. Some other propositional cases
have been dealt with in [Wilson, 89].

ALGORITHM
The algorithm can be generalised to deal with arbi­
trary logics [Wilson, 90a]. Let L be the language of
some logic. For each i, Bel; is now a function from L
to [0, 1] saying how much the evidence warrants belief
in propositions in L and the compatibility function is
a function f; : ll; f-> L. The combined compatibility
function r is now defined by

f((El, ... ,Em)) =

m

1\ f;(E;),
i=l

6

DISCUSSION

There are two obvious drawbacks with the Monte­
Carlo algorithm:
(i) if very high accuracy is required then the Monte­
Carlo algorithm will require a large number of trials
(quadratic in the reciprocal of accuracy) so giving a
very high constant factor to the complexity;
(ii) when the evidence is highly conflicting the Monte­
Carlo algorithm loses some of its efficiency. I don't see

A Monte-Carlo Algorithm for Dempster-Shafer Belief

this as a great problem since an extremely high weight
of conflict would suggest, except in exceptional circum­
stances, that Dempster's Rule is being applied when
it is not valid, e.g. updating a Bayesian prior with a
Dempster-Shafer belief function [see Wilson, 91]. I also
argue there that, although Dempster's Rule has strong
justifications for the combination of a finite number of
simple support functions, the more general case has
not been convincingly justified: the Monte-Carlo algo­
rithm is guaranteed to give results in accordance with
Dempster's Rule, but it remains to be seen if these are
always sensible.
It may be important to know which relatively small
sets have relatively high beliefs: the Monte-Carlo algo­
rithm can be easily applied to deal with this problem.
Dempster's Rule makes particular independence as­
sumptions, using a single probability function on 0.
By modifying step 1 of the algorithms the beliefs cor­
responding to other probability functions on n can be
calculated.

Acknowledgements
I am currently supported by the ESPRIT basic re­
search action DRUMS (3085). Most of the material
in this paper was produced in the period Summer '87Summer '88 when I was employed by the The Hotel
and Catering Management, and Computing and Math­
ematical Sciences Departments of Oxford Polytechnic.
Thanks also to Bills Triggs and Boatman for their help
during this period, and more recently to Mike Clarke.

References
Barnett, J .A., 1981, Computational methods for a
mathematical theory of evidence, in: Proceedings
IJCAI-81, Vancouver, BC 868-875.
Bonissone, P. P., 1987, 'Reasoning, Plausible' in En­
cyclopedia of Artificial Intelligence. Shapiro, S. C.
(Ed.), John Wiley and Sons, 1987.
Dempster, A. P., 67, Upper and Lower Probabilities
Induced by a Multi-valued Mapping. Ann. Math.
Statistics 38: 325-39.
Gordon, J. and Shortliffe, E.H., 1985, A method of
managing evidential reasoning in a hierarchical hy­
pothesis space, Artificial Intelligence 26, 323-357.
Kampke, Thomas, 88, About Assessing and Evaluat­
ing Uncertain Inferences Within the Theory of Ev­
idence, Decision Support Systems 4 433-439.
Kennes, Robert, and Smets, Philippe, 1990, Compu­
tational Aspects of the Mobius transform, Uncer­
tainty in Artificial Intelligence, July 1990, Cam­
bridge, USA.
Kreinovich, V., and Barrett, W., 90, Monte-Carlo
Methods Allow to Avoid Exponential Time in

Dempster-Shafer Formalism, Technical Report
UTEP-CS-90-5, Computer Science Department,
University of Texas at El Paso.
Kyburg, H .E., Jr., 87, Bayesian and Non-Bayesian Ev­
idential Updating, Artificial Intelligence 31 271293.
Nguyen, Hung T., 78, On Random Sets and Belief
Functions. Journal of Mathematical Analysis and
Applications 65: 531-542.
Orponen, Pekka, 90, Dempster's Rule of Combination
is #?-complete, Artificial Intelligence 44 245-253.
Pearl, Judea, 88, Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference, lVIorgan
Kaufmann Publishers Inc. 1988, Chapter 9, in par­
ticular 455-457.
Provan, G., 90, A Logic-based Analysis of Dempster­
Shafer Theory, International Journal of Approxi­
mate Reasoning, 4, 451-495.
Shafer, G., 76, A Mathematical Theory of Evidence,
Princeton University Press, Princeton, NJ.
Shafer, G., 90, Perspectives on the Theory and Prac­
tice of Belief Functions, International Journal of
Approximate Reasoning.
Shafer, G. and Logan, R., 1987, Implementing Demp­
ster's Rule for Hierarchical Evidence, Artificial In­
telligence 33 271-298.
Shafer, G. and Shenoy, P. P. 1988, Local Computations
in Hypertrees, Working Paper No. 201, School of
Business, The University of Kansas, Lawrence, KS,
66045, USA.
Wilson, N., 87, On Increasing the Computational Ef­
ficiency of the Dempster-Shafer theory, Research
Report no. 11, Sept. 1987, Dept. of Computing
and Mathematical Sciences, Oxford Polytechnic.
Wilson, Nic, 89, Justification, Computational Effi­
ciency and Generalisation of the Dempster-Shafer
Theory, Research Report no. 15, June 1989, Dept.
of Computing and Mathematical Sciences, Oxford
Polytechnic., to appear in Artificial Intelligence.
Wilson, Nic, 90a, Rules, Belief Functions and Default
Logic, in Bonissone, P., and Henrion, 1\1., 90, eds
Proc. 6th Conference on Uncertainty in Artificial
Intelligence, MIT, Cambridge, Mass.
Wilson, Nic, 90b, Implementation and Practical Anal­
ysis, DRUMS (ESPRIT Basic Research Action
3085) RP3.2, 12 month report, September 1990.
Wilson, Nic, 91, The Combination of Belief: When
and How Fast, A Reply to Glenn Shafer's paper
Perspectives on the Theory and Practice of Belief
Functions, to appear in International Journal of
Approximate Reasoning.

417

