
Bayesian optimisation

We consider a sequential decision approach to global optimization of smooth functions f (Â·) : X 7â†’
R over an index set X âŠ‚ Rd . At the t-th decision round, we select an input xt âˆˆ X and observe the
value of a black-box reward function f (xt ). The returned value may be deterministic, yt = f (xt ),
PT
or stochastic, yt = f (xt ) + t . Our goal is to maximise the cumulative rewards t=1 f (xt ). That
is, we wish to approach the performance of the optimiser xâˆ— = arg maxxâˆˆX f (x) rapidly. Since the
optimiser is unknown, we have to trade-off exploitation and exploration in the search process.
This sequential optimisation approach is natural when the function does not have an obvious mathematical representation (e.g., when querying people to maximize some objective) or when the function is too expensive to evaluate (e.g., as in control problems and automatic algorithm configuration
with massive datasets and models).
Although the function is unknown, we assume that it is smooth. It is natural to adopt a Bayesian
modelling approach whereby one introduces a prior to encode our beliefs over the smoothness of
the function, and an observation model to describe the data Dt = {x1:t , y1:t } up to the t-th round.
Using these two models and the rules of probability, we derive a posterior distribution p(f (Â·)|Dt )
from which we can carry out inference about properties of f (Â·) in light of the data, such as the
location of its maxima.
2.1

Bayesian optimisation with Gaussian processes

A Gaussian processes (GP) offer a flexible and relatively simple way of placing priors over functions;
we refer the reader to [22] for details on these stochastic processes. Such priors are completely
characterised by a mean function m(Â·) and a covariance kernel k(Â·, Â·) on the index sets X and
X âŠ— X . In particular, given any finite collection of inputs x1:t the outputs are jointly Gaussian,
f (x1:t )|Î¸ âˆ¼ N (m(x1:t ), KÎ¸ (x1:t , x1:t )),
where KÎ¸ (x1:t , x1:t )ij = k Î¸ (xi , xj ) is the covariance matrix (parametrised by Î¸) and m(x1:t )i =
m(xi ) the mean vector. For convenience, we assume a zero-mean prior. We consider the following
types of covariance kernels
Î¸
kSE
(x, x0 )

=

Î¸
kMateÌrn(5/2)
(x, x0 )

=

where r

=

exp(âˆ’ 12 r2 )
âˆš
âˆš
exp(âˆ’ 5r)(1 + 5r + 53 r2 )
2 âˆ’1

(x âˆ’ x0 )T diag(Î¸ )

(1)
(2)

(x âˆ’ x0 ).

Both kernels are parametrised by d length-scale hyper-parameters Î¸i . These kernels work well in
situations where little is known about the space in question, although the MateÌrn tends to make less
stringent smoothness assumptions, thus making it a good fit for Bayesian optimization.
We assume that the observations of the function at any point xt are corrupted by Ïƒ-sub-Gaussian
noise yt = f (xt ) + t . Our theoretical results cover this general type of noise, which encompasses
symmetric Gaussian and Bernoulli noise. However, for ease of presentation, we will focus on the
tractable case of Gaussian noise t âˆ¼ N (0, Ïƒ 2 ) in this section. We refer the reader to [4] for an
example of discrete noise, which necessitates the introduction of approximate inference methods.
Given the data Dt = {x1:t , y1:t }, the joint distribution of the data and an arbitrary evaluation point
x is


  Î¸

y1:t
Kt + Ïƒ 2 I kÎ¸t (x)
Î¸ âˆ¼ N 0,
.
f (x)
kÎ¸t (x)T
k Î¸ (x, x)
where KÎ¸t = KÎ¸ (x1:t , x1:t ) and kÎ¸t (x) = kÎ¸ (x1:t , x). It is well known that the predictive posterior
distribution of any evaluation point x is marginally Gaussian f (x)|Dt , Î¸ âˆ¼ N (Âµt (x; Î¸), Ïƒt (x; Î¸))2 ,
where
Âµt (x; Î¸)
KtÎ¸ (x, x0 )
Ïƒt (x; Î¸)2

=

E [f (x)|Dt ] = kÎ¸t (x)T (KÎ¸t + Ïƒ 2 I)âˆ’1 y1:t ,
0

Î¸

0

= E [f (x)f (x )|Dt ] = k (x, x ) âˆ’
=

KtÎ¸ (x, x).

kÎ¸t (x)T (KÎ¸t

(3)
+Ïƒ

2

I)âˆ’1 kÎ¸t (x0 )

(4)
(5)

2

Having specified a distribution over the target function and a mechanism for updating this distribution as data arrives, we turn our attention to the problem of selecting an acquisition function Î±(Â·|Dt )
for choosing the next query point,
xt+1 = arg max Î±(x|Dt ).
xâˆˆX

The choice of acquisition function is crucial. It must be efficiently computable since it will be
optimized at every decision round. More subtly, it must use the statistics of p(f (x)|Dt , Î¸) to tradeoff exploitation (where Âµt (x; Î¸) is high) and exploration (where Ïƒt (x; Î¸) is high) effectively.
Although many acquisition functions have been proposed (see for example [20, 14, 10, 9, 23, 11]),
the expected improvement (EI) criterion remains a default choice in popular Bayesian optimisation
packages, such as SMAC and Spearmint [13, 23]. If we let x+
t = arg maxiâ‰¤t f (xi ; Î¸) denote the
current incumbent, the EI acquisition function can be written in closed form as
Î±Î¸EI(f) (x|Dt ) = E[max{0, f (x) âˆ’ f (x+ )}|Dt ] = Ïƒt (x; Î¸)[aÎ¦(a) + Ï†(a)]
with a =

Âµt (x;Î¸)âˆ’f (x+ )
,
Ïƒt (x;Î¸)

(6)

and Ï† and Î¦ are the standard normal density and distribution functions

respectively. In the special case of Ïƒt (x; Î¸) = 0, we set Î±Î¸EI(f) (x|Dt ) = 0. The expected improvement is best understood as a family of one-step-decision heuristics [5], with many members in this
family. While the above member is reasonable for deterministic optimization, the noise in the evaluation of the incumbent, f (x+ ), causes it to be brittle in the stochastic case. In the stochastic setting,
the improvement over the best mean value Âµ+
Î¸ = maxxâˆˆX Âµt (x; Î¸) seems to be a more reasonable
alternative. For this choice, we obtain a similar expression for EI,
Î±Î¸EI(Âµ) (x|Dt ) = E[max{0, f (x) âˆ’ Âµ+
Î¸ }|Dt ] = Ïƒt (x; Î¸)[uÎ¦(u) + Ï†(u)],
where u =

Âµt (x;Î¸)âˆ’Âµ+
Î¸
Ïƒt (x;Î¸)

(7)

. In this paper, we will consider a re-scaled version of this criterion:

u
u u
(8)
Î±Î¸EI (x|Dt ) = E[max{0, f (x) âˆ’ Âµ+
Î¸ }|Dt ] = Î½Ïƒt (x; Î¸)[ Î¦( ) + Ï†( )]
Î½ Î½
Î½
where Î½ is a parameter must be estimated. Intuitively, this parameter enables us to rescale the
kernel. In the deterministic case, it plays an equivalent role to multiplying the kernel by an unknown
coefficient Î½. (For notational simplicity, we are not making dependence of EI on Î½ explicitly in the
expression Î±Î¸EI (x|Dt ).)
2.2

An algorithm inspired by the theory

Our main theorem (Theorem 1) establishes sufficient conditions to guarantee that the regret of a
Bayesian optimisation algorithm with EI and hyper-parameter estimation, vanishes as the number
of function evaluations increases. To illustrate the value of Theorem 1, we use its guidelines to
construct an algorithm in this section.
For Theorem 1 to hold, it is necessary that we adapt the hyper-parameters in a particular manner.
First, we must ensure that that there exist upper-bounds on the hyper-parameters Î¸, which we group
in the vector Î¸ U ,such that the objective function f (Â·) is an element of the reproducing kernel Hilbert
space induced by this narrower kernel HÎ¸U (X ) (these spaces will be explained in Section 3.4).
Figure 1 (right) shows what happens to the confidence intervals as the entries of Î¸ U shrink with t,
by narrowing the kernel.
In practice, it is difficult to assess this condition. To surmount this difficulty, we draw inspiration
from [28], and propose to reduce the upper bound of the length scales Î¸ U when the algorithm
becomes over confident. In particular, we adaptively reduce Î¸ U whenever the model repeatedly
samples points of low posterior variance in comparison to the noise variance Ïƒ 2 . Once the algorithm
optimizes to the precision of the noise variance, it suffers from a slower convergence rate.
By choosing to lower the upper bound as proposed in Algorithm 1, we essentially enable the algorithm to explore more, as opposed to over-exploiting a local mode. This is illustrated in Figure 1,
which depicts the result of running the proposed algorithm and a standard Bayesian optimisation
scheme. We will explain the experiment in more detail at the end of this section.
3

Algorithm 1 Bayesian Optimization with Hyper-parameter Optimization.
input Threshold tÏƒ > 0, percentage of reduction parameter p âˆˆ (0, 1), and c2 > c1 > 0.
input Lower and upper bounds Î¸ L , Î¸ U for the hyper-parameters.
input Initial length scale hyper-parameter Î¸ L â‰¤ Î¸ 1 â‰¤ Î¸ U .
1: Initialize E = 0
2: for t = 1, 2, . . . do
3:
Select xt = arg maxxâˆˆX Î±Î¸EIt (x|Dtâˆ’1 )
2
4:
if Ïƒtâˆ’1
(xt ; Î¸t ) < tÏƒ Ïƒ 2 then
5:
E =E+1
6:
else
7:
E=0
8:
end if
9:
Augment the data Dt = Dtâˆ’1 âˆª (xt , yt )
10:
if E = 5 then



11:
Restrict Î¸ U such that Î¸iU = max min p maxj {Î¸jU }, Î¸iU , Î¸iL
12:
E=0
13:
end if
14:
Choose hyper-parameters Î¸ t+1 such that Î¸ L â‰¤ Î¸ t+1 â‰¤ Î¸ U .
Î¸
Î¸ t+1
Î¸ t+1
Î¸ t+1
15:
Choose hyper-parameter Î½t t+1 such that c1 Î¾t+1
â‰¤ Î½t+1
â‰¤ c2 Î¾t+1
, where Î¾tÎ¸t is defined in
Equation (9).
16: end for
As Î¸ U is successively decreased, after a finite number of iterations, we can ensure that f (Â·) âˆˆ
HÎ¸U (X ) as long as there exists Î¸ â‰¥ Î¸ L such that f (Â·) âˆˆ HÎ¸ (X ). In practice, we advocate a
conservative choice of Î¸ L whenever we have little knowledge of the range of possible values of Î¸.
Theorem 1 also imposes a condition on Î½. To satisfy it, we constrain Î½tÎ¸t to be in the interval
c1 Î¾tÎ¸t â‰¤ Î½tÎ¸t â‰¤ c2 Î¾tÎ¸t , where


p
Î¾tÎ¸t = IÎ¸t (ytâˆ’1 ; ftâˆ’1 ) + log1/2 (2t2 Ï€ 2 /3Î´) IÎ¸t (ytâˆ’1 ; ftâˆ’1 ) + log(t2 Ï€ 2 /3Î´) .
(9)
(The information gain will be defined in Section 3.3.) The careful reader may have noticed that
the above condition does not match perfectly the condition detailed in Theorem 1. Upon closer
examination, however, we see that replacing the maximum information gain Î³TÎ¸ with IÎ¸ (yT ; fT )
does not break the convergence result. We have used Î³TÎ¸ in Theorem 1 instead of IÎ¸ (yT ; fT ) simply
to simplify the presentation.
In practice, we could use a number of strategies for estimating the hyper-parameters, provided they
fall within the bounds set by Theorem 1. In particular, we could use maximum likelihood to estimate
the hyper-parameters in this constrained space. Note that the Î½ parameter could also be treated as a
kernel hyper-parameter (kernel scale), therefore removing the need of estimating it separately.
Finally, the astute reader would have noticed the parameters tÏƒ , p, c2 and c1 in the algorithm. If
we want to achieve an accuracy comparable to the noise variance, we should set tÏƒ = 1. The other
parameters simply determine how fast the algorithm converges and should be set to reasonable fixed
values, e.g. p = 0.5, c2 = 1 and c1 = 0.001. Provided tÏƒ > 0, p âˆˆ (0, 1) and c2 > c1 > 0, the
theory is satisfied.
If we have strong beliefs about our GP prior model, it may seem unnecessary to estimate our parameters with Algorithm 1. When our prior belief is misplaced, however, we could fail to converge if
we were to follow the traditional probabilistic approach. We provide an illustration of this effect by
optimize the following stochastic function:
1
2
f (x) = 2kÎ¸SE
(x1 , x) + 4kÎ¸SE
(x2 , x) + 

over the interval [0, 1], where Î¸1 = 0.1, Î¸2 = 0.01, x1 = 0.1, x2 = 0.9, and  is zero-mean Gaussian
with 10âˆ’2 standard deviation. Figure 1 compares Algorithm 1 against standard Bayesian optimisation with the same EI function, but using slice sampling to infer the kernel hyper-parameters (without
imposing the theoretical bounds on the hyper-parameters). We see that, in the absence of reasonable
4

4

4

3

3

2

2

1

1

0

0

1

1

2
0.0

0.2

0.4

0.6

0.8

2
0.0

1.0

4

4

3

3

2

2

1

1

0

0

1

1

2
0.0

2
0.0

0.2

0.4

0.6

0.8

1.0

4

4

3

3

2

2

1

1

0

0

1

1

2
0.0

0.2

0.4

0.6

0.8

2
0.0

1.0

t = 20

0.2

0.4

0.6

0.8

1.0

t = 40

0.2

0.4

0.6

0.8

1.0

t = 60

0.2

0.4

0.6

0.8

1.0

Figure 1: Convergence of EI with slice sampling over the kernel hyper-parameters [left] and EI
using Algorithm 1 [right] at three function evaluation steps (t). The objective function (in blue)
was constructed so that it has a trap. Unless EI with slice sampling hits the narrow optimum by
random chance, it becomes too confident and fails to converge after 60 evaluations. In contrast,
the confidence bounds for Algorithm 1 can increase enabling it to sample the function in a more
reasonable way and thus find the optimum.

prior beliefs, conditions like the ones detailed in our theoretical results are necessary to guarantee
reasonable sampling of the objective function. (The same behaviour for the plot on the left is observed if we replace slice sampling with maximum likelihood estimation of the hyper-parameters.)
While heteroskedastic GP approaches could mitigate this problem, there are no theoretical results to
guarantee this to the best of our knowledge.

3

Theoretical analysis

Our theoretical analysis uses regret to measure convergence and information gain to measure how
informative the samples are about f (Â·). It assumes that the noise process t is sub-Gaussian, and
that the function f (Â·) is smooth according to the reproducing kernel Hilbert space (RKHS) associated with the GP kernel k Î¸ (Â·, Â·). Before presenting our main result, we briefly review these four
background areas.
5

3.1

Background: Regret

As in [24], we will measure the performance of the Bayesian optimization algorithm using regret.
The instantaneous regret at iteration t is defined as rt = f (xâˆ— ) âˆ’ f (xt ). The corresponding cumulaPT
tive regret after T iterations is RT = t=1 rt . While the regret measures are never revealed to the
algorithm, bounds on these enable us to assess how rapidly the algorithm is converging.
3.2

Background: Sub-Gaussian noise

We assume independent Ïƒ-sub-Gaussian noise. Formally, we say t is Ïƒ-sub-Gaussian if there exists
a Ïƒ â‰¥ 0 such that
 2 2
Ï Ïƒ
E [exp(Ït )] â‰¤ exp
âˆ€Ï âˆˆ R.
2
In other works, t is Ïƒ-sub-Gaussian if its Laplace transform is dominated by the Laplace transform
of a Gaussian random variable with zero mean and variance Ïƒ 2 . It is easy to show that if t is
sub-Gaussian, then E[t ] = 0 and Var[t ] â‰¤ Ïƒ 2 .
There are many examples of sub-Gaussian variables, including zero-mean Gaussian random variables with variance Ïƒ 2 , symmetric Bernoulli random variables and symmetric uniform distributions.
3.3

Background: Information gain

To measure the reduction in uncertainty about f (Â·) from observing yA for a set of sampling points
A âŠ‚ X , we need to introduce the concept of information gain, which is defined as the mutual
information between f (Â·) and a set of observations yA :
I(yA ; f (Â·)) = H(yA ) âˆ’ H(yA |f (Â·)).

(10)

This concept plays a central role in the results of [24], who also define the maximum information
gain Î³T after T decision rounds as
Î³T =

I(y1:t ; f (Â·)).

(11)

1
log |I + Ïƒ âˆ’2 KÎ¸A |.
2

(12)

max

AâŠ‚X :|A|=T

Note that for Gaussian distributions,
Î³TÎ¸ =

max

AâŠ‚X :|A|=T

Our regret bounds will be given in terms of Î³TÎ¸ . It should perhaps be clarified that the bounds apply
to Ïƒ-sub-Gaussian noise, despite the appearance of the variable Î³TÎ¸ in their statements.
3.4

Background: Reproducing kernel Hilbert spaces

To discuss convergence, we must state formally what we mean by f (Â·) being smooth. In short, we
assume that f (Â·) is an element of an RKHS with reproducing kernel k(Â·, Â·). For an intuitive grasp
of this formalisation of smoothness, we need to briefly review some RKHS fundamentals. These
fundamentals are also evoked in our proofs.
Let Lx be an evaluation functional: Lx f (Â·) = f (x). A (real) RKHS H is a Hilbert space of real
valued functions with the property that for each x âˆˆ X , the evaluation functional is bounded. That
is, there exists a positive constant M = Mx such that |Lx f (Â·)| = |f (x)| â‰¤ M kf (Â·)kH for all
functions f (Â·) âˆˆ H, where k Â· kH denotes the norm in the Hilbert space. If H is an RKHS, by the
Riesz Representation Theorem, there exists an element k(Â·, x) âˆˆ H with the property,
f (x) = Lx f (Â·) = hk(Â·, x), f (Â·)i

(13)

for all x âˆˆ X and f (Â·) âˆˆ H, where hÂ·, Â·i denotes the inner product in H.
Pn
To construct H, we consider the linear manifold t=1 Î»t k(Â·, xt ) for all choices of n, Î»1 , . . . , Î»n
and x1 , . . . , xn âˆˆ X , with inner product
n
n
n X
n
n
X
X
X
X
h
Î»i k(Â·, xi ),
Î»j k(Â·, xj )i =
Î»i k(xi , xj )Î»j = k
Î»i k(Â·, xi )k2H â‰¥ 0.
i=1

j=1

i=1 j=1

i=1

6

(14)

The above norm is non-negative because of the positive-definiteness of k(Â·, Â·). Clearly, for any
element f (Â·) of this linear manifold,
n
n
X
X
f (xj ) = hf (Â·), k(Â·, xj )i = h
Î»i k(Â·, xi ), k(Â·, xj )i =
Î»i k(xi , xj )
i=1

(15)

i=1

A consequence of this is that for any Cauchy sequence {fn (Â·)}, we have the following bound by
Cauchy-Schwartz: |fn (x)âˆ’f (x)| = hfn (Â·)âˆ’f (Â·), k(Â·, x)i â‰¤ kfn (Â·)âˆ’f (Â·)kH kk(Â·, x)kH . In words,
norm convergence implies point-wise convergence.
The preceding steps illustrate that we can construct a unique RKHS for any positive definite kernel
k(Â·, Â·). The converse is also true (Moore-Aronszajn Theorem).
A positive definite function k(Â·, Â·), under general Rconditions,
has an eigenvector-eigenvalue deR
composition. Suppose k(Â·, Â·) is continuous and X X k 2 (x, y)dxdy < âˆ, then there exists
an orthonormal sequence of continuous
eigenfunctions q1 (Â·), q2 (Â·), . . . and eigenvalues âˆ†1 â‰¥
Pâˆ
âˆ†2 â‰¥ . P
. . â‰¥ 0, with k(x, y) = Î½=1 âˆ†Î½ qÎ½ (x)q
R Î½ (y). Next, consider the orthonormal expansion
âˆ
f (Â·) = Î½=1 fÎ½ qÎ½ (Â·) with coefficients fÎ½ = X f (x)qÎ½ (x)dx. It is easy to prove that f (Â·) is an
element of the RKHS associated with k(Â·, Â·) if and only if
kf (Â·)k2H =

âˆ
X
fÎ½2
< âˆ.
âˆ†Î½
Î½=1

(16)

To obtain the above finiteness condition, the coefficients fÎ½ of the expansion of f (Â·) must decay
quickly. For the kernels we consider in this paper, elements of RKHS can uniformly approximate any
continuous function with compact support. Therefore, RKHS is well suited as a tool for analyzing
convergence behaviors of Bayesian optimization algorithms.
3.5

Main result

In this section, we present our regret bound and sketch its proof. For space considerations, detailed
proofs appear in the appendix provided in the supplementary material.
As discussed when presenting the algorithm, our theorem assumes bounds on the kernel hyperparameters of the form Î¸ L â‰¤ Î¸ t â‰¤ Î¸ U for all t â‰¥ 1 with f (Â·) âˆˆ HÎ¸U (X ). While we could recall
all the conditions on the kernel function necessary for our theorem to apply, we simply restrict the
family of kernels to one that satisfies the conditions detailed in [6]. Without loss of generality, we
assume that k(x, x)= 1.
Our theorem characterising the growth in the cumulative regret RT with the number of function
evaluations T follows.
Qd Î¸U
Theorem 1. Let C2 := i=1 Î¸iL . Suppose Î¸ L â‰¤ Î¸ t â‰¤ Î¸ U for all t â‰¥ 1 and f (Â·) âˆˆ HÎ¸U (X ). If
i
q



1/2
Î¸ 2
Î¸
2 2
Î¸
Î½t = Î˜ Î³tâˆ’1 + log (2t Ï€ /3Î´) Î³tâˆ’1
+ log(t2 Ï€ 2 /3Î´) for all t â‰¥ 1. Then with probability at least 1 âˆ’ Î´, the cumulative regret obeys the following rate:
 q

L
Î¸
RT = O Î²T Î³T T ,
(17)
where Î²T = 2 log
C2 kf k2H

Î¸U

T
Ïƒ2



L

Î³TÎ¸ âˆ’1 +

âˆš

8 log

T
Ïƒ2



log1/2 (4T 2 Ï€ 2 /6Î´)


âˆš

C2 kf kHÎ¸U (X ) +


q
L
Î³TÎ¸ âˆ’1 +

(X ) .

Our result is analogous to Theorem 3 of [24] which proves convergence rates for the GP-UCB
algorithm in the agnostic setting. Their result, however, does not allow for the estimation of hyperparameters. In addition, our algorithm does not require explicit knowledge of the RKHS norm of
the objective function while GP-UCB does require this.
Using the results of Srinivas et al. we can further detail these rates as follows.
Theorem 2 (Theorem 5 of [24]). Let X âŠ† Rd be compact and convex, d âˆˆ N. Assume the kernel
function satisfies k(x, x0 ) â‰¤ 1.
7


1. Exponential spectral decay. For the squared Exponential kernel: Î³TÎ¸ = O (log T )d+1 .
Î¸
2. Power law spectral decay. For
 MateÌrn kernels with degree of freedom Î½ > 1: Î³T =
d(d+1)/(2Î½+d(d+1))
O T
log T .

The proof of Theorem 1 is provided in the appendix. We sketch the main ideas here. Our proof
methodology is inspired by the works of [24] and [6].
We start the proof-sketch by considering the instantaneous regret:
rt

= f (xâˆ— ) âˆ’ f (xt )
=

+
(f (xâˆ— ) âˆ’ Âµ+
Î¸ t ) âˆ’ (f (xt ) âˆ’ ÂµÎ¸ t )

EI
where Âµ+
Î¸ t = maxxâˆˆX Âµtâˆ’1 (x; Î¸ t ) and xt = arg maxxâˆˆX Î±Î¸ t (x|Dtâˆ’1 ). T

The first challenge of the proof is to bound the difference between the posterior mean of the GP and
the objective function. Such a bound allows us to quantify the difference between our belief about
the objective function and the true objective. Specifically, we bound |Âµtâˆ’1 (x, Î¸ t ) âˆ’ f (x)| âˆ€x âˆˆ X
in each iteration with high probability. By way of the Cauchy-Schwarz inequality,

1/2
Î¸t
|Âµtâˆ’1 (x, Î¸ t ) âˆ’ f (x)| â‰¤
Ktâˆ’1
(x, x)
kÂµtâˆ’1 (Â·; Î¸) âˆ’ f (Â·)kKÎ¸t
tâˆ’1

â‰¤

Ïƒtâˆ’1 (x; Î¸ t )kÂµtâˆ’1 (Â·; Î¸) âˆ’ f (Â·)kKÎ¸t .
tâˆ’1

The first part of our proof (Section A.1 in the appendix) is then dedicated to providing a probabilistic bound for kÂµtâˆ’1 (Â·; Î¸) âˆ’ f (Â·)kKÎ¸t by means of concentration inequalities. In more detail,
tâˆ’1

Lemma 3 and 4 bound separate terms that appear in kÂµtâˆ’1 (Â·; Î¸) âˆ’ f (Â·)kKÎ¸t using properties of retâˆ’1
producing kernel Hilbert spaces and concentration results for sub-Gaussian random variables [12].
Proposition 1 combines the aforementioned results via a union bound.
The second challenge of the proof is to relate EI with quantities that are easier to analyse, such as
the posterior variance and the improvement function ItÎ¸ (x) = max{0, f (x) âˆ’ Âµ+
Î¸ }. To bound the
instantaneous regret, we observe that
i
h
Î¸t
+
+
Î¸
Ïƒ
(x
;
Î¸
)
.
âˆ’
Âµ
(x
;
Î¸
))
+
Ï•
)
â‰¤
I
(x)
+
(Âµ
)
âˆ’
(f
(x
)
âˆ’
Âµ
(f (xâˆ— ) âˆ’ Âµ+
tâˆ’1
t
t
tâˆ’1
t
t
t
t
t
Î¸t
Î¸t
Î¸t
(Here Ï•Î¸t t is a quantity that arises in the concentration bound of Proposition 1.) The improvement function is upper-bounded by a constant times the expected improvement Î±Î¸EIt (xt |Dtâˆ’1 ) via
Lemma 9, which builds on results by [6]. The expected improvement is in turn bounded by a multiple of the posterior standard deviation Ïƒtâˆ’1 (xt ; Î¸ t ).
Next, we turn our attention to the term (Âµ+
âˆ’ Âµtâˆ’1 (xt ; Î¸ t )). We bound this term in Lemma 10,
pÎ¸t
log(t
âˆ’ 1 + Ïƒ 2 ) âˆ’ log(Ïƒ 2 )Î½Ïƒtâˆ’1 (xt ; Î¸ t ).
which states that Âµtâˆ’1 (xt ; Î¸ t ) âˆ’ Âµ+
â‰¤
Î¸t
By now, we have bounded the instantaneous regret in each iteration by a multiple of the pos2
terior variance Ïƒtâˆ’1
(x; Î¸ L ). Finally, we can sum over t and use Lemma 7, which states that
PT
L
2
2
Î¸L
t=t0 Ïƒtâˆ’1 (x; Î¸ ) â‰¤ log(1+Ïƒ 2 ) Î³T , and subsequently bound the cumulative regret by the maximal information gain, which as we said is related to the posterior variance of the GP (Lemma 5). To
accommodate different hyper-parameters, we make use of Lemma 8 from [6].

4

Conclusion

Despite the rapidly growing literature on Bayesian optimisation and the proliferation of software
packages that learn the kernel hyper-parameters, to the best of our knowledge, only Bull [6] and us
have attacked the question of convergence of GP-based Bayesian optimisation with unknown hyperparameters. Bullâ€™s results focused on deterministic objective functions. Our new results apply to the
abundant class of noisy objective functions.

8

References
[1] J. Azimi, A. Jalali, and X.Z. Fern. Hybrid batch bayesian optimization. In ICML, 2012.
[2] R. Benassi, J. Bect, and E. Vazquez. Robust Gaussian process-based global optimization using a fully
Bayesian expected improvement criterion. In Learning and Intelligent Optimization, pages 176â€“190.
Springer, 2011.
[3] J. Bergstra, R. Bardenet, Y. Bengio, and B. KeÌgl. Algorithms for hyper-parameter optimization. In NIPS,
pages 2546â€“2554, 2011.
[4] E. Brochu, T. Brochu, and N. de Freitas. A Bayesian interactive optimization approach to procedural
animation design. In ACM SIGGRAPH / Eurographics SCA, pages 103â€“112, 2010.
[5] E. Brochu, V. M. Cora, and N. de Freitas. A tutorial on Bayesian optimization of expensive cost functions,
with application to active user modeling and hierarchical reinforcement learning. Technical Report UBC2009-23 and arXiv:1012.2599v1, 2009.
[6] A. D. Bull. Convergence rates of efficient global optimization algorithms. Journal of Machine Learning
Research, 12:2879â€“2904, 2011.
[7] K. Finley. Netflix is building an artificial brain using Amazons cloud, February, Wired.com 2014.
[8] R. Garnett, M. A. Osborne, and S. J. Roberts. Bayesian optimization for sensor set selection. In
ACM/IEEE IPSN, pages 209â€“219. ACM, 2010.
[9] P. Hennig and C.J. Schuler. Entropy search for information-efficient global optimization. Journal of
Machine Learning Research, 13:1809â€“1837, 2012.
[10] M.W. Hoffman, E. Brochu, and N. de Freitas. Portfolio allocation for Bayesian optimization. In UAI,
pages 327â€“336, 2011.
[11] M.W. Hoffman, B. Shahriari, and N. de Freitas. On correlation and budget constraints in model-based
bandit optimization with application to automatic machine learning. In AIStats, pages 365â€“374, 2014.
[12] D. Hsu, S. M. Kakade, and T. Zhang. A tail inequality for quadratic forms of subgaussian random vectors.
Electronic Communications in Probability, 17(52):1â€“6, 2012.
[13] F. Hutter, H. H. Hoos, and K. Leyton-Brown. Sequential model-based optimization for general algorithm
configuration. In LION, pages 507â€“523, 2011.
[14] D.R. Jones. A taxonomy of global optimization methods based on response surfaces. J. of Global Optimization, 21(4):345â€“383, 2001.
[15] D.R. Jones, M. Schonlau, and W.J. Welch. Efficient global optimization of expensive black-box functions.
J. of Global optimization, 13(4):455â€“492, 1998.
[16] D. Lizotte, T. Wang, M. Bowling, and D. Schuurmans. Automatic gait optimization with Gaussian process
regression. In IJCAI, pages 944â€“949, 2007.
[17] N. Mahendran, Z. Wang, F. Hamze, and N. de Freitas. Adaptive MCMC with Bayesian optimization. In
AIStats, pages 751â€“760, 2012.
[18] R. Marchant and F. Ramos. Bayesian optimisation for intelligent environmental monitoring. In IROS,
pages 2242â€“2249, 2012.
[19] R. Martinez-Cantin, N. de Freitas, A. Doucet, and J. A Castellanos. Active policy learning for robot
planning and exploration under uncertainty. RSS, 2007.
[20] J. MocÌŒkus. The Bayesian approach to global optimization. In Systems Modeling and Optimization,
volume 38, pages 473â€“481. Springer, 1982.
[21] M. A. Osborne, R. Garnett, and S. J. Roberts. Gaussian processes for global optimisation. In LION, 2009.
[22] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2006.
[23] J. Snoek, H. Larochelle, and R. P. Adams. Practical Bayesian optimization of machine learning algorithms. In NIPS, pages 2951â€“2959, 2012.
[24] N. Srinivas, A. Krause, S. M. Kakade, and M. Seeger. Gaussian process optimization in the bandit setting:
No regret and experimental design. In ICML, pages 1015â€“1022, 2010.
[25] K. Swersky, J. Snoek, and R. P. Adams. Multi-task Bayesian optimization. In NIPS, pages 2004â€“2012,
2013.
[26] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In KDD, pages 847â€“855, 2013.
[27] Z. Wang, B. Shakibi, L. Jin, and N. de Freitas. Bayesian multi-scale optimistic optimization. In AIStats,
pages 1005â€“1014, 2014.
[28] Z. Wang, M. Zoghi, D. Matheson, F. Hutter, and N. de Freitas. Bayesian optimization in high dimensions
via random embeddings. In IJCAI, pages 1778â€“1784, 2013.

9

A
A.1

Proofs
Concentration



a2
Lemma 1. If T is Ïƒ-sub-Gaussian, then P(|T | â‰¥ a) â‰¤ 2 exp âˆ’ 2Ïƒ
âˆ€a > 0.
2
Proof. By Markovâ€™s inequality, we can see that âˆ€Ï > 0
 2 2

E [exp(ÏT )]
Ïƒ Ï
P (T â‰¥ a) = P [exp(ÏT ) â‰¥ exp(Ïa)] â‰¤
â‰¤ exp
âˆ’ Ïa .
exp(Ïa)
2


a2
By taking Ï = Ïƒa2 , we have that P(T â‰¥ a) â‰¤ exp âˆ’ 2Ïƒ
. By symmetry, we have that P(|T | â‰¥
2


2
a
a) â‰¤ 2 exp âˆ’ 2Ïƒ
.
2

Lemma 2. Let t be independently Ïƒ-sub-Gaussian with t âˆˆ {1, Â· Â· Â· , T }. Then,
(kÎ»kÏƒ)-sub-Gaussian.
Proof. For all Ï âˆˆ R, we have
"
!#
T
X
E exp Ï
Î»t t

"
= E

t=1

T
Y

#
exp (ÏÎ»t t ) =

t=1

â‰¤

T
Y

T
Y

PT

t=1

Î»t t is

E [exp (ÏÎ»t t )]

t=1


exp

t=1

Ï2 Î»2t Ïƒ 2
2


= exp

Ï2 Ïƒ 2

PT

t=1

2

Î»2t

!
.

To shorten the notation, in the remainder of this paper, we will use fT to denote the vector
(f1 , . . . , fT ) = (f (x1 ), . . . , f (xT )) and, similarly, we use T in place of 1:T and yT in place
of y1:T .

Lemma 3. fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T is kf kHÎ¸ (X ) -sub-Gaussian.
Proof. Consider the optimization problem
min
gâˆˆHÎ¸ (X )

T
X

2

[g(xt ) âˆ’ ft ] + Ïƒ 2 kgk2HÎ¸ (X ) .

(18)

t=1

By the Representer Theorem of the RKHS, we know that g(x) = Î»T kÎ¸T (x). (We remind the reader
of our notation: KÎ¸T = KÎ¸ (x1:T , x1:T ) and kÎ¸T (x) = kÎ¸ (x1:T , x).) The preceding optimisation
problem is therefore equivalent to the following one:
min
Î»

T h
i2
X
Î»T kÎ¸T (xt ) âˆ’ ft + Ïƒ 2 Î»T KTÎ¸ Î».

(19)

t=1

The optimizer of (19) is Î» = fTT (KTÎ¸ + Ïƒ 2 I)âˆ’1 , with optimum value Ïƒ 2 fTT (KTÎ¸ + Ïƒ 2 I)âˆ’1 fT . Using
Lemma 2, with Î» = fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 , we notice that we only need to bound Î»T Î». Proceeding,
Î»T Î»

tr(fTT (KTÎ¸ + Ïƒ 2 I)âˆ’2 fT )
1 T Î¸ âˆ’1
â‰¤
f (KT ) fT
Ïƒ2 T
1
â‰¤
kf k2HÎ¸ (X )
Ïƒ2

=

10

(20)
(21)
(22)

The first inequality follows by choosing a constant C1 = Ïƒ1 so that the quadratic term (KTÎ¸ )2i,j upperbounds the linear term C12 (KTÎ¸ )i,j . The last inequality holds because of the fact that fTT (KTÎ¸ )âˆ’1 fT
is the minimum value for the optimization problem:
min
gâˆˆHÎ¸ (X )

s.t.

kgk2HÎ¸ (X )
g(xt ) = ft for t = 1, . . . , T

for which f satisfies the constraint. That is, the function g(Â·) that agrees with f (xt ) has minimum
norm fTT (KTÎ¸ )âˆ’1 fT . Hence, any other function f (Â·) that agrees with f (xt ) must have equal or larger
norm.


q
Lemma 4. P Ïƒ âˆ’2 kT k2 âˆ’ TT (KÎ¸T + Ïƒ 2 I)âˆ’1 T > 2Î³TÎ¸ + 2 2Î³TÎ¸ Î· + 2ÏƒÎ· â‰¤ eâˆ’Î· for any Î· >
0.
Proof. First, by rearrangement we have that:


Ïƒ âˆ’2 kT k2 âˆ’ TT (KÎ¸T + Ïƒ 2 I)âˆ’1 T = TT Ïƒ âˆ’2 I âˆ’ (KÎ¸T + Ïƒ 2 I)âˆ’1 T = TT QT Î£QT
In
equation QT Î£Q is the eigenvalue decomposition of the matrix Î›
 âˆ’2the above
Ïƒ I âˆ’ (KÎ¸T + Ïƒ 2 I)âˆ’1 where Q is an orthonormal matrix and Î£ is a diagonal matrix.

:=

The diagonal entries of Î› are such that Î£i,i = Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) where âˆ†i is the ith eigenvalue of KÎ¸T . We
2
PT
PT 
know that tr(Î›) = tr(Î£) = i=1 Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) and tr(Î›2 ) = tr(Î£2 ) = i=1 Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) . It is
PT
easy to see that tr(Î›) â‰¤ Ïƒ âˆ’2 i=1 log(1 + Ïƒ âˆ’2 âˆ†i ) since Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) â‰¤ Ïƒ âˆ’2 log(1 + Ïƒ âˆ’2 âˆ†i ) for all
PT
1 â‰¤ i â‰¤ T . Also tr(Î›2 ) â‰¤ Ïƒ âˆ’4 i=1 log(1 + Ïƒ âˆ’2 âˆ†i ) since Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) < Ïƒ âˆ’2 for all 1 â‰¤ i â‰¤ T .
q
Finally, kÎ›k2 = max1â‰¤iâ‰¤T Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) â‰¤ Ïƒ âˆ’1 again because of the fact that Ïƒ2 (âˆ†âˆ†i i+Ïƒ2 ) â‰¤ Ïƒ âˆ’2 .
Using the definition of maximum information gain Î³TÎ¸ for Gaussians, we have the following three
facts:
tr(Î›) â‰¤ 2Ïƒ âˆ’2 Î³TÎ¸

(23)

tr(Î›2 ) â‰¤ 2Ïƒ âˆ’4 Î³TÎ¸

(24)

kÎ›k2

â‰¤ Ïƒ

âˆ’1

.

(25)

By Theorem 2.1 of [12], we have that




q
q
T
Î¸
T
2
âˆ’2 Î¸
âˆ’1
Î¸
Î¸
âˆ’4
P T Î›T > 2Î³T + 2 2Î³T Î· + 2ÏƒÎ· = P T Î›T > Ïƒ (2Ïƒ Î³T + 2 2Ïƒ Î³T Î· + 2Ïƒ Î·)


q
2
T
â‰¤ P T Î›T > tr(Î›) + 2 tr(Î› )Î· + 2kÎ›kÎ·
(26)
â‰¤ eâˆ’Î·

(27)

which concludes the proof.
q
q
2 2
2 2
Proposition 1. Let (Ï•Î¸T )2 = kf k2HÎ¸ (X ) + 8Î³TÎ¸ âˆ’1 log( T 3Î´Ï€ )+ 2 log( 2T3Î´Ï€ )kf kHÎ¸ (X ) +2Î³TÎ¸ âˆ’1 +


2 2
2Ïƒ log( T 3Î´Ï€ ). Then P kÂµT (Â·; Î¸) âˆ’ f (Â·)kKTÎ¸ â‰¤ Ï•Î¸T +1 â‰¥ 1 âˆ’ Ï€2 (T6Î´+1)2 .
Proof. Let kf kKTÎ¸ denote the RKHS norm of f (Â·) associated with the posterior covariance KTÎ¸ of
the GP (equation (4)). From Lemma 7.2 of [24], we have
kÂµt (Â·; Î¸) âˆ’ f (Â·)k2KÎ¸

T

= kf k2HÎ¸ (X ) âˆ’ yTT (KÎ¸T + Ïƒ 2 I)âˆ’1 yT + Ïƒ âˆ’2 kT k2 .
11

(28)

This expression, with yT = fT + T , can be easily bounded
kÂµT (Â·; Î¸) âˆ’ f (Â·)k2KÎ¸

kf k2HÎ¸ (X ) âˆ’ fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 fT âˆ’ 2fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T

=

T

âˆ’TT (KÎ¸T + Ïƒ 2 I)âˆ’1 T + Ïƒ âˆ’2 kT k2
kf k2HÎ¸ (X ) âˆ’ 2fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T âˆ’ TT (KÎ¸T + Ïƒ 2 I)âˆ’1 T + Ïƒ âˆ’2 kT k2 .

â‰¤

Next, we prove that 2fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T and Ïƒ âˆ’2 kT k2 âˆ’ TT (KÎ¸T + Ïƒ 2 I)âˆ’1 T are bounded with
high probability.

By Lemma 3 we know that fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T is kf kHÎ¸ (X ) -sub-Gaussian. Hence, we can apply
the concentration result of Lemma 1 to this variable, as follows:
"
#
r
2 Ï€2
4(T
+
1)
P |2fTT (KÎ¸T + Ïƒ 2 I)âˆ’1 T | â‰¥ 2 log(
)kf kHÎ¸ (X )
6Î´
ï£¶
ï£«
2 2
Ï€
)kf k2HÎ¸ (X )
2 log( 4(T +1)
6Î´
ï£¸
â‰¤ 2 exp ï£­âˆ’
2kf k2HÎ¸ (X )
6Î´
.
+ 1)2

=

2Ï€ 2 (T
2

(29)

2

Ï€
By Lemma 4, with the choice Î· = log( 2(T +1)
), we obtain
6Î´


q
2
kT k
6Î´
T
Î¸
2 âˆ’1
Î¸
Î¸
P
âˆ’ T (KT + Ïƒ I) T > 2Î³T + 8Î³T Î· + 2ÏƒÎ· â‰¤
.
2
2
Ïƒ
2Ï€ (T + 1)2

Finally, we can use a union bound to combine these two results, yielding
h
i
6Î´
P kÂµT (Â·; Î¸) âˆ’ f (Â·)kKTÎ¸ â‰¥ Ï•Î¸T â‰¤ 2
.
Ï€ (T + 1)2

A.2

Supporting lemmas

Lemma 5 (Lemma 5.3 of [24]). The information gain for the points selected can be expressed in
terms of the predictive variances. That is
T

IÎ¸ (yT ; fT ) =


1X
log 1 + Ïƒ âˆ’2 Ïƒtâˆ’1 (xt ; Î¸)
2 t=1

0

Lemma 6. If Î¸ 0 â‰¤ Î¸, then Î³TÎ¸ â‰¤ Î³TÎ¸ .
Proof. By definition there exist a set A such that Î³TÎ¸ = IÎ¸ (yA ; fA ). Hence, using Lemma 5,
Î³TÎ¸

= IÎ¸ (yA ; fA )

1 X
=
log 1 + Ïƒ âˆ’2 Ïƒtâˆ’1 (xt ; Î¸)
2
xt âˆˆA

1 X
â‰¤
log 1 + Ïƒ âˆ’2 Ïƒtâˆ’1 (xt ; Î¸ 0 )
2
xt âˆˆA
"
#

1 X
0
âˆ’2
â‰¤
max
log 1 + Ïƒ Ïƒtâˆ’1 (xt ; Î¸ )
BâŠ‚X :|B|=T 2
xt âˆˆB

=

0
Î³TÎ¸ .

12

Lemma 7 (Based on Lemma 5.4 of [24]).
Proof. Since s2 â‰¤

1
Ïƒ 2 log(1+Ïƒ 2 )

T
X

PT

t=1

2
Ïƒtâˆ’1
(x; Î¸) â‰¤

2
Î¸
log(1+Ïƒ 2 ) Î³T .

log(1 + s2 ), we have that by Lemma 5

2
Ïƒtâˆ’1
(x; Î¸) â‰¤

t=1

T
X
t=1

=
â‰¤

Ïƒ2
2
log(1 + Ïƒ âˆ’2 Ïƒtâˆ’1
(x; Î¸))
Ïƒ 2 log(1 + Ïƒ 2 )

2
IÎ¸ (yT ; fT )
log(1 + Ïƒ 2 )
2
Î³Î¸ .
log(1 + Ïƒ 2 ) T

(30)

Lemma 8 (Lemma 4 of [6]). If f âˆˆ HÎ¸ (X ), then f âˆˆ HÎ¸0 (X ) for all 0 < Î¸ 0 â‰¤ Î¸ and
!
d
Y
Î¸i
2
kf kHÎ¸0 (X ) â‰¤
kf k2HÎ¸ (X ) .
0
Î¸
i=1 i
A.3

Properties of the expected improvement acquisition function

Lemma 9 (Based on Lemma 8 of [6]). Let Ï•Î¸t be as defined in Proposition 1 and Î½ > 0. Assume
that |Âµtâˆ’1 (x, Î¸) âˆ’ f (x)| â‰¤ Ï•Î¸t Ïƒtâˆ’1 (x; Î¸). For x âˆˆ X , t âˆˆ N, set Âµ+
Î¸ = maxxâˆˆX Âµtâˆ’1 (x, Î¸), and
}.
Then
for
ItÎ¸ (x) = max{0, f (x) âˆ’ Âµ+
Î¸
Ï„ (z) := zÎ¦(z) + Ï†(z),
we have that


Ï„ (âˆ’Ï•Î¸t /Î½) Î¸
Î¸
Î¸
max It (x) âˆ’ Ï•t Ïƒtâˆ’1 (x; Î¸),
I (x) â‰¤ Î±Î¸EI (x|Dtâˆ’1 ) â‰¤ ItÎ¸ (x) + (Ï•Î¸t + Î½)Ïƒtâˆ’1 (x; Î¸)
Ï„ (Ï•Î¸t /Î½) t
Proof. If Ïƒtâˆ’1 (x; Î¸) = 0, then Î±Î¸EI (x|Dtâˆ’1 ) = ItÎ¸ (x) which makes the result trivial. Thus for the
f (x)âˆ’Âµ+

Âµ

(x,Î¸)âˆ’Âµ+

Î¸
Î¸
remainder of the proof, we assume that Ïƒtâˆ’1 (x; Î¸) > 0. Set q = Ïƒtâˆ’1 (x;Î¸)
, and u = tâˆ’1
Ïƒtâˆ’1 (x;Î¸) .
Then we have that
u
Î±Î¸EI (x|Dtâˆ’1 ) = Î½Ïƒtâˆ’1 (x; Î¸)Ï„
.
Î½
By the assumption, we have that |u âˆ’ q| < Ï•Î¸t . As Ï„ 0 (z) = Î¦(z) âˆˆ [0, 1], Ï„ is non-decreasing and
Ï„ (z) â‰¤ 1 + z for z > 0. Hence,


max{0, q} + Ï•Î¸t
Î±Î¸EI (x|Dtâˆ’1 ) â‰¤ Î½Ïƒtâˆ’1 (x; Î¸)Ï„
Î½


max{0, q} + Ï•Î¸t
â‰¤ Î½Ïƒtâˆ’1 (x; Î¸)
+1
Î½

Î¸
Î¸
= It (x) + Ï•t + Î½ Ïƒtâˆ’1 (x; Î¸)

If ItÎ¸ (x) = 0, then the lower bound is trivial as Î±Î¸EI (x|Dtâˆ’1 ) is non-negative. Thus suppose ItÎ¸ (x) >
0. Since Î±Î¸EI (x|Dtâˆ’1 ) â‰¥ 0, and Ï„ (z) â‰¥ 0 for all z, and Ï„ (z) = z + Ï„ (âˆ’z) â‰¥ z. Therefore,


q âˆ’ Ï•Î¸t
Î±Î¸EI (x|Dtâˆ’1 ) â‰¥ Î½Ïƒtâˆ’1 (x; Î¸)Ï„
Î½


q âˆ’ Ï•Î¸t
â‰¥ Î½Ïƒtâˆ’1 (x; Î¸)
Î½
â‰¥ ItÎ¸ (x) âˆ’ Ï•Î¸t Ïƒtâˆ’1 (x; Î¸).
13

(31)

Also, as Ï„ is increasing,
Î±Î¸EI (x|Dtâˆ’1 )


â‰¥ Î½Ïƒtâˆ’1 (x; Î¸)Ï„

âˆ’Ï•Î¸t
Î½


.

(32)

Combining (31) and (32), we get
Î±Î¸EI (x|Dtâˆ’1 ) â‰¥

Ï•Î¸t

Î½Ï„ (âˆ’Ï•Î¸t /Î½)
Ï„ (âˆ’Ï•Î¸t /Î½) Î¸
ItÎ¸ (x) =
I (x)
Î¸
+ Î½Ï„ (âˆ’Ï•t /Î½)
Ï„ (Ï•Î¸t /Î½) t

which concludes the proof.
Lemma 10. Âµtâˆ’1 (xt ; Î¸ t ) âˆ’ Âµ+
Î¸t â‰¤

p
log(t âˆ’ 1 + Ïƒ 2 ) âˆ’ log(Ïƒ 2 )Î½Ïƒtâˆ’1 (xt ; Î¸ t )

Proof. For convenience, define x+
= arg maxxâˆˆX Âµtâˆ’1 (x; Î¸ t ).
Recall that Âµ+
=
t
Î¸t
maxxâˆˆX Âµtâˆ’1 (x; Î¸ t ). Therefore, by the fact that Î±Î¸EIt (xt |Dtâˆ’1 ) = maxxâˆˆX Î±Î¸EIt (x|Dtâˆ’1 ), we have
+
EI
Î½Ïƒtâˆ’1 (x+
t ; Î¸ t )Ï„ (0) = Î±Î¸ t (xt |Dtâˆ’1 )

â‰¤

Î±Î¸EIt (xt |Dtâˆ’1 )

= Î½Ïƒtâˆ’1 (xt ; Î¸ t )Ï„

where Ï„ is defined as in Lemma 9. We know that Ï„ (0) =
as

âˆš1 .
2Ï€

Âµtâˆ’1 (xt ,Î¸ t )âˆ’Âµ+
Î¸t
Î½Ïƒtâˆ’1 (xt ;Î¸ t )

!
,

(33)

Thus, equation (33) can be re-written

Âµtâˆ’1 (xt , Î¸ t ) âˆ’ Âµ+
Î¸t
Î½Ïƒtâˆ’1 (xt ; Î¸ t )

Ïƒtâˆ’1 (x+
;Î¸ )
âˆš t t â‰¤ Ïƒtâˆ’1 (xt ; Î¸ t )Ï„
2Ï€
By the definition of Âµ+
Î¸ t we know that

Âµtâˆ’1 (xt , Î¸ t ) âˆ’ Âµ+
Î¸t
Î½Ïƒtâˆ’1 (xt ; Î¸ t )

!
.

(34)

â‰¤ 0. Therefore

!

Ï„

!
Âµtâˆ’1 (xt , Î¸ t ) âˆ’ Âµ+
Âµtâˆ’1 (xt , Î¸ t ) âˆ’ Âµ+
Î¸t
Î¸t
â‰¤Ï†
Î½Ïƒtâˆ’1 (xt ; Î¸ t )
Î½Ïƒtâˆ’1 (xt ; Î¸ t )
ï£«
!2 ï£¶
Âµtâˆ’1 (xt , Î¸ t ) âˆ’ Âµ+
1
1
Î¸t
ï£¸.
= âˆš exp ï£­âˆ’
2
Î½Ïƒtâˆ’1 (xt ; Î¸ t )
2Ï€

Combining equations (34) and (35), we have
s
Âµt (xt ; Î¸ t ) âˆ’

Âµ+
Î¸t

â‰¤



2 log

(35)


Ïƒtâˆ’1 (xt ; Î¸ t )
Î½Ïƒtâˆ’1 (xt ; Î¸ t ).
Ïƒtâˆ’1 (x+
t ; Î¸t )

2
2
2
Since log(Ïƒtâˆ’1 (xt ; Î¸ t )) â‰¤ 0, it remains to show that âˆ’ log(Ïƒtâˆ’1
(x+
t ; Î¸ t )) â‰¤ log(tâˆ’1+Ïƒ )âˆ’log Ïƒ .
+
2
2
2
To show this, it suffices to show that Ïƒtâˆ’1 (xt ; Î¸ t ) â‰¥ Ïƒ /(t âˆ’ 1 + Ïƒ ). To see this, first note that
+
2
Ïƒtâˆ’1
(x+
t ; Î¸ t ) is minimized if xi = xt âˆ€i â‰¤ t âˆ’ 1. That is
2
T
2 âˆ’1
Ïƒtâˆ’1
(x+
1
t ; Î¸ t ) â‰¥ 1 âˆ’ 1 (J + Ïƒ I)

where J is a matrix of all ones. Notice that J is of rank 1. Let QÎ£QT be the eigen-decomposition
of J such that Î£1,1 = Î» where Î» is the only eigenvalue of J. Since 1 is an eigenvector of J, we
know that Î» = k1k22 and QT 1 = [k1k, 0, Â· Â· Â· , 0]T . Because (J + Ïƒ 2 I)âˆ’1 = Q(Î£ + Ïƒ 2 I)âˆ’1 QT , we
k1k22
have that 1T (J + Ïƒ 2 I)âˆ’1 1 = k1k2 +Ïƒ
2 . Therefore
2

2
Ïƒtâˆ’1
(x+
t ; Î¸t ) â‰¥ 1 âˆ’

k1k22
Ïƒ2
=
k1k22 + Ïƒ 2
k1k22 + Ïƒ 2

which concludes the proof since k1k22 = t âˆ’ 1.
14

A.4

Proof of main result

Proof of Theorem (1). We will need the following definitions Âµ+
Î¸ t = maxxâˆˆX Âµtâˆ’1 (x; Î¸ t ) and xt =
arg maxxâˆˆX Î±Î¸EIt (x|Dtâˆ’1 ). By the Cauchy-Schwarz inequality,

1/2
Î¸t
|Âµtâˆ’1 (x, Î¸ t ) âˆ’ f (x)| â‰¤
Ktâˆ’1
(x, x)
kÂµtâˆ’1 (Â·; Î¸ t ) âˆ’ f (Â·)kKÎ¸t
tâˆ’1

=

Ïƒtâˆ’1 (x; Î¸ t )kÂµtâˆ’1 (Â·; Î¸ t ) âˆ’ f (Â·)kKÎ¸t .
tâˆ’1

By Proposition 1 and the union bound, we know that kÂµtâˆ’1 (Â·; Î¸ t ) âˆ’ f (Â·)kKÎ¸t â‰¤ Ï•Î¸t t for all t â‰¥ 1
tâˆ’1
Pâˆ
holds with probability at least 1 âˆ’ t=1 Ï€6Î´
2 t2 = 1 âˆ’ Î´. Thus for the remainder of the proof, let us
assume that |Âµtâˆ’1 (x, Î¸ t ) âˆ’ f (x)| â‰¤ Ï•Î¸t t Ïƒtâˆ’1 (x; Î¸ t ) âˆ€t âˆˆ N, x âˆˆ X .
The regret at round t is
rt

=

f (xâˆ— ) âˆ’ f (xt )

=

+
(f (xâˆ— ) âˆ’ Âµ+
Î¸ t ) âˆ’ (f (xt ) âˆ’ ÂµÎ¸ t )
i
h
Î¸t
ItÎ¸t (xâˆ— ) + (Âµ+
Î¸ t âˆ’ Âµtâˆ’1 (xt ; Î¸ t )) + Ï•t Ïƒtâˆ’1 (xt ; Î¸ t ) .

â‰¤

(36)

By Lemma 9, which defines the improvement as ItÎ¸ (x) = max{0, f (x) âˆ’ Âµ+
Î¸ }, we know that
 2
Î¸t
Î¸
Ï„ (Ï•tâˆ’1
/Î½t t )
Î¸t
Î¸t
EI
âˆ—
âˆ—
, there exists a constant
Î± (x |Dtâˆ’1 ). By the assumption on Î½t
It (x ) â‰¤
Î¸t
Î¸
Ï„ (âˆ’Ï•tâˆ’1
/Î½t t ) Î¸ t


Î¸t
Î¸t
Ï„ (Ï•t /Î½t )
C3 such that
â‰¤ C3 . By Lemma 10, we also have that (Âµ+
Î¸
Î¸
Î¸ t âˆ’ Âµtâˆ’1 (xt ; Î¸ t )) â‰¤
Ï„ (âˆ’Ï•t t /Î½t t )
q

2
log t+Ïƒ
Î½tÎ¸t Ïƒtâˆ’1 (xt ; Î¸ t ).
Ïƒ2
s

rt

!

2
t
+
Ïƒ
log
Î½tÎ¸t + Ï•Î¸t t Ïƒtâˆ’1 (xt ; Î¸ t )
â‰¤ C3 Î±Î¸EIt (xâˆ— |Dtâˆ’1 ) +
Ïƒ2
s 
!

t + Ïƒ 2 Î¸t
Î¸t
EI
â‰¤ C3 Î±Î¸t (xt |Dtâˆ’1 ) +
log
Î½t + Ï•t
Ïƒtâˆ’1 (xt ; Î¸ t )
Ïƒ2
s 
!



t + Ïƒ 2 Î¸t
Î¸t
Î¸t
Î¸t
Î¸t
â‰¤ C3 It (xt ) + (Ï•t + Î½t )Ïƒtâˆ’1 (x; Î¸ t ) +
log
Î½t + Ï•t
Ïƒtâˆ’1 (xt ; Î¸ t )
Ïƒ2


+
â‰¤ C3 (Âµtâˆ’1 (xt , Î¸ t ) + Ï•Î¸t t Ïƒtâˆ’1 (xt ; Î¸ t ) âˆ’ Âµ+
Î¸t )
s 
!
!
t + Ïƒ2
Î¸t
Î¸t
+ (C3 + 1)Ï•t + C3 + log
Î½t
Ïƒtâˆ’1 (xt ; Î¸ t )
Ïƒ2
s 
!
!
t + Ïƒ2
Î¸t
Î¸t
Î½t
â‰¤
(2C3 + 1)Ï•t + C3 + log
Ïƒtâˆ’1 (xt ; Î¸ t ).
(37)
Ïƒ2


q
âˆš
âˆš
L
1/2
L 2
2
Î¸L
2 2
Î¸
Define (Ï•t ) := C2 kf kH U (X ) + 2Î³tâˆ’1 + 8 log (2t Ï€ /3Î´)
C2 kf kHÎ¸U (X ) + Î³tâˆ’1 +
Î¸

2Ïƒ log(2t2 Ï€ 2 /3Î´). By Lemma 8, we know that kf k2HÎ¸ (X ) â‰¤ C2 kf k2H U (X ) . Also, by Lemma 6,
Î¸
2
L
Î³tÎ¸t â‰¤ Î³tÎ¸ . Therefore, (Ï•Î¸t t )2 â‰¤ Ï•L
.
t
s
rt

â‰¤

(2C3 +

1)Ï•L
t

(2C3 +

1)Ï•L
t

+

C3 +


log

s
â‰¤

+

C3 +


log

15

t + Ïƒ2
Ïƒ2

!

t + Ïƒ2
Ïƒ2

!

!
L
Î½tÎ¸

Ïƒtâˆ’1 (xt ; Î¸ t )
!

L
Î½tÎ¸

Ïƒtâˆ’1 (xt ; Î¸ L ).

(38)

To simplify notation, let t0 be such that log

T
X

rt2

â‰¤

t=t0

â‰¤

â‰¤

t0
Ïƒ2



> 1 and WLOG assume C3 > 1. Then

!2

t
Î¸L
2
Ïƒtâˆ’1
Î½t
(x; Î¸ L )
(2C3 + 1)
+ log
2
Ïƒ
t=t0

 

T
X
t
2
L 2
Î¸L 2
2
(Î½t ) Ïƒtâˆ’1
2(2C3 + 1) (Ï•t ) + log
(x; Î¸ L )
2
Ïƒ
t=t0

 
X
T
T
2
L 2
Î¸L 2
2
2(2C3 + 1) (Ï•T ) + log
(Î½
)
Ïƒtâˆ’1
(x; Î¸ L ).
T
Ïƒ2
t=t
s

T
X

2

Ï•L
t



(39)

0

L

PT

2
Î¸
2
Ïƒtâˆ’1
(x; Î¸ L ) â‰¤ log(1+Ïƒ
2 ) Î³T . Finally, applying the CauchyP
T
Schwarz inequality yields RT2 â‰¤ T t=1 rt2 thus concluding the proof.

By Lemma 7, we know that

t=t0

16

