function which is the result of conditioning on B
being true. We define the conditional belief as the
lower en'llelope (that is, the infimum) of a family
of conditional probability functions, and provide a
closed-form expression for it. We show by example
the intuitive appeal of our definition, and compare
it in detail to the more standard definition, showing
why and how it differs.
belief,

1

Introduction

How should one update one's belief given new ev­
idence? If beliefs are expressed in terms of proba­
bility, then the standard approach is to use condi­
tioning. If an agent's original estimate of the prob­
ability of A is given by Pr(A), and then some new
evidence, say B, is acquired, then the new estimate
is given by the conditional probability Pr(AIB),
defined as Pr(A n B)/Pr(B).1
The Dempster-Shafer approach to reasoning
about uncertainty [Sha76] has recently become
quite popular in expert systems applications (see,
for example, [Abe88, Fal88, LU88, LG83]). This
approach uses belief functions, a class of functions
that satisfy three axioms, somewhat related to the
axioms of probability. In this paper, we consider
how to define a. notion of conditional belief, which
generalizes conditional probability.
1 Thie definition ie not completely uncontrovereial ( aee,
e.g., [DZ82) for a diecu11ion and further references).

One definition for conditional belief was already
suggested by Dempster [Dem67J, and is derived us­
ing the rule of combination; hereafter we refer to
Dempster's definition a.s the DS definition of con­
ditional belief. Although the DS definition also gen­
eralizes conditional probability, it is well known to
give counterintuitive results in a. number of situa­
tions (see, e.g., [Ait68, Bla87, Dia78, DZ82, Hun87,
Lem86, Pea.88, Pea.89, Za.d84]) We provide here
a. new definition of conditional belief, which also
generalizes conditional probability, but is different
from the DS definition in general. We can show
that our definition avoids many of the problems as­
sociated with the DS definition.
The motivation for our definition of conditional
belief comes from probability theory. It is well
known that a. belief function Bel is the lower en­
'l!elope of the family of a.ll probability functions Pr
consistent with Bel. That is, Bel(A) is the infimum
of Pr(A), where the infimum is taken over a.ll pro.b­
a.bility functions Pr such that Bel(A') � Pr(A') for
a.ll A'.2 We define Bel(AIB) to be the lower enve­
lope of the family of a.ll functions Pr(·IB) where
Pr is consistent with Bel (similarly to the situa­
tion with conditional probability, we assume that
Bel(B) > 0, so that everything is well defined).
Although we define Bel( ·IB) in terms ofa.lower en­
velope, we show that there is an elegant closed form
expression for it. Moreover, we can show that just
a.s the conditional probability function is in fact a
probability function, our conditional belief function
is a belief function.
The rest of this paper is organized as follows. In
the next section, we review belief functions and de­
fine our notion conditional belief. We show how it
compares to the DS notion by applying both defiSome author& (e.g., [DP88]) have used the term lower
to denote what we are calling lower envelopes.
We have ueed the term lower envelope here to avoid con·
fuaion with Dempeter'& technical uaage of the phraae lower
probability in [Dem67, Dem68J, which, although related, is
not equivalent to what we are calling a lower envelope.
2

probability

318

nitions to the well-known three pri1oner1 problem
[Gar61, Dia78]. We then conduct a more thor­
ough investigation of the differences between the
two notions, and their relationship to conditional
probability, showing why the DS notion occasion­
ally provides counterintuitive answers. In Section 4
we discuss the relationship between belief functions
and sets of probability functions. We conclude in
Section 5 with some discussion on the implications
of our results to the use of belief functions.
2

Updating belief functions

Recall that a probability space is a tuple (S, X, Pr),
where S is the sample space, X is a collection of sub­
sets of S containing S and closed under complemen­
tation and countable union, and Pr is a probability
function defined on X. Note that Pr is defined not
on all subsets of S, but only on the sets in X, tra­
ditionally called the mea1urable sets. Subsets of S
not in X are called nonmea1urable.
The Dempster-Shafer theory of evidence [Sha76]
provides an approach to attaching likelihoods to
events that is different from probability theory. The
theory starts out with a belief function. For every
event (i.e., set) A, the belief in A, denoted Bel(A),
is a number in the interval [0, 1] that places a lower
bound on likelihood of A. We have a corresponding
number Pl(A) = 1- Bel(A), called the plausibility
of A, which places an upper bound on the likelihood
of A. Thus, to every event A we can attach the in­
terval [Bel(A), Pl(A)]. Like a probability measure,
a belief function assigns a "weight" to subsets of a
set S, but unlike a probability measure, the domain
of a belief function is always taken to be all subsets
of S. Formally, a belief function Bel on a set S is
a function Bel: 2 5 -+ [0, 1] satisfying:
BO. Bel(0)

=

0

Bl. •Bel(A)� 0
B2. Bel(S)
B3. Bel(A1

=

1

A.�:)�
LI!;{l,...,A:},I:f:0 (-1)111+1 Bel(niEI Ai).
u ... u

We remark that a probability function defined on
all of 2 5 is easily seen to be a belief function.
In a companion paper [HF90], we argue that
there are two quite distinct ways of relating be­
lief functions to probability theory. One approach
views belief as a generalized probability; the sec­
ond views it as a way of representing evidence. H
we would like to update beliefs, then it seems most
appropriate to view beliefs as generalized probabil­
ities. There are a number of ways of doing this

[Dem67, Dem68, FH89b, Kyb87, Sha79]. We fo­
cus on one here, since it is perhaps the most well
known: that is the approach of viewing a belief
function as an infimum of a family of probability
functions. Given a set 1' of probability functions
all defined on a sample space S, define the lower
en11elope of 1' to be the function J such that for
each A� S, we have f(A) = inf {Pr(A) : Pr E 1'}.
We have the corresponding definition of the upper
en'!Ielope of 1'. It was already known to Dempster
[Dem67) that a belief function can be viewed as a
lower envelope. More formally, let Bel be a belief
function defined on S, and let (S, X, Pr) be a prob­
ability space with sample space S. We say that Pr
is consistent with Bel if Bel(A) � Pr(A) � Pl(A)
for each A E X. Intuitively, Pr is consistent
with Bel if the probabilities assigned by Pr are
consistent with the intervals [Bel(A), Pl(A)] given
by the belief function Bel. It is easy to see that
Pr is consistent with Bel if Bel(A) � Pr(A) for
each A E X (that is, it follows automatically that
Pr(A) � PI(A) fo� each A E Xl:_ This is because
Pl(A) = 1 - Bel(A) �· 1 - Pr(A) = Pr(A). Let
1'Bel be the set of all probability functions defined
on 2 5 consistent with Bel. The next theorem tells
us that the belief function Bel is the lower envelope
of 1'Bel1 and Pl is the upper envelope.
Theorem 2.1: Let Bel be a belief function on S.
Then for all

A� S,

Bel(A) = infp,e-p8,1 Pr(A)
Pl(A) = supp, E 'Ps ., Pr(A).
We remark that the converse to Theorem 2.1
does not hold: not every lower envelope is a be­
lief function. Counterexamples are well known
[Bla87, Dem67, Kyb87]. We return to this issue
in Section 3.
Theorem 2.1 suggests how we might update a
belief function to a conditional belief function (and
a plausibility function to a conditional plau1ibility
function). We define:
Bel(AIB)

=

Pl(AIB) =

inf

Pr(AiB)

sup

Pr(AiB).

P•E'Psel
P•E'Psel

It is not hard to see that the infimum and supre­
mum above are not well-defined unless Bel(B) > 0;
therefore, we define Bel(AIB) and Pl(AIB) only if
Bei(B) > 0. It is straightforward to check that if
Bel is actually the probability function Pr, then
Bel(AlB) = Pr(AIB). Thus, our definition of con­
ditional belief generalizes that of conditional prob­
ability. Note that taking B = true in the preceding

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

319

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

definition, we get as a special case that Bei(A) =

infp,e1'8,1 Pr(A) and Pl(A) = supp,E1'
s.t Pr(A),

which is Theorem 2.1 above.
Our definition of conditional belief and plausibil­
ity does not give us much help in computing these
expressions. We would like to have a closed-form
expression for them. We can in fact provide an
elegant closed-form expression, as shown in the fol­
lowing theorem.
Theorem 2.2: If Bel is a belief function on S such

that Bei(B) >
Bei(AIB)

O,

=

Pl(AIB) =

then
Bel(A n B)
Bel(An B)+ Pl(A n B)
PI(An B)

Pl(An B)+ Bel(A n B)

The expressions given above for conditional belief
and plausibility are quite natural. Not sm.11risingly,
it turns out that other authors have discovered
them as well. In particular, essentially these ex­
pressions appear in [Wal81], [SK89], and [dCLM90].
Indeed, it even appears (lost in a. welter of notation)
as Equation 4.8 in [Dem67]! (Interestingly, none of
these papers references any other work as the source
of the formula.)
It is well known that the conditional probability
function is a probability function. That is, if we
start with a probability function Pr on S, and B is
a subset of S such that Pr(B) > 0, then the func­
tion Pr(·IB) is a probability function. We might
hope that the same situation holds with belief func­
tions, so that the conditional belief and plausibility
functions are indeed belief and plausibility func­
tions. Given our definitions of conditional belief
and plausibility as lower and upper envelopes, it is
not clear that this should he so, since lower and up­
per envelopes of arbitrary sets of probability func­
tions do not in general result in belief and plau­
sibility functions. Fortunately, as the next result
shows, in this case they do. Thus, we have a way
of updating belief and plausibility functions to give
us new belief and plausibility functions in the light
of new information.
Theorem 2.3: Let Bel be a belief function defined

on S, and PI the corresponding plausibility func­
tion. Let B � S be such that Bel(B) > 0� Then
Bel(·IB) is a belief junction and Pl(·IB) is the cor­
responding plausibility function.

The proof of Theorem 2.3 is somewhat difficult.
We outline the proof in the appendix; full details
can be found in the full paper [FH89a]. We remark

that this result-which we view as the main tech­
nical result of the paper-appears in none of the
papers cited above that contain the expression for
conditional belief from Tlteorem 2.2. In [dCLM90]
the question of whether Bel( ·IB) is a belief function
is discussed, but left unanswered.
As we mentioned in the introduction, our defi­
nition is quite different from that given by Demp­
ster. Given a belief function Bel , Dempster defines
a conditional belief function Bel(·IIB) as follows
[Sha76, p. 97]:3
Bel(AIIB) =

Bel(Au B)- Bel(B)
.
1- Bel(B)

The corresponding plausibility function is shown to
satisfy:
PI( An B)
Pl(AIIB) =
Pl(B) .
A brief glance at the DS definition compared with
the formula in Theorem 2.2 should convince the
reader that in general these two definitions of con­
ditional belief will not agree. It is easy to show
that both definitions of conditional belief general­
ize the standard definition of conditional probabil­
ity as long as all sets are measurable, that is, have
a probability assigned to them. The key difference
turns out to be in the way they treat nonmeasurable
sets. (See [FH89b] for a discussion of nonmeasur­
able sets and their relationship to belief functions.)
We return to this issue below; we first consider an
example that highlights the differences between the
two approaches.
Example: In order to compare our updating tech­
nique with that of Dempster, we consider the well­
known three prisoner11 problem.4

Of three prisoners a, b, and c, two are
to be executed but a does not know which.
He therefore says to the jailer, "Since ei­
ther b or c is certainly going to be ex­
ecuted, you will give me no information
about my own chances if you give me the
name of one man, either b or c, who is go­
ing to be executed." Accepting this argu­
ment, the jailer truthfully replies, "b will
be executed." Thereupon a feels happier
1Dempacer't definition is uaually

given

aa a special ap­

plication of a more {eneral 1'Uie of combination for belief
functions. It would take us too far afield here co discuaa the

rule of combination; aee the companion paper

(HF90]

for a

ditcuaaion of the role of the rule of combination.
4 For

an excellent introduction to the problem as well a• a

Bayeaian aolution, see

(Gar61].

Our description of the story

ia taken from (Dia78] and much of our discuuion is baaed on
that of Diaconis and Zabell [Dia78, DZ82] .

320

because before the jailer replied, his own

Thus, in this case, the jailer's answer does not affect

chance of execution was two-thirds, but

a's probability.
Suppose more generally that

afterwards there are only two people, him­
self and

c,

= a:,

who could be the one not ex­

one-half.

a

replied, he seems to be implicitly assuming that

I

Pr(aaya-b) = Pr( {(a, b)}) +Pr( {(c, b)})= (a:+1)/3

I

the one to get pardoned is chosen at random from
and

c.

Then straightforward compu­

Pr(livea-a)
= a:/3

to believe that his own

chance of execution was two-thirds before the jailer

a, b,

1.

:5

Pr(livea-ajaaya-b) =

We make this assumption ex­

plicit in the remainder of our discussion.

Is a justified in believing that his chances of es­
caping have improved? It seems that the jailer did
not give him any relevant extra information. Yet
how could a's subjective probabilities change if he

does not acquire any relevant extra information?

X

a:/3
= a:/(a: + 1).
(a: + 1)/3

This says that if a:#;

1/2 ( i.e., if the jailer had a par­
ticular preference for answering either b or c when
a was the one pardoned) , then a would learn some­
thing from the answer, in that he would change his
estimate of the probability that he will be executed.

For example, if

a: =

0, then if a is pardoned, the
Thus, if the jailer actu­

[DZ82], we model a possible situation
by an ordered pair (:c, y), where :c, y E {a, b, c}. In­
tuitively, a pair (:c, y) represents a situation where
:c is pardoned and the jailer says that y will be ex­

jailer will definitely say

ecuted in response to a's question. Since the jailer

c is pardoned, then the jailer will say b, while
if b is pardoned the jailer will say c. Given that
the jailer says b, then from a's point of view the
one pardoned is equally likely to be him or c; thus,
Pr(live•-al•ays-b) = 1/2. As a: ranges from 0 to
1, it is easy to check that Pr(livea-aiaaya-b) ranges
from 0 to 1/2.

Following

answers truthfully, we cannot have

:c

= y;

since

the jailer will never tell a directly that a will be

y = a. Thus, the set
of possible outcomes is {( a, b), (a, c) , (b, c) , ( c, b)}.
The event that a lives, which we denote livea-a,
corresponds to the set {(a, b), (a, c)}. Similarly, we
define the events livea-b and livea-c, which corre­
spond to the sets {(b, c)} and {(c, b)}, respectively.
executed, we cannot have

By assumption, each of these three events has prob­
ability

1/3.

aaya-b,

ally says

b,

pardoned, i.e., that

ilarly, if

c.

then a knows that he is definitely not

a: = 1,

Pr(livea-aiaaya-b) =

0. Sim­

then a knows that if either he

or

How can we capture this situation using a belief

function? It seems reasonable that if
lief function and

PI

Bel

is the be­

the corresponding plausibility

function used to capture the situation, then

Bel

b,

which we de­

should agree with probability function where the

corresponds to the set

{(a, b), (c, b)};

probability is known, so that,

The event that the jailer says
note

a priori, both the
li'lles-a, li'lles-b,

the story does not give us a probability for this

belief and plausibility of the events

event.

li'IJt:s-c should be 1/3. All we know about the
a priori probability of says-b is that it lies between
1/3 and 2/3: it is at least the probability that c
is chosen ( since in that case the jailer must say b),

In order to do a Bayesian analysis of the

situation, we will need this probability. Note that
we do know that the probability of

{(c, b)} is 1/3;
{(a, b)}.

we just need to know the probability of

This depends on the jailer's strategy in the one case
that he has free choice, namely when
gets to choose between saying

b

and

c

a

lives. He

in that case.

We need to know the probability that he says
i.e.,

If

b,

Pr(aaya-bjlivea-a).
we assume that the jailer chooses at ran­

b and c if a is pardoned, so
that Pr(aaya-bjlivea-a) = 1/2, then Pr({(a, b)}) =
Pr( {(a, c)})= 1/6, and Pr(aaya-b) = 1/2. We can
dom between saying

now easily compute that

Pr(livea-ajaaya-b)
= Pr(livea-a n aaya-b)/Pr(aaya-b)
(1/6)/(1/2) = 1/3.

I

Pr(aaya-bjlivea-a)

Pr( {( a, b)})

Note that in order for

a:

tations show that

ecuted, and so his chance of execution is

among

for 0 :5

Pr(aaya-bllives-a)

I

and

and it cannot be more than the probability that

b

Bel satis­
Pl(aay-b) = 2/3. Simi­
we can argue that Bel(livea-a n aaya-b) = 0
Pl(livea-a n aaya-b) = 1/3. Plugging these

is not chosen. Thus, we assume that

fies

Bel(aay-b) = 1/3

larly,
while

and

numbers into our formulas, it is easy to compute
that

1/2.

Bel(livea-aii•aya-b) = Pl(livea-aiiaaya-b) =
Thus,

for the DS notion of conditional

probability, the range reduces to the single point

1/2. By way of contrast, it is easy to check that
Bel(livea-ajaaya-b) = 0 while Pl(livea-ajaaya-b) =
1/2. I
This example shows that the two notions of con­
ditioning can give quite different answers.

The

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

321

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

range [0, 1/2] computed by our notion of condition­
ing is easy to explain: it is precisely the range de­
termined by letting the probability that the jailer
will say b in the one situation that he has a choice
between saying b and c, namely, when a is the one
pardoned, range from 0 to 1. The fact that our
definition gives this range is not an accident! It is
a direct consequence of our definitions and Theo­
rem 2.2.
The range [1/2, 1/2] determined by the DS no­
tion of conditioning seems much more mysterious.
The answer 1/2 corresponds to the situation where
the jailer says b whenever he can (i.e., whenever a is
pardoned or c is pardoned). Why is this a reason­
able answer? More importantly, why does it arise?
Is there a natural probabilistic interpretation for it?
In the full paper, we consider this issue in detail.
The following construction, which is a generaliza­
tion of the "beehive" example in [SK89] (as well
as being a formalization of some comments made
in [dCLM90]), may help provide a partial explana­
tion.
Suppose a set S is partitioned into (nonempty)
disjoints sets X1,
, Xk. An agent chooses X; with
probability a; (where a1 +
+ ak = 1) and then
chooses z: E X; with some unknown probability.
Given subsets A and B of S, we want to know what
the probability is that the element z: chosen is in A,
and the probability that x is in A given that it is in
B. H A = X;, then it is clear that the probability
that x E A is a;. However, if A is not one of the
X;'s, then all we can compute are upper and lower
bounds on the probability.
Let 'P be the set of probability functions on S
consistent with this situation; namely, Pr E 'P iff
Pr(X;) = a;, fori= 1, . .., k. Let Bel be the lower
envelope of 'P; it is not hard to show that Bel is a
belief function (we do so in the full paper). It seems
reasonable to argue that the best lower and upper
bounds we can give on the probability that z: E A
are Bel(A) and Pl(A). Similarly, the best lower
and upper bounds we can give on the probability
that z: E A given that x E B are given by the
infimum and supremum of {Pr(AIB) : Pr E 'P}.
These are precisely Bel(AIB) and Pl(AIB).
Now suppose we slightly change the rules of the
game. We are told that the probabilistic process
that chooses an element in X; will definitely choose
an element in B if possible. This does not affect
anything if X; � B or if X; � B. However, if
X; n B #- 0 and X; n B #- 0, then, rather than
choosing X; with probability a;, the probability is
now redistributed so that X; n B is chosen with
probability a;, while X; n B is chosen with proba•

•

•

·

·

·

bility 0. The probability that used to be spread over
all of X; is now concentrated on X; n B. W hat is
the probability that an element of A is chosen given
that the element chosen is definitely in B with re­
spect to this new process, where an element of B
is chosen whenever possible? We now have to con­
sider the family 'P' of probability functions consis­
tent with this new process, and take the infimum
and supremum of {Pr'(AIB) : Pr E 'P'}. As we
show in the full paper, these bounds are given by
Bel(AIJB) and Pl(AIIB).
Suppose we now reconsider the three prisoners
problem from this point of view. We can now
see that Bel(lives-aiJsays-b) gives the probability
that a lives given the extra hypothesis that the
jailer says b whenever possible. In particular, this
means that the jailer definitely says b if a is the
one that is pardoned; i.e., Pr(says-bJlives-a) = 1.
Under this revised situation, the probability that
a lives given that the jailer says b is indeed ex­
actly 1/2. W ith this understanding of the DS no­
tion of updating, the result Bel(lives-aJJsays-b) =
Pl(lives-aJJsays-b) = 1/2 should come as no sur­
prise.
To sununarize, this discussion has shown that
Bel(AIIB) corresponds to a somewhat unnatural
updating process, where before we condition with
respect to B, we first try to choose an element
in B whenever possible. In terms of the process
discussed above, it is easy to see that this extra
step before updating makes no differen�e if B is
the union of some of the X;'s. This amounts to B
being a measurable set. It will make a difference if
B is not measurable. This is the case in the three
prisoner problem, where says-b is not a measurable
set, and is the cause of the answer 1/2 that we get
when we try to apply DS conditioning in this case.
We remark that this analysis can also be
used to explain the well-known observation that
Bel(AIB) � Bel(AIIB) � Pl(AIIB) � Pl(AIB)
([Dem67, Dem68]; see also [Kyb87]).
Not
only does it show why the interval defined
by [Bel(AlB), Pl(AIB)] contains that defined by
[Bel(AIIB), Pl(AIIB)], it explains when and why
we get equality. See the full paper for details.
3

Belief functions
velopes

and

lower

en­

Theorem 2.1 says that each belief function is the
lower envelope of a set of probability functions, and
each plausibility function an upper envelope. Un­
fortunately, the lower envelope of an arbitrary set
of probability functions is not in general a belief
function, nor is the upper envelope of an arbitrary

322

set of probability functions in general a plausibil­
ity function. Nevertheless, results such as Theo­
rem 2.3 show that there are natural sets of proba­
bility functions that do induce belief and plausibil­
ity functions. Although a general characterization
is lacking, further examples in [F H89b, HF90] sug­
gest that this is not an isolated example.
However, even if a set P of probability functions
does induce a belief and plausibility function, say
Bel and PI, it is reasonable to ask whether we
should represent P by Bel and Pl. Clearly the
answer depends very much on the intended appli­
cation. However, it is worth noting that this rep­
resentation of P might result in a loss of valuable
information. For example, consider a sample space
consisting of three points, say {a, b, c}. Let P con­
sist of all probability functions on S with the follow­
ing three properties: (1) 1/4 � Pr({a}) � 1/2, (2)
1/4 � Pr({b}) � 1/2, and (3) Pr({a}) = Pr({b}).
It is not hard to show that the lower envelope of P
is a belief function. If we call this belief function
Bel and take PI to be the corresponding plausi­
bility function, we get Bel({a}) = Bel({b}) = 1/4
and PI( {a}) = PI( {b}) = 1/2. Thus, we retain
the information that the probability of a and b
both range between 1/4 and 1/2. However, we
have lost the information that the probabilities of
a and b are the same in all the probability func­
tions in P. This loss of information has some se­
rious repercussions. As we show in the full paper
(by extending the example above), one consequence
is that updates do not commute. More precisely,
suppose we start with a belief function Bel on a
set S, observe B � S and then observe C � S.
The result is the belief function BeiB(·IC), where
Be18(A) = Bei(AIB). Similarly, if we observe C
and then B, we get the belief function Belc(·IB).
We might hope that for all sets A, we would have
Be18(AIC) = Belc(AIB) = Bei(AIBAC). That is,
observing B then C should be the same as observ­
ing C then B, which in turn should be the same
as observing B A C. This is certainly the case if
Be l is a probability function, but not in general.
It turns out that the problem here is that informa­
tion is lost as we update the belief function. (See
the full paper for further details of this issue.) By
way of contrast, the DS rule of conditioning is com­
mutative. Conditioning with respect to C and then
with respect to B is equivalent to conditioning with
respect to B A C. However, as we have pointed out,
it has other problems when viewed as a technique
for updating beliefs.
These observations suggest to us that the ques­
tion of the "best" representation of evidence does

not have a unique answer. It may be easier to com­
pute with a pair of belief and plausibility functions
than to have to carry around a whole set of prob­
ability functions. Nevertheless, since information
may be lost in this process, this ease of computation
comes at a cost. (See [Pea89] for further examples
of this phenomenon.)
4

Conclusions

We have defined a new notion of conditional belief,
distinct from the DS notion, that seems to lead to
more intuitive results. Our notion also allows us to
avoid some paradoxes associated with the DS no­
tion. For example, we would expect that if both
an agent's belief in a proposition p given q and his
belief in p given -.q are at least a:, then his belief
in p should be at least a:, whether or not he learns
anything about q. This is essentially what Sav­
age [Sav54] has called the sure thing principle. It
is easy to see that conditional probability satisfies
the sure thing principle, but the DS conditioning
rule does not (see [Pea89] for an example). On
the other hand, it is easy to see that our notion of
conditioning does satisfy the sure thing principle.
For suppose we have an arbitrary belief function
Bel such that Bel(plq) � a: and Bel(pl-.q) � a:.
Choose an arbitrary probability function Pr com­
patible with Bel. By our definition of conditional
belief as an infimum, we see that Pr(plq) � a: and
Pr(pl-.q) � a:. So Pr(p) � a:. Thus, Pr(p) � a: for
all probability functions Pr compatible with Bel.
So, from Theorem 2.1, it follows that Bel(p) � a:.
Although our results show that belief functions
can play a useful role even when one wants to think
probabilistically, the observations of the previous
section do show that information can be lost if we
pass to belief functions. This suggests they should
be used with care.
One thing we have not really discussed in this
paper is what is considered perhaps the key com­
ponent of the Dempster-Shafer approach, namely,
the rule of combination. This rule is a way of com­
bining two belief functions to obtain a third one.
The reason we have not discussed it is that we feel
that the rule of combination does not fit in well
with the viewpoint of belief functions as a general­
ization of probability functions that is discussed in
this paper. However, there is another way of view­
ing belief functions, which is as representations of
evidence. This is in fact the view taken in [Sha76].
When belief is viewed as a representation of evi­
dence, then the rule of combination becomes more
appropriate. These issues are discussed in more de­
tail in a companion paper [HF90].

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

323

I
I
I
I
I
I
I

Appendix: Proof of Theorem 2.3
In order to carry out this proof, it will be tech­
nically useful to think in terms of mass function
rather than belief functions. A mass function on S
is simply a function m: 25 -+ [0,1] such that

m( 0) = 0

M2.

:EA�5 m(A)

Proposition 4.1:

I
I
I
I
I
I
I
I
I
I
I

2.

I

( [Sha76, p. 39])

If Bel is a belief function on 25 and S is fi­
nite, then there is a unique mass function m
on 25 such thatBel( A) = :EncA m(B) for every sub6et A of S.
-

Recall that we want to show Bel(·IB) is a belief
function, and PI(·IB) is the corresponding plausi­
bility function, provided that Bel(B) > 0. For sim­
plicity in this proof, we work under the assumption
that S is finite, so that there is a mass function m
corresponding to Bel. We remark that using tech­
niques of [F H89b] we could drop this assumption.
It is easy to see, using the formulas in Theo­
rem 2.2, that
=

=

=

. .. u A�o)

( -1)1II+lBel'( n A;).
iEI
I� { l,...,k) J;t:0

1.

If m is a mass function on S, then the func­
tion Bel: 25 -+ [0,1] defined by Bel( A) =
:En�A m(B) is a belief function.

Pl(AIB)

u

L:

>
=

Intuitively, m(A) is the weight of evidence for A
that has not already been assigned to some proper
subset of A. W ith this interpretation of mass, we
would expect that an agent's belief in A is the sum
of the masses he has assigned to all the subsets of A;
i.e., Bel(A) = :EncA m(B). Indeed, this intuition
is correct.

I

It is clear that Bel' satisfies BO-B2. All that
remains is to show that Bel' satisfies B3. Thus we
must show that the following inequality holds:

Bel'(A1

Ml.

1.

satisfies axioms BO-B3, it immediately follows that

Bel(·IB) does.

Pl(AnB)
PI( AnB) + Bel( AnB)
Bel( An_B
--' )'--­
-=- _ _,__
1
Pl(AnB) + Bel( AnB)
1 - Bel(AIB).
_

Thus, once we show that Bel(·IB) is a belief func­
tion, it will immediately follow that Pl(·IB) is the
corresponding plausibility function.
Let Bel' be the function defined on 28 such that
for each subset A of B,

Let B1 ,
,B1 be the distinct sets with positive
mass contained in B. Let A�, ..., A� be the distinct
sets with positive mass that intersectB but are not
subsets of B, and let Ai = A; n B, for 1 ::::; i ::::; n.
Since Bel(B) > 0, we know that there is some Bi
( but there may be no A;). Let a; = m(A;), and
{jf = m(B;), for each i. Let N = 2:::7=1 a:+ :E:=l f3f .
Note that N > 0, since there is some Bi. Let ai =
a:fN, and !3i = (3:/N, for each i. Thus, the ai's
and f3i's are normalized versions of the a; 's and f3; 's.
We want to define a mass function m' corre­
sponding to Bel'. We first need to do a small
detour. If s1
s�o is a string, and if 1 ::::; i1 <
< ip ::::; k, then we call B i
B i, a substring of
1
s1
Bin which we write as B i1
B i, j B1
Bk.
For example, s1s3s4 is a substring of BJB2B3B4B5.
The substring is proper if it does not equal the full
string ..,1
s,�:; we then write Bi1
Bi, � BJ . .. s�o.
We now define a function m", whose domain is
{A11 ..., A,.,B1, ... ,Bt}•, the set of finite strings
over the alphabet consisting of the names of the
sets with positive mass that intersect B. ( We shall
usually not bother to distinguish between a set and
the name of a set, but, as we shall see, it is con­
venient to consider explicitly strings of names of
sets. ) First, we let m"(B;) = !3i, for 1 ::::; i ::::; t. As­
sume now that we have defined m"(BiA h .. Ai, )
whenever s < r and j1 <
< j,. Assume that
i1 < . . < j•. Let
•

It clearly suffices to show that Bel' is a belief
function, since for all subsets C of S, we have
Bel(CIB) = Bel'(C nB). Once we show that Bel'

•

•

·

·

•

•

·

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

·

·

·

·

·

{3j

...A·)
m" (B·A·
I
}I
}.

(1)
m"(BiY).

L
Y -<Ai J ···Aj,

If A is not of the formBiAh .. Aj. with i1 < . . <
j., then m"(A) = 0.
We are now ready to define the alleged mass func­
tion m'. If X is the string Bi A h
Aj,, where
i1 < · < j., then we say that X represents the
set given by Bi U Ah U
U Aj,. We would like
to let m' be simply m" ( that is, by letting m' ap­
plied to a set be equal to m" applied to a string
that represents the set, and let m'(A) = 0 for sets
not of the form Bi Ah Aj. ). The problem is that
·

·

·

·

Bel'(A) = Bel(A)/(Bel(A) + Pl(AnB)).

•

·

•

·

·

·

·

·

·

·

324

several distinct strings may represent the same set;
for example, it is quite possible that, say, the sets
B1 U A 1 and B2 U A4 U As are the same. We define
m'(A) to be Lx represents A m"( X). For example,
if the set A equals both B1 U A 1 and B2 U A4 U As,
but if A is not of the form B; UAil ··· U Aj. for any
other choices of B;, Ail, ... , Aj. with il < ·· · < j
,,
then m'(A) = m"(B1A!) + m"(B2A4As). We
shall prove that m' is a mass function, and that
Bel '(A) = L ccA m'(C). This will show that Bel'
is a belief funct"'ion.
Thus, we must show that
A.

m'(0) = 0.

B.

m'(A) 2:: 0, for each A�B.

C. LA�B
D.

m'(A) = 1.

Bel'(A) = Lc�A m'(C).

By definition of m" and m', we know that (A)
holds. We now prove (D). Let AA:p• .. , A.�:, (where
k1 < ··· < kq) be the A; 's contained in A, and let
B;1, ••• , B;, be the B;'s contained in A. W hat is
Bel'(A)? As before, let N = 2:�1 a:: + L�=l f3I .
It is easy to see that Bel(A) = /3I1 + ··· + !3L, and
Pl(A n B) = N - ( a:A,1 + ···+ a:A,, + f3t1 + ···+ /3:, ).
Hence,

=

Bel'(A)
Bel(A)/(Bel(A) + Pl(A n B))
(f3tl + ··· + f3t,)/( N - a:A,l - ··· - a:A,,).

W hen we divide numerator and denominator by N,
we see that

To prove (D), we must show that LccA m'(C)
equals the right-hand side of (2). Let us call an
expression m"(B;Ah ···Aj,), where i is a mem­
ber of {i1, ... ,i,}, and where i1 < ... < j
,
are members of {k11 ••• , kq}, a good tenn. Note
that if m"(B;Ah ···Aj.) is a good term, then
B; U Ail U ··• U Aj, �A. Now LccA m'(C) equals
the sum of all good terms. This is because (a)
each good term is a part of the sum defining m'( C)
for exactly one C � A, and (b) if C � A, then
m'(C) is defined as the sum of certain good terms.
So we must show that the sum of all of the good
terms equals the right-hand side of (2). Now let
i be a fixed member of {i1,...,i,}. The sum of
all good terms of the form m"(B;Ah · ·Aj.) ex­
cept for the good term m"(B;A,�:1 ···A.�:,) is simply
·.

I
I

L

Y -<A,1 ··· A ,,

m"(B;Y),

it follows that the sum of all good terms of the form
m"(B;Ah ·· Aj.) equals /3;/(1- 0:,1:1 -···-a:,�:,).
So the sum of all good terms is ( /3;1 + ···+ /3;,)/(1a:,�:1 - ·· - a:.�=,), as desired. This proves (D).
Now (C) follows from (D), since it is easy to see
that Bel'(B) = 1. So we need only prove (B). The
proof of (B) involves some nontrivial combinatorial
arguments; the details can be found in the full pa­
per. I
·

·

We remark that in response to an early draft
of this paper, Zhang [Zha89] constructed a proof
along very different lines (although also quite com­
plicated).
Acknowledgments: The second author would
like to thank Judea Pearl for a series of net conver­
sations that inspired the development of the def­
inition of conditional belief. We also gratefully
acknowledge Nati Linial for his help in the proof
of Theorem 2.3. Comments by Hector Levesque,
Philippe Smets, and Moshe Vardi inspired a num­
ber of useful changes. Finally, we thank Judea
Pearl, Tom Strat, and Sue Andrews, for sending us,
respectively, [dCLM90], [SK89], and [Wal81], and
Enrique Ruspini for pointing out that our expres­
sions for conditional belief and plausibility actually
appear in [Dem67].

References
[Abe88] S. Abel.
The sum-and-lattice-points
method based on an evidential-reasoning
system applied to the real-time vehicle
guidance problem. In Uncertainty in Arti­
ficial Intelligence 2, pages 365-370, 1988.
[Ait68] J. Aitchison. Discussion on Professor
Dempster's paper. Journal of the Royal
StaJi5tical Society, Series B, 30:234-237,
1968.

I
I
I
I
I
I
I
I
I
I
I
I
I

[Bla87] P.Black. Is Shafer general Bayes? In Proc.
Third AAAI Uncertainty in Artificial In­
telligence Workshop, pages 2-9, 1987.

I

[dCLM90] L. M. de Campos, M. T. Lamata, and
S. Moral. The concept of conditional fuzzy
measure, to appear. International Journal
of Intelligent Sy!tems, 1990.

I
I
I

325

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

[Dem67) A. P. Dempster. Upper and lower prob­
abilities induced by a multivalued map­
ping. Annals of Mathematical Statidics,
38:325-339, 1967.
[Dem68] A. P. Dempster. A generalization of
Bayesian inference. Journal of the Royal
Statistical Society, Series B, 30:205-247,
1968.
[Dia78] P. Diaconis. Review of "A Mathemati­
cal Theory of Evidence". Journal of the
American Statistical Society, 73(363):677678, 1978.
[DP88) D. Dubois and H. Prade. Representation
and combination of uncertainty with belief
functions and possibility measures. Com­
putational Intelligence, 4:244-264, 1988.
[DZ82]

[Fal88)

[LG83] J. D. Lowrance and T. D. Garvey. Evi­
dential reasoning: an implementation for
multisensor integration. Technical Report
TN 307, SRl lnternational, 1983.
[LU88]

Z. Li and L. Uhr. Evidential reasoning in
a computer vision system. In Uncertainty
in Artificial Intelligence 2, pages 403-412,
1988.

[Pea88] J. Pearl.

B. Falkenhainer.
Towards a generalpurpose belief maintenance system. In

[Pea89] J. Pearl. Reasoning with belief functions:
a critical assessment. Technical Report R136, UCLA, 1989.

Uncertainty in Artificial Intelligence

2,

pages 125-131, 1988.
[FH89a] R. Fagin and J. Y. Halpern. A new ap­
proach to updating beliefs. Research Re­
port RJ 7222, ffiM, 1989. (A revised ver­
sion will appear in June, 1990.).
[FH89b] R. Fagin and J. Y. Halpern. Uncertainty,
belief, and probability. In Eleventh In­
ternational Joint Conference on Artificial

pages 1161-1167,
1989. An expanded version of this paper
appears as ffiM Research Report RJ 6191,
April 1988.
Intelligence (IJCAI-89),

[Gar61] M. Gardner.

Second Scientific American

Book of Mathematical Pu.z.zles and Diver­
sions.

Simon & Schuster, 1961.

[HF90] J. Y. Halpern and R. Fagin. Two views
of belief: Belief as generalized probabil­
ity and belief as evidence. In Proc. of
National Conference on Artificial Intelli­

I
I

[Hun87] D. Hunter. Dempster-Shafer vs. proba­
bilistic logic. In Proc. Third AAAI Uncer­
tainty in Artificial Intelligence W ork.!hop,
pages 22-29, 1987.

I

[Lem86] J. F. Lemmer. Confidence factors, empiri­
cism, and the Dempster-Shafer theory of
evidence. In L. N. Kanal and J. F. Lem­
mer, editors, Uncertainty in Artificial In­
telligence, pages 167-196. North-Holland,
1986.

P. Diaconis and S. L. Zabell. Updat­
ing subjective probability. Journal of the
American Statistical Society, 77(380):822830, 1982.

1990. An expanded ver­
sion appears as ffiM Research Report RJ
7221, June, 1990.

I

[Kyb87) H. E. Kyburg, Jr. Bayesian and non­
Bayesian evidential updating. Artificial
Intelligence, 31:271-293, 1987.

gence (AAAI-90),

Probabilistic Reasoning in Intel­

ligent Systems.

Morgan Kaufmann, 1988.

[Sav54] L. J. Savage. Foundations
John Wiley & Sons, 1954.

of Statistics.

[Sha76] G. Shafer. A Mathematical Theory of Ev­
idence. Princeton University Press, 1976.
[Sha79] G. Shafer. Allocations of probability. An­
nals of Probability, 7(5):827-839, 1979.
[SK89]

P. Smets and R. Kennes. The transferable
belief model: comparison with Bayesian
models, unpublished manuscript, ffiiDIA,
Universite Libre de Bruxelles, 1050 Brus­
sels, Belgium. 1989.

[Wal81] P. Walley. Coherent lower (and upper)
probabilities. Unpublished manuscript,
Dept. of Statistics, University of Warwick,
Coventry CV4 7AL, England, 1981.
[Zad84] L. A. Zadeh. A mathematical theory of
evidence (book review). AI Magazine,
5(3):81-83, 1984.
[Zha89] L. Zhang. A new proof to Theorem 3.2 of
F agin and Halpern's paper. Unpublished
memorandum, 1989.

