influences
been

combining
between

much

(e.g. ,

for

in

Hence

recent

time

constructing BNs

[Spirtes et al. , 1993,

in

and

spec­

experts

causal direction of

variables.

interest

mated methods

probabilities,

there

has

in

auto­

from

data

Wallace and Korb, 1999,

Beckerman and Geiger, 1995]).

Most evaluation of

these automated methods is done by taking an exist­
ing BN model, generating data from it that is given to
the automated learner; the learned BN is compared to
the original.

investigate how certain existing automated

While there have been attempts to combine knowl­

knowledge discovery methods might support

edge elicitation from experts and automated knowl­

the BN knowledge engineering process.

edge discovery methods (e.g. [Heckerman et a!., 1994,
Onisko et al., 2000]), there is as yet no established
methodology [Kennett et al . , 2001]. Appropriate eval­

1

INTRODUCTION

Bayesian networks have become a popular AI represen­
tation for reasoning under uncertainty, with successful
applications in (medical) diagnosis, planning, moni­
toring, vision, information retrieval and intelligent tu­
toring [Conati et al., 1997, Mayo and Mitrovic, 2001,
VanLehn and Niu, 2001]. Most successful applications
to date have been built through knowledge elicita­
tion from experts.

time consuming

In general, this is difficult and

[Druzdzel and van der Gaag, 200 1],

with problems involving incomplete knowledge of
'School of Computer Sci. and Soft. Eng., Monash Uni­
versity, VIC 3800, Australia. annnfllcsse.monash.edu.au.
sity

t Department of Computer Science, The Univer­
of Melbourne, Parkville, VIC 3052, Australia.

bonehfllstudents.cs.mu.oz.au

tAs for A. Nicholson. tawll!csse.monash.edu.au
§ Department of Science and Mathematics Educa­
tion, The University of Melbourne, VIC 3010, A ustralia.

uation, in particular, is an open question; most auto­
mated methods use some sort of statistical measure of
how well the BN model fits the data whereas elicited
models are assessed in part by how well their predic­
tions on particular test scenarios meet expert expecta­
tions. When both data and expert knowledge about a
domain is available, it is not simply a question of using
the automated methods to validate the expert elicited
BN, or using the expert to choose between learned
networks or complete those not fully specified.

Net­

works built using the different methods may be very
different. The question then becomes how to resolve
such differences such that the resultant BN model is
acceptable to the expert/client and hence deployable.
In this paper, we present a case study in the construc­
tion of a BN model in the intelligent tutoring system
(ITS) (Section 2). We describe the initial network con­
struction using expert elicitation, together with a pre­
liminary evaluation (Section 3).

We then apply au­

k.staceyfllunimelb.edu.au.

tomated knowledge discovery methods to each main

, Department of Information Systems, The Uni­
versity of Melbourne, Parkville, VIC 3052, Australia.

task in the construction process: (Section 4): ( 1 ) we

LizS�staff.dis.unimelb.edu.au.

we perform simple parameter learning based on fre-

liAs for K. Stacey.

v. steinleflledfac.unimelb.edu. au

apply a classification method to student test data; (2)

NICHOLSON ET AL.

UA1 2001

quency counts to the expert BN structures and (3) we
apply an existing BN learning program. In each case

387

for that item type by that student class other than the

we compare the performance of the resultant network

combinations seen above. We note that the fine mis­
conception classifications have been "grouped" by the

with the expert elicited networks, providing an insight

experts into a coarse classification

into how elicitation and knowledge discovery might b e

decimals are larger numbers), S (shorter is larger), A

combined in the B N knowledge engineering process.

-

L (think longer

(apparent expert) and UN (other). The LU, SU and AU
fine classifications correspond to students who on their
answers on Type 1 and 2 items behave like others in

THE ITS DOMAIN

2

their coarse classification, however they don't b ehave

D ecimal notation is widely used in our society.

Our

testing [Stacey and Steinle, 1999] of 5383 students has
indicated that less 70% of Year 10 students (age
about 15 years) understand the notation well enough
to reliably judge the relative size of decimals.

(age about 10 years) have mastered this important
Expertise grows only very slowly through­

out the intervening years under normal instruction
in our schools, and so an intelligent tutoring ap­
proach to this important topic is of interest.

Stu­

dents' understanding of decimal notation has been
mapped using a short test, the Decimal Comparison
Test (DCT), where the student is asked to choose
the larger number from each of 24 pairs of decimals
[Stacey and Steinle, 1 999]. The pairs of decimals are
carefully chosen so that from the patterns of responses,
students' (mis)understanding can be diagnosed as be­
longing to one of a number of categories. These cate­
gories have been identified manually, based on exten­
sive research [Stacey and Steinle,

1999].

may be students behaving consistently according to
an unknown misconception, or students who are not
following any consistent interpretation.

On

the other hand, more than 30% o f Grade 5 students
concept.

like them on the other item types. These and the UNs

For most stu­

Table 1: Responses experts expect from students with
different misconceptions
Expert
Class

ATE
AMO
MIS
AU
LWH

LZE
LRV

LU

SDF
SRN

su
UN

1
0.4
0.35
H
H
L
H
L

L
L
L
H

H

H

2
5.736
5.62
H
H

L
H
H
H
H
H

Item type
3
4
4.7
0.452
4.08
0.45
H
H
H
L

L

L

L

H
H

H

L
L
L

L

H

H

L

H

L

5
0.4
0.3

6
0.42
0.35

H
H

H
H
L

H

H
H

H
H
L

H

H

L

L

L

dents, there is consistency in their responses to similar
test items and some children display the same miscon­
ception over long periods of time.
Most are based on

false analogies, which are sometimes embellished by
isolated learned facts (such as a zero in the tenths
column makes a number small). For example, many
younger students think 0.4 is smaller than 0.35 be­
cause there are 4 parts (of unspecified size, for these
students) in the first number and 35 parts (also of
unspecified size) in the second. However, these stu­
dents (LWH in Table 1) get many items right, e.g.
5.736 compared with 5.62, with the same erroneous
thinking. Students in the SRN class (Table 1) choose
0 .4 as greater than 0.35 but for the wrong reason, as
they draw an analogy between fractions and decimals
and use knowledge that 1/4 is greater than 1/35 . See
[Stacey and Steinle, 1999] for a detailed discussion of
these responses and categories of students.

Table 1

shows the rules the experts originally used to classify
students based on their response to

6

types of DCT

test items: H = High correctness (e.g. 4 or 5 out of 5),
L

=

have

developed

an

i ntelligent

tutoring

sys­

tem based on computer games for this decimals

A bout a dozen misconceptions have been identified
using the DCT and interviews.

We

Low number correct (e.g. 0 or

1

out of 5), with

'.' indicating that any performance level is observable

domain[Mclntosh et al., 2000].

The overall architec­

ture of the system is shown in Figure 1.

The com­

puter game genre was chosen to provide children with
an experience different from, but complementary to,
normal classroom instruction and to appeal across the
target age range (Grade 5 and above).

Each game

focuses on one aspect of decimal numeration, thinly
disguised by a story line.

It is possible for a stu­

dent to be good at one game or the diagnostic test,
but not good at another; emerging knowledge is often
compartmentalised.1
1In the "Hidden Numbers" game students are con­
fronted with two decimal numbers with digits hidden be­
hind closed doors; the task is to find which number is the
larger by opening as few doors as possible. The game "Fly­
ing Photographer" requires students to place a number on a
number line, prompting students to think differently about
decimal numbers. The "Number Between" game is also
played on a number line, but particularly focuses on the
density of the decimal numbers; students have to type in
a number between a given pair. "Decimaliens" is a classic
shooting game, designed to link various representations of
the value of digits in a decimal number.

NICHOLSON ET AL.

388

UAI2001

The simple expert rules classification described above

the conditional probability tables associated with each

makes quite arbitrary decisions about borderline cases.

network node. For our purposes we consider there to

The use of a BN to model the uncertainty allows it to

be an additional task (4) the evaluation of the network.

make more informed decisions in these cases. Using a

While in theory these tasks can be performed sequen­

BN also provides a framework for integrating student

tially, in practice the knowledge engineering process

responses from the computer games with DCT infor­

iterates over these task until the resultant network is

mation. The BN is initialised with a generic student

considered "acceptable". In this section we describe

model, with the options of individualising with class­

the elicitation of the decimal misconception BN from

room or online DCT results. The BN is used to update

the education domain experts.

an ongoing assessment of the student's understanding,
to predict which item types that student might be ex­
pected to get right or wrong, and, using sensitivity
analysis, to identify which evidence would most im­
prove the misconception diagnosis. The development
of the BN is described below.
The system controller module uses the information

3.1

BN VARIABLES

Student misconceptions are represented on two levels,
by two variables. The coarseClass node can take the
values L, S, A, and UN, whereas the f ineClass node,
incorporating all the misconception types identified by
the experts, can take the 12 values shown in column

provided by the BN, together with the student's previ­

1 of Table 1. Note that the experts consider the clas­

ous responses, to select which item type to present to

sifications to be mutually exclusive. If that were not

the student next, and to decide when to present help

the case, then two variables would not be sufficient;

or change to a new game.

This architecture allows

flexibility in combining the teaching "sequencing tac­
tic" (that is, whether easy items are presented before
harder ones, harder first, or alternating easy /hard),
coverage of all item types, and items which will most
improve the diagnosis.

More detailed descriptions of

both the architecture and the item selection algorithm
are given in [Stacey et al., 2001]. The ITS shown in

rather we would require a Boolean variable for each of
the classifications.
Each DCT item type is made a variable in the BN, rep­
resenting student performance on test items of those
types; student test answers are entered as evidence for
these nodes. The following alternatives were consid­
ered for the possible values of the item type nodes.

Figure 1 (including the four computer games) has

1. Suppose the test contains N items of a given type.

been fully implemented. The game interfaces are cur­

One possible set of values for the BN item type node is

dren, with deployment and assessment in the class­

{0, 1, ... , N}, representing the nu m ber of the items the
student answered correctly. The number of items may

room environment to take place over the next year.

vary for the different types, and for the particular test

rently being assessed for usability on individual chil­

set given to the students, but it is not difficult to adapt
the BN. Note that the more values for each node, the
more complex the overall model; if N were large (e.g.
> 20), this model may lead to complexity problems.

2. The item type node may be given the values {High,
Medium, Low}, reflecting an aggregated assessment of
the student's answers for that item type. For example,
if 5 such items were presented, 0 or 1 correct would
be considered low, 2 or 3 would be medium, while 4
or

5

would be High. For types with 4 items, medium

encompasses only 2 correct, while for types with only
3 itemsl the medium value is omitted completely. This
Figure 1: Intelligent Tutoring System Architecture

3

EXPERT ELICITATION

It is generally accepted that building a BN for a
particular application domain involves three tasks
[Druzdzel and van der Gaag, 2001]: ( 1) identification
of the important variables, and their values; (2) iden­

reflects the expert rules classification described above.
3.2

BN STRUCTURE

The experts considered the coarse classification to be
a strictly deterministic combination of the fine classifi­
cation, hence the coarseClass node was made a child
of the fineClass node, For example, a student was
considered an L if and only if it was one of an LWH,

tification and representation of the relationships be­
tween variables in the network structure; and (3) pa­

LZE, LRV or LU.

rameterisation of the network, that is determining

The type nodes are observation nodes, where entering

UA1 2001

N ICHOLSON ET AL.

389

evidence for a type node should update the posterior

hundred students from Grades

probability of a student having a particular misconcep­

then pre-processed to give each student's results in

tion.

This diagnostic reasoning is typically reflected

terms of the

6

5

test item types;

and

6.

These were
were the

5,5,4,4,3,3

in a BN structure where the class, or "cause" is the

number of items of these type 1 to 6 respectively. The

parent of the "effect" (i.e. evidence) node. Therefore

particular form of the pre-processing depends on the

an arc was added from the subclass node to each of

item type values used: with the

the type nodes. No connections were added between

ues, a student's results might be 541233, whereas with

0

-

N type node val­

any of the type nodes, reflecting the experts' intuition

the H/M/L values, the same students results would be

that a student's answers for different item types are

represented as HHLMHH.

independent, given the subclassification.

The expert rule classifications were used to generate

A part of the expert elicited BN structure implemented

the priors for the sub-classifications.

in the ITS is shown in Figure 2 . This network fragment

of the test item types take the form of· P(Type

shows the coarseClass node (values L,S,A,UN), the

ValuejClassification

detailed misconception fineClass node (12 values),

the domain description, the experts expect particu­

X).

=

All the CPTs

=

As we have seen from

the item type nodes used for the DCT, plus additional

lar classes of students to get certain item types cor­

nodes for some games. These additional nodes are not

rect, and others wrong.

described in this paper but are included to illustrate

model the natural deviations from such "rules", where

the complexity of the full network.2 The balded nodes

students make a careless error, that is, they apply

are those in the restricted network used subsequently

their own logic but do not carry it through.

in this paper for evaluation and experimentation.

ample, students who are thinking according to the

However we do need to

For ex­

LWH misconception are predicted to get all
of Type 2 correct.
ability of

0.1

5

items

If however that there is a prob­

of a careless mistake on any one item,

the probability of a score of 5 is

(0.9)5,

and the prob­

ability of other scores follows the binomial distribu­

tion; the full vector for P(Type2JSubclass=LWH) is

(0.59,0.33,0.07,0.01,0.00,0.00)
When

the

item

type

(to two decimal places).

values

H/M/L

are

used,

the numbers are accumulated to give the vector
(0.92,0.08,0.00) for H, M and L. We note that the ex­
perts consider that this mistake probability is consid­
erably less than

0.1, say

of the order of 1-2%.

Much more difficult than handling the careless errors
in the well understood behaviour of the specific known
misconceptions, is to model situations where the ex­
perts do not know how a student will behave. This was
the case where the experts specified '.' for the classifi­
cations LU, SU, AU and UN in Table 1. We modelled the
expert not knowing what such a student would do on
the particular item type in the BN by using
Figure 2: Fragment of the expert elicited BN currently
implemented. Bold nodes are those discussed here.

50/50

0.5

(i.e.

that a student will get each item correct) with

the binomial distribution to produce the CPTs.
We ran experiments with different probabilities for

3.3

BN PARAMETERS

The education experts had collected data that con­
sisted of the test results and the expert rule classifi­
cation on a 24 item DCT for over two thousand five
2 An indication as to the meaning of these additional
nodes is as follows. The "HN" nodes relate to the Hidden
Numbers game, with evidence entered for the number of
doors opened before an answer was g iven, and a measure
of the "goodness of order" in opening doors. The root
node for the Hidden Number game subnet reflects a player's
game ability - in this case door opening "efficiency".

a single careless mistake

(pcm=0.03, 0.11

and

0.22),

with the CPTs calculated in this manner, to investi­
gate the effect of this parameter on the behaviour of
the system. These number were chosen to give a com­
bined probability for HIGH (for 5 items) of

0.99, 0.9

and 0.7 respectively, numbers that our experts thought
were reasonable. Results are described in Section
3.4

3.5.

BN EVALUATION P ROCESS

During the expert elicitation process we performed the
following three basic types of evaluation.

First was

NICHOLSON ET AL.

390

Case-based evaluation, where the experts "play" with
the net, imitating the response of a student with cer­
tain misconceptions and review the posterior distribu­
tions on the net.

Depending on the BN parameters,

it was often the case that while the incorporation of
the evidence for the

6

item types from the DCT test

data greatly increased the BN's belief for a particu­
lar misconception, the expert classification was not the
BN classification with the highest posterior, because it
started with a low prior. We found that it was useful to
the experts if we also provided the ratio by which each
classification belief had changed (although the highest
posterior is used in all evaluations).
During the use of the BN in the full ITS (see Figure 1),
each

Table

2:

UAI2001

Expert rule vs expert elicited BN classifica­

tion. Type node states 0-N, pcm=O.Il.
lwh lze lrv lu sdf srn su ate amo mis au un
lwh 386 0 0 0 0
0 0 0 0
0
0 0
lze
0 98 0 0 0 0 0
0 0 0 0
0
lrv
10 0 0 0 0 0 0
0 0 0 0
0
lu
6 9 0 54 0 0 0
0
0 0 0 6
sdf
0 0 0 0 83
0
0 0 0 0
0 4
srn
0 0 0 0 0 159 0
0 0 0 0
0
su
0 0 0 0 :2 22 40
3
0 0 0 2
ate
0 0 0 0 0 0 0 1050
0 0 0 0
amo
0 0 0 0 0 0 0
0
79 0 0 0
mis
0 0 0 0 0 0 0
0 6 0 0
0
au
9 0 0 0 0
0 0 1
8
0 0 63
un
43 6 0 15 35 14 11 119 26 2 0 66

time student answers are entered, the posteriors

for the fine classification are updated and in turn be­
come the new priors for that node; in this way, the
network adapts to the individual student over a range
of games and item types over time. This adaptive as­
pect allows the system to identify students with mis­
conceptions that are fairly infrequent in the overall
population. This motivated our Adaptiveness evalua­

tion, where the experts imitate repeated responses of
a student, update the priors after every test and enter
another expected test result. This detection of classi­
fications over repetitive testing built up the confidence
of the experts in the adaptive use of the BN.
Next, we undertook Comparison evaluation between
th e classifications of th e BN compared to the expert

rules on the DCT data.3

As well as a comparison

grid (see next subsection), we provided the experts
with details of the records where the BN classification
differed from that of the expert rules.

This output

proved to be very useful for the expert in order to
understand the way the net was working and to build
their confidence in the net.

have had on the overall behaviour. The iterative pro­
cess halts when the exp erts feel the behaviour of the
BN is satisfactory.

3.5

RESULTS

Table 2 is an example of the comparison grids for the
fine classification that were produced during the com­
parison evaluation phase. Similar grids were produced
for the coarse classification. Each row corresponds to
the expert rules classification, while each column cor­
responds to the BN classification, using the highest
posterior; each entry in the grid shows how many stu­
dents had a particular combination of classifications
from the two methods. The grid diagonals show those
students for whom the two classifications are in agree­
ment, while the "desirable" changes are shown in ital­

ics, and undesirable changes are shown in bold. Note

that we use the term "match" , rather than saying that
the BN classification was "correct", because the expert

Finally, we undertook a Prediction evaluation which
considers the prediction of student performance on in­
dividual item type nodes rather than direct miscon­
ception diagnosis. We enter a student's answers for

5

of the 6 item type nodes, then predict their answer for
the remruning one; this is repeated for each item type.
The number of correct predictions gives a meas ure of
the accuracy of each model, using a score of 1 for a
correct prediction (using the highest posterior) and 0
for an incorrect prediction. We also look at the pre­
dicted probability for the actual student answer. Both
measures are averaged over all students.

we modified the BN structure or the CPTs. This way
we were aware of the implications this change may

4

We performed these four types of evaluation every time
3We note that this evaluation is similar to the compar­
ison used in [van der Gaag et al., 2000].

4This evaluation method was suggested by an anony­
mous reviewer; the analysis of results using these predic­
tion measures is preliminary due to time constraints.

ule classification is not necessarily ideal.

r

Further assessment of these results by the experts re­
vealed that when the BN classification does not match
the expert rules classification, the misconception with
the second highest posterior often did match. The ex­
perts then assessed whether differences in the BN's

classification from the expert rules classification were
in some way desirable or undesirable, depending on
how the BN classification would be used. They came
up with the following general principles which provided
some general comparison measures: (1) it is desirable
for expert rule classified LUs to be re-classified as an­
other ofthe specific Ls, similarly for A Us and SUs, and
it was desirable for Us to be re-classified as an ything

else; (because this is dealing with borderline cases that

the expert rule really can't say much about); (2) it
is undesirable for

(a)

specific classifications (i.e. not

those involving any kind of

"U")

to change, because

UAI2001

Table

NICHOLSON ET AL.

Coarse classification grid, expert rules vs ex­

3:

pert elicited BN, varying
item type values

pcm (0.22, 0.11, 0.03),
(H/M/L and 0- N ) .

0-N
s

0.22
A

s

L
UN
0.11
A
s
L
UN
0.03
A
s
L
UN

A
L
UN
86.95% 12.56% 0.49%
1207
0
9
0
3
0
312
0
0
0
0
569
157
71
31
78
88.02% 11.12% 0.86%
1206
1
0
9
2
3
310
0
0
6
563
0
147
66
64
60

89.29% 9.48% 1.23'fo
1202
0
6
8
4
308
3
0
0
9
0
560
102
106
80
49

and

H[MJL
L
A
UN
S
87.61% 11.98% 0.41'fa
1213
0
3
0
4
1
0
310
557
0
2
0
45
150
60
82
87.28% 10.71% 2.01%
1184
23
9
0
1
0
4
310
5
7
557
0
49
139
76
73

91.63% 5.25% 3.12%
43
0
1173
0
0
11
304
0
22
547
0
0
209
36
83
9

391

Table 4: Fine classification summary

com p arison

ious models compared to the expert rules
Method

Type
values

Expert
BN

0-N

0-N
H/M/L

Avg
Avg
Avg
Avg

86.51
83.48

0-N
H/M/L

Avg
Avg

EBN
learned

24 DCT
0-N
H/M/L
0-N
H/M/L

CaMML
constr.

CaMML
uncons.

0.22
0.11
0.03
0.22
0.11
0.03

77.88
82.93
84.37
80.47
83.91
90.40
79.81
72.06
72.51
95.97
97.63

HfMJL
SNOB

Match

86.15
92.63

Des.
change
20.39
15.63
11.86
18.71
13.66
6.48
17.60
16.00
17.03
2.36
1.61
5.08
8.12

5.87
4.61

var­

Uncles.
change
1.72
1.44
3.78
0.82
2.42
3.12
2.49
11.94
10.46
1.66
0.75
8.41
8.34
7.92
2.76

ond, the expert elicited BN structure and parameters
the experts are confident about these classifications,

reflects both the experts' good understanding for the

and (b) for any classification to change to UN, be­

known fine classifications, and their poor understand­

cause this is in some sense throwing away information

ing of the behaviour of "U" students (LU, SU, AU,

(e.g. LU to UN loses information about the "1-like"

and UN). Finally, as discussed earlier, some classes are

behaviour of the students).

broken down into fine classifications more than others,

Table

3

shows the coarse classification comparison

grids obtained when varying the probability of a care­

resulting in lower priors, so the more common classifi­
cations (such as ATE and UN) tend to draw in others.

less mistake

(pcm=0.22, 0.11 and 0.03) and the item
(O-N vs H/M/L). Each grid is accompanied

Closer inspection also shows that some "undesirable"

type values

changes are reasonable. For example a student answer­

by the percentages for match, desirable and undesir­

ing 443322 is classified as an ATE by both the expert

able change.

rule and the H/M/L BN, since one mistake on any

As the probability decreases, the total

number of matches with expert classifications goes up,

item is considered "high". However the 0-N BN (for

due to more UN students being in agreement, how­
ever more L,S and A students no longer match, which

pcm=0.03) classifies the student as UN, since the com­
bined probability of 5 careless mistakes (one on each

is considered "undesirable" (see above). In effect, the

item type) is very low.

definition of A,S, and L becomes more stringent as the
probability of a careless error decreases, so more move
out of A, Land S into UN, and less move from UN into
A, L and S. T here are also shifts between undesirable
classification differences, for example the 8 A students
who the BN classifies as L (values

0-N, pcm=0.22)

(in

fact, highly offensive to our experts!), shift to the also
generally undesirable UN

(pcm=0.03).

It is not possible for reasons of space to present the
full set of results for the fine classifications. Table

4

(Set 1) shows a summary of the expert BN fine clas­
sification, varying the type values and probability of
careless mistake, in terms of percentage of matches
(i.e. on the grid diagonal), desirable changes and un­
desirable changes. We can see that matches are higher
for H/M/L than the corresponding 0-N run, desirable

We believe that the differences between the BN and

changes are lower, while there is no consistent trend

the expert rule classifications are due to the follow­

for undesirable changes. The undesirable change per­

ing factors. First, the expert rules give priority to the

centages are quite low, especially considering that we

type 1 and type

2 results, whereas the BN model gives
6 item types. An example of
a student with answers 450433, who the expert

know some of these can be considered quite justified.

equal weighting to all

Table 5 (Set

this is

Section

1) shows the two prediction measures (see
3.4), averaged over all predicted item types, for

rule classifies as AU due to the "High" result for item

all students. Both measures show the H/M/L model

with a fairly high chance of a careless mistake

(0.22)

ing O-N run. Both measures show the probability of

says this student looks like an LHW

as the

a careless error effects the results for the 0-N models,

only difference is the answer for item type 1, while for

but only the predicted probability shows an effect on

types 1 and 2 (ignoring the other answers ) . The BN

pcm=0.03,

(050433},

the BN classifies the student as UN. Sec-

giving better prediction results than the correspond­

the H/M/1 model results.

392

NICHOLSON ET AL.

Table 5: Accuracy of various models predicting stu­
dent item type answers.
Method

Expert
BN

Type
values

0-N
H/M/L

0.22
0.11
0.03
0.22
0.11
0.03
Avg
Avg

0.34
0.83
0.82
0.89
0.89
0.88
0.83
0.89

O-N
H/M/L

Avg

0.83
0.88

0-N

H/M/L
EBN
learned
CaMML
constr.
CaMML

uncons.

Avg Pred.
Accuracy

0-N

H/M/L

Avg
Avg

Avg

Avg Pred.

Prob.
0.34
0.53
0.70
0.69
0.80
0.83
0.74
0.83

0.83
0.89

0.72
0.79
0.74
0.83

Overall it is clear that the expert elicited network per­
forms a good classification of students misconceptions,
and captures well the different uncertainties in the ex­
perts domain knowledge. In addition, its performance
is quite robust to changes in parameters such as the
probability of careless mistakes or the granularity of
the evidence nodes.
4

KNOWLEDGE DISCOVERY

The next stage of the project involved the application
of certain automated methods for knowledge discovery
to the domain data.
4.1

CLASSIFICATION

The first aspect investigated was the classification of
decimal misconceptions. We applied the SNOB clas­
sification program[Wallace and Dowe, 2000], based on
the information theoretic Minimum Message Length
(MML). SNOB was run on the data from 2437 stu­
dents on 24 DCT items, each being a binary value as
to whether the student got the item correct or incor­
rect, with a variety of initial guesses for the number
of classes (5,10,15,20,30). All five classifications were
very similar; we present here results from the model
with the lowest MML estimate (5 initial classes). Us­
ing the most probable class for each member, we con­
structed a grid comparing the SNOB classification
with the expert rule classification. Of the 12 classes
produced by SNOB, we were able to identify 8 that
corresponded closely to the expert classifications (i.e.
had most members on the grid diagonal). Two classes
were not found (LRV and SU). Of the other 4 classes,
2 were mainly combinations of the AU and UN classi­
fications, while the other 2 were mainly UNs. SNOB
was unable to classify 15 students (0.6%). The per­
centages of match, desirable and undesirable change
are shown in Table 4 (set 2, row 1). They are compa­
rable with the expert BN 0-N and only slightly worse
than the expert BN H/M/L results.

UAI2001

SNOB was then run on the pre-processed data consist­
ing of student answers on the 6 item types (values 0-N
and H/M/1). The comparison results for this run were
not particularly good. For O,N type values, SNOB
found only 5 classes (32 students
1.3% not classi­
fied), corresponding roughly to some of the most pop­
ulous expert classes� 1WH, SDF, SRN, ATE and UN,
and subsuming the other expert classes. For H/M/1
type values, SNOB found 6 classes (33 students= 1.4%
not classified), corresponding roughly to 5 of the most
populous expert classes (1WH, SDF, SRN, ATE, UN),
plus a class that combined MIS with UN. In this case
1ZEs were all grouped with ATEs, as were AMOs. The
match results are shown in Table 4 (set 2, rows 2 and
3). Clearly, summarising the results of 24 DCT into
types gives relatively poor performance; it is proposed
that this is because many pairs of the classes are dis­
tinguished by student behaviour on just one item type,
and SNOB might consider these differences to be noise
within one class.
=

The overall good performance of the classification
method shows that automated knowledge discovery
methods may be useful in assisting expert identify suit­
able values for classification type variables.
4.2

PARAMETER S

Our next investigation was to learn the parameters for
the expert elicited network structure. The data was
randomly divided into five 80%-20% splits for training
and testing; the training data was used to parame­
terise the expert BN structures using the Netica BN
software's parameter learning feature5, while the test
data was given to the resultant BN for classification.
The match results (averaged over the 5 splits) for the
fine classification comparison of the expert BN struc­
tures (with the different type values, 0-N and H/M/L)
with learned parameters are shown in Table 4 (set 3),
with corresponding prediction results (also averaged
over the 5 splits) given shown in Table 5 (set 2).
The average prediction probabilities for the BN with
learned parameters are better than for the expert BNs
for the 0-N type values {0. 74 compared to 0. 70); the
other prediction results show no significant difference.
The match percentages for both BNs with learned pa­
rameters are significantly higher than for all the ex­
pert BNs with elicited parameters (with varying pcm),
while both the desirable and undesirable changes are
lower; most of the difference is due to the reduction in
desirable changes. Within the learned parameter re­
sults, the match percentage is significantly higher for
H/M/1 than 0-N, while the changes are lower. In both
cases, the percentage of undesirable changes is lower
than the desirable change. Clearly, learning the pa5ww.norsys.com

NICHOLSON ET AL.

UAI2001

393

rameters from data, if it is available, gives results that

The undesirable changes include quite a few shifts from

are much closer to the expert rule classification. The

one specific classification to another, which is particu­

trade-off is that the network no longer makes changes

larly bad as far as our experts are concerned; for exam­

to the various "U" classifications, i.e. it doesn't shift

ple, several of the networks do not identify the SDF

LUs, SUs, AUs and UNs into other classifications that

and MIS classifications, instead grouping them with

may be more useful in a teaching context. However it

ATE. We also note that the variation between the re­

does mean that expert input into the knowledge en­

sults for each data set 1-5 was much higher than for

gineering process can be reduced, with the parameter

the variation when learning parameters for the expert

learning on an elicited structure giving a BN model

BN structure. This no doubt reflects the difference be­

that can be used in the ITS.

tween the network structure learned for the different

4.3

tween the complexity of the learned network structures

splits. However we did not find a clear correlation be­
STRUCTURE

and their classification performance.
Our third investigation involved the application of
Causal MM1 (CaMM1) [Wallace and Korb,
learn network structure.

1999]

to

In order to compare the

learned structure with that of the expert elicited BN,
we decided to use the pre-processed

6

type data; each

program was given the student data for 7 variables
(the fine classification variable and the

6

item types),

with both the 0-N values and the H/M/1 values. The
same

5

random 80%-20% splits of the data were used

for training and testing. The training data was given
as input to the structural learning algorithm, and then

used to parameterise the result networks using Netica's
parameter learning method.

In seeking to improve automated discovery of struc­
ture by exploiting expert domain knowledge, experts
could provide constraints to guide the search and could
manually select for further investigation those alterna­
tive structures which were best interpretable in terms
of the domain concepts.

5

CON CLUSION S

This work began with the recognition that we had ac­
cess to a novel combination of data and information
which could enable the developments and compara­
tive studies reported above: a domain where student

We ran CaMM1 once for each split (a) without any

misconceptions abound; involvement of experts with a

constraints and (b) with the ordering constraint that

detailed understanding of the basis of the misconcep­

the classification should be an ancestor of each of

tions, and how they relate to domain specific activities;

This constraint reflects the gen­

and an extensi ve data set of student behaviour on test

the type nodes.

eral known causal structure.

Each run produced a

items in the domain.

The work reported here falls

slightly different network structure, with some hav­

into three components: (a) the development, by expert

ing the fineClass node as a root, some not.

elicitation, of a Bayesian network designed to be the

One

fairly typical network with the ordering constraint con­

"engine" of an adaptive tutoring system; an elicitation

tained 4 arcs from the class node to type nodes, with

strongly informed by the experts' detailed understand­

one type node also being a root node, only two type

ing of patterns in the data set; (b) a study of learn­

nodes leaves, and 10 arcs between type nodes.

ing techniques applied to the same data set - looking

The

arcs/nodes ratio of the learned structures varies from

at learning of classification, structure, and parameters

1.4 to 2.2, while the number of parameters varies from

- which could be compared against the experts' net­

about 700 to 144,000; the structures produced for the

work; and (c) some reflection, based on the experience

H/M/L data seem simpler using these measures, but

of working with the experts and the automated tools,

this is not statistically significant.

as to how elicitation and knowledge discovery might be

The percentage match results comparing the CaMML
BN classifications (constrained and unconstrained, O­

N and H/M/L) are also shown in Table 4 (sets 4 and

5), with the prediction results shown in Table 5 (sets
3 and 4). The prediction results for both 0-N and

combined in the BN knowledge engineering process.
A first, important, observation is that the automated
techniques were able to yield networks which gave
quantitative results comparable to the results from the
BN elicited from the experts. This level of matching

H/M/1 are similar to those of the fully elicited expert

provides a form of 'validation' of the learning tech­

BNs.

niques and suggests that automated methods can re­

The match percentages are similar to those of

the fully elicited expert BN for the 0-N, however the

duce the input required from domain experts. It also

undesirable change percentages are higher, while the

supports the reciprocal conclusion regarding the valid­

desirable change percentages are lower. For H/M/1,

ity of manual construction when there is enough expert

the match results are higher than for the expert BN

knowledge but no available data set. In addition, we

compared to the highest of 90.40), with fewer

have seen that the use of automated techniques can

(92.63

desirable and undesirable changes.

provide opportunities to explore the implications of

NI CHOLSON ET AL.

394

mo delli n g choices and to get a feel for design tradeoffs
- some examples of this were reported above in both

the initial eli cit ation stage, and the discovery stage
(e.g. 0-N vs. H/M/L) .

UA1 2001

networks and decision theory. Int. Journal of AI in

Education (to appear), 1 2 .

[Mcintosh et

al. ,

2000]

J.,

Mcintosh ,

S t acey,

De s ig ning

Tromp, C . , and Lightfoot , D . (2000) .

G iven that elicited BN was based on the expert knowl­

K.,

constructivist computer games for teaching about

.

J. B .

edge that had been accumulated over a period of time

decimal numbers .

through much analysis and investigation, how useful

t or , Mathematics Education Beyond 2000. (Proc. of

is an automated approach in domains where such de­

the 23rd A nnual Conf. of the Mathematics Educa­

t ailed (validation) knowledge is not available?

Our

experience suggests that a hybrid of expert and au­

tomated approaches is feas ib le.
these methods in a situation

We plan to apply

( st u d ent

work on alge­

bra) where we have data on student behaviour, but do
not have detailed prior exp ert analysis of the data.

knowledge the preliminary work undertaken by Elise
Dettman, an d thank Brent Boerlage for his assistance
with Netica and the anonymous reviewers for their
helpful s ugg e s t io ns .

modeling

C.,

Gertn er , A . , Van­
On-line stu­

for coached problem solving using

B ayesian Networks.

In UM97 - Proc. of the 6th

Int. Conf. on User Modeling, p ages 231-242.
[Druzdzel and van der Gaag, 200 1] Druzdzel,

M.

and

van der Gaag, L. (200 1 ) . Building probabilistic net­
works: Where do the numbers come from? G u est

editors int ro duct ion .

IEEE Trans. on Knowledge

and Data Engineering, 1 2 (4) :481-486.
[He cker man and G ei ger , 1995] Heckerman,

and

( 1 995) . Learning B ayesian networks: A

P.

In

and Hanks, S . , ed i t ors , UAI95 - Proc.

of the 1 1th Conf. on Uncertainty in A rtificial Intel­
ligence, pages 274-284, San Francisco.

and Chickering, D .

(1994) . L earning

Bayesian net­

works: the combination of knowledge and statisti­
In de Mantras, L. and Poole, D . , edi­

tors, UAI94 - Proc. of the 1 0th Conf. on Uncer­
tainty in Artificial Intelligence, pages 293-301 , San
Francisco.
[K en ne t t et al. , 2001] Ken n e tt ,
N ichol son , A. (200 1 ) .

Bayesian networks.

R.,

Korb,

K . , and

Seabreeze prediction using

In PAKDD '01 - Proc. of the

4th Pacific-Asia Conf. on Knowledge Discovery and
Data Mining, p ages
(M ayo and
(200 1 ) .

Dr uzd zel , M., and

rameters from small data sets: application of Noisy­

Working Notes of the Workshop on

"Bayesian and Causal networks: from inference to
data mining. " 12th European Conf. on Artificial in­
telligence

(ECAI-2000).

[S pir t e s et al. , 1993] Spirtes,

(1 993) .

P. ,

G lymo ur,

C . , and

Causation, Prediction and

148-153,

Mitrovic, 2001]

2001]

[St acey et al . ,

Stacey,

K . , Sonenberg, L . , Nicholson, A . , Boneh, T . , and
Steinle, V. (200 1 ) . Modelling teaching for concep­

tual change using a Bayesian network.

Submitted

to Int. Journal of AI in Education.
[Stacey and Steinle, 1 999] Stacey, K. and Steinle,
( 1 999 ) .

V.

A longitudinal study of childen's thin k­

ing about decimals: a preliminary analy s i s . In Za­
slavsky, 0 . ,

editor, Proc. of the 23rd Conf. of the

Int. Group for the Psychology of Mathematics Edu­
[van der Gaag et al. , 2000] van der Gaag, L., Renooij ,

S . , Ale m an ,

B. ,

and Taal, B . (2000) . Evaluation of

a probabilistic model for staging of oesophageal car­
cinoma. In Medical Infobahn for Europe: Proc. of
MIE2000 and GMDS2000, pages 772-776, Amster­

dam. !OS Press.

[Heckerman et al. , 1994] Hecker man , D., Geiger, D . ,

cal data.

O ni sko , A.,

cation, volume 4, pages 233-241 , Haifa. PME.

D.

unification for discret e and gaussian domains.
Besnard,

al. , 2000]

Wasyluk, H. (2000) . Learning Bayesian network p a­

Search. Number 8 1 in Lecture Notes in Statistics.

Lehn, K . , and Druzdzel, M . ( 1997) .

D.

[Onisko et

S pringe r Verlag.

[Conati et al. , 1997] Conati,

Geiger,

tion Research Group of Australasia), pages 409-4 1 6 .

Scheines, R.

References

dent

A . , edi­

MERG A , Freemantle.

OR gates. In

The authors would like to ac­

Acknowledgements

In Chapman,

H o ng Kong.

M ayo , M. and Mitrovic, A.

Optimising ITS behaviour with Bayesian

[VanLehn and Niu, 2001] VanLehn, V. and Niu,

Z.

(200 1 ) . Bayesian student modelling, user interfaces
and fe edb ack : a sensitivity analysis. Int. Journal of

AI in Education (to appear), 1 2 .

(Wallace and

Dowe, 2000] Wallace, C.

and

Dowe, D .

(2000) . MML clustering o f mult i- s t at e , Poisson, von

Mises c i rcul ar and Gaussian distributions. Statistics
and Computing, 1 0 ( 1 ) : 73-83.
[Wall ace and Korb, 1999] Wallace, C. S. and Korb,

K.

B. ( 1999) .

Learning linear causal models by

MML sampl ing. In Gammerman, A., edi t or, Causal

Models and Intelligent Data Management. Springer­
Verlag.

