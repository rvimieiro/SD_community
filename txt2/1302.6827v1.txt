A consequence relation is then generally defined by
taking the intersection of the logical closures of these
preferred sub-bases. Each formula of the KB is con­
sidered as a distinct piece of information, which can
1 In this case the preferred sub-bases coincide with the
extensions of default logic [36] restricted to normal defaults
without prerequisites.

be kept in the knowledge base or rejected from it in­
dependently from the others; therefore, it may happen
that two semantically equivalent knowledge bases may
be revised differently and thus lead to different conclu­
sions - this is why they are called syntax-based. Con­
sider for instance K1 = {p, •p, q} and K2 = {pl\q, •p};
q holds in all maximal consistent sub-bases of Kt but
this is not the case for K2. When cardinality is used
to select preferred subbases, even the number of oc­
currences of identical (or logically equivalent) formu­
las in K matters: for instance, {p, -,p} has two consis­
tent sub-bases of maximum cardinality ( {p} and { -,p})
where as {p, •p, -,p} has only one ( { -,p, •p}).
Now, in model-based diagnosis, the consistency-based
approaches (see [37], [13], [35]) proceed in a very sim­
ilar manner, since they look for preferred candidates,
i.e. minimal (w.r.t. a given selection criterion) sets of
faulty components, such that the description of how
the non-faulty components work is consistent with the
observations2. The link between default reasoning and
model-based diagnosis has already been well studied
(e.g. [33], [37], [26], [20]): indeed, the principles be­
hind consistency-based diagnosis and syntax-based ap­
proaches are basically the same: there is a correspon­
dance between a source providing us with a piece of
information and a component of a diagnosis problem;
a faulty component corresponds to an erratic source
which gives a piece of information which is not rele­
vant (by analogy, we will say that the source is faulty).
When the component is working correctly, the formula
describing its normal behaviour must be satisfied, and
analogously, when the source is not faulty, the formula
associated to it must be true in the real world. Then, a
candidate in a diagnosis problem (i.e. a set of compo­
nents consistent with the observations) corresponds to
a candidate in a syntax-based default reasoning prob­
lem (i.e. a set of formulas whose deletion restores the
consistency of the knowledge base).
In the well-known diagnosis system GDE, De Kleer
and Williams [11] propose a probabilistic criterion to
2The principle of minimizing the set of faulty compo­
nents w.r.t. a given criterion is generally called principle
of parsimony (see e.g. [29]).

392

Lang

rank candidates: each component has an initial prob­
ability of fault, and it is assumed that components fail
independently; then, the a posteriori probability that
a given candidate is the real candidate is computed
via Bayes' rule, conditioning by the observations. This
principle of ranking candidates w .r.t. their probability
assumes the initial probabilities of fault are available.
W hen it is not the case, De Kleer [12] proposes to as­
sume that all components have a very small probability
of fault. W hat we propose to do here is to use a similar
assumption for syntax-based default reasoning, which
induces probabilities of the consistent sub-bases of the
KB (which comes down to compute the probabilities
of the candidates - a candidate specifies which pieces
of information have to be rejected and thus which ones
remain in the KB). We will check that, as expected,
the consistent sub-bases of maximal cardinality are the
most probable ones. This probability distribution in­
duces then a Dempster-Shafer belief function, which
evaluates the probability that a formula can be proved
from the available evidence (which consists only in the
KB and the assumptions of independence and small
probabilities of fault). The most original contribution
of this paper is to propose (and to compare) many
different ways to define a syntax-based consequence
relation from this induced belief function. An inter­
esting point is that we will then recover some already
known syntax-based consequence relations (but with a
new justification) and obtain a few new ones. Lastly,
we propose briefly a generalization to the case of pri­
oritized knowledge bases.
2

Inconsistent knowledge bases as
systems to diagnose

From now on, £ denotes a propositional language gen­
erated by a finite number of propositional variables.
Formulas will be denoted by greek letters rp, ¢, etc.
T denotes t autology, F= classical entailment and Cn
logical closure.
A knowledge base (KB) intuitively consists of a set :F of
hard facts which cannot be rejected, and a multiset �
of default formulas which can be rejected if necessary3.
To distinguish each default from the others, we create
a set of assumptions A = {A1, ... ,An} (with as many
assumptions as defaults) and label each default with
a distinct assumption. We define a knowledge base as
in [31] and we then recall well-known definitions of the
ATMS and model-based diagnosis literatures [10], [37],
[11], [13].
Definition 1 A knowledge base K is defined as a
couple K = (:F, Ll) where
3We recall that in a multiset several occurrences of the
same element are distinguished: this obviously has to be
the case for syntax-based approaches where several occur­
rences of the same default constitute several distinct pieces
of information.

•

:F is a finite set of formulas (hard facts)

•

Ll=

{'Pl. .. . , 'Pn} a finite multiset of formulas (de­
faults).

The assumption set A (K) associated to K (denoted
by A when no confusion is possible) is defined by A
= { A1, ... , An} where each assumption is associated to
a default by the mapping 6: Vi= l...n, 8(Ai) ='Pi·
Definition 2 A subset of A is called an environ­
ment. The context of an environment E is defined
by Context( E) = Cn(:F U{ rp; lA; E E} ) 5. An envi­
ronment E is consistent iff Context(E) is consis­
tent. It is irredundant iff no proper superset of E is
consistent6 It is consistent with maximal cardinality
(or, for short, maxcard consistent) iff for any con­
sistent E' we have lEI 2: IE' I·
A nogood is an inconsistent environment. A candi­
date C is the complementary of a consistent environ­
ment. It is minimal iff no proper subset of C is a
candidate; it is a candidate of minimal cardinality (or
mincard for short) iff for any candidate C' we have
ICI � IC'I7·
•

Pursuing the analogy with model-based diagnosis, the
source of information corresponding to the assumption
A; can be viewed as a component; rp; is then the log­
ical description of how the component works. If A; is
true then the source is "non-faulty" and the associated
formula 'Pi is satisfied in the real world; if A; is false
then the source is "faulty" and then we don't know
whether the associated formula is satisfied or not in
the real world {in terms of diagnosis, it corresponds
to the assumption that we don't know how behaves a
faulty component).
As in [13] a nogood {Ait> .. . , Ai,} will also be written logically by -.A; 1 V ... V ..,A; P 8 ; a candidate
{Ah, . .., AJ.} will also be written logically by -,Ail ('­
... I\ -.AJ.· The nogood base, denoted by -.N, ts
the conjunction of all irredundant nogoods; it is well­
known to be equivalent to the conjunction of all mini­
mal nogoods, and as well to the disjunction of all [irre­
dundant] candidates [13]. A detailed example is given
in Section 3 and continued in Section 4.

4Instead of this we could have equivalently generated
the set of ATMS justifications A; ---+ <p;
5Note that Context(A) K.
6This is called an interpretation in [10]
7 Obviously, a minimal (resp. mincard) candidate is the
complementary of an irredundant (resp. maxcard) consis­
tent environment.
8Note that -.A;, corresponds to De Kleer et al.'s [13]
notation AB( c;i) meaning that the component c;1 is faulty.
=

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

393

... I\ ;,. �

t:n-k+l.

From syntactical knowledge bases to

3

belief functions
3.1

(

Computing the probability of
environments

As in

[12}

we make the two following basic assump­

tions:
(I) each assumption is independent from the oth­
ers. This means t ha t each default piece of infor­
mation is kept or rejected independently from the
others - which is in accordance with the spirit of
syntax-based approaches to default reasoning.

•

(S) all assumptions are assigned the same initial

•

1\

of more than two C;'s: P r (C; 1
C )
k
Thus, Pr(-.N) = pt:n- + O(e-n-Hl). Now,

probability (the sources have the same prior prob­
ability of fault), and this probability of fault is
very small: Vi, Prob(-.A;) = t:, with£« 1.
This leads to define a probability assignment on the en­
vironment set 2A. Thus, the prior probability of an en­
vironment E of cardinality k is P r(E) = t:Tl-k(l- c)k
(which is approximated by c:Tl-k when c:-+ 0). Pr ( E)
is the prior probability that E is the real environment,
i.e. the environment corresponding to the real world.
Now, this real environment must be consistent; to en­
sure that inconsistent environments are given a zero
probability, the prior probability is conditioned on the
consistent environments (see e.g.

E f=

-.N

�
,n-IEI(t-€ 1EI)
�'
so Pr E I -.N) = P r(-,N} = •"-li+0(€ "-1<+1 ) ; th ere1ore
P
if /EI = k, Pr(EI-.N) = � + O(t:); and if lEI < k,
Pr(EI•N) = O(e-J:-1£1).
Computing the probability of the consistent environ­
ments is exactly the same task as computing the proba­
bilities of candidates in consistency-based model-based
diagnosis ([11], [12], [35]). Proposition 1 tells that the
only consistent environments whose probability does
not tend to

0

when t:

-+

0

are those of maximal car­

dinality. This is in accordance with a version of the
principle of parsimony consisting in considering only
the candidates of minimum cardinality

( [12} , [29]).

It is also interesting to compute the probability of fault

of a single source, namely

Pr(-.Ad-.N):

Proposition 2 As before, assume that there are e:r­
actly p maxcard consistent environments and let k be
their cardinality. Let A; be an assumption.
•

if A; is absent of r �
ronments, then

•

if A; appears in all maxcard consistent environ­
ments, and is absent of r' irredundant consistent

1

maxcard consistent envi­

[22)), i.e.

environments of cardinality k- 1, then

p max­
card consistent environments; let k be their cardinality.
Let E be any consistent environment. Then9

Proposition 1 Assume that there are exactly

•

if /E/ = k then Pr(E/-,N)=

•

if /E�

Proof:

<

l +

p

O(t:)

k then Pr(EI-.N) = O(t:k-IEI)

us prove first prove that Pr( -.N)
Let C1, ... ,Cp be the mincard
candidates; they are the complementary of the max­

k
pen- +

let

O(t:Tl-k+1).

card consistent environments, so their cardinality is
n - k. Let Cp+l, . . . , Cq be the other irredundant can­
didates. P r (-.N ) = Pr(C1 v . . . v Cq) == Pr(Ct) +
... + Pr(Cp) +Pr(Cp+t) + .. . + Pr(Cq)- Li#i Pr(C; 1\

Ci )+ "E.,;'Ii,UI,ifl Pr(C;I\Ci 1\Cf)+ ... . Now, Pr(C1) =
... = Pr(Cp)= cn-k; Vi= p + l...q, Pr(C;) = t:Tl-k+l;
and Vi, j such that i :j:. j, C; 1\ C; contains at most
n - k + 1 l iterals ..,A;'s (if it contained only n - k,
since n - k is the m aximum cardinality of a con­
sistent environment, one of the two candidates C;
and Cj would be contained in the other one, which

would contradict the fact they are irredundant); thus,
Pr( C; 1\ C;) � e-" -k+l. A fortiori, for all conjunctions
9We recall that the notation O(gk) denotes any function

f of

g

such that

.IJ�l

-+c-o

0.

The proof uses the same kind of considerations as the
proof of Proposition 1.

Remark: if A; appears in all irredundant consistent
environments, then r' = 0 and Proposition 1 gi ves

Pr(-,A;/•N) = €. Indeed, in this case, -.A; never
appears in -.N and therefore -.A; and •N are inde­
pendent; thus Pr(-.A;/-,N)= Pr(•A;)::::: €.

Example: F :::: {a} and to contains the following for­
mulas (with their respective Ai 's):
b 1\ e 1\ f

A1

a -+

A.1

e
-.b 1\ ..,c 1\ -.e 1\ g
b 1\ -.c 1\ d 1\ --..e 1\ -,g

A2 a-> c 1\ d
Aa ..,b v -.d
As
As

Here are the irredundant consistent environments,
their probability and their context10:
10We omit the Cn notation in the context culumn, so
for instance it should be read Context({A1,A2,A�})
Cn( {a, b, c, d, e, f}) etc.
=

394

Lang

E

) Pr(E)-.N) l

Context(E)

� + O(e:)
� + O(e:)

b, •d, e, f
--,b, c, d, e
a, •b, --,c, •e, g
a, b, •c, d, -.e, -.g

{At,Aa,A4}
{A2,Aa,A 4}
1A3,Asl
{As}
Here are the

a,

Be lx (t/J )

a,

O(e:)
O(e::t)

Pr( -.A;I•N):

The

maxcard
consistent
environments
{At,A2,A4}, {At,A3,A4} and {A2,A3,A4}.

are

How probabilities of candidates induce a
belief function

We have seen that the knowledge base K induces
a probability assignment of the environment see 2.A.
This probability assignment of the assumption set in­
duces a Dempster-Sha.fer belieffunction (see

f22}, [34],

[27], [9], [38] for a study of this connection between
ATMS and belief functions). As studied in detail by
Smets [38], this belief function represents a probability
of deductibility, i.e. the probability that the evidence is
sufficient to prove the proposition (see also [22], (27]).
This belief function is given by11

Pr(E I · N)
EE2"\"P/IE Context(E)
Proposition 3

Belx ( t/J)

= 1

iff :F

I= t/J

Proof if :F I= 1j; for any environment E, ¢ E
Context(E) and therefore Belx(¢) = 1. Reciprocally,
if Belx(¢) = 1 then consider the environment 0; it
has a non-zero probability and its context is only :F,
therefore :F F= t/J.
Let k..p be the maximum cardinality of
a consistent environment E such that t/J E Context(E)
(if any) and let U!fi be the number of such environ­
ments; as before, let k be the cardinality of a maxcard
consistent environment. Then

Proposition 4

•

if k!/1

=

k then

Be/K(¢)
•

if k!/1

<

u..p

=-

p

+

O(e:)

k then

Belx(¢)

=

O(e:k-k")

11
An equivalent expression of
stance [22])

1

B e I1'. ( ·"'· )

=

Belg(I/J)

=

0

The proof comes immediately from Proposition 1.

Pr(-.A1)-.N) = Pr(-.A2) = Pr(-.Aa) = � + O(e:);
Pr(-.A4)-.N) = (1 + k)e: + O(e:2) = �c + 0(.:2);
Pr(•A5)-.N) = Pr(•A6)-.N) = 1 +O(c);

3.2

if there is no consistent environment E such that
1j; E Conte:ct(E) then

•

is (see for in­

Pr( la b e l ( 1/J) A -.N)
Pr( -.N)

where label( 1/J) is the logical expression of the set of all ir­
redundant consistent env ironments in which 1/J is provable.

Example (continued):
Belx (b V c ) = 1;
Belx(b) = � + O(s);
Be lx(g) = O(s);
Belx(•g) = O(e:2);
Belx(-.f) = 0.

4

Inducing consequence relations

We have seen that, given a knowledge base K, and
assuming small fault probabilities and independence
of the sources, we obtain a belief function Belx on £
induced by K; Be/K (¢) is the probability that ¢ be
deductible from K from the evidence. Now, we can use
this generated belief function to define nonmonotonic
consequence relations (CR) on £. We are going to
investigate several proposals of CRs, many of which
will appear to be well-known. We define the CRs in the
syntax as Pinkas and Loui [30], namely K f'-- ¢ means
that the formula¢ is inferred from the knowledge base

K12.

As in [31] we define a scenario of K = (:F, �) as a
consistent subset S of :F U� containing :F (note that
Cn(S) is the context of a consistent environment). A
scenario is said irredundant (resp. maxcard) iff it is
maximal w.r.t. set inclusion (resp. cardinality).
Definition 3

K h ¢ iff Belx(¢)

Proposition 5

S of K, S f= t/J.

-+

...... o 1

K f'--t 1j; iff for any maxcard scenario

The proof comes easily from the fact that only max­
card consistent environments have a probability which
does not tend to 0. This kind of CR is known as a
strong CR. More precisely, f---1 has been studied in a
more general setting (and with priorities) in (23] and
[1]13. This result gives thus a n ew interpretation of
this well-known inference relation.
12Note that, in spite of the syntax K f"-- 1/J, f"-- is actu­
ally a unary CRs; a binary CR induced by K would be f"-- K
where rp f"--K 1/J means that with respect to the background
knowledge represented by K, if we assume rp then we infer
nonmonotonically 1/J (and the unary case is recovered when
rp = T). For the sake of simplicity, in this paper we define
only the unary restrictions of the CRs; however this restric­
tion is not essential: indeed, syntax-based CRs generally
satisfy tp f"--K 1/J iff f---Add(K,\0') 1/J, where Add(K,rp) = (.F
U{<p}, t:.) (see [1]).
13 As shown in [23] and (1], the binary and prioritized
version a£ f"--1 is a rational inference relation which is fur­
thermore well adapted to the handling of default rules.

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

0 such that

395

Proposition 6 K r-2 1/J iff there is a maxcard sce­
nario S such that S f= 1/;.

A sufficient condition for K f---6 ¢ to hold is when
the number of maxcard s ce n ari os entail ing 1/; is greater
than the number of maxcard scenarios ent ailin g -,'1/J.
However this condition is n ot necessary; the exact
characterization is more complex:

Again, the proof comes from the fact that the consis­
tent environments with a non infinitely small belief are
the maxcard ones. This CR is the weak ( existential)
counterpart of f---1.

Proposition 11 Let u(k, '1/J) be the number of sce­
narios of K of cardinality k entailing ¢.
Let
diff ('I/J, -.¢) = Max{k, u(k, 1/!) =/: u(k, •1/J)}. Then
K f-.-7 '1/J iff u(diff(l/J, -.1/J), 1/!) > u(diff('I/J, -.'1/J), -.'1/J).

Definition 4 K

BelK(l/J)

-+-,

..... o

a

r-2

1/J iff 30!

5 K f-.-a 1/J iff3a
and BelK(-.1/J) -+c-o 0.

Definition
a

>

> 0 s.t. BelK(l/J)

Proposition 7 K f---3 1/J iff K f-.-2

-+,

1/; and K J'v2

..... o

-.'1/J.

The proof comes straightforwardly from Propositions
5 and 6. This kind of CR, called argumentative in [2),
is intermediate between weak and strong CRs.

Definition 6 K f-.-4 1/J iff BelK ( 1/J) > 0
Proposition 8 K f-.-4 1/J iff there is a scenario S of
K such that S f= 1/J, or equivalently, iff there JS an
irredundant scenario S of K such that S f= '1/J.
The proof comes from the fact that all consistent en­
vironments have a non-zero probability. This well­
known weak CR corresponds to the provability in at
least one extension of a normal default theory without
prerequisites14.

Definition 7 K
BelK(•I/!) = 0

f---5 1/J iff BelK ('1/J)

>

0 and

Proposition 9 K r-5 '1/J iff there is a scenario of K

entailing '1/J and if there is no scenario of K entailing
-,-rjJ.
This result is a corollary of Propositi on

8.

This CR is

another argumentative CR.

Definition 8 K

f-.-s 1/! iff BelK(1/!)

>

K f---6 -rjJ iff '1/J is provable in the ma­
jority (more than one half) of the maxcard scenarios
of K.

The proof comes directly from the fact that all max­
card consistent environments have all the same proba­
b ility ( namely l) and that the non-maxcard ones have

infinitely

been called

p

small probability. This kind of

majority

CR has

CR in [30].

Definition 9 K f---7 -rjJ iff BelK('IfJ) > BelK(•'I/J)

(

1•
The corresponding strong CR provability in all exten­
sions , which is more interesting and which has received
many improvements in the literature, seems to have no

)

nice characterization in our framework.

y

this case, let

7

k*

be the cardinality of the
maxcard consistent environments, then u(k*, 1/J) = u.p,
u(k*, -,¢) = u-..p and diff('I/J, -.-rjJ) = k*;

u-..p > 0; in

O(ek1) and BelK(-,-rjJ) = O(ek�) with
BelK(-.1/J) = 0; in this case, u(k•­
k1,'1/J) > 0, u(k*- k1,•'1/J) = 0 and diff('I/J,-.'1/J) =
k*- kt;
- BelK(rP) = O(c:k1) and BelK(-.7/J) = O(c:k1) as well;
in this case, we have to develop further the expres­
sion of Pr(EI -.N) in Proposition 1 , which would show

�

BelK(I/!)

=

k2 > k1 � 0, or

that if among the consistent environments of cardinal­
ity k.p(= k...,.p), there are more entailing 1/; than en­
tailing -.1/J, but if there are exactly as many, then it
depends on the number of c onsist ent environments of
cardinality k.p - 1, and so on.

that this CR has a lexi­
indeed, Prop ositi on 11 co uld have
stated equ ivalently by :
It is dear from this proof

co grap hic spirit :

L('I/J)
L(-.¢) = (u(k,-.1/;),k =

(u( k , '1/J), k = n. .. l) and
then K f-.-7 '1/J iff
L(¢) >lex L(-.1/J), where >lex is the lexicographic or­
dering.

Proposition 12 Let

Definition 10 K
BeiK .,.p
BeiK 1/J)

_,.<-+0

O

=

n .. . l)

f-.-s ¢ iff BelK(l/J)

>

0 and

·

Proposition 13 K f-.-a ¢ iff k.p > k-..p, where k.p is
been defined like in Proposition 4, with the convention

�

Proposition 10

an

Here is a s ke t ch of the proof: there are 3 situations
where BelK(l/J L > Be/K(-.7/J):
- BelK(rP) =
and BelK(•I/!) =
where u.p >

kl/i = -oo iff¢
environment.

appears

in the context of no consistent

The proof comes easily from Proposition 4.

Definition 11 K r-9 w iff BelK('l/J) = 1.
Proposition 14 K f---9 '1/J iff :F
This is

a

f= 1/;.

cl one of P ro p osit i on 3 and has thus

already

been proved. This CR is very strong and it is even
monotonic since it accepts only the consequences of
hard facts.

Proposition 15 Let --< be the relation between CR 's
(as in {30}) defined by h--< h iffVK., ¢, K h -rjJ =>

K 1----J 7/J. This relation between our f-.-; 's is depicted
by the graph on Figure 1.

396

Lang

llh

a

bvc
c

b

f

-,d
g

�J

{

..,g

...,f
5

Figure 1: the

-<

relation between l---i's

The proof would be long and tedious but does not
present any particular difficulty. Note that the exam­
ple at the end of the Section gives counterexamples
corresponding to almost all couples of CR.s such that
hi h · Pinkas and Loui [30) define a safe CR as a
CR !--- such that '</K, '</1/J, K J'v 1/J or K J'v -.tjJ. It
can be checked easily that !---2 and l---4 are generally
unsafe while the other ones are safe.
Proposition 16

When K is consistent, all f--; 's ex­
cept f--.-9 collapse to classical entailment, i.e. K r-; tjJ
iff :F UA f= t/J.

Proof" when K is consistent, there is only one maxcard
scenario: K itself. Therefore K !---1 if; iff K f= 1/;, and
a fortiori, all h below in the graph collapse to f=. It
remains to show it for f--.-5, which is straightforward.

This list of CR's is of course not exhaustive and
one could think of giving other definitions, possibly
parametrized by a given a > 0. The interest of such
a list of CR's is to enable the user to use the most
adapted CR to her specific problem, knowing that
whichever CR she chooses, it will have an interpre­
tation in terms of the belief function induced by the
KB and assumptions (I) and (S). While very cautious
CR.s such as r-1 and very adventurous ones such as r-4
or r-s are often considered as too extreme in practice,
the more quantitative CR.s r-s, !---1 (and r-s which is
maybe a bit less quantitative) seem to be good com­
primises inbetween, and furthermore their DS inter­
pretation is appealing.
Example (continued):

Let � = ( b V c V -.e ) 1\ g. In the following table, the sign
x (resp. the sign - ) means that the formula is (resp.
is not) entailed w.r.t. h· There is no column for r-9
(obviously, only a is a r-9-consequence of K).

X
X

-

hlhhhFrlh
X
X
X
X

-

X
X
X

X

-

X
X
X
X
X
X

-

X
X
X

X

X
X
X
X
X

-

-

X
X

X
X

-

-

X

X

X

-

h
X
X
X
X
X
X
X
X
X

-

Extension to the prioritized case

Many syntax-based approaches to default reasoning
assume that the knowledge base is partitioned into
priority levels, namely K = (Kt, . .., Kn) (1 being by
convention the most prioritary level); these levels are
qualitative and generally it is more acceptable to vi­
olate any number of formulas of a lower priority level
then violate one formula of a higher priority level.
A generalization of the maximum cardinality princi­
ple to the prioritized case is defined both in [1] and
in [23]: a sub-base A of a prioritized knowledge base
(K1, ... , Kn) is lexicographically strictly preferred to a
sub-base B iff there exists a i E l..n such that '</j > i,
lA n Sj I = IB n Sj I and lA n Sd > IB n si I; the
same selection criterium has been used in diagnosis
by DeKleer [1 '2]. Now, it is possible to character­
ize lexicographically preferred subtheories in terms of
probabilities of fault; following De Kleer [12], for any
piece of information in Ki we assign an initial proba­
bility of fault of t:; to its source, with the constraint
that '</i and '</j > i, €J � €i (more precisely, that
€j < c{ma:r, where fmax is an upper bound of the
maximum number of formulas of a priority level - we
may take for instance fmax = IKJ). Then it can be
shown that the only consistent environments of K hav­
ing an a posteriori probability which does not tend to
0 when € --+ 0 correspond exactly to the lexicograph­
ically preferred subbases (which generalizes Proposi­
tion 1 ) , and that 1/J is lexicographically deduced from
K iff Belx('I/J) -t-o 1 (which generalizes Proposition
5).

6

Related work and conclusion

We have strengthened the already known connections
between syntax-based default reasoning, model-based
diagnosis and ATMS, and belief functions, by building
on deKleer's infinitesimal probabilities of fault. We
have followed the following steps:
(1) syntax-based nonmonotonic entailment is viewed
as diagno sis, by considering each piece of information
as the description of how a component works, and the
source which provided us with it as the component;
(2) we assume that all sources have very small {and
equal) initial probabilities of fault, and that they are

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

independent;

(3)

we compute the probabilities of each candidate,
and then a belief function on the language which can
be interpreted as a probability of provability;

(4) we use this belief function to define syntax-based
nonmonotonic consequence relations;
(5) lastly, we position these definitions in the litera­
ture of syntax-based approaches to nonmonotonic en­
tailment.
Our work integrates various subfields of AI and thus
there are many rel;ated works, more so bacause the
links between these subfliels had already received a lot
of attention in the literature. Many authors assign
prior probabilities to assumptions or components and
compute then posterior probabilities of candidates,
and some of them compute a belief function ([34] [27]

(22], (35])

but generally the initial probabilities are as­
sumed to be given by the user. De Kleer [12) uses the
same basic assumptions as us (2) but he computes then
posterior probabilities of candidates conditioned by a
measurement (in order to find the best measurement
to do next), which diverges from our step (4).
Furthermore,

397

definitions given in Section 4 still make sense in the
case we start with non-infinitesimal user-given proba­
bilities of failure; but the results do not hold any longer
and the characterization of these inference relations is
thus much less interesting.
We would like to emphasize that our contribution does
not really propose a new formalism nor a new way
to perform nonmonotonic reasoning, but rather puts
together the (already known) links between syntax­
based default reasoning on one side, and ATMS, di­
agnosis and belief functions on the other side, and as­
sumes further independence of the pieces of informa­
tion and infinitely small probabilities of failure. Now,
although the theoretical complexity of syntax-based
entailment relations has received recently some atten­
tion [25) [7], up to now, the more practical algorithmic
and implementation issues have been less studied in
the literature of syntax-based default reasoning than
in the literature of ATMS and model-based diagnosis.
Therefore, our conclusion (and our hope) is that that
syntax-based default reasoning should benefit from ex­
isting works on the aforementioned fields, such as the
characterization of tractable subclasses (e.g. [5]), ex­
perimental results etc.

it is worth noticing that the "non­

trivial" (i.e. other than 0 and 1) belief weights we
obtain when £ --> 0 are obtained from a completely
syntactic knowledge base without explicit numbers. A
related work which shares this feature is the Dempster­
Shafer handling of default rules of Benferhat and

Smets [3]: they start from a set of ranked default rules,
where the ranking comes either from the user or from
the ranking procedure of Goldszmidt and Pearl's Sys­
tem Z [28]; they associate then to each def ault of rank
i the mass 1-Ei (with Ei � 1 and Ei+! � ci) and com­
pute then a belief function assuming independence be­

cf

cJ',

tween the defaults. Note that
and
as well as ar­
bitrary products of£; 's, are not comparable. The com­
puted belief function is used to define an inference re­
lation (in the same way as f---I) which solves the prop­
erty inheritance blocking problem. The common point
to their work and ours is the generation of a belief
function from a knowledge base (in their approach, a
ranked set of default rules); but the objective pursued
is different: while they search for a consequence rela­
tion solving the blocking inheritance problem, we want
to characterize consequence relations in terms of prob­
abilities of fault of the sources. Other authors have
used infinitesimal probabilities in nonmonotonic rea­
soning, following Adams' £-semantics (especially Pearl
[27], Goldszmidt et al. [18)); in these approaches the
default rule a _. f3 is translated by Pr(f31a) � 1 - e:

with £ � 1. The main difference with our use of in­
finitesimal probabilities relies in their interpretation
(in the latter approaches they are conditional probabil­
ities qualifying default rules while in ours they qualify
the relevance of a piece of information).
Obviously, steps (3) and (4) can be done without as­
suming infinitely small prior probabilities. Thus, the

Acknowledgements
This work has been supported by the ESPRIT-BRA
Research Project "DRUMS-2" (Def e asible Reasoning
and Uncertainty Management Systems). Thanks to
Salem Benferhat, Didier Dubois and Henri Prade for
helpful discussions and comments on earlier versions,
and to the anonymous reviewers for helpful criticisms.

References
[1]

Salem Benferhat, Claudette Cayrol, Didier
Dubois, Jerome Lang and Henri Prade, Incon­
sistency management and prioritized syntax-based
entailment, Proceedings of IJCAI'93,640-645.

[2]

Salem Benferhat, Didier Dubois and Henri Prade,
Argumentative inference in uncertain and incon­
sistent knowledge bases, Proceedings of Uncer­
tainty in AI'93, 411-419.

[3]

Salem Benferhat and Philippe Smets, Belief func­
tions for logical problems: default logic by e:­
calculus, Abstracts of the Dagstuhl Seminar on
Automated Practical Reasoning and Argumenta­
tion, Dagstuhl (Germany), August 93.

(4] Gerd Brewka,

Preferred su.btheories: an extended

logical framework for default reasoning, Proceed­
ings of IJCAI'89, 1043-1048.

(5]

Tom Bylander, Dean Allemang, Michael C. Tan­
ner and John R. Josephson, The computational
complexity of abduction, Artificial Intelligence 49

(1991), 25-60.

398

Lang

[6] Claudette Cayrol,

Un modele logique general pour
le raisonnement revisable, Revue d'lntelligence

Artificielle 6(3): 255-284, 1992.
[7] Claudette Cayrol and Marie-Christine Lagasquie,

On the complexity on nonmonotonic entailment
in syntax-based approaches, Tech. Report, IRIT,

Toulouse, France, 1994. To appear.
[8] Luca Console and Piero Torasso, A

spectrum of
logical definitions of model-based diagnosis, Com­

putational Intelligence 7 (3), 1991.
[9] Bruce D'Ambrosio, Combining symbolic
meric approaches

[10]

[11]
[12)
[13]

[14]

[15]

[16]
[17]

and nu­
to uncertainty management,

Proc. of the Uncertainty in AI Workshop 1987,
386-393.
Johan de Kleer, An assum_Pti?n-based TMS and
_
Extending the ATMS, Arttfictal lntelhgence 28,
127-162 and 163-196.
Johan de Kleer and Brian C. Williams, Diag­
nosing multiple faults, Artificial Intelligence 32
(1987), 97-130.
Johan de Kleer, Usi�g cr�de probabiWy esti­
.
_
mates to guide disgnosas, Artificial Intelbgence
45
(1990), 381-392.
Johan De Kleer, Alan K Mackworth and Ray­
mond Reiter, Characterizing diagnoses and sys­
tems, Artificial Intelligence 56 (1992), 197-222.
Ronald Fagin, Jeffrey D. Ullman and Moshe Y.
Vardi , On the semantics of updates in databases,
.
in 2nd ACM SIGACT-SIGMOD Symposmm on
the Principles of Databases Systems, Atlanta,
1983, 352-365.
Hector Geffner, Causal and conditional theories,
MIT Press, 1992.
M.L. Ginsberg. D.E. Smith, Reasoning � bout ac­
.
tions I: a possible worlds approach, Artificial In­
telligence 35 (1988), 165-195.
Moises Goldszmidt and Judea Pearl, System z+:

a formalism for reawsoning with variable-strength
defaults, Proceedings of AAAI'91.

[18] Moises Goldszmidt, Paul Morris and Judea Pearl,
A maximum entropy approach to nonmonotonic
reasoning, Proceedings of AAAI'90, 646-652.

[19] Georg Gottlob, Complexity results for nonm:ono­
tonic logics, Journal of Logic and Computatwn 2
(3), 397-42.5, 1992..
(20] Ulrich Junker, Prioritized defaults: implementa­
tion by TMS and application to diagnosis, Proc.
of IJCAI'91, 310-315.
[21] Sarit Kraus, Daniel Lehmann and Menahem
Magidor, Nonmonotonic reasoning, preferential
models and cumulative logics. Artificial Intelli­
gence 44 (1990), 167-207.
[22] Kathryn B. Laskey and Paul E. Leh�er.' Assum�­
tions, beliefs and probabilities, Artificial Intelh­
gence 41 (1989/90), 65-77.

[23] Daniel Lehmann, Another perspective on default
reasoning, Technical Report 92-12., Hebrew Uni­
versity of Jerusalem, 1992.
[24] Bernhard Nebel, A knowledge level analysis of be­
lief revision, Proceedings of KR'89, 301-311.
[25] Bernhard Nebel, Belief revision and defa�lt rea­
soning: syntax-based approaches, Proceedmgs of
KR'91, 417-428.
[26] Eric Neufeld, Default and probabilities; extensions
and coherence, Proceedings of KR'89, 312-323.
[27] Judea Pearl, Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference, Mor­
gan Kaufmann, 1988.
[28] Judea Pearl, System Z: a natural ordering of de­
faults with tractable applications to default rea­
soning, Proceedings of TARK'90, 121-135.'

[29) Y. Peng and J.A. Reggia,

Abductive inference
models for diagnostic problem-solving. Symbolic

Computation - AI series, Springer Verlag, 1990.
[30] Gadi Pinkas and Ronald P. Loui, Reasoning from
inconsistency: a taxonomy of principles for re­
solving conflicts, Proceedings of KR'92, 709-719.

[31] David Poole, A logical framework for default reasoning, Artificial Intelligence 36 (1988), 27-47.
David
Poole, Normality and faults in logic-based
[32]
diagnosis, IJCAI'89, 1304-1310.
[33] David Poole, Randy <?oebel and Romas Aleli­
.
unas, Theorist: a logzcal reasontng
system for
defaults and diagnosis, in The Knowledge Fron­
tier: Essays in the Representation of Knowledge

(N. Cercone, G. McCalla, eds.), Springer-Verlag,
1987, 331-352.
[34) Gregory M. Provan, An analysis of ATMS-bas�d

techniques for computing Dempster-Shafer beluf
functions, IJCAI'89, 1115-1120.

[35] David Poole and Gregory M. Provan ,
the most

What is

likely diagnosis?, Uncertainty in Artifi­

cial Intelligence 6 (P Bonissone, M. Henrion, L.
Kanal, J .F. Lemmer eds. ), 89-105.
[36] Raymond Reiter, A logic for default reasoning,
Art ificial Intelligence 13, 1 (1980), 81-132.
[37) Raymond Reiter, A theory of diagnosis from first
principles, Artificial Intelligence 32 (1987), 57-95.
[38] Philippe Smets, The provability of ded-uctibility
and belief functions, Proc. of ECSQARU'93, 332340.

