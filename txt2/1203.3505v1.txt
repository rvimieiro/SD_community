1983), and “strong ignorability” (Rosenbaum and Rubin, 1983).
This paper addresses a different question: Given two
sets of variables in a DAG, decide if the two are equally
valuable for adjustment, namely, whether adjustment
for one set is guaranteed to yield the same asymptotic
bias as adjustment for the other.
The reasons for posing this question are several. First,
an investigator may wish to assess, prior to taking
any measurement, whether two candidate sets of covariates, differing substantially in dimensionality, measurement error, cost, or sample variability are equally
valuable in their bias-reduction potential. Second, assuming that the structure of the underlying DAG is
only partially known, one may wish to assess, using
c-equivalence tests, whether a given structure is compatible with the data at hand; structures that predict
equality of post-adjustment associations must be rejected if, after adjustment, such equality is not found
in the data.
In Section 2 we define c-equivalence and review the
auxiliary notions of admissibility, d-separation, and
the back-door criterion. Section 3 derives statistical
and graphical conditions for c-equivalence, the former
being sufficient while the latter necessary and sufficient. Section 4 presents a simple algorithm for testing c-equivalence, while Section 5 gives a statistical
interpretation to the graphical test of Section 3. Finally, Section 6 discusses potential applications of cequivalence for effect estimation, model testing, and
model selection.

2

PRELIMINARIES:
c-EQUIVALENCE AND
ADMISSIBILITY

Let X, Y , and Z be three disjoint subsets of discrete
variables, and P (x, y, z) their joint distribution. We
are concerned with expressions of the type
X
A(x, y, Z) =
P (y|x, z)P (z)
(1)
z

Such expressions, which we name “adjustment estimands,” are often used to approximate the causal effect of X on Y , where the set Z is chosen to include
variables judged to be “confounders.” By adjusting
for these variables, one hopes to create conditions that
eliminate spurious dependence and thus obtain an unbiased estimate of the causal effect of X and Y , written
P (y|do(x)) (see Pearl (2000) for formal definition and
methods of estimation).
Definition 1. (c-equivalence)
Define two sets, T and Z as c-equivalent (relative to
X and Y ), written T ≈ Z, if the following equality
holds for every x and y:
X
X
P (y|x, t)P (t) =
P (y|x, z)P (z)
∀ x, y (2)
t

z

or
A(x, y, T ) = A(x, y, Z)

∀ x, y

This equality guarantees that, if adjusted for, sets T
and Z would produce the same asymptotic bias relative
to the target quantity.
Definition 2. (Admissibility)
Let P (y|do(x)) stand for the “causal-effect” of X on
Y , i.e., the distribution of Y after setting variable X to
a constant X = x by external intervention. A set Z of
covariates is said to be “admissible” (for adjustment)
relative to the causal effect of X on Y , if the following
equality holds:
X
P (y|x, z)P (z) = P (y|do(x))
(3)

node that is outside S and has no descendant in S.
If S blocks all paths from X to Y , it is said to “dseparate X and Y,” written (X⊥
⊥Y |S)G and then, X
and Y are independent given S, written X⊥
⊥Y |S, in
every probability distribution that can be generated by
a process structured along G (Pearl, 1988).
Lemma 1. (The back-door criterion: G-admissibility)
Let G be a directed acyclic graph (DAG) that encodes
the causal relationships between variables in a problem, observables as well as unobservable. A sufficient
condition for a subset S of covariates to be admissible
is that it satisfies the following two conditions (Pearl,
1993):
1. No element of S is a descendant of X
2. The elements of S “block” all “back-door” paths
from X to Y , namely all paths that end with an
arrow pointing to X.
A set S satisfying the back-door criterion will be called
G-admissible.
For proof and intuition behind the back-door test, especially a relaxation of the requirement of no descendants, see (Pearl, 2009a, p. 339).
Clearly, if two subsets Z and T are G-admissible they
are also admissible and they must be c-equivalent, for
their adjustment estimands coincide with the causal
effect P (y|do(x)). Therefore, a trivial graphical condition for c-equivalence is for Z and T to satisfy the
back-door criterion of Lemma 1. This condition, as
we shall see in the next section, is rather weak; cequivalence extends beyond admissible sets.

3

CONDITIONS FOR
c-EQUIVALENCE

Theorem 1. A sufficient condition for the cequivalence of T and Z is that Z satisfies:
(X⊥
⊥Z|T )
(Y ⊥
⊥T |X, Z)

(i)
(ii)

z

Equivalently, one can define admissibility using the
equalities:
P (y|do(x)) = P (Yx = y)
(4)
where Yx is the counterfactual or “potential outcome”
variable (Neyman, 1923; Rubin, 1974). The equivalence of the two definitions is shown in (Pearl, 2000).
Definition 3. (d-separation)
A set S of nodes in a graph G is said to block a path p if
either (i) p contains at least one arrow-emitting node
that is in S, or (ii) p contains at least one collision

Proof:
Conditioning on Z, (ii) permits us to rewrite the lefthand side of (2) as
P
P
A(x, y, T ) = Pt P (t) Pz P (y|z, x, t)P (z|t, x)
= t P (t) z P (y|z, x)P (z|t, x)
and (i) further yields P (z|t, x) = P (z|t), from which
(2) follows:
P P
A(x, y, T ) = Pt z P (y|z, x)P (z, t)
= z P (y|z, x)P (z)
= A(x, y, Z)

W1

W2

W1 , while choosing Z = {W2 } and T = {W1 , W2 }
violates condition (ii) by unblocking the path W1 →
X ← V1 → V2 → Y . Likewise, the sets T = {W1 }
and Z = {W2 } block the same path and, yet, are not
c-equivalent; they fail indeed to satisfy condition (ii)
of Theorem 1.

V2

V1

Y

X

Figure 1: The sets T = {V1 , W1 } and Z = {V2 , W2 }
satisfy the conditions of Theorem 1. The sets T =
{V1 , W2 } and Z = {V2 , W2 } block all back-door paths
between X and Y , hence they are admissible and cequivalent. Still they do not satisfy the conditions of
Theorem 1.
Corollary 1. A sufficient condition for the cequivalence of T and Z is that either one of the following two conditions holds:
C ∗ : X⊥
⊥Z|T
C ∗∗ : X⊥
⊥T |Z

and
and

Y⊥
⊥T |Z, X
Y⊥
⊥Z|T, X

We are now ready to broaden the scope of Theorem 1
and derive a condition (Theorem 2 below) that detects
all c-equivalent subsets in a graph.
Definition 4. (Markov boundary)
For any set of variables S in G; let Sm be the minimal
subset of S that satisfies the condition
(X⊥
⊥S|Sm )G

(6)

In other words, measurement of Sm renders X independent of all other members of S, and no proper subset of Sm has this property. This minimal subset is
called the Markov Boundary of X relative to S, or
“Markov boundary” for short.

(5)

The Markov boundary as defined above is known to be
unique, which follows from the intersection property of
d-separation (Pearl, 1988, p. 97). See Appendix A.

Proof:
C ∗ permits us to derive the right hand side of Eq. (2)
from the left hand side, while C ∗∗ permits us to go
the other way around.

Lemma 2. Every set of variables, S, is c-equivalent
to its Markov boundary Sm .

The conditions offered by Theorem 1 and Corollary 1
do not characterize all equivalent pairs, T and Z. For
example, consider the graph in Figure 1, in which each
of T = {V1 , W2 } and Z = {V2 , W1 } is G-admissible
they must therefore be c-equivalent. Yet neither C ∗
nor C ∗∗ holds in this case.
On the other hand, condition C ∗ can detect the cequivalence of some non-admissible sets, such as T =
{W1 } and Z = {W1 , W2 }. These two sets are nonadmissible for they fail to block the back-door path
X ← V1 → V2 → Y , yet they are c-equivalent according to Theorem 1; (i) is satisfied by d-separation, while
(ii) is satisfied by subsumption (T ⊆ Z).
It is interesting to note however that Z = {W1 , W2 },
while c-equivalent to {W1 }, is not c-equivalent to T =
{W2 }, though the two sets block the same path in the
graph.1 Indeed, this pair does not meet the test of
Theorem 1; choosing T = {W2 } and Z = {W1 , W2 }
violates condition (i) since X is not d-separated from
1
The reason is that the strength of the association between X and Y , conditioned on W2 , depends on whether
we also condition on W1 . Else, P (y|x, w2 ) would be equal
to P (y|x, w1, w2 ) which would render Y and W1 independent given X and W2 . But this is true only if the path
(X, V1 , V2 , Y ) is blocked.

Proof.
Choosing Z = S and T = Sm satisfies the two conditions of Theorem 1; (i) is satisfied by the definition of
Sm , while (ii) is satisfied by subsumption (T ⊆ Z).
Theorem 2. Let Z and T be two sets of variables
containing no descendant2 of X. A necessary and sufficient conditions for Z and T to be c-equivalent is that
at least one of the following conditions holds:
1. Zm = Tm
or
2. Z and T are G-admissible
Proof
1. Proof of sufficiency:
Condition 2 is sufficient since G-admissibility implies admissibility and renders the two adjustment
estimands in (2) equal to the causal effect. Condition 1 is sufficient by reason of Lemma 2, which
2

The sufficiency part of Theorem 2 is valid without excluding descendants of X. The necessary part can allow
descendants of X if we interpret Zm and Tm to represent
“reduced Markov boundaries,” namely Markov boundaries
exclusive of all nodes that are d-separated from Y given X.
For example, two children of X that are not on pathways
to Y would then be properly identified as “c-equivalent,”
even though they do not satisfy the conditions of Theorem
2.

W1

yields:

W4

Z ≈ Zm ≈ Tm ≈ T
2. Proof of necessity:
We need to show that if conditions (1) and (2)
are violated then there is at least one parameterization of G (that is, an assignment of conditional probabilities to the parent-child families in
G) that violates Eq. (2). If exactly one of (Z, T )
is G-admissible then Z and T are surely not cequivalent, for their adjustment estimands would
differ for some parameterization of the graph. Assume that both Z and T are not G-admissible
or, equivalently, that none of Zm or Tm is Gadmissible. Then there is a back-door path p from
X to Y that is not blocked by either Zm or Tm .
If, in addition, condition (1) is violated (i.e., Zm
differs from Tm ) then Tm and Zm cannot both be
disconnected from X, (for then Zm = Tm = ∅,
satisfying condition (1)), there must be a path p1
from either Zm to X that is not blocked by Tm
or a path p2 from Tm to X that is not blocked by
Zm . Assuming the former case, there must be an
unblocked path p1 from Zm to X followed by a
back door path p from X to Y . The existence of
this path implies that conditional on t, Z acts as
an instrumental variable with respect to the pair
(X, Y ). For such a structure, the following parameterization would violate Eq. (2). First we weaken
the links from Tm to X to make the left hand side
of (2) equal to P (y|x), or A(x, y, Tm ) = A(x, y, 0).
Next, we construct a linear structural equation
model in which Zm is a strong predictor of X
and X and Y are confounded. Wooldridge (2009)
has shown (see also (Pearl, 2009b)). that adjustment on Zm under such conditions results in a
higher bias relative to the unadjusted estimand, or
A(x, y, Zm ) 6= A(x, y, 0). This violates the equality in Eq. (2) and prove the necessary part of Theorem 2.

4

STEP-WISE TEST FOR
c-EQUIVALENCE

Figure 2 illustrates the power of Theorem 2. In this
model, no subset of {W1 , W2 , W3 } is G-admissible
(because of the back-door path through V1 and V2 )
and, therefore, equality of Markov boundaries is necessary and sufficient for c-equivalence among any two
such subsets. Accordingly, we can conclude that
T = {W1 , W2 } is c-equivalent to Z = {W1 , W3 }, since
Tm = W1 and Zm = W1 . Note that W1 and W2 ,
though they result (upon conditioning) in the same
set of unblocked paths between X and Y , are not
c-equivalent since Tm = W1 6= Zm = W2 . Indeed,

W2

W3

V1

V2

X

Y

Figure 2: W3 and W4 are non-admissible yet cequivalent; both having ∅ as a Markov boundary. However, W2 and W3 are not c-equivalent with Markov
boundaries W2 and ∅, respectively.

each of W1 and W2 is an instrumental variable relative
to {X, Y }, with potentially different strengths, hence
potentially different adjustment estimands. Sets W4
and W3 however are c-equivalent, because the Markov
boundary of each is the null set, {∅}.
We note that testing for c-equivalence can be accomplished in polynomial time. The Markov boundary
of an arbitrary set S can be identified by iteratively
removing from S, in any order, any node that is dseparated from X given all remaining members of S
(see Appendix A). G-admissibility, likewise, can be
tested in polynomial time (Tian et al., 1998).
Theorem 2 also leads to a step-wise process of testing
c-equivalence,
T ≈ T1 ≈ T2 ≈ . . . ≈ Z
where each intermediate set is obtained from its predecessor by an addition or deletion of one variable only.
This can be seen by organizing the chain into three
sections.
T ≈ . . . ≈ Tm ≈ . . . ≈ Zm ≈ . . . ≈ Z
The transition from T to Tm entails the deletion from
T of all nodes that are not in Tm ; one at a time, in any
order. Similarly, the transition from Zm to Z builds up
the full set Z from its Markov boundary Zm ; again, in
any order. Finally, the middle section, from Tm to Zm ,
amounts to traversing a chain of G-admissible sets, using both deletion and addition of nodes, one at a time.
A Theorem due to (Tian et al., 1998) ensures that
such a step-wise transition is always possible between
any two G-admissible sets. In case T or Z are nonadmissible, the middle section must degenerate into
an equality Tm = Zm , or else, c-equivalence does not
hold.
Figure 2 can be used to illustrate this stepwise transition from T = {W1 , W2 , V1 } to Z = {V2 , W3 }. Start-

ing with T , we obtain:
T ={W1 , W2 , V1 } ≈ {W1 , V1 } = Tm ≈ {V1 } ≈ {V1 , V2 }
≈ {V2 } = Zm ≈ {V2 , W3 } = Z
If, however we were to attempt a stepwise transition
between T = {W1 , W2 , V1 } and Z = {W3 }, we would
obtain:
T = {W1 , W2 , V1 } ≈ {W1 , V1 } ≈ {V1 }
and would be unable to proceed toward Zm = {W3 }.
The reason lies in the non-admissibility of Z which necessitates the equality Tm = Zm , contrary to Markov
boundaries shown in the graph.
Note also that each step in the process T ≈ . . . ≈ Tm
(as well as Zm ≈ . . . ≈ Z) is licensed by condition
(i) of Theorem 1, while each step in the intermediate
process Tm ≈ . . . ≈ Zm is licensed by condition (ii).
Both conditions are purely statistical and do not invoke the causal reading of “admissibility.” This means
that condition 2 of Theorem 2 may be replaced by the
requirement that Z and T satisfy the back-door test in
any diagram compatible3 with P (x, y, z, t); the direction of arrows in the diagram need not convey causal
information. Further clarification of the statistical implications of the admissibility condition, is given in the
next section.

interest; rarely is one in possession of prior information about conditional independencies, (as required by
Theorem 1), that is not resting on causal knowledge
(of the kind required by Theorem 2). The utility of
statistical characterization surfaces when we wish to
confirm or reject the structure of the diagram. We
will see that the statistical reading of Theorem 2 has
testable implication that, if failed to fit the data, may
help one select among competing graph structures.
Our first step is to apply Theorem 1 to the special case
where T is a subset of Z.
Theorem 3. (Set-subset equivalence)
Let T and S be two disjoint sets. A sufficient condition
for the c-equivalence of T and Z = T ∪ S is that S can
be partitioned into two subsets, S1 and S2 , such that:
(i0 )
and
(ii0 )

FROM CAUSAL TO
STATISTICAL
CHARACTERIZATION

Theorem 2, while providing a necessary and sufficient
condition for c-equivalence, raises an interesting theoretical question. Admissibility is a causal notion,
(i.e., resting on causal assumptions about the direction of the arrows in the diagram) while c-equivalence
is purely statistical. Why need one resort to causal
assumptions to characterize a property that relies on
no such assumption? Evidently, the notion of Gadmissibility as it was used in the proof of Theorem 2
was merely a surrogate carrier of statistical information; its causal reading was irrelevant. The question
then is whether Theorem 2 could be articulated using
purely statistical conditions, avoiding admissibility altogether, as is done in Theorem 1.
We will show that the answer is positive; Theorem
2 can be rephrased using a statistical test for cequivalence. It should be noted though, that the quest
for statistical characterization is of merely theoretical
3
A diagram G is said to be compatible with a probability function P if there is a parameterization of G that
generates P , i.e., if every d-separation in G corresponds to
a valid conditional independence in P .

S2 ⊥
⊥Y |S1 , X, T

Proof:
Starting with
A(x, y, T ∪ S) =

XXX
t

5

S1 ⊥
⊥X|T

s1

P (y|x, t, s1 , s2 )P (s1 , s2 , t)

s2

(ii0 ) permits us to remove s2 from the first factor and
write
P P P
A(x, y, T ∪ S) = Pt Ps1 s2 P (y|x, t, s1)P (s1 , s2 , t)
=
t
s1 P (y|x, t, s1 )P (s1 , t)
while (i0 ) permits us to reach the same expression from
A(x, y, T ):
P P
A(x, y, T ) = Pt Ps1 P (y|x, t, s1 )P (s1 |x, t)P (t)
=
t
s1 P (y|x, t, s1 )P (s1 , t)
which proves the theorem.
Theorem 3 generalizes closely related theorems by
Stone (1993) and Robins (1997), in which T ∪ S is
assumed to be admissible (see also Greenland et al.
(1999)). The importance of this generalization was
demonstrated by several examples in Section 3. Theorem 3 on the other hand invokes only the distribution
P (x, y, z, t) and makes no reference to P (y|do(x)) or
to admissibility.
Theorem 3 can also be proven by double application
of Theorem 1; first showing the c-equivalence of T and
{T ∪ S1 } using (i) (with (ii) satisfied by subsumption),
then showing the c-equivalence of {T ∪ S1 } and {T ∪
S1 ∪ S2 } using (ii) (with (i) satisfied by subsumption).

The advantage of Theorem 3 over Theorem 1 is that
it allows certain cases of c-equivalence to be verified in
a single step. In Figure 1, for example, both (i0 ) and
(i00 ) are satisfied for T = {V1 , W2 }, S1 = {V2 }, and
S2 = {W1 }), Therefore, T = {V1 , W2 } is c-equivalent
to {T ∪ S} = {V1 , V2 , W1 , W2 }
The weakness of Theorem 3 is that it is applicable to
set-subset relations only. A natural attempt to generalize the theorem would be to posit the condition that
T and Z each be c-equivalent to T ∪ Z, and use Theorem 3 to establish the required set-subset equivalence.
While perfectly valid, this condition is still not complete; there are cases where T and Z are c-equivalent,
yet none is c-equivalent to their union. For example,
consider the path
X→T ←L→Z←Y
Each of T and Z leaves the path between X and Y
blocked, which renders them c-equivalent, yet {T ∪ Z}
unblocks that path. Hence, T ≈ Z and T 6≈ T ∪ Z.
This implies that sets T and Z would fail the proposed
test, even though they are c-equivalent.
The remedy can be obtained by re-invoking the notion
of Markov boundary (Definition 4) and Lemma 2.
Theorem 4. Let T and Z be two sets of covariates,
containing no descendant of X and let Tm and Zm be
their Markov boundaries. A necessary and sufficient
condition for the c-equivalence of T and Z is that each
of Tm and Zm be c-equivalent to Tm ∪ Zm according to
the set-subset criterion of Theorem 3.
Proof
1. Proof of sufficiency:
If Tm and Zm are each c-equivalent to Tm ∪ Zm
then, obviously, they are c-equivalent themselves
and, since each is c-equivalent to its parent set (by
Lemma 2) T and Z are c-equivalent as well.
2. Proof of necessity:
We need to show that if either Tm or Zm is not
c-equivalent to their union (by the test of Theorem 3), then they are not c-equivalent to each
other. We will show that using “G-admissibility”
as an auxiliary tool. We will show that failure of
Zm ≈ Tm ∪Zm implies non-admissibility, and this,
by the necessary part of Theorem 2, negates the
possibility of c-equivalence between Z and T . The
proof relies on the monotonicity of d-separation
over minimal subsets (Appendix B), which states
that, for any graph G, and any two subsets of
nodes T and Z, we have:
(X⊥
⊥Y |Zm )G &(X⊥
⊥Y |Tm )G ⇒ (X⊥
⊥Y |Zm ∪Tm )G

Applying this to the subgraph consisting of all
back-door paths from X to Y , we conclude that
G-admissibility is preserved under union of minimal sets. Therefore, the admissibility of Zm and
Tm (hence of Z and T ) entails admissibility of
Zm ∪ Tm . Applying Theorem 2, this implies the
necessity part of Theorem 3.
Theorem 4 reveals the statistical implications of
the G-admissibility requirement in Theorem 2. Gadmissibility ensures the two c-equivalence conditions:
Tm ≈ {Tm ∪ Zm }

(7)

Zm ≈ {Tm ∪ Zm }

(8)

In other words, given any DAG G compatible with
the conditional independencies of P (x, y, t, z), whenever Z and T are G-admissible in G, the two statistical
conditions of Theorem 3 should hold in the distribution, when applied to the set-subset relations in (7)
and (8). Enforcing conditions (i0 ) and (ii0 ) with the
proper choice of S1 and S2 , yields
{Tm ∪ Zm }m ⊥
⊥Y |X, Zm

(9)

{Tm ∪ Zm }m ⊥
⊥Y |X, Tm

(10)

which constitute the statistical implications of admissibility. These implications should be confirmed in any
graph G0 that is Markov equivalent to G, regardless of
whether T and S are G-admissible in G0 .
We illustrate these implications using Fig. 2. Taking
T = {W2 , V2 } and Z = {V1 , W3 }, we have:
Tm
{Tm ∪ Zm }m

= {W2 , V2 }, Zm = {V1 },
= {V1 , V2 , W2 }m = {V1 , W2 }

We find that the tests of (9) and (10) are satisfied
because
{V1 , W2 }⊥
⊥Y |X, V1

and {V1 , W2 }⊥
⊥Y |X, W2 , V2

Thus, implying Z ≈ T . That test would fail had we
taken T = {W2 } and Z = {W3 }, because then we
would have:
Tm
{Tm ∪ Zm }m

= {W2 }, Zm = {∅}.
= W2

and the requirement
{Tm ∪ Zm }m ⊥
⊥Y |X, Zm
would not be satisfied because
W2 ⊥
6 ⊥Y |X

T

Z

Y

X
(a)

T

Z

Y

X

T

Z

Y

X

(b)

(c)

Figure 3: Failing the T ≈ {T ∪ Z} test should reject
Model (a) in favor of (b) or (c). Failing Z ≈ {T ∪ Z}
should reject Models (a) and (b) in favor of (c).

6

EMPIRICAL RAMIFICATIONS
OF c-EQUIVALENCE TESTS

Having explicated the statistical implications of admissibility vis a vis c-equivalence, we may ask the inverse
question: What can c-equivalence tests tell us about
admissibility? It is well known that no statistical test
can ever confirm or refute the admissibility of a given
set Z (Pearl, 2000, Chapter 6; Pearl, 1998). The discussion of Section 5 shows however that the admissibility of two sets, T and Z, does have testable implications. In particular, if they fail the c-equivalence test,
they cannot both be admissible. This might sound
obvious, given that admissibility entails zero bias for
each of T and Z (Eq. (5)). Still, Eq. (8) implies that it
is enough for Zm (or Tm ) to fail the c-equivalence test
vis a vis {Zm ∪ Tm } for us to conclude that, in addition to having different Markov boundaries, Z and T
cannot both be admissible.
This finding can be useful when measurements need be
chosen (for adjustment) with only partial knowledge
of the causal graph underlying the problem. Assume
that two candidate graphs recommend two different
measurements for confounding control, one graph predicts the admissibility of T and Z, and the second does
not. Failure of the c-equivalence test

choice and behoove us to adjust for both T and Z.
However, when the dimensionality of the conditioning
sets increases, conditional independence tests are both
unreliable and computationally expensive. Although
both c-equivalent and conditional-independence tests
can reap the benefits of propensity scores methods (see
Appendix C) which reduce the dimensionality of the
conditioning to a single scalar, it is not clear where the
benefit can best be realized, since the cardinalities of
the sets involved in these two types of tests may be
substantially different.
This raises the interesting question of whether the
discrimination power of c-equivalence equals that of
conditional independence tests. We know from Theorem 4 that all c-equivalence conditions can be derived
from conditional independence relations. The converse, however, is an open question if we allow (X, Y )
to vary over all variable pairs.

7

CONCLUSIONS

Theorem 2 provides a simple graphical test for deciding whether one set of covariates has the same biasreducing potential as another. The test requires either
that both sets satisfy the back-door criterion or that
their Markov boundaries be identical. Both conditions
can be tested by fast, polynomial time algorithms, and
could be used to guide researchers in deciding what
measurement sets are worth performing. We have
further shown that the conditions above are valid in
causal as well as associational graphs; the latter can be
inferred from nonexperimental data. Finally, we postulate that c-equivalence tests could serve as valuable
tools in a systematic search for graph structures that
are compatible with the data.
Acknowledgments

Tm ≈ {Tm ∪ Zm } ≈ Zm
can then be used to rule out the former.
Figure 3 illustrates this possibility. Model 3(a) deems
measurements T and Z as equally effective for bias
removal, while models 3(b) and 3(c) deem T to be insufficient for adjustment. Submitting the data to the
c-equivalence tests of Eq. (7) and Eq. (8) may reveal
which of the three models should be ruled out. If both
tests fail, we must rule out Models 3(a) and 3(b), while
if only Eq. (8) fails, we can rule out only Model 2(a)
(Eq. (7) may still be satisfied in Model 3(c) by incidental cancellation).
Of course, the same model exclusion can be deduced
from conditional independence tests. For example,
Models 3(a) and 3(b) both predict T ⊥
⊥Y |X, Z which,
if violated in the data, would leave Model 3(c) as our

This research was supported in parts by grants from
NIH #1R01 LM009961-01, NSF #IIS-0914211, and
ONR #N000-14-09-1-0665.

APPENDIX A
In this Appendix we prove the uniqueness of the
Markov boundary Sm , as defined in Eq. (6), and provide a simple algorithm for its construction. Since dseparation is a graphoid (Pearl, 1988, p. 128), we will
use the five graphoid axioms to prove uniqueness.
For a given X and S in a DAG G, assume X has two
different Sm ’s, U1 and U2 . Let S1 be the intersection
of U1 and U2 ; and let
U1 = S1 + S2 ; U2 = S1 + S3 ; S4 = S − (U1 + U2 ).

Since U1 and U 2 are both Markov boundaries we have
(X⊥
⊥S2 S4 |S1 S3 )G and (X⊥
⊥S3 S4 |S1 S2 )G

(A-1)

Theorem 5. Given a DAG and two vertices x and y
in the DAG and a set {Z1 , . . . , Zk } of minimal separators between x and y. The union of the separators
in the set, denoted by Z!, is a separator.

(A-2)

Proof.
We mention first two observations:

By Decomposition, we have
(X⊥
⊥S2 |S1 S3 )G and (X⊥
⊥S3 |S1 S2 )G
By Intersection we get
(X⊥
⊥S2 S3 |S1 )G

(A-3)

From (A-1) and Weak Union we obtain
(X⊥
⊥S4 |S2 S3 S1 )G

(A-4)

Now, applying Contraction to (A-3) and (A-4) we have
(X⊥
⊥S2 S3 S4 |S1 )G

(A-5)

It follows that S1, which is smaller than U 1 and U 2
also satisfies Eq. (6) contradicting the minimality of
U 1 and U 2
This completes the proof. (The case where S1 is empty
is included.)
It follows from the proof above that the Markov
boundary Sm is the intersection of all subsets of S
that d-separate S from X. This implies that no member of Sm can be d-separated from X by any such
subset. Therefore, the procedure of sequentially removing from S any node that is d-separated from X
by all remaining nodes is guaranteed never to remove
a member of Sm , hence it must terminate with the
unique Sm .
(Note: The contraction axiom guarantees that removing any such node keeps all previously removed nodes
d-separated from X by the remaining nodes.)

APPENDIX B
We prove that, for any graph G, and any two subsets
of nodes T and Z, we have:
(X⊥
⊥Y |Zm )G

&

(X⊥
⊥Y |Tm )G ⇒ (X⊥
⊥Y |Zm ∪Tm )G

Where Zm and Tm are any minimal subsets of Z and
T , that satisfy (X⊥
⊥Y |Zm )G and (X⊥
⊥Y |Tm ) respectively.
The following notation will be used in the proof: A
TRAIL will be a sequence of nodes v1 , . . . , vk such that
vi is connected by an arc to vi+1 . A collider Z is
EMBEDDED in a trail if two of his parents belong to
the trail. A PATH is a trail that has no embedded
collider. We will use the “moralized graph” test of
Lauritzen et al. (1990) to test for d-separation (“Ltest,” for short).

(a) Given a minimal separator Z between x and y.
If Z contains a collider w then there must be a
path between x and y which is intercepted by w,
implying that w is an ancestor of either x or y or
both. This follows from the minimality of Z. If
the condition does not hold then w is not required
in Z.
(b) It follows from (a) above that w as defined in (a)
and its ancestors must belong to the ancestral subgraph of x and y.
Let us apply the L-test to the triplet (x, y|Z1 ). As Z1
is a separator, the L-test must show this. In the first
stage of the L-test, the ancestral graph of the above
triplet is constructed. By observation (b) it must include all the colliders that are included in any Zi . In
the next stage of the L-test, the parents of all colliders
in the ancestral graph are moralized and the directions
removed. The result will be an undirected graph including all the colliders in the separators Zi and their
moralized parents and their ancestors. In this resulting
graph, Z1 still separates between x and y. Therefore
adding to Z1 all the colliders in Zi , i = 1 to k , will
result in a larger separator. Adding the noncolliders
from all the Zi to Z1 will still keep the separator property of the enlarged set of vertices (trivial). It follows
that Z! is a separator. End of proof.

Appendix C
Let the propensity score L(z) stand for P (X = 1|z).
It is well known (Rosenbaum and Rubin, 1983)
that, viewed as a random variable, L(z) satisfies
X⊥
⊥L(z)|Z.
This implies that A(x, y, L(z)) =
A(x, y, Z) and, therefore, testing for the c-equivalence
of Z and T can be reduced to testing the c-equivalence
of L(z) and L(t). The latter offers the advantage
of dimensionality reduction, since L(z) and L(t) are
scalars, between zero and one. (See Pearl (2009a, pp.
348–352)).
The same advantage can be utilized in testing conditional independence. To test whether (X⊥
⊥Y |Z) holds
in a distribution P , it is necessary that (X⊥
⊥Y |L(z))
holds in P . This follows from the Contraction axiom of
conditional independence, together with the fact that

Z subsumes L. Indeed, the latter implies
X⊥
⊥Y |Z ⇔ X⊥
⊥Y |L(z), Z
which together with X⊥
⊥L(z)|Z gives
X⊥
⊥Z|L(z) & X⊥
⊥Y |L(z), Z ⇒ X⊥
⊥Y |L(z)
The converse requires an assumption of faithfulness.

References
Dawid, A. (2002). Influence diagrams for causal modelling and inference. International Statistical Review
70 161–189.
Engle, R., Hendry, D. and Richard, J. (1983).
Exogeneity. Econometrica 51 277–304.
Glymour, M. and Greenland, S. (2008). Causal
diagrams. In Modern Epidemiology (K. Rothman,
S. Greenland and T. Lash, eds.), 3rd ed. Lippincott
Williams & Wilkins, Philadelphia, PA, 183–209.
Greenland, S., Pearl, J. and Robins, J. (1999).
Causal diagrams for epidemiologic research. Epidemiology 10 37–48.
Greenland, S. and Robins, J. (1986). Identifiability, exchangeability, and epidemiological confounding. International Journal of Epidemiology 15 413–
419.

Pearl, J. (2000). Causality: Models, Reasoning, and
Inference. Cambridge University Press, New York.
2nd edition, 2009.
Pearl, J. (2009a). Causality: Models, Reasoning,
and Inference. 2nd ed. Cambridge University Press,
New York.
Pearl, J. (2009b). On a class of bias-amplifying
variables that endanger effect estimates. Tech.
Rep. R-356, Department of Computer Science,
University of California, Los Angeles, CA.
<http://ftp.cs.ucla.edu/pub/stat ser/r356.pdf>.
Forthcoming, Proceedings of UAI, 2010.
Robins, J. (1997). Causal inference from complex longitudinal data. In Latent Variable Modeling and Applications to Causality (M. Berkane, ed.). SpringerVerlag, New York, 69–117.
Rosenbaum, P. and Rubin, D. (1983). The central
role of propensity score in observational studies for
causal effects. Biometrika 70 41–55.
Rubin, D. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies.
Journal of Educational Psychology 66 688–701.
Spirtes, P., Glymour, C. and Scheines, R. (2000).
Causation, Prediction, and Search. 2nd ed. MIT
Press, Cambridge, MA.

Lauritzen, S. (2001). Causal inference from graphical models. In Complex Stochastic Systems (D. Cox
and C. Kluppelberg, eds.). Chapman and Hall/CRC
Press, Boca Raton, FL, 63–107.

Stone, R. (1993). The assumptions on which causal
inferences rest. Journal of the Royal Statistical Society 55 455–466.

Lauritzen, S. L., Dawid, A. P., Larsen, B. N.
and Leimer, H. G. (1990). Independence properties of directed Markov fields. Networks 20 491–505.

Tian, J., Paz, A. and Pearl, J. (1998).
Finding minimal separating sets.
Tech.
Rep. R-254, Computer Science Department,
University of California, Los Angeles, CA.
<http://ftp.cs.ucla.edu/pub/stat ser/r254.pdf>.

Neyman, J. (1923). On the application of probability
theory to agricultural experiments. Essay on principles. Section 9. Statistical Science 5 465–480.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San Mateo, CA.
Pearl, J. (1993). Comment: Graphical models,
causality, and intervention. Statistical Science 8
266–269.
Pearl, J. (1995). Causal diagrams for empirical research. Biometrika 82 669–710.
Pearl, J. (1998).
Why there is no statistical test for confounding, why many think
there is, and why they are almost right.
Tech. Rep. R-256, Department of Computer Science, University of California, Los Angeles, CA.
<http://ftp.cs.ucla.edu/pub/stat ser/R256.pdf>.

Wooldridge, J. (2009).
Should instrumental variables be used as matching variables?
Tech. rep., Michigan State University, MI.
<https://www.msu.edu/∼ec/faculty/wooldridge/
current%20research/treat1r6.pdf>.

