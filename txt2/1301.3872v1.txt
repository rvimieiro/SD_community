literature (see von Winterfeldt and Edwards (1988) for
a review) and in artificial intelligence (Druzdzel & van
der Gaag 2000), relatively little work has been done on
composing model structure. At the same time, there
are strong indications that the quality of advice is more
sensitive to the model structure than to the precision

Tze Yun Leong
Medical Computing Laboratory
Department of Computer Science
School of Computing
National University of Singapore
Singapore 119260
leongty@comp. nus. edu. sg
of its numerical parameters (Pradhan et al. 1996).
There are essentially four approaches to aid model
building. The first approach focuses on providing more
expressive building tools. The Noisy-OR model (Pearl
1988; Henrion 1989) and its generalizations (Dlez 1993;
Srinivas 1993) simplify the representation and elici­
tation of independence interactions among multiple
causes. Beckerman (1990) developed the similarity
network and partition as tools for representing subset
independence to facilitate the structure construction
and probability elicitation. The second approach, usu­
ally referred to knowledge-based model construction
(KBMC), emphasizes aiding model building by auto­
mated generation of decision models from a domain
knowledge-base guided by the problem description and
observed information (see a special issue at the journal
IEEE Transactions on Systems, Man and Cybernetics
on the topic of KBMC (Breese, Goldman, & Wellman
1994)). The third approach focuses on algorithms that
can learn the model structure and parameters from a
database of observations (Cooper & Herskovits 1991;
Pearl & Verma 1991; Spirtes, Glymour, & Scheines
1993). Although model construction from data can
reduce the knowledge engineering effort, the learning
approach faces other problems such as small data sets,
unmeasured variables, missing data, selection bias, and
the flexibility of model granularity.
While we acknowledge that in the future it may be
possible to build powerful computer systems that will
model human creativity, sense for relevance, and sim­
plicity, we believe that these tasks are and will long be
performed better by humans. Our view is that model
building, a task that relies on all these capacities, is
best implemented as an interactive process. The fourth
approach on aiding model construction that is most re­
lated to our work is to apply system engineering and
knowledge engineering techniques for aiding the pro­
cess of building Bayesian networks. Laskey and Ma­
honey (1996; 1997) address the issues of modulariza­
tion, object-orientation, knowledge-base, and evalua-

354

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

tion in a spiral model of development cycle. Koller
and Pfeffer (1997; 1999) developed Object-Oriented
Bayesian Networks (OOBN) that use objects as orga­
nizational units to reduce the complexity of modeling
and increase the speed of inference.
Our approach on aiding model construction is based
on the concept of causal mechanisms. Causal mecha­
nisms, which are local interactions among domain vari­
ables, are building blocks that determine the causal
structure of a model. As they encode our understand­
ing of local interactions and are fairly model inde­
pendent, causal mechanisms can be easily reused in
various models. When the algebraic form of the in­
teraction is known, causal mechanisms are captured
by so called structural equations. When less informa­
tion is available about the interaction, it can be spec­
ified in a probabilistic format. As shown by Druzdzel
and Simon (1993), conditional probability tables in
Bayesian networks that model causal relations among
their variables can be also viewed as descriptions of
causal mechanisms. Similarly to object-hierarchy ab­
straction, causal mechanism can be organized hierar­
chically in nearly decomposable system (Iwasaki & Si­
mon 1994). At the same time they provide a valu­
able heuristic for acquiring and managing knowledge:
causality.
In our framework, we encode causal mechanisms as
functional relations among variables and, wherever
causal mechanisms are asymmetric, the direction of
causal influence among variables. We extend Simon's
causal ordering algorithm (Simon 1953) to develop a
modeling process that uses the output graph of this
algorithm in the interaction with users. We assist the
model building process by helping user (1) to identify
a set of mechanisms related to the current model and
to bring them into model workspace (2) to integrate
the newly added mechanisms with the model under
construction (3) to specify the variables that can be
manipulated, and (4) to extract reusable causal mech­
anisms from existing models into the knowledge base.
The final model structures generated by our modeling
process are guaranteed to be causal if the underlying
structural equations reflect causal mechanisms of the
modeled problem.
In addition to being intuitive for human users and facil­
itating crucial user interface functions such as explana­
tion, causal models support prediction of the effect of
manipulation, i.e., changes in structure (Simon 1953;
Spirtes, Glymour, & Scheines 1993; Pearl 1995). The
users of such models (and that includes autonomous
robots) can ask questions like "What will happen if
I perform action A?" Manipulation is especially im­
portant in strategic planning, where it is important to
derive creative decision options and not only evaluate

existing decision options. In the process of creating a
model, a user may want to explore the possibility of
manipulating its different elements. Supporting this
manipulation is not straightforward, as some mecha­
nisms may be reversible, i.e., acting in reverse direc­
tion. For example, when driving up the hill, car engine
causes the wheels to turn; but when driving down the
hill in a low gear, the model should be able to predict
that the wheels will cause the engine to slow down.
Our approach supports causal modeling that includes
reversible causal mechanisms and offers an integrated
framework for building and using causal models.
The remainder of this paper is structured as follows.
Section 2 gives an overview of structural equation mod­
els, causal mechanisms, and how these support changes
in structure. Section 3 discusses the process of inter­
active model construction, including issues related to
the representation of causal mechanism, assistant in­
terface, and the extension of causal ordering algorithm.
Section 4 presents an example of user interaction with
our system, ImaGeN/e. F inally, we discuss the impli­
cations of our approach and outline the direction for
our future work.
2

STRUCTURAL EQUATION
MODELS

When scientists study phenomena or problems, they
normally focus on systems, pieces of the real world
that can reasonably be studied in isolation. Scien­
tists identify the relevant variables, the ranges of the
variables' values, and the relations among variables to
form abstractions of these systems, known as mod­
els. One way of representing models is by systems
of structural equations where each structural equa­
tion describes a conceptually distinct causal mecha­
nism active in the system. Such systems are known as
Structural Equation Models (SEMs) (Haavelmo 1943;
Simon 1953). A structural equation describing a causal
mechanism M is often encoded as an implicit function

where f is some algebraic function and its arguments
V; are variables that directly participate in the mech­

anism M.
A variable in a SEM is exogenous if it summarizes
an outside influence on the system, i.e., its value is
determined outside of the model. An exogenous vari­
able is truly exogenous if it represents a variable in the
real world system that we cannot manipulate without
changing the boundaries of the system. An exogenous
variable is a policy variable if it represents a variable
that we can manipulate, i.e., set its value. For exam­
ple, we normally model outside temperature as a truly

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

exogenous variable in an agricultural model, but we
can model the temperature as a policy variable in a
model of a greenhouse. For each exogenous variable,
there is a value assignment structural equation to des­
ignate the observed value ( or a probability distribution
over observed values) for the truly exogenous variable
or the chosen value for the policy variable. A variable
in a SEM is endogenous if its value is derived by substi­
tuting the values of exogenous variables into the core
structural equations that depict the relations among
modeled variables in the system and by solving these
equations in SEM .
A SEM S with m causal mechanisms and n variables
is represented as
m
S

=

U fM,(Vl, V2, V3, ... , Vn).
i=l

Since the knowledge of which variables participate in
which mechanisms is sufficient to determine the di­
rection of causation, 1 in the remainder of this paper
we will only use structure matrix (Druzdzel & Simon
1993), a qualitative representation of a SEM.
Definition 1 (structure matrix) A structure ma­
trix A of a SEM S = U:1 fM,(Vl, V2, V3, . .., Vn) = 0
is a m x n matrix with element a;j = x if Vj participates
in f M;, where x is a marker, and a;j = 0 otherwise.
Let Amxn be the structure matrix of a SEM S with m
equations and n variables. S is non-over-constrained
if following property holds.
Definition 2 (non-over-constrained system) A
system of m structural equations S is non-over­
constrained if in any subset of k ::; m equations of
S at least k different variables appear with nonzero co­
efficients.
A non-over-constrained Amxn is self-contained if m =
n. A non-over-constrained Amxn is under-constrained
if m < n. Amxn is over-constrained if it violates non­
over-constrained property.
Example:

The University Performance Budget Planning
Model (UPBPM) (Simon, Kalagnanam, & Druzdzel 2000)
is comprised of 38 core equations that describe interactions
among 88 variables in the university strategic budget plan­
ning context. The model has been adopted by the Office
for Planning and Budget at Carnegie Mellon University for
the purpose of strategic planning of university operations.

The following simple model, StudentFacultyRatio model,
extracted from UPBPM, consists of one core equations and
two value assignment equations and describes the interac­
tion among three variables: StudentFacultyRatio (SFR),
NumberOJStudents (NS), and NumberOfFaculty (NF).

1 Only when calculating the strength of the influences,
we need the exact form of equations.

355

The corresponding structure matrix for this self-contained
model is shown at the right hand side.

{"

/2:
h:

2.1

NS
NF
SFR

=
=
=

22102
3006
NSjNF

NS
h
h
h

X

0

X

NF
0
X
X

SFR
0
0
X

0

Causal Ordering

As shown by Simon (1953), a self-contained SEM ex­
hibits asymmetries that can be represented by a di­
rected acyclic graph and interpreted causally. Simon
developed a causal ordering algorithm that takes a self­
contained structure matrix A as input and outputs
a causal graph G = {N(G), A(G)}, where the nodes,
N(G), are sets of variables and the arcs, A (G), describe
causal relations among them.
Let B be a subset of equations in a non-over­
constrained SEM and Cpxq be the structure matrix
of B. We say that B is a self-contained subset if
p = q; B is a under-constrained subset if p < q. A
self-contained subset is minimal if it does not contain
any self-contained ( proper) subsets itself. A minimal
self-contained subset is a strongly coupled component
if it contains more than one equation, which usually
represents a feedback system in the real world.
The causal ordering algorithm starts with identifying
the minimal self-contained subsets in input A. These
identified minimal self-contained subsets are called
complete subsets of 0-th order and a node is created
for each subset. Next, the algorithm removes the equa­
tions of the complete subsets of 0-th order from A as
solving the values of variables. Then it removes all
variables that occur in the complete subsets of 0-th or­
der from the remaining equations in A as substituting
the values of solved variables into remaining equations.
The remaining set of equations is called the derived
system of first order, a self-contained structure. The
algorithm repeats the process of identifying, solving,
and substituting on the derived system of k-th order
until it is empty. In addition, whenever a node m is
created for a minimal self-contained subset M, the al­
gorithm refers the set of equations EM of M back to
the original set of equations OEM in A and adds arcs
from the nodes representing variables in OVM \ VM to
m, where VM is the set of variables participating in
EM and OVM is the set of variables participating in
OEM·

Example:
The UPBPM (Simon, Kalagnanam, &
Druzdzel 2000) implements Simon (1953) causal ordering
algorithm that given an assignment of values to 50 exoge­
nous variables, derives the structure of the model.
When applying the causal ordering algorithm to the struc­
ture matrix of StudentFacultyRatio model, we first identify

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

356

h and h as the complete subset of 0-th order. After
solving and substituting of NS and NF, we then identify

NS

f� as the complete subset of 1-st order. The structure ma­

X

trix and the corresponding causal graph are shown below.

NS

NF

SFR

0

0

X

0
0

X

X

X

NF

SFR

0

0

X

X

X

0

0

X

()liL-D NF

~

In the revised system, the causal ordering shows that NF
has become an endogenous variable affected by NS and
SFR. Now, changing the number of students will affect

X

the number of faculty. Manipulation has lead to a change
in structure.

D

Given the causal graph, we can read off the causal rela­
tions among the nodes by focusing on the node of interest
and its parents. For example, SFR directly depends on
D

NF and NS.

Notice that the causality that we read off causal graphs
is defined within models and causal asymmetries arise
when mechanisms are placed in context. If the context
has changed, it may result in changes in structure.
2.2

Changes in Structure

The main value of structural equation models is that
they support prediction of the effects of changes in
structure, i.e., external manipulations that intervene
in the mechanisms captured by the original system of
equations. Such changes are modeled by modifying
the equations that describe the affected mechanisms
and leaving those equations that correspond to unaf­
fected mechanisms unmodified. The causal ordering
algorithm applied to the modified SEMs derives the
new causal structure of the system.
Normally, the effect of external manipulation is lo­
cal and, when related back to the graph, amounts to
arc cutting (Pearl 1995; Spirtes, Glymour, & Scheines
1993). The assumption underlying the arc-cutting op­
eration is that imposing a value on a variable by an
external intervention makes that variable independent
of its direct causes. This assumption is valid for mech­
anisms with strong asymmetric relationship between
a variable and its causes; for example, wearing sun­
glasses protects our eyes from the sun but it does
not make the sun go away. However, when a model
contains reversible causal mechanisms (Simon 1953;
Druzdzel & van Leijen 2000), manipulation can have
a drastic effect on the graph.
Example: From the causal graph of StudentFacultyRa­
tio model in previous example, we k now that changing NS
will affect SFR but not NF. Now, consider that the budget
planning officer would lik e to set the StudentFacultyRa­
tio to advertise their faculty availability. If needed, she
is willing to adjust the NumberOfFaculty (e. g. , hire more
faculty) . According to the revised modeling context, she
needs to designate the variable SFR as exogenous, e. g. ,
j4 : SFR = 10, and release h : NF
3, 006. The result­
ing structure matrix and corresponding causal graph are:
=

Figure 1: Interactive and Iterative Model Construction
System Architecture. The arcs show the direction of
the information flow.

3

INTERACTIVE MODEL
CON STRUCTION

We have developed an interactive and iterative model
construction environment, ImaGeNie, that assists
users in building graphical decision model in causal
form. We use the causal ordering algorithm to gen­
erate the causal model structures which can later be
associated with different node types and parameters
and transformed into Bayesian networks or influence
diagrams. Figure 1 shows the architecture of ImaGe­
N/e. It includes three knowledge structures: mech­
anism knowledge bases, which hold domain knowl­
edge expressed as causal mechanisms, model build­
ing workspace, which serve as a blackboard for model
composition, and models. The domain knowledge
can be maintained either by the equation authoring
interface, where model builders can compose struc­
tural equations directly, or by the mechanism ex­
traction operation that enables model builders to ex­
tract reusable causal mechanisms from existing mod­
els. Model builders can use hierarchy navigation in­
terface to locate the mechanisms of interest and select

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

them into the model building workspace with assis­
tance of the mechanism selection operation. In ad­
dition to mechanism selection and traditional model
authoring operations, model builders can manipulate
variables and merge mechanisms as model building
process evolves. The underlying causal ordering mod­
ule will restructure the models according to the user
actions.
3.1

Knowledge Representation

In ImaGeNie, the fundamental knowledge representa­
tion units are causal mechanisms, which are encoded as
structural equations. For example, we can specify the
student faculty ratio as h (S F R, NS, N F ). Users may
optionally provide explicit functions for causal mech­
anisms such as algebraic functions, conditional prob­
ability tables, truth tables, value/utility tables, and
choice tables.
While most mechanisms will be described in one, per­
haps their only, mode of operation, some mechanisms
are reversible in the sense of being flexible as to the
direction of causality that they imply when they are
embedded in different contexts. We define the manip­
ulativeness and observability for each variable in our
domain knowledge base to express the characteristics
of the variable that may aid in the process of model
building. Along with the manipulativeness character­
istic, a variable can be truly exogenous, manipulatable,
or truly endogenous. For the sun and sunglasses exam­
ple, we may use two structural equations !5(S, G) and
f6(S) to describe causal relation between S and G and
assign S as a truly exogenous variable to express the
fact that it is impossible to manipulate the sun in the
current modeling domain. We may assign G as manip­
ulatable to designate it as a potential policy variable.
A variable is truly endogenous if its value has to be de­
rived from embedded mechanisms. The observability
is important in deciding whether adding this variable
(observable or unobservable) will be of benefit to the
model. In the diagnostic domain, it may be desired to
develop the cost model that can associate manipulation
cost/ observation cost with manipulatable/observable
variables.
Our domain knowledge base is organized as a hierar­
chical system that consists of subsystems and causal
mechanisms as its fundamental building elements. The
hierarchical approach not only helps domain experts to
express their domain knowledge in cognitively mean­
ingful units but also helps knowledge engineers to
access stored mechanisms easily. Our approach is
similar to type-hierarchy in (Koller & Pfeffer 1997;
Laskey & Mahoney 1997) but without imposing the
inheritance constraint since knowledge can be pos­
sibly organized hierarchically from different perspec-

357

tives. More details on the syntax of our knowledge
representation language can be found in (Lu 1999).
3.2

Extending Causal Ordering to
Under-constrained Model

In ImaGeNie, the model construction process is a re­
flection of our problem solving. The under-constrained
models evolved in such process reveal different problem
recognition stages. In an under-constrained model, the
mechanisms are our observations of how the problem
should be described so far. Model building process is
strongly related to causal manipulation. The exoge­
nous variables are those outside influences that have
been committed. An under-constrained model can­
not be drawn as a directed acyclic graph, as the di­
rection of causal interactions is not completely deter­
mined until the model is self-contained. However, it
is desired to have a graphical representation of under­
constrained models during the whole process of model
construction, since the graphical representation may
help model builder identify her focus and change her
commitments of the outside influences. We extend Si­
mon's causal ordering algorithm to explicate the causal
ordering that has been identified in under-constrained
models. We also propose a graphical representation
to depict the causal ordering results in an informative
graphical form that aims to help user in model build­
ing.
In order to formalize our extensions, we need to re­
state the theorem that was originally proved by Simon
(1953).

Theorem 1 Let A and B be two minimal self­
contained subsets of equations of a non-over­
constrained SEM, S. Then the structural equations
of A and B, and likewise the variables in A and B are
disjunct.
Consider any subset B of the equations of a non-over­
constrained SEM. We will denote the number of equa­
tions in Bas ne8, and the number of variables appear­
ing in B as nvB.

Theorem 2 Let S be a non-over-constrained system
and D be the derived system of structural equations
from S by applying identification, solving, and sub­
stitution. If D is not empty, then D is non-over­
constrained.
Proof:

In the process of identification, let M be the
union of all the minimal self-contained subsets, M = M 1 U
M2 U ... U Mk, and the remainder R. We k now R is not
empty since V is not empty.
Suppose that V violates the non-over-constrained property.

Then there exists a subset £' of V such that net:' >

nvt:'·

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

358

Let & be the subset of R that &' derives from. We know

M U &.
The equations of M and & are disjunct because M and R
that

ne£

=

Now, consider the subset :F

ne£1·

are disjunct and &

neM + ne£1.

� R. Therefore,

ne;:

=

=

neM + ne£

=

Since &' derives from & by substitution, the

variables appearing in & are either in

M

or in &'.

sequently, the variables in :F are either in
Moreover, the variables in

M

M

Con­

or in &'.

and &' are disjunct because

M.
Therefore, nv;: = nvM + nV£1. Since the equations of M ,
i
and likewise the variables in M , are disjunct by Theo­
i
&' derives from & by substituting out the variables in

nVM = L;nvM, and neM = L;neM;·
nVM = neM. Therefore, ne;: = neM + ne£ =
neM + ne£1 > neM + nV£1 = nvM + nV£1 = nv;:, i.e., the
rem 1, we have
Hence

Procedure ExtendedCausalOrdering
Input:
A structure
constrained SEM.

V0

Definition 3 (strictly under-constrained sub­
sets) The strictly under-constrained subsets of a non­
over-constrained SEM are those under-constrained
subsets that do not contain any self-contained subsets.
Theorem 3 A SEM, S, is under-constrained if and
only if there exists a derived strictly under-constrained
subset inS.
Proof (sketch):

We can prove => by construction and

¢:: by contradiction given Theorem
the formal proof.

2.

See (Lu

1999)

Mi

(a) Create nodes

vM•. ·
J

non-over-

Vi,

Mi
Vi

is
is

Nj for all variables in

(b) Add arcs from the nodes represent

OVMJ'. \ VMJ'. to nodes in Nj, where
OVMJ'. is the set of the variables

D

Given Theorem 2, we can keep applying identifica­
tion, solving, and substitution operations on derived
non-over-constrained system until either V is empty
or there are no more minimal self-contained subsets
that can be identified. If V is empty, we know that S
is self-contained. If V is not empty and no more self­
contained subsets can be identified, we know that S
is under-constrained and we call V the derived strictly
under-constrained subsets.

a

1. for each minimal self-contained subset
Mj E Mi, where 1:::; j:::; IMil

2 contradicting the fact that S is non-over-constrained.

V must be non-over-constrained.

of

Let i := 0 and
:= A
while there exists
c
where
the complete subset of i:th order and
the derived structure of i-th order.

variables of :F. In other words, the set :F violates Defini­
We conclude that

A

Output: A graph G = {V, A( G)}, where V are
the variables in A and A( G) is a set of directed, hi­
directed, or undirected arcs.

number of equations of :F is greater than the number of
tion

matrix

in

OEM'.,
J

equations
(c) if

INJI

the original equations of

EM'.
J

>

1,

of

Mj

in A.

add pair-wise hi­

directed arcs among elements of

Nj.

Mi from Vi to deriveR; (solv­
Mi from
Ri to derive V (substituting).
3. Let i := i + 1 and Vi : = V.
if vi is not empty
2.

Remove

ing) and remove variables of

for each remaining equation
where 1:::; k:::;

vi,
1.

ek in

IV'I
Create nodes Nek for the
of variables, v.k' in ek.

set

2.

Add arcs from nodes repre­
senting
to

3.

Add pair-wise undirected arcs
between nodes

OV.k \ Vek

N.k.

N.k.

Figure 2: Extended Causal Ordering Algorithm

for
D

Figure 2 outlines our extended causal ordering algo­
rithm that is based on Theorem 3. The input of the
algorithm is a non-over-constrained structure matrix
A. The output is a graph G = {V, A(G)}, where the
nodes V are variables and A(G) is a set of directed,
hi-directed, or undirected arcs. The algorithm essen­
tially follows the steps of identification, solving, and
substitution as Simon's causal ordering algorithm un­
til there are no more self-contained subsets that can be
identified from the derived system. The algorithm will
explicitly depict the causal relations and relevant rela­
tions encoded in the strictly under-constrained subset,
if there remains one.
The graph generated by our extended causal ordering
algorithm is specifically designed to aid the process of

model construction. Unlike the original causal order­
ing algorithm, each variable in the system is repre­
sented as a separate node so that the model builder
can access and manipulate it directly. Directed arcs
depict the causal relations among variables. In addi­
tion to these, our algorithm explicates the causal re­
lations encoded in the under-constrained system. Bi­
directed arcs denote feedback mechanisms in strongly­
coupled subsets. User can visualize the effect of break­
ing the feedback system by manipulating one of vari­
ables connected by the hi-directed arc. Undirected arcs
visually express relevant but undetermined causal rela­
tions among variables so that model builder can focus
on clarifying the mechanisms governing these variables
and complete the model.
Example: Suppose the budget planning officer wants to

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

extend the StudentFacultyRatio model to take the average
class size into account. She adds the structural equations
h : CS = (NS * CL)/(NF * TL) and Is : CL = 15 to
describe the relations among ClassSize ( CS), ClassLoad
( CL), TeachingLoad ( TL), NS and NF. The structure ma­
trix of the extended model is as follows.

NS
/1
h
h

h

Is

X

NF
0

0

X

X

X

X

X

0

0

SFR
0
0

cs

0
0

X

X

0
0
0

CL
0
0
0

TL
0
0
0

0

X

0

X

X

After applying the extended causal ordering algorithm to
the system, she obtains the following under-constrained
causal graph.

359

nipulatable variables as exogenous helps in obtaining
a self-contained system, i.e., orienting all arcs in the
model graph. If the user assigns a potential policy
variable, a manipulatable variable that is endogenous
in a self-contained system, as exogenous, the whole
model becomes over-constrained, because the num­
ber of equations is greater than the number of vari­
ables. We allow a model to be under-constrained or
self-contained at any stage of the model development
in ImaGeNie, but we disallow a model to be over­
constrained. W hen a model becomes over-constrained,
the system pops up a list of mechanisms that are
currently in the model and asks users to release one
of them in order to change the system into a self­
contained or an under-constrained system.

CL
4

SESSION

TL
From the under-constrained causal graph, she can read
off the current stage of problem formulation as follows:

StudentFacultyRatio is determined by NumberOIStudents
NumberOfFaculty; currently both ClassSize and
TeachingLoad depend on NumberOfStudents, Num­
berOfFaculty, and ClassLoad, but the relation between
ClassSize and TeachingLoad is not yet determined, which

and

is the consequence of the fact that the system is still
under-constrained.
3.3

EXAMPLE MODEL BUILDING

D

We continue on extending our simple model to demon­
strate how to interact with ImaGeNie to build a sim­
plified university budget model from U P B PM knowl­
edge base encoded in ImaGeN/e. Suppose the officer
has designated TL variable as exogenous with equa­
tion fg : TL 6. Figure 3 shows ImaGeNie interface
with the navigation tree of the knowledge base and the
model we have built so far in the workspace.
=

'f GeNie GeNie1

PI�

Modeling Process

The modeling process starts with an initial focus,
which is normally, in the spirit of value-focused think­
ing (Keeney 1994), the value variable. Users can also
start with other focus variables, for example decision,
observation, and whatever else is relevant or impor­
tant a-priori. W ith the assistant interface, users can
interactively browse the mechanisms related to their
focus variables, select those that best depict the prob­
lem at hand, merge them, or specify exogenous vari­
ables to set the boundary of the system. However, we
suggest the users to focus on one variable and add rel­
evant mechanisms one at a time as the model evolves,
since it resembles the action of focusing on a variable
of interest, explaining or observing it in terms of its
underlying mechanism. The user repeats the process
iteratively until the model is requisite. In other words,
users make decisions on the level of granularity and
when to stop with the model building process. The
system only plays the passive role of an assistant: sug­
gesting mechanisms to choose from, indicating the pos­
sible mechanisms to merge, and denoting the manipu­
latable variables.
Normally a model evolves from an under-constrained
system to a self-contained system. Designating rna-

Ur�ver:sity_Mecharum_�
Smple Unversity �
UnivetsityCore
ClassS�te

Figure 3: ImaGeNie Interface: Navigation Tree and
the Graphical Model Including Equations: JI, ]2, h ,
h, fs, and fg.
Suppose she would like to plan the expenses related to
faculty salary. She may use the navigation tree to lo­
cate mechanisms for faculty salary. Suppose she identi­
fies the mechanism f10: FS =(OJ +TA*NS)j(NF*
( 1 + 0)) that describes the interactions among vari­
ables: FacultySalary (FS), Otherlncome (OJ), Tu­
itionAmount (TA), Overhead (0), NS and N F . She
drags it into the workspace. In order to maintain the
unique variable identifiers in the model, ImaGeNie au­
tomatically renames the NS and N F into NSO and

360

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS

NF O. The extended causal ordering algorithm gener­
ates the graph shown in Figure 4.
IJGeNiel

1!!11!1£1

Figure 4: Model builder selects and drags !Io into
workspace; the extended causal ordering algorithm
generates a corresponding graph.
She can then integrate the added mechanism with the
model by merging NS to NSO and NF to NFO. ( See
Figure 5).
iii! GeNiel

2000

that describes the dependence relations among those
variables of interests ( See Figure 6 top). She can now
read off the following dependency relations from the
complete model:
•

Faculty salary is determined by the number of stu­
dents, the number of faculty, tuition amount, other
income, and overhead.

•

Student-faculty ratio is determined by the number of
students and the number of faculty.

•

Class size is determined by the number of students,
the number of faculty, class load, and teaching load.

After inspecting the current self-contained model, she
would like to analyze the model under the condition
that the average class size is fixed at 15 students per
class. She makes the variable CS exogenous by spec­
ifying a value assignment equation as fi4 : CS = 15.
Consequently the original self-contained model will be­
come over-constrained. ImaGeNie will ask her to re­
lease one of the equations ( Figure 6 top). Suppose that
she chooses to release the value assignment equation
for the variable T L. The resulting graph generated by
the causal ordering is shown in Figure 6 bottom.

IIIII!JE'l

CS •INS "Cl.)/(NF"TLJ
.,e;;:___..c;;:__-j��:(�JtJA"NS)I(NF•(1 +0))
CL • 15
NF • 3006
01

ill GeNiel

•

30000000

I!II(!J £l

Figure 5: Model builder performs the merge opera­
tions for NS (top). The causal ordering generates the
corresponding graph (bottom).

Figure 6: A change in structure on a self-contained
model. The user manipulates CS by setting JI4 :
CS = 15 and releasing f9: TL = 6 (top). The causal
ordering generates the corresponding graph (bottom).

She then makes TA , 0, and OJ exogenous by assigning
equations: fn : TA = 1, 200, !I2 : 0 = 0.48, and
JI3 : OJ= 30,000,000 and obtains a complete model

Now, she can read off the local effect of her change
on the system from the causal graph: teaching load is

361

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

determined by the number of students, the number of
faculty, class load, and class size.

ImaGeNie also supports model builder in extract­
ing reusable mechanisms from the workspace into the
knowledge base. Model builder simply selects the
nodes of interest and drags them into the destination
branch in the navigation tree. Due to space limita­
tions, we are omitting this example.
5

DISCUSSION A N D FUTURE
WORK

Support for building model structure is one of the
best ways of improving the quality of advice based on
decision-theoretic models. While existing approaches
focus on automatic model construction either from
knowledge base or directly from data, our approach
favors a closely-coupled loop between the system and
its user. This is based on our belief that human judge­
ment with respect to relevance, model size, complete­
ness, and granularity is more reliable. Built on the
assumption that under-constrained models reflect our
problem recognition stages, ImaGeNie assists users in
encoding their conceptual problem framing in a causal
graph generated by the extended causal ordering al­
gorithm. Furthermore, ImaGeNie provides users with
the flexibility to choose building blocks from knowl­
edge base to extend the model, to manipulate the
variables in order to observe the effect of intervention
(structure changes), and to extract reusable mecha­
nisms from existing models to knowledge bases. The
concept of causal mechanisms, on which ImaGeNie re­
lies, provides a general mean to accommodate different
forms of knowledge description and makes knowledge
acquisition task easier.
Recent research in applying the object-oriented frame­
work to extend Bayesian networks for modeling com­
plex domains (Koller & Pfeffer 1997; Laskey & Ma­
honey 1997; Pfeffer et al. 1999) is closely related to
our work. Each of these approaches organizes do­
main knowledge into a hierarchical system. In Object­
Oriented Bayesian Network ( O O B N), the domain
knowledge is structured explicitly as class-hierarchy
for the type system and as object-hierarchy for the
real model. In our framework, we do not impose any
constraint on how users should organize their domain
knowledge in the knowledge base. In the future, we
would like to explore the semantics for combining type
system with causal mechanisms so that our knowledge
base can efficiently store the domain knowledge and be
effectively used by users. As for the constructed mod­
els, ImaGeNie provides submodels to group nodes into
a graphical organization unit for the sake of succinct
presentation, but there is no special semantic meaning

attached to submodels in terms of inference. We plan
to impose d-sepset (Xiang, Poole, & Beddoes 1993)
constraint on submodels composition such that each
submodel has well defined 1/0 sets to resemble object
hierarchy in O O B N.
Once the model structures generated from our frame­
work are associated with variable ranges and their nu­
merical parameters such as explicit equations or con­
ditional probability tables ( CP Ts), manipulation on
the model may invalidate these numerical parameters.
Druzdzel and van Leijen (2000) have shown the special
conditions under which the CP Ts in Bayesian networks
can be reversed under manipulation. As for the ex­
plicit equations, ImaGeNie tries to solve the manipu­
lated system symbolically if there exists a solution. We
would like to further explore conditions under which
we can derive the numerical parameters from the mix­
ture models after manipulation.

ImaGeNie provides a flexible interactive model build­
ing environment for users to build models in causal
form with as much system assistance as possible but
without giving up their control over the model build­
ing process. We believe our efforts in incorporating
causality as a heuristic in aiding model building and
knowledge acquisition is an important extension to the
existing approaches.
Acknowledgments
This research was supported by the Air Force Office of Sci­
entific Research, grants F49620-97-1-0225 and F4962000-1-0112,

by the National Science Foundation under

Faculty Early Career Development (CAREER) Program,
grant IRI-9624629 , and by a strategic research grant num­
ber RP960351 from the National Science and Technology
Board and the Ministry of Education in Singapore. We
thank anonymous reviewers for suggestions improving the
clarity of the paper.

SMILE and GeNie are available at

http://www2.sis.pitt.edu/�genie.

References

Breese, J. S.; Goldman, R. P.; and Wellman,
M. P. 1994. Introduction to the special section on
knowledge-based construction of probabilistic and de­
cision models. IEEE Transactions on Systems, Man
and Cybernetics 24(11):1577-1579.
Cooper, G. F., and Herskovits, E. 1991. A Bayesian
method for constructing Bayesian belief networks
from databases. In Proceedings of the Seventh Annual
Conference on Uncertainty in Artificial Intelligence
(UAI-91}, 86-94. San Mateo, California: Morgan
Kaufmann Publishers.
Dfez, F. J. 1993. Parameter adjustment in Bayes net-

362

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

works. The generalized noisy OR-gate. In Proceedings
of the Ninth Annual Conference on Uncertainty in
Artificial Intelligence (UAI-93), 99-105. San Fran­
cisco, CA: Morgan Kaufmann Publishers.
Druzdzel, M. J., and Simon, H. A. 1993. Causality in
Bayesian belief networks. In Proceedings of the Ninth
Annual Conference on Uncertainty in Artificial Intel­
ligence (UAI-93), 3-11. San Francisco, CA: Morgan
Kaufmann Publishers.
Druzdzel, M. J., and van der Gaag, L. C. 2000. Intro­
duction to the special issue on building probabilistic
networks: Where do the numbers come from? Jour­
nal of IEEE Transactions on Knowledge and Data
Engineering. To appear.
Druzdzel, M. J., and van Leijen, H. 2000. Causal
reversibility in Bayesian networks. Journal of Ex­
perimental and Theoretical Artificial Intelligence. To
appear.
Haavelmo, T. 1943. The statistical implications of
a system of simultaneous equations. Econometrica
11(1): 1-12.
Heckerman, D. 1990. Probabilistic similarity net­
works. Networks 20(5):607-636.
Henrion, M. 1989. Some practical issues in construct­
ing belief networks. In Uncertainty in Artificial Intel­
ligence 3, 161-173. New York, N. Y.: Elsevier Science
Publishing Company, Inc.
Iwasaki, Y., and Simon, H. A. 1994. Causality and
model abstraction. Artificial Intelligence 67(1): 143194.
Keeney, R. L. 1994. Value-focused Thinking: a Path
to Creative Decision Making. Cambridge, MA: Har­
vard University Press.
Koller, D., and Pfeffer, A. 1997. Object-oriented
Bayesian networks. In Proceedings of the Thirteenth
Annual Conference on Uncertainty in Artificial In­
telligence (UAI-97), 302-313. San Francisco, CA:
Morgan Kaufmann Publishers.
Laskey, K. B., and Mahoney, S. M. 1997. Network
fragments: Representing knowledge for constructing
probabilistic models. In Proceedings of the Thirteenth
Annual Conference on Uncertainty in Artificial Intel­
ligence (UAI-97), 334-341. San Francisco, CA: Mor­
gan Kaufmann Publishers.
Lu, T. C. 1999. ImaGeNie - interactive model au­
thoring in GeNie. Master's thesis, University of Pitts­
burgh, Pittsburgh, PA 15260.
Mahoney, S.M., and Laskey, K. B. 1996. Network en­
gineering for complex belief networks. In Proceedings
of the Twelfth Annual Conference on Uncertainty in
Artificial Intelligence (UAI-96), 389-396. San Fran­
cisco, CA: Morgan Kaufmann Publishers.

Pearl, J., and Verma, T. S. 1991. A theory of in­
ferred causation. In Allen, J.; Fikes, R.; and Sande­
wall, E., eds., KR-91, Principles of Knowledge Rep­
resentation and Reasoning: Proceedings of the Second
International Conference, 441-452. Cambridge, MA:
Morgan Kaufmann Publishers, Inc., San Mateo, CA.
Pearl, J. 1988. Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference. San Ma­
teo, CA: Morgan Kaufmann Publishers, Inc.
Pearl, J. 1995. Causal diagrams for empirical re­
search. Biometrika 82(4):669-710.
Pfeffer, A.; Koller, D.; Milch, B.; and Takusagawa,
K. T. 1999. SPOOK: A system for probabilistic
object-oriented knowledge representation. In Proceed­
ings of the Fifteenth Annual Conference on Uncer­
tainty in Artificial Intelligence (UAI-99), 541-550.
San Francisco, CA: Morgan Kaufmann Publishers.
Philips, L. D. 1982. Requisite decision modeling: A
case study. Journal of Operational Research Society
3:303-311.
Pradhan, M.; Henrion, M.; Provan, G.; Del Favero,
B.; and Huang, K. 1996. The sensitivity of belief
networks to imprecise probabilities: An experimental
investigation. Artificial Intelligence 85 ( 1-2):363-397.
Simon, H. A.; Kalagnanam, J. R.; and Druzdzel,
M. J. 2000. Performance budget planning: The case
of a research university. In preparation.
Simon, H. A. 1953. Causal ordering and identifia­
bility. In Hood, W. C., and Koopmans, T. C., eds.,
Studies in Econometric Method. Cowles Commission
for Research in Economics. Monograph No. 14. New
York, NY: John Wiley & Sons, Inc. chapter III, 4974.
Spirtes, P.; Glymour, C.; and Scheines, R. 1993. Cau­
sation, Prediction, and Search. New York: Springer
Verlag.
Srinivas, S. 1993. A generalization of the noisy-OR
model. In Proceedings of the Ninth Annual Confer­
ence on Uncertainty in Artificial Intelligence (UAI93), 208-215. San Francisco, CA: Morgan Kaufmann
Publishers.
von Winterfeldt, D., and Edwards, W. 1988. Deci­
sion Analysis and Behavioral Research. Cambridge:
Cambridge University Press.
Xiang, Y.; Poole, D.; and Beddoes, M. P. 1993. Multi­
ply sectioned Bayesian networks and junction forests
for large knowledge based systems. Computational
Intelligence 9(2):171-220.

