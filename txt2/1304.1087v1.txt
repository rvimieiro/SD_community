mal diagnosis have different qualitative meamngs, even
given the same input data. We argue that the most ap­
propriate definition of (optimal) diagnosis needs to �ake
into account the utility of outcomes and what the diag­
nosis is used for.
1

INTRODUCTION

Within diagnostic reasoning there have been a number
of proposals of what constitutes a diagnosis, an� so pre;
.
sumably, what constitutes an optimal or mo�t likely di­
agnosis. These include most probable posterior h�poth­
esis [Pearl 1986], most probable interpretation lPearl,
1987], most probable provable hypothesis [Reiter, 1987,
de Kleer and Williams, 1987, de Kleer et al., 1990],
most probable covering hypothesis [Reggia et al., 1985,
Peng and Reggia, 1987a, Peng and Reggia.' 1987b]. Un­
like earlier logic-based diagnoses that consider what can
be proven about a faulty device [Genes�reth, 1984� , th�e
papers have considered that the quest10� ��at i.s a di­
agnosis?" is important to answer. The mt�itlOn IS �h�t
it is important to characterise the set of "logical possibil­
ities" for a diagnosis, presumably to be able to compare
them. Most of these approaches assume that the most
likely diagnosis must be computed, and that a definition
of the what should be computed can be made a priori,
independently of what the diagnosis is used for.
*This author was supported by NSERC gra.nt
OGP0044121.
tThe author completed this research with the support of
NSERC grant A9281 to A.K. Mackworth.

Once the sets of hypotheses considered as diagnoses
are determined one of the ways we may want to compare
competing diagnoses to give us the most likely diagnosis
is by using probability [de Kleer and Williams, 1987,
Neufeld and Poole, 1987, de Kleer and Williams, 1989,
Pearl, 1987]. In computing the probability of A given B,
p(AIB), Bayesian analysis tells us that the B should be
all of the available evidence [Kyburg, 1988, Pearl, 1988],
but does not give us any hints as to what A should be.
This paper asks the question of what combination of
hypotheses A should be in order to be most usef�l.
In this paper we study six approaches to dia�nos­
tic reasoning, and their associated notions of opt�al­
ity based on probability theory (or another uncertamty
calculus). Each approach considers a conjunction ?f hy­
potheses as a most likely diagnosis. We call the slX ap­
proaches:
1. most likely single-fault hypothesis;
2. most likely posterior hypothesis;
3. most likely interpretation;
4. probability of provability;
5. covering explanations; and
6. utility-based explanation.
We contrast the first five approaches to diagnostic rea­
soning with a classic utility-based approach to diagnostic
reasoning [Ledley and Lusted, 1959].
.
In analysing these proposals, we show that the differ­
ent definitions of optimal diagnosis have different qual­
itative (and quantitative) results, even given �he sa�e
input data. Moreover, we argue that the diagnostic
problem, as currently posed, is incomplete: it does .�ot
consider how the diagnosis is to be used, or the utility
associated with either the diagnosis or the treatment of
the abnormalities. We argue that the most appropri­
ate definition of (optimal) diagnosis should be based on
what the diagnosis is used for. The point of this paper is
to question current approaches to formalising diagnos­
tic reasoning, and hopefully focus attention on crucial
questions not being studied.
The remainder of the paper is organised as follows.
Section 2 introduces the notation and discusses what
the diagnostic problem should entail. Section 3 formally
defines the six approaches to diagnosis studied in this
paper. Section 4 shows examples of how the diagnoses

47

produced by the different approaches are qualitatively
different. Section 5 discusses the proposals, evaluating
their strengths and weaknesses. Finally, Section 6 draws
a few conclusions.
2

Figure 1: A complete diagnostic cycle

I

WHAT IS THE DIAGNOSTIC

I

PROBLEM?
2.1

Notation

We call E the knowledge used to compute a diagnosis.
E can be broken down into a set F of facts which are
unchanging from instance to instance (e.g. F can be a
model of a circuit which is being diagnosed), and a set
0 of observations concerning a particular instance. We
call H = {h1, ..., hm} the set of hypotheses under con­
sideration given E. T = {t1, ..., tl} is the set of possible
treatments.
This diagnostic problem can be formalised in either
probabilistic or logical terminology. In terms of logi­
cal terminology, we use the Theorist framework of hy­
pothetical reasoning [Poole et al., 1987, Poole, 1987], a
formalism well suited to the task as the paradigms can
be naturally represented in the simple formal framework.
Theorist [Poole, 1987] is defined as follows. The user pro­
videsF, a set of closed formulae (called the facts) and
H, a set of open formulae (called the possible hypothe­
ses). A scenario is a set DUF where D is a conjunction
of hypotheses D = 1\i hi for some i = 1, ... , m, such that
D U F is consistent. An explanation of formula g is a
scenario that logically implies g. An extension is the
set of logical consequences of a maximal (with respect to
set inclusion) scenario.
For a given treatment r s;;; T, we define a utility
function u(E, D, r) . Using a standard decision-theoretic
approach (e.g. [Berger, 1985]), the goal of diagnostic
reasoning can be defined as choosing r to maximise
u(E, D, r ) . If there are probability distributions de­
fined over E and D, then the maximum expected utility,
&[ u(E, D, r)], is required. For example, if for diagno­
sis i, i = 1, ... ,k, the utility associated with treating
diagnosis Di is u(E, Di, r) = ai, and diagnosis Di oc­
curs with probability p(Di), the goal is to choose r to
maximise Ei(ai p(Di)). In computing expected utility
values, influence diagrams [Howard and Matheson, 1981,
Shachter, 1986] can be used to find the treatment with
highest utility.
·

2.2

Diagnostic Problem

A complete diagnostic cycle consists of reasoning from
evidence E to hypothesised diagnosis H, and then ad­
ministering a treatment T for the diagnosis (or abnor­
malities). This is shown in Figure 1.
In most current formal theories of diagnosis (e.g.
[Reiter, 1987, Peng and Reggia, 1987a, de Kleer and
Williams, 1987, Pearl, 1987, Pople, 1982]), the treat­
ment phase is not considered at all, and diagnoses are
defined with respect to the evidence-hypothesis phase
only. These approaches ignore utility considerations to­
tally. It is interesting to note that in one of the earli­
est analyses of medical diagnostic reasoning, Ledley and

I

Lusted [1959] described a method of implementing the
full diagnostic cycle.
We argue that diagnostic reasoning must take into ac­
count the complete cycle, and should consider utility
maximisation. In using a utility-based approach, the
definition of a diagnosis is strongly influenced by how
the diagnosis is to be used.
There are a number of possible uses of a diagnosis,
including:
1. to find out the thing (or things) that is wrong; that
is, through testing, to determine the exact state of
the world with respect to the symptoms observed;
2. to give a plausible account (an explanation) for the
symptoms; that is, to give a description of what is
wrong that is understandable to people;
3. to enable a decision as to how to fix something; that
is, to maximise the utility derived from the diagnos­
tic process through the treatment of the abnormal­
ities;
4. to fix the symptoms; in some cases we may be happy
to fix the symptoms without caring about what is
really wrong.
The first of these may be carried out by someone who
is trying to determine what errors occur so that they can
be prevented (for example, by redesigning some compo­
nents). The second and the third are both activities
that an ideal doctor must undertake. As well as giving
optimal treatment they also have to be able to give a ra­
tionale for the treatment. The fourth may be something
that has to be done in an emergency, for example reduc­
ing the temperature of a patient with fever, or restoring
power in a failed power station.
While each of these may seem reasonable, we will see
that different goals will lead to different evaluation cri­
teria. For example, the best decision may involve av­
eraging over many cases, which may not be conducive
to a good explanation. Also there may be no point in
finding the exact causes for a problem if further refine­
ment of the problem will not improve the outcome. In
computing explanations, the most coherent explanation
may not contain all the evidence or hypotheses.
It is important to keep these different goals in mind
when considering different proposals.
3
3.1

DESCRIPTION OF PROPOSALS
Most likely single-fault hypothesis

In this approach, the hypotheses considered are the
unit hypotheses, h1, ..., hm. A single-fault diagnosis is
defined as a conjunction of hypotheses, only one of

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

48
which is true. Hence, if hypothesis hi is the proposed
single-fault hypothesis, the single-fault diagnosis Hi is
7ii 1\7i2 1\ 1\ hi 1\ 1\h,;; = hi 1\ 1\i ¢i 7ij. For example,
if an electrical circuit contains m components, a single­
fault diagnosis is that component i is faulty and all other
components are functioning normally. The most likely
diagnosis is defined as the diagnosis with the highest
probability, p(HiiE), over the set i E {1, ... , m}.
•

3.2

·

•

·

·

·

Most likely posterior hypothesis

As in the single-fault approach, the hypotheses consid­
ered are the unit hypotheses, h1, ... , hm. The most likely
diagnosis is defined as the hypothesis with the highest
posterior probability p(hi IE).
This is the approach taken in MEDAS [Ben-Bassat
et al., 1980], INTERNIST [Pople, 1982], and by
Pearl [1986], for example. Pearl frames his analysis
within Bayesian networks. This entails defining a causal
graph of the problem, where the nodes represent random
variables (or propositions) and directed edges represent
direct causal influences between random variables.
3.3

Most likely interpretation

This approach entails considering the set I = {h, ..., Ik}
of interpretations, the set of truth assignments for the
propositions in H. The interpretation which is most
likely given the evidence must be determined. Pearl
[1987] defines this optimal interpretation as the interpre­
tation which has the highest posterior probability given
the evidence, p(IdE), where there is no Ij such that
p(IdE) < p(Ij IE). Reiter and Mackworth [1990] ad­
vocate considering all visual interpretations for a given
image formalised as a set of logical clauses. Note that
all interpretations need not be computed in order to find
the most likely one [Pearl, 1987].
3.4

Probability of provability

In this case we use a logical axiomatisation of the prob­
lem, as well as a probabilistic model of the domain.
The logical model is used to prove the logical possibili­
ties of the observations 0 (which constitute the set of
hypotheses in which one is interested), and then the
probabilistic model is used to compute the likelihood
of these. This corresponds to finding the most likely
consistency-based diagnosis [Reiter, 1987, Poole, 1989b,
de Kleer et al., 1990].
In terms of normal and abnormal function of system
components, a consistency-based diagnosis is defined as:
Definition 3.1 (Consistency-Based Diagnosis)

A consistency-based diagnosis is a minimal set of
abnormalities such that the observations are consistent
with all other components acting normally [Reiter, 1987].
This approach entails axiomatising the problem as a
logical theory 7 which consists of a set E of clauses rep­
resenting 0 and F. From E a set r of clauses logically
entailed by E can be derived. This set can be defined as
a minimal disjunct of maximal conjuncts of elements of

H that follow from E, 1 i.e.
0 1\F �(hi 1\ ... 1\hj )V (h�; 1\ ... l\h1) V... V (hm 1\... 1\hn)•

Each conjunct is defined to be a diagnosis .
In order to compute the probabilities of the elements
of r, a probability distribution (or some other measure)
must be assigned to E. Then the measure assigned to
the 'Yi E r must be computed.
One method of such a computation is provided by the
ATMS, as described in [de Kleer and Williams, 1987] or
[Provan, 1990, Laskey and Lehner, 1990].2 An assump­
tion can be assigned to each clause Ei E E to symboli­
cally represent the measure assigned to Ei. The ATMS
then computes the set of assumptions assigned to each
literal consistent with E. Consequently, the assumption
set associated with each 'Yi can be computed. Assigning
a measure to each assumption enables the measure for
each 'Yi to be derived.
The causal relationship in this approach has been de­
scribed by Pearl [1988] as evidential, as the direction of
causality proceeds from evidence to cause.
3.5

Covering explanations

In this case the goal is to abduce a causal explanation of
the observations.
Definition 3.2 (Abductive Diagnosis) Given
a
causal axiomatisation of the system, an abductive di­
agnosis is a minimal set of hypotheses which, together
with the background knowledge implies the observations
0 [Poole et al., 1987, Poole, 1989a].
As in the provability approach, a logical axiomatisation
is required. More formally, the hypotheses considered
are the minimal conjunct of elements of H that imply 0
from F (cf. [Poole, 1987]):
F 1\ ((hi 1\... 1\hi )V(hk 1\... 1\h,)V...V(hm 1\... 1\hn))

� 0.

Each conjunct is an explanation or diagnosis.
Abduction is used to compute a causal explanation for
the observations. Note that the background knowledge
F must be axiomatised differently in this ap proach and
the previous one [Poole, 1988, Poole, 1989aj.
Another method of describing this approach using
graph theory is that of a. causal bipartite graph [Reg­
gia et al., 1985]. In such a. graph the bipartite edge sets
consist of cause nodes and observation nodes, with di­
rected edges from cause nodes to observation nodes. A
node covering of causes for a given set of observation
nodes is required.
A probabilistic analysis of this approach can be found
in [Peng and Reggia, 1987a, Peng and Reggia, 1987b] and
in [Neufeld and Poole, 1987]. Peng and Reggia [1987b]
and Neufeld and Poole [1987] describe a method of com­
puting the best diagnoses by evaluating the best partial
diagnoses only.
1See, for example, [Reiter, 1987], [de Kleer and Williams,
1987] or [de Kleer et al., 1990] for details.
2For the purposes of this paper it is irrelevant what type of
measure or combination function is used. What is of interest
here is the measure assigned to r, and what is contained in
r.

49
a

Pearl [Pearl, 1988] describes this u a causal approach,
as the direction of causality proceeds from cause to evi­
dence.

I

c
3.6

Utility-hued explanation

To compute utilities, we can use the definition of a
Bayesian network (as done in the first two approaches
described in the paper) augmented with a set of deci­
sion nodes, a value node and utility values (an influence
diagram [Shachter, 1986]).
This approach makes no commitment as to which set
of hypotheses constitute a diagnosis, unlike the logic­
based approaches (approaches 3 and 4). Bayesian net­
works can also be used to compute the probability of
any conjunction of hypotheses, by creating a new node
that represents the conjunction of the hypotheses of the
nodes it is influenced by.
Dependent on the utilities of a given problem instance,
different combinations of hypotheses will be considered.
In general, utility can be assigned on a problem by prob­
lem basis. Obviously, dependent on the utility func­
tion chosen, this approach can end up computing differ­
ent combinations of hypotheses than for the "diagnosis"
from the first five approaches.
The utility-based approach is influenced by work in
computer vision, planning and in cognitive science in
which a high-level description of the task influences both
the objective function to be evaluated and the method
of solving the task. For example, in computer vision,
model-based object recognition systems use a descrip­
tion of the object to speed recognition of the object by
looking for only image primitives which will most likely
constitute a part of the object [Chin and Dyer, 1986].
We argue that the problem representation must be de­
pendent on the nature of the diagnosis required. Thus,
if distinguishing among diagnoses does not affect the de­
cision made, there is no point to computing the different
diagnoses, or an optimal diagnosis. Or, if the utility
value is indifferent to particular liver diseases or heart
diseases, the problem can be reformulated (e.g. all liver
diseases considered as a "group", and all heart diseases
considered as another "group").

As another example, consider a computer which has
four main circuit boards, each of which can be divided
into groups of components. If the computer goes down
due to hardware failure, then the optimal diagnosis for
a situation in which the computer must be fixed as soon
as possible is to identify which circuit boards need to
be replaced. If there is no time pressure, the optimal
diagnosis may be to identify which group of components,
or which specific components, must be replaced, given
the high cost of replacing entire boards.

I

b

This approach computes not the most probable conjunc­
tion of hypotheses (or diagnosis), but the conjunction of
hypotheses that are most useful for the treatment phase
of diagnosis.

d

Figure

4

2: A

I

circuit

ARE THEY REALLY ALL THE
SAME?

In this section we demonstrate that the approaches do
indeed give different answers.

Example 4.1 Consider the analogue circuit of figure 2.
In this figure a, b, c and d are gates that are faulty if
they are closed (i.e., they are supposed to be open, but
they can be shorted). Let A be the proposition that is
true if a is shorted, and B be the proposition that is true
if b is shorted, etc.
Suppose we have the knowledge that the gates break
independently and we have the priors

p(A)
p(B)
p(C)

=

p(D)

=

=
=

0.016
0.1
0.15
0.1

P2=
Ps=

P4 =

P& =
P6 =

P7=
Ps=
pg =
PlO =
Pu =

P12 =
Pts=
P14 =
Pl& =

p(A" B Ac"DIE)
p(AABACA -.DIE)
p(A" BA ...,c"DIE)
p(AABA ...,cA ..,DIE)
p(A" ...,B "cADIE)
p(AA ...,BACA -.DIE)
p(A" ...,B" ...,c"DIE)
p(AA ...,BA ...,CA-.DIE)
p(...,AABA.CADIE)
p(-.A ABACA -,DIE)
p(-.AA BA -.CADIE)
p(...,AABA ...,CA ..,DIE)
p(-.A" ...,B" c"DIE)
p( -.AA ..., BACA -.DIE)
p ...,A" ...,BA ...,c"DIE)
p ..,AA -.BA ...,cA ..,DIE)

�

I
I
I
I
I
I

Suppose we observe that there is a current flowing
through the circuit. Let E be the proposition that rep­
resents this evidence. The diagnoses computed by each
of the approaches are now examined. We first give the
interpretations as the the probabilities of all interpreta­
tions serves as a generator for all the probabilities.
The 16 possible interpretations are:
Po=
Pt =

I

0.0006
0.0055
= 0.0035
= 0.0313
= 0.0065
= 0.0497
= 0.0313
= 0.2816
= 0.0377
= 0.3395
= 0.2138
= 0.0
= 0.0
= 0.0
= 0.0
= 0.0
=

=

There are a few things to notice about the probabilities
of the interpretations:

I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

50

1. All of the other posterior probabilities can be gen­

erated from the Pi· In particular, for any formula
we have
p(wiE) =

w

2. All of the interpretations that are not possible have
probability zero. The last 5 interpretations are not
possible given the circuit, and so must have proba­
bility zero. Note that there was no need to do any
logical pruning before the probability phase. The
logical axiomatisation of the provability and cover­
ing cases ( 4 and 5) was not to remove impossible in­
terpretations (as in [Ledley and Lusted, 1959]) but
to determine what it is that we are getting the prob­
ability of.
The possible single-fault diagnoses are
obtained by saying that all of the interpretations
except P7, Pu, P1s and P14 are impossible. There is
only one possible single fault diagnosis: a is shorted.
This does not depend on any prior probabilities, ex­
cept for the knowledge that the probability is zero
for all of the impossible diagnoses.
Posterior. When computing the most likely posterior,
we compare
p(AIE)
p(BjE)
P (CjE)
p(DIE)

p(AjE)
p(B A OlE)
p(B 1\ DjE)

p(IIE)
{I:w is true in I}

Single-fault.

Numerically, the probabilities are:
=
=
=

0.409
0.383
0. 256.

The most likely diagnosis is that a is shorted.
For the covering hypothesis case we also
need a logical axiomatisation, such as

Covering.

A�E
BI\C�E
BI\D�E
When E is observed, we get the same comparisons
as the previous case, and the same most likely diag­
nosis.
Utility-based. The final case is where we have to take
utilities into account. The next three examples show
how this can interact with the diagnoses.
Example 4.2 Suppose that we can fix up the gates of
example 4.1 independently. In this case the only relevant
probabilities are the posteriors of each of the hypotheses.
We denote byF:: the treatment of fixing gate x. Con­
sider the following utility values:
u(E, D::, r) =

{

=

+$1 ifF:: E r 1\ XED::
-$1 ifF:: E r 1\ X¢ D::
otherwise
0

Po+ Pl + P2 + Ps + P4 + P5 + P6 + P1
Po+ Pl + P2 + Ps + Ps + P9 + Plo+ Pll
In this case, since p(BIE) is greater than 0. 5, we ex­
= Po+ Pl + P4 + Ps + Ps + P9 + P12 + P1s
pect to gain from fixing gate b, but do not gain from
Po+ P2 + P4 + P6 + Ps + P1o+ P12 + Pl4 fixing any of the other gates. Thus it is only worthwhile
fixing gate b.
Numerically, the posterior probabilities are:
If one believes that the aim of the diagnosis is to fix
all of the problems, then this is a peculiar thing to do.
p(AjE) = 0. 409
Based on the logical analysis, it cannot be the case that
p(BjE) = 0.632
only b is shorted.
p(CIE) = 0.439
Example 4.3 Suppose there is a heavy penalty for not
p(DIE) = 0.292
fixing the circuit by replacing a particular gate, as shown
in the following utility function:
The most likely faulty component is b.
ifF:: E r 1\ XE D::
+$1
Interpretation. The highest probability is P9, which
-$1 ifF:: E r /\X¢ D::
indicates that the most likely interpretation is that
u(E, D::, TD,.)=
-$10 ifF:: ¢ r 1\ XED::
b and c are shorted, and a and d are not shorted.3
0
ifF#) rf. r 1\ X rf. D::
Provability. In the fourth case we need to axiomatise
In this case, all gates will be replaced in our example.
the circuit:
All we needed to compute was the posterior probabilities
E�AV(BA(CVD)),
for the individual hypotheses.
Example 4.4 Suppose we can fix up gates b and c in­
and find the probabilities of the resulting diagnoses:
dependently, but that the ways to fix up gates a and
p(AIE) = Po+ Pl + P2 + Ps + P4 + P5
d interact in a complex way. In this case the relevant
probabilities are
+P6 + P1
p(B 1\ CjE) = Po+ Pl + Ps + Ps
p(AjE) = 0.409
=
p(B A DIE)
p(BjE) = 0. 632
Po+ P2 + Ps + Plo·
p(CIE) = 0.439
3Note that this diagnosis just coincidentally corresponds
p(A 1\ DIE) = 0. 041
to the most likely posterior hypothesis (in that they both
have b broken). If we changed the priors slightly to make
p(AA-,DjE) = 0.368
p(C) = 0.12, the most likely interpretation becomes the one
p(...,AADIE) = 0.251
with just A true, but the most likely posterior hypothesis is
p(-,AA-,DIE) = 0.340
unchanged.

{

52

which is not what any of the diagnOiiell computed. Note
that in this case the probabilities that are needed are
not determined by what can explain the observations,
but rather what is needed for the treatment.
It might coincidentally happen that two approaches
compute the best qualitative diagnosis, but this is not
true in general. It is, however, not coincidence that the
provability and covering approaches produce the same
answer. It can be shown that, under certain reasonable
assumptions about how the knowledge is represented,
the propositional versions of the abductive and the de­
ductive systems [Poole, 1988] are identical. This is not,
however, necessarily true for the non-propositional ver­
sions. The difference arises because of the level of detail
of the diagnoses. The more specific the diagnoses, the
less likely it is. The abductive systems require the level of
detail specific enough to imply the observations. In the
deductive system, the level of detail is prescribed, not
by the observation, but by the knowledge base [Poole,
1989a].
ANALYSIS OF PROPOSALS

5

Each of the proposals has good and bad points, some of
which are now discussed.
5.1

Single-fault Diagnosis

The main problem with the most likely single fault hy­
pothesis is that it may be wrong. The real diagnosis may
be a combination of faults.
Another problem is that the single fault definition de­
pends on the representation used. At one level of ab­
straction a single fault may be a very complicated com­
bination of faults at another level of detail. For example,
at one level of abstraction a problem may be that one
power supply is broken. At another level of detail there
may be a number of pwblerns with the one power supply.
5.2

Most Likely Posterior

There are a number of problems with the "most likely
posterior hypothesis" approach:
1. It is the weakest statement about the world. Thus,
if a pigeon is a type of bird, one must have
p(pigeoniE) $ p(birdiE).
2. High (possibly irrelevant) priors may dominate the
relevant hypotheses.
3. Groups of hypotheses are not considered. This ap­
proach cannot compute diagnoses which consist of
sets of hypotheses. Multiple-hypothesis diagnoses
can be determined by heuristics only (e.g. as is done
in INTERNIST [Pople, 1982]). In contrast, the in­
terpretation, consistency and covering methods can
compute multiple-hypothesis diagnoses based on the
underlying theory of the method. Note that this
does not imply we cannot diagnose systems with
multiple faults, but rather that we do not consider
conjunctions in diagnoses.
Note that we can add hypotheses which are con­
junctions of hypotheses, but these will always be
less likely that the original hypotheses.

5 .3

Most Likely Interpretation

In the most likely interpretation approach (# 3) there
can be an exponential number of interpretations, and so
for any reasonable sized problem we do not want to de­
rive all interpretations (as in [Reiter and Mackworth,
1990]). Many interpretations will be highly unlikely,
and computing them will be a waste of computational
resources. However, it is not necessary to enumerate
all interpretations [Pearl, 1987, de Kleer and Williams,
1989]4•
Another drawback of this approach is that the most
likely interpretation does not let us be agnostic about
any proposition; we have to give a truth value to every
hypothesis, no matter how related to the observations.
Changing the space of hypotheses can change the prob­
ability of the most likely composite, and even what the
most likely composite is [Pearl, 1988, p.285). Even more
importantly, for building large knowledge bases adding
"irrelevant" hypotheses can also change the most likely
interpretation. If we imagine a random variable that
is probabilistica.lly independent of the other variables,
then the most likely qualitative conjunct will remain the
same: we will end up with the product of the most likely
prior of the irrelevant hypothesis and the most likely in­
terpretation. If however the new random variable is not
independent, then just by imagining different scenarios
we can change the qualitative diagnosis, as the following
example shows.
Example 5.1 Consider a. patient who has symptoms
which suggest either the flu or yellow fever, the flu be­
ing the more likely diagnosis. Now, suppose we add a
variable that represents where the person was at some
particular time two weeks previously. We partition the
world so that the different places all have equal probabili­
ties (e.g., "Africa" may be one area, and "above the most
northerly fioor tile in their office" may be another). If
these new variables are independent of the disease vari­
able, the most likely interpretation will consist of the
most likely values for each variable. Simply by assuming
that it is much more likely that the patient has yellow
fever if she was in Africa, the most likely composite hy­
pothesis may be that the patient has Yellow fever and
was in Africa5•

One other problem with finding the most likely in­
terpretation is that the most likely interpretation may
have very low probability. Peng and Reggia [1987c] first
pointed this out and suggested that rather than finding
the most likely interpretation, we should find a set of
interpretations that covers some percentage of all of the
cases.
�Note that the phase of removing interpretations inconsis­
tent with the knowledge (i.e., those interpretations that are
not models of the logical constraints) is unnecessary because
p(hi\E) = 0 if h; is inconsistent with evidence E.
&This example is different from the example given by Pearl
[1988, p. 285], in that we are adding a new hypothesis rather
than changing a hypothesis. Just by imagining a new hy­
pothesis, and making no new observations, we can change
the value of the most likely interpretation.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

53
5.4

Covering Explanations

Approaches 4 and 5 are discussed together because
propositional versions of these approaches have been
shown to produce the same results under certain assump­
tions [Poole, 1988]. These differ from the interpretation
approach in enabling us to be agnostic about the value
of some variables which are irrelevant to the goal.
5.5

Consistency and Covering Approaches

These logic-based approaches are limited to what is prov­
able within the logical theory T. Hence, they are sensi­
tive to the particular logical description. If an observa­
tion is not provable, then nothing can be said about it.
(Similarly, for the Bayesian approach, if the appropri­
ate conditional probabilities are present for an observa­
tion, no �easure c�� be assigned to the observation.) In
contrast, m the utility-based approach considered here
what is computed depends on the goal of the diagnosis :
Both the consistency and covering approaches rely on
making assumptions about the system under examina­
tion. Pearl [1990] has shown that this approach has
two major flaws: (1) independencies among events with
unkn�wn probabilities cannot be represented; and (2)
domam knowledge describing defeasible conditional sen­
tences cannot be represented. Thus, these approaches
are limited to problems in which the domain knowledge
can be defined in categorical terms, e. g. strict taxo­
nomic hierarchies, deterministic systems (electronic cir­
cuits but not medical diagnosis or default reasoning), etc.
If these approaches are misapplied to certain domains '
non-intuitive results can be obtained.
. Pearl [1990] argues that instead of making assump­
tiOns about the hypotheses, examining the logical con­
sequenc;�s of these assumptions, and then assigning a
probability measure over the assumptions a probability
measure should be assigned over the logical clauses :E
and the probabilities assigned to interpretations be ex­
a.mined (as .done in approach 2). If not all clauses are as­
�Igned a weight, then probability bounds (specifically the
mner and outer measure) can be obtained for the mea­
sure assigned to the h�potheses. For example, Nilsson
[1986] presents a techmque which can accept an incom­
plete pr�babilistic specification, and computes ranges for
the reqmred measures for hypotheses. This paper argues
that it is not clear that the approach suggested by Pearl
(i.e. that the most likely interpretation must be evalu­
ated) is always the best one.
However, because these logic-based approaches seem
to be appealing for a number of reasons, it may be impor­
tant to determine subcases of non-categorical domains in
which paradoxes do not arise.
5.6

Utility-based diagnoses

The utility-based approach assumes that utilities are
domain-dependent, which implies that diagnoses must
be domain-dependent as well. In contrast, the other
approaches assume that the definition of diagnosis is
domain-independent. In addition, preferences used to
define best diagnoses cannot be assigned in a domain­
independent manner. Doyle and Wellman [1989] have
proven that there exists no universally-valid preference

set; in other words, preferences are consistent only within
particular domains. Furthermore, Doyle [1989j argues
for a decision-theoretic, and not merely probabilistic
definition of consistency and rationality in decision�
making (and therefore diagnosis).
T�e util.it!-based approa:h is considered the proper
o�e m declSion theory and m several areas of cognitive
science. For example, in visual recognition it has been
shown. how several low-level (and quite primitive) pre­
attentive processes are used to focus attention on the
�ost salient features of a scene [Treisman, 1982], and
simple features are used to guide scene interpretation
[Rose�feld, 1987]. In some cases, results from these pre­
attentive processes are used directly to initiate action.
For example, in the forest if a deer sees motion close by
(the presence of motion in the visual field can be detected
pre-attentively), it will start running without identifying
the cause of the motion, as it might get eaten if it spent
the time trying to identify the cause of the motion. If
the deer is not in danger, motion can trigger a closer
scrutiny for the cause of the motion.
One of the problems of the utility-based approach is
that there is nothing in a diagnosis unless there is a goal
and utilities. There is no ''value free" definition of a
diagnosis. Whether this is desirable or not is left up to
t�e reader. There is also the problem of being able to
g1ve someone an understandable explanation to answer
the question "what is wrong?".
6

CONCLUSIONS

This paper has analysed several definitions of what a
dia�n�sis, an � so, presumably, what a most-likely diag­
?osis Is, showmg them to be mutually incompatible. It
IS not clear that one definition is correct over all domains
and situations, and for all possible uses that there could
be for the diagnosis. Instead, we argue that the notion
of most likely diagnosis cannot be defined a priori, but is
defined based on what the diagnosis is to be used for and
o.n the uitlity of the outcomes of treating the abnor:Oali­
ties. In other words, there may be no a priori ontological
definition of optimal diagnosis; it is epistemological and
situation-dependent.
References

[Ben-Bass�t et al., 1980] M. Ben-Bassa.t, R.W. Carlson,
V. Pun, M. Da.venport, J. Schriver, L. Mohammed
R. Smith, L. Portigal, E. Lipnik, and M. Weil. Pattern�
Based Interactive Diagnosis of Multiple Disorders: the
MEDAS System. IEEE Transactions on Pattern Analy­
sis and Machine Intelligence, 2:148-160, 1980.

[Berger, 1985]

J.O. Berger.
Springer Verlag, 1985.

Statistical Decision Theory.

[Chin and Oyer, 1986] R. Chin and C. Dyer. Model-based
Recognition in Robot Vision. Computing Surveys, 18:67108, 1986.

[de Kleer and Williams, 1987]

J. de Kleer and B. Williams
Diagnosing Multiple Fa.ults. Artificial Intelligence Journal;
32:97-130, 1987.

[de !_(leer �d �illiams, �989]

J. de Kleer and B. Williams.
DiagnoslS With Behavioral Modes. In Proceedings of the

53
International Joint Conference on Artificial Intelligence,

pages 1324-1330, 1989.
[de Kleer et al., 1990) J. de Kleer, A. Mackworth, and R. Re­
iter. Characterizing Diagnoses. In Proceedings of the
American A66ociation for Artificial Intelligence, 1990.
[Doyle and Wellman, 1989) J. Doyle and M.P. Wellman. Im­
pediments to Universal Preference-Based Default Theories.
In Proceedings of the Conference on Principles of Knowl­
edge Representation and Reasoning, pages 94-102, 1989.
[Doyle, 1989] J. Doyle. Constructive Belief and Rational
Representation. Computational Intelligence, 5:1-11, 1989.
[Genesereth, 1984] M. Genesereth. The Use of Design De­
scriptions in Automated Diagnosis. Artificial Intelligence
Journal, pages 411-436, 1984.
[Howard and Matheson, 1981] R.A. Howard and J.E. Math­
eson. Influence diagrams. In R. Howard and J. Ma.theson,
editors, The Principles and Applications of Decision Anal­
ysis, pages 720-762. Stra.tegic Decisions Group, CA, 1981.
[Kyburg, 1988] H. Kyburg. Epistemological Relevance and
Statistical Knowledge. In Proc. Conference on Uncertainty
in Artificial Intelligence, pages 2347-244-, 1988.
[Laskey and Lehner, 1990] K. Blackmond Laskey and P.E.
Lehner. Assumptions, Beliefs and Probabilities. Ar tificial
Intelligence Journal, 41:65-77, 1990.
[Ledley and Lusted, 1959] R.S. Ledley and L. B. Lusted.
Reasoning Foundations of Medical Diagnosis. Science,
130:9-21, 1959.
[Neufeld and Poole, 1987] E. Neufeld and D. Poole. Towards
Solving the Multiple Extension Problem: Combining De­
faults and Probabilities. In Proc. Conference on Uncer­
tainty in Artificial Intelligence, 1987.
[Nilsson, 1986] N.J. Nilsson. Probabilistic logic. Artificial
Intelligence Journal, 28:71-87, 1986.
[Pearl, 1986] J. Pearl. Fusion, Propagation, and Structuring
in Belief Networks. Artificial Intelligence Journal, 29:241288, 1986.
[Pearl, 1987] J. Pearl. Distributed Revision of Composite
Beliefs. Artificial Intelligence Journal, 33:173-215, 1987.
[Pearl, 1988] J. Pearl. Probabilistic Reasoning in In telligent
Systems. Morgan Kaufmann, 1988.
[Pearl, 1990] J. Pearl. Which is More Believa.ble, the Prob­
ably Provable or the Provably Probable. In Proc. CSCSI,
1990.
[Peng and Reggia, 1987a] Y. Peng and J. Reggia. A Proba­
bilistic Causal Model for Diagnostic Problem Solving. Part
One: Integrating Symbolic Causal Inference with Numeric
Probabilistic Inference. IEEE Trans. Systems, Man and
Cybernetics, 1987.
[Peng and Reggia, 1987b] Y. Peng and J. Reggia.. A Proba­
bilistic Causal Model for Diagnostic Problem Solving. Part
Two: Diagnostic Strategy. IEEE Trans. Systems, Man and
Cybernetics, 1987.
[Peng and Reggia., 1987c] Y. Peng and J. Reggia.. Being
Comfortable with Plausible Diagnostic Hypotheses. Tech­
nical Report TR-1753, Dept. of Computer Science, Uni­
versity of Maryland, 1987.
[Poole et al., 1987] D.L. Poole, R. Goebel, and R. Aleliu­
nas. THEORIST: A Logical Reasoning System for Defaults
and Diagnosis. In N. Cercone and G McCalla., editors,
The Knowledge Frontier: E66ays in the Representation of
Knowledge. Springer Verlag, 1987.

[Poole, 1987] D.L. Poole. A Logical Framework for Default
Reasoning. Artificial Intelligence Journal, 36:27-47, 1987.
[Poole, 1988] D.L. Poole. Representing Knowledge for Logic­
based Diagnosis. In Proc. Itnl. Conf. on Fifth Generation
Computer Sustems, pages 1282-1290, 1988.
[Poole, 1989a.] D.L. Poole. Explanation and Prediction: An
Architecture for Default and Abductive Reasoning. Com­
putational Intelligence, 5:97-110, 1989.
[Poole, 1989b] D.L. Poole. Normality and Faults in Logic­
based Diagnosis. In Proceedings of the International Joint
Conference on Artificial Intelligence, pages 1304-1310,
1989.
[Pople, 1982] H. Pople. Heuristic Methods for Imposing
Structure on Ill-Structured Problems: The Structuring of
Medical Diagnoses. In P. Szolovits, editor, AI in Medicine,
pages 119-190. Westview Press, 1982.
[Prova.n, 1990] G. Prova.n. A Logic-based Analysis of Demp­
ster Shafer Theory. International Journal of Approxi­
mate Reasoning, Special Issue on Belief Functions and Be­
lief Maintenance in Artificial Intelligence, page to appear,
1990.
[Reggia et al., 1985] J. Reggia, D. Nau, and P. Wang. A For­
mal Model of Diagnostic Inference. Information Sciences,
pages 227-285, 1985.
[Reiter and Mackworth, 1990] R. Reiter and A.K. Mack­
worth. A Logical Framework for Depiction and Image In­
terpretation. Artificial Intelligence Journal, 41:125-155,
1990.
[Reiter, 1987] R. Reiter. A Theory of Diagnosis from First
Principles. Artificial In telligence Journal, 32:57-96, 1987.
[Rosenfeld, 1987] A. Rosenfeld. Recognizing Unexpected
Objects: A Proposed Approach. In Proc. of the DARPA
Image Understanding Workshop, pages 620-627, 1987.
[Shachter, 1986] R. Shachter. Evaluating Influence Dia­
grams. Operations Research, 34:871-882, 1986.
[Treisman, 1982] A. Treisman. Perceptual Gouping and At­
tention in Visual Search for Features and for Objects. J.
of Experimental Psychology, 8:194-214, 1982.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

